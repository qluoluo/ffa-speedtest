According to the National Inventory of Dams, as of January 2016 there are approximately 90,500 dams in the United States and about 2.5 percent of these (approximately 2,100 dams) are associated with hydropower projects. Hydropower projects are owned and operated by both non-federal entities—such as private utility companies, municipalities, and state government agencies—or federal government agencies—primarily the U.S. Army Corps of Engineers (the Corps) and the Bureau of Reclamation. Collectively, these dams associated with hydropower projects account for about 8 percent of the total electric generating capacity in the United States. Hydropower projects generally consist of one or more dams and other key components associated with hydroelectric power generation and water storage, and are uniquely designed to accommodate watersheds, geology, and other natural conditions present at the time of construction. These components include both those that allow operators to adjust reservoir water levels, such as spillways and gates, as well as those that produce and distribute electricity, such as transmission lines and powerhouses, among others. (See fig. 1.) The Federal Power Act provides for FERC’s regulatory jurisdiction over a portfolio of about 1,000 non-federal hydropower projects comprising over 2,500 dams. While FERC does not construct, own, or operate dams, it licenses and provides oversight of non-federal hydropower projects to promote their safe operation. Licensees are responsible for the safety and liability of dams, pursuant to the Federal Power Act, and for their continuous upkeep and repair using sound and prudent engineering practices. FERC officials in each of the agency’s five regional offices work directly with licensees to help ensure these projects comply with licenses and meet federal guidelines for dam safety. In addition, stakeholder groups such as the Association of State Dam Safety Officials can assist licensees in staying current on federal and state dam laws and regulations, dam operations and maintenance practices, and emergency action planning, among other things. FERC’s regulations, supplemented by its Operating Manual and Engineering Guidelines, establish a framework for its dam safety oversight approach. FERC’s Operating Manual provides guidelines for the FERC staff performing inspections that are aimed at ensuring that structures are safe, are being properly maintained, and are being operated safely. FERC’s Engineering Guidelines provides FERC staff and licensees with procedures and criteria for the review and analysis of license applications, project modification proposals, technical studies, and dam designs. For example, one chapter presents guidelines for FERC staff to use to determine the appropriateness and level of geotechnical investigations and studies for dams. The Engineering Guidelines states that every dam is unique and that safety analysis of each dam require that engineers apply technical judgement based on their professional experience. As part of FERC’s safety oversight approach, it assigns a hazard classification to each dam in accordance with federal guidelines that consider the potential human or economic consequences of the dam’s failure. The hazard classification does not indicate the structural integrity of the dam itself, but rather the probable effects if a failure should occur. Depending on the hazard classification, the extent of and the frequency of safety oversight activities can vary. Low hazard dams are those where failure —an uncontrolled release of water from a water-retaining structure—would result in no probable loss of human life but could cause low economic and/or environmental losses. Significant hazard dams are those dams where failure would result in no probable loss of human life, but could cause economic loss, environmental damage, or other losses. High hazard dams are those dams where failure would probably cause loss of human life. FERC has designed a multi-layered oversight approach that involves both independent and coordinated actions with dam owners and independent consultants. Key elements of this approach include ensuring licensees have a safety program in place, conducting regular safety inspections, reviewing technical analyses, and analyzing safety as a part of project relicensing. (See fig. 2.) Licensee’s dam safety program. According to FERC guidance, licensees have the most important role in ensuring dam safety through continuous visual surveillance and ongoing monitoring to evaluate the health of the structure. Beyond this expectation for continuous oversight, FERC requires licensees of high and significant hazard dams to have an Owner’s Dam Safety Program. FERC dam safety inspection. The dam safety inspection, also called operation inspection, is a regularly-scheduled inspection conducted by a FERC regional office project engineer primarily addressing dam and public safety. FERC’s Operating Manual establishes the frequency that a FERC engineer conducts dam safety inspections. Independent consultant inspection and potential failure mode analysis. FERC requires licensees to hire a FERC-approved independent consulting engineer to inspect and evaluate high hazard dams and certain types of dams above a certain height or size and submit a report detailing the findings. Additionally, FERC requires the licensee of a high or significant hazard dam to conduct a potential failure mode analysis. A potential failure mode analysis is an exercise to identify and assess all potential failure modes under normal operating water levels and under extreme conditions caused by floods, earthquakes, and other events. FERC relicensing of projects. FERC issues hydropower licenses for the construction of new hydropower projects, and reissues licenses for existing projects when licenses expire. Licensees may submit applications for a new license for the continued operation of existing projects as part of a process known as relicensing. During relicensing, in addition to the power and development purposes for which FERC issues licenses, FERC must evaluate safety, environmental, recreational, cultural, and resource development among other factors when evaluating projects, according to its guidance. In addition, FERC requires licensees to conduct various engineering studies related to dam performance in accordance with FERC safety requirements. Required engineering studies focus on dam performance as affected by hydrology, seismicity, and dam stability. Licensees may also produce engineering studies, such as a focused spillway assessment, for their own operations or at the request of FERC. We found, based on our analysis of the 42 dam safety inspections we reviewed, that FERC staff generally conducted and collected information from these inspections consistent with guidance in its Operating Manual. According to FERC’s Operating Manual, staff’s approach to conducting these inspections and collecting information is to include preparing for the inspection by reviewing documents, conducting a field inspection of the dam and associated project components, and discussing inspection findings with licensees and with FERC supervisors. Preparation for inspection: We found that FERC staff generally met document review requirements in preparation for safety inspections of the 42 dams we reviewed. (See table 1.) According to the Operating Manual, FERC staff are to review safety-related information contained in documents such as potential failure mode analyses and hazard potential classifications. For example, we found that staff documented their review of the most recent independent consultant inspection report and potential failure mode analysis for each of the 16 high hazard dams we reviewed. FERC staff told us that they generally used checklists when preparing for these inspections. For example, some of the staff told us they tailor the checklist included in the Operating Manual, based on the dam’s type, characteristics, and hazard classification. Additionally, for each of the dams in our sample, staff stated that they prepared for the inspection by reviewing prior inspection reports and recommendations. Field inspection: We found that FERC staff generally met requirements for reviewing project components and documenting their findings from field inspections of the 42 dams we reviewed. (See table 2.) According to the Operating Manual, FERC staff are to conduct visual inspections of the dam, typically alongside the licensee, to assess the dam and project components by observing their condition and identifying any safety deficiency or maintenance requirement. Also during the inspection, FERC staff are to compare current conditions of the dam and project components to those described in prior inspection reports, and as applicable, collect information on the licensee’s progress towards resolving deficiencies and maintenance issues that can affect safety. To assess safety, FERC staff we interviewed stated that they primarily rely on their engineering judgment. Inspection findings: According to our interviews with FERC staff from selected projects, we found that staff generally followed FERC guidance in discussing inspection findings with licensees and supervisors prior to preparing inspection reports to document their findings. According to the Operating Manual, following the dam safety inspection, FERC staff are to discuss the inspection with the licensee, giving direction on how to address any findings. Additionally, upon returning to the office, staff are to discuss inspection findings with their supervisors who may suggest additional actions. FERC staff are then to develop a dam safety inspection report that documents observations and conclusions from their pre-inspection preparation and their field inspection and identifies follow-up actions for the licensee. We found that FERC staff prepared inspection reports to document findings from the 42 dam safety inspections we reviewed. In response to inspection findings, FERC requires licensees to submit a plan and schedule to remediate any deficiency, actions that FERC staff then reviews, approves, and monitors until the licensees have addressed the deficiency. While we found that FERC staff conducted inspections and collected inspection findings consistently in the files we reviewed, FERC’s approach to recording information varies across its regions, thus limiting the usefulness of the information. FERC’s approach to recording inspection information relies on multiple systems to record inspection information and affords broad discretion to its staff on how to characterize findings, such as whether to track inspection findings as maintenance issues or as safety deficiencies. As related to systems for recording inspection information, FERC staff use the Data and Management System (DAMS), the Office of Energy Projects-IT (OEP-IT) system, as well as spreadsheets. In particular, according to FERC staff: Four out of FERC’s five regional offices use DAMS—which is primarily a workload tracking tool—to track plans and schedules associated with safety investigations and modifications as well as inspection follow-up items. FERC staff stated that since the inspection information in DAMS is recorded as narrative text in a data field instead of as discrete categories, sorting or analysis of the information is difficult. One regional office uses OEP-IT to track safety deficiencies while the system is more widely used across FERC to track licensees’ compliance with the terms and conditions of their licenses. Three out of FERC’s five regional offices also use spreadsheets and other tools that are not integrated with DAMS or OEP-IT to track inspection information and licensee progress toward resolving safety deficiencies. FERC staff said that use of these different systems to record deficiencies identified during inspections limits their ability to analyze safety information. For example, according to FERC officials, OEP-IT was not designed to track safety deficiency information and is not compatible with DAMS for use in tracking information on a national level. Furthermore, because spreadsheets and other tools are specific to the regional office in which they are used, FERC staff does not use the information they contain for agency-wide analysis. Concerning decisions on how to characterize inspection findings, FERC staff relies on professional judgment, informed by their experience and the Engineering Guidelines, to determine whether to track inspection findings as a safety deficiency or as a maintenance item, according to FERC officials. With input from their supervisors, FERC staff also determines what information to record and how to track the status of the inspection finding. For example, staff assigned to a dam at a FERC- licensed project in New Hampshire observed concrete deterioration on several parts of the dam and its spillway and asked the licensee to monitor all concrete surfaces, making repairs as necessary. According to staff we interviewed, regional staff and supervisors decided not to identify this as a deficiency to be tracked in DAMS because concrete deterioration is normal and to be expected in consideration of the area’s harsh winter weather. In contrast, staff assigned to a dam at a FERC- licensed project in Minnesota observed concrete deterioration on several parts of the project, including the piers and the powerhouse walls, and entered the safety item in DAMS as requiring repair by the licensee. FERC officials stated they are comfortable with the use of professional judgement to classify and address inspection findings because it is important to allow for consideration of the characteristics unique to each situation and how they affect safety. FERC’s approach to recording inspection information is inconsistent because FERC has not provided standard language and procedures about how staff should record and track deficiencies including which system to use. Federal standards for internal control state that agencies should design an entity’s information system and related control activities to achieve objectives and control risks. In practice, this means that an agency would design control activities—such as policies and procedures—over the information technology infrastructure to support the completeness, accuracy, and validity of information processing by information technology. FERC officials acknowledged that there are inconsistent approaches in where and how staff record safety deficiency information, approaches that limit the information’s usefulness as an input to its oversight. While the agency has not developed guidance, officials stated that FERC plans to take steps to improve the consistency of recorded information by replacing the OEP-IT system with a new system, tentatively scheduled for September 2018, that will have a specific function to track dam safety requirements. However, this new system will not replace the functions of DAMS, which FERC will continue to use to store inspection information. The two will exist as parallel systems with the eventual goal of the two systems’ sharing information. By developing standard language and procedures to standardize the recording of information collected during inspections, FERC officials could help ensure that the information shared across these systems is comparable, steps that would allow FERC to identify the extent of and characteristics associated with common safety deficiencies across its entire portfolio of regulated dams. Moreover, with a consistent approach to recording information from individual dam safety inspections, FERC will be positioned to proactively identify comparable safety deficiencies across its portfolio and to tailor its inspections towards evaluating them. While FERC uses inspection information to monitor a licensee’s efforts to address a safety deficiency for an individual dam, FERC has not analyzed information collected from its dam safety inspections to evaluate safety risks across the entire regulated portfolio of dams. For example, FERC has not reviewed inspection information to identify common deficiencies among certain types of dams. Federal standards for internal control state that agencies should identify, analyze, and respond to risks related to their objectives. These standards note that one method for management to identify risks is the consideration of deficiencies identified through audits and other assessments. Dam safety inspections are an example of such an assessment. As part of such an approach, the agency analyzes risks to estimate their significance, which provides a basis for responding to the risk through specific actions. Furthermore, in our previous work on federal facilities, we have identified that an advanced use of risk management involving the ability to gauge risk across a portfolio of facilities could allow stakeholders to comprehensively identify and prioritize risks at a national level and direct resources toward alleviating them. FERC officials stated that they have not conducted a portfolio-wide analysis in part due to the inconsistency of recorded inspection data and because such an evaluation has not been a priority compared to inspecting individual dams. According to officials, the FERC headquarters office collects and reviews information semi-annually from each of its five regional offices on the progress of outstanding dam investigations and modifications in those regions. FERC’s review is designed to monitor the status of investigations on each individual dam but does not analyze risks across the portfolio of dams at the regional or national level. For example, officials from the New York Regional Office stated they do not perform trend analysis across the regional portfolio of dams under their authority, but they compile year-to-year data for each separate dam to show any progression or changes from previous data collected from individual dams. A portfolio-wide analysis could help FERC proactively identify safety risks and prioritize them at a national level. FERC officials stated that a proactive analysis of its portfolio could be useful to determining how to focus its inspections to alleviate safety risks, but it was not an action that FERC had taken to date. The benefits of a proactive analysis, for example, could be similar to those FERC derived from the analysis it conducted in reaction to the Oroville Dam incident. To conduct this analysis, FERC required 184 project licensees, identified by FERC regional offices as having spillways similar to the failed spillway at the Oroville Dam, to assess the spillways’ safety and capacity. According to FERC officials, these assessments identified 27 dam spillways with varying degrees of safety concerns. They stated that FERC’s spillway assessment initiative was a success because they were able to target a specific subgroup of dams within the portfolio and identify these safety concerns at 27 dam spillways. FERC officials stated that they are working with the dam licensees to address these safety concerns. A similar and proactive approach based on analysis of common deficiencies across the portfolio of dams under FERC’s authority could also help to identify any safety risks that may not have been targeted during the inspections of individual dams and prior to a safety incident. As directed by FERC, licensees and their consultants develop and review, or update, various engineering studies related to dam performance to help ensure their dams meet FERC requirements and remain safe. FERC regulations and guidelines describe the types and frequency of studies and analyses required based on dams’ hazard classifications. For all high hazard and some significant hazard dams, existing studies are to be reviewed by each licensee’s consultants every 5 years, as part of the independent consultant inspection and accompanying potential failure mode analysis. According to FERC officials, for those significant hazard dams that do not require an independent consultant inspection and for low hazard dams, FERC’s regulations and guidelines do not require any studies, but in practice FERC directs many licensees to conduct them. FERC also may request engineering studies in response to dam safety incidents at other projects, or engage a board of consultants to oversee the completion of a study. For example, as previously noted, following the Oroville Dam incident in 2017, FERC requested a special assessment of all dams with spillways similar to the failed spillway at the Oroville Dam. To develop these studies, all six of the consultants we interviewed stated that they follow guidelines provided by FERC and other dam safety agencies. Specifically, they stated that they use FERC’s Engineering Guidelines, which provide engineering principles to guide the development and review of engineering studies. In recognition of the unique characteristics of each dam, including its construction, geography, and applicable loading conditions, the Guidelines provides consultants with flexibility to apply engineering judgment, and as a result, the approach that licensees and their consultants use and the focus of their reviews of engineering studies may vary across regions or projects. For example, one independent consultant we interviewed noted that seismicity studies are not highlighted during the independent consultant inspections for projects in the Upper Midwest in comparison to projects in other areas of the country because the region is not seismically active, but that inspections do look closely at ice loads during the winter months. To create these studies, we found that licensees and their consultants generally use data from other federal agencies and rely on available modeling tools developed by federal agencies and the private sector to evaluate dam performance. For example, many of the engineering studies we reviewed rely on data from the National Weather Service and the National Oceanic and Atmospheric Administration to estimate precipitation patterns and the U.S. Geological Survey to estimate seismic activity. In addition, licensees and their consultants use modeling tools and simulations, such as those developed by the Corps to estimate hydrology, to develop engineering studies. FERC staff noted that the engineering studies developed by licensees and their consultants generally focus on the analysis of extreme events, such as earthquakes and floods. In reference to extreme events, FERC staff said that both actual past events and likely future events are considered in determining their magnitude. FERC staff noted the probable maximum flood—the flood that would be expected to result from the most extreme combination of reasonably possible meteorological and hydrological conditions—as an example of a dam design criterion that is based on application of analysis of extreme events. In describing the efficacy of probable maximum flood calculations, FERC officials stated that they had not observed a flood that exceeded the probable maximum flood calculated for any dam and noted that their Engineering Guidelines provides a conservative approach to estimating the probable maximum flood and other extreme events. FERC officials stated that requiring a conservative approach to estimating extreme events helps to mitigate the substantial uncertainty associated with these events, including in consideration of emerging data estimating the effects of climate change on extreme weather events. Once developed, engineering studies we reviewed often remained in effect for a number of years, until FERC or the licensee and its consultant determined an update was required. For example, we found that the hydrology studies were 20 years or older for 17 of the 42 dams in our review, including for 9 of the 16 high hazard dams in our sample. FERC’s Engineering Guidelines states that studies should be updated as appropriate. For example, FERC’s Engineering Guidelines on hydrology studies state that previously accepted flood studies are not required to be reevaluated unless it is determined that a re-analysis is warranted. The Guidelines notes that FERC or the consultant may consider reanalyzing the study for several reasons, including if they identify (1) significant errors in the original study; (2) new data that may significantly alter previous study results; or (3) significant changes in the conditions of the drainage basin. FERC staff and consultants we interviewed stated that age alone is not a primary criterion to update or replace studies and that studies should be updated as needed depending on several factors including age, new or additional data, and professional judgment. Consultants we interviewed identified some limitations that can affect their ability to develop engineering studies for a dam. For example, they noted that some dams may lack original design information, used prior to construction of the dam, which includes the assumptions and calculations used to determine the type and size of dam, the amount of water storage capacity, and information on the pre-construction site geology and earthquake potential. FERC officials estimated that for a large percentage of the dams they relicense, the original information is no longer available. For example, according to the report from the independent forensic team investigating the Oroville Dam incident and as previously noted, some design drawings and construction records for the dam’s spillway could not be located and some other documents that were available were not included in the most recent independent consultant inspection report submitted to FERC. To overcome the lack of original design information, FERC told us that licensees and their consultants may use teams of experts, advanced data collection techniques, and other modern methods, where feasible, to assess the dam’s ability to perform given current environmental conditions. In cases where design or other engineering information is incomplete, consultants stated that they generally recommend the licensee conduct additional studies based on the risk presented by the missing information but also noted that the financial resources of a licensee may affect its willingness and ability to conduct additional studies. However, FERC officials stated that FERC staff are ultimately responsible for making decisions on whether additional engineering studies are needed to evaluate a dam’s performance. FERC has established policies and procedures that use formal guidance, and permit the use of professional judgment, to evaluate and review engineering studies of dam performance submitted by licensees and their consultants. FERC officials in both the headquarters and regional offices emphasized that their role as the regulator is to review and validate engineering studies developed by the licensee and their consultants. FERC generally does not develop engineering studies as officials noted that dam safety, including the development of engineering studies, is primarily the licensee’s responsibility. To carry out their responsibility to ensure public safety, FERC staff stated they use procedures and criteria in the FERC Engineering Guidelines to review engineering studies and apply professional judgment to leverage their specialized knowledge, skills, and abilities to support their determinations of dam safety. FERC’s Engineering Guidelines provides a framework for the review of engineering studies, though the Guidelines recognizes that each dam is unique and allows for flexibility and exemptions in their use. Moreover, the Guidelines notes that analysis of data is useful when evaluating a dam’s performance, but should not be used as a substitute for judgment based on experience and common sense. Because FERC’s Engineering Guidelines allows for the application of professional judgment, the methods used to review these studies vary depending on the staff, the region, and individual dam characteristics. For example, FERC staff said that when they review consultants’ assumptions, methods, calculations and conclusions, in some cases they may decide to conduct a sensitivity analysis if—based on the staff’s judgment—they need to take additional steps to validate or confirm factors of safety for the project. FERC officials also stated that staff may conduct their own independent analyses, as appropriate, such as evaluating a major structural change to the dam or validating submitted studies. For example, as part of its 2016 review of the Union Valley Dam in California, FERC staff validated the submitted hydrology study by independently calculating key inputs, such as precipitation rates and peak floods, to evaluate the dam’s performance and verify the spillway’s reported capacity. In addition, FERC has established various controls to help ensure the quality of its review, including using a risk-based review process, assigning multiple staff to review the studies, and rotating staff responsibilities over time. We have previously found in our reporting on other regulatory agencies that practices such as rotating staff in key decision-making roles, and including at least two supervisory staff when conducting oversight reviews help reduce threats to independence and regulatory capture. Risk-based review process. FERC’s review approach is risk-based, as the frequency of staff’s review of these studies is based on the hazard classification of the dam as well as professional judgment. FERC relies on three primary engineering studies (hydrology, seismicity, and stability), and others as appropriate, which form the basis for determining if a dam is safe. In addition, FERC requires licensees to hire a FERC-approved independent consulting engineer at least every 5 years to inspect and evaluate high hazard and other applicable dams and submit a report detailing the findings as part of the independent consultant inspection process. In general, for the dams we reviewed, we found that FERC staff reviewed engineering studies for dams subject to independent consultant inspections (which are typically high or significant hazard dams) more frequently than those engineering studies associated with dams for which FERC does not require an independent consultant inspection (typically low hazard dams). For example, we found FERC staff had reviewed the most recent hydrology studies for all 22 high and significant hazard dams in our sample subject to independent consultant inspections within the last 6 years and documented their analysis. According to FERC officials, for dams not subject to an independent consultant inspection, FERC staff review engineering studies on an as needed basis, depending on whether the underlying assumptions and information from the previous studies are still relevant. For example, for the 20 dams in our study not subject to an independent consultant inspection, we found that most (15) of these studies were reviewed by FERC within the past 10 years, usually during the project’s relicensing. Multiple levels of supervisory review. As part of FERC’s quality control and internal oversight process, multiple FERC staff are to review the studies produced by the licensee and its consultant, with the number of successive reviews proportional to the complexity or importance of the study, according to FERC officials. FERC’s Operating Manual establishes the general procedure for the review of engineering studies. To begin the review process, the staff assigned to a dam is to review the engineering study and prepares an internal memo on its findings; that memo is then to be reviewed for accuracy and completeness by both a regional office Branch Chief, and the Regional Engineer. If necessary, Washington, D.C., headquarters office staff are to review and approve the final memo. Upon completion of review, FERC staff are to provide a letter to the licensee indicating any particular areas where additional information is needed or where more studies are needed to evaluate the dam’s performance. According to FERC officials, each level of review adds successive quality control steps performed by experienced staff. We have previously found in reporting on other regulatory agencies that additional levels of review increases transparency and accountability and diminishes the risk of regulatory capture. Rotation of FERC staff responsibilities. As part of an internal quality control program to help minimize the risk of missing important safety- related items, FERC officials told us they rotate staff assignments and responsibilities approximately every 3 to 4 years. According to FERC officials, this practice decreases the chance that a deficiency would be missed over time due to differences in areas of engineering expertise between or among staff. We have previously found in our reporting on other regulatory agencies that strategies such as more frequently rotating staff in key roles can help reduce the risk to supervisory independence and regulatory capture. Some FERC regional offices have developed practices to further enhance their review of these studies. For example, the New York Regional Office established a subject matter expert team that helps review dams with unusually complex hydrology issues. This team was created, in part, because FERC staff noted that some of the hydrology studies conducted in the 1990s and 2000s were not as thorough as they would have wanted, and warranted a re-examination. Currently, the New York Regional Office is reviewing the hydrology analysis associated with 12 dam break studies to determine if the hydrology data used in developing these studies were as rigorously developed and validated. According to the FERC staff in this office, utilizing a team of subject matter experts has reduced Regional Office review time and improved the hydrology studies’ accuracy. FERC staff in the New York Regional Office also told us that they are working with other regional offices on setting up similar technical teams. For example, FERC staff in the New York Regional Office have been working with the Portland Regional Office to set up a similar team. FERC procedures require the use of engineering studies at key points over the dam’s licensing period to inform components of its safety oversight approach, including during the potential failure mode analyses of individual dams as well as during relicensing. Potential failure mode analysis. The potential failure mode analysis is to occur during the recurring independent consultant inspection and is conducted by the licensee’s independent consultant along with other key dam safety stakeholders. As previously explained, the analysis incorporates the engineering studies and identifies events that could cause a dam to potentially fail. During the potential failure mode analysis, FERC, the licensee, the consultant, and other key dam safety stakeholders are to refer to the engineering studies to establish environmental conditions that inform dam failure scenarios, the risks associated with these failures, and their consequences for an individual dam. Further, according to a FERC white paper on risk analysis, FERC is beginning to use information related to potential failure modes as inputs to an analysis tool that quantifies risks at each dam. With this information, FERC expects to make relative risk estimates of dams within its inventory and establish priorities for further study or remediation of risks at individual dams, according to the white paper. Relicensing. During relicensing, FERC staff are to review the engineering studies as well as information such as historical hydrological data and extreme weather events, which also inform their safety evaluation of the licensee’s application. FERC officials also stated that as a result of their relicensing review, they might alter the articles of the new license before it is issued should their reviews indicate that environmental conditions affecting the dam’s safety have changed. We found that FERC generally met its requirement to evaluate dam safety during the relicensing process for the 42 dams we reviewed. During the relicensing process, we found that for the dams we reviewed, FERC staff review safety information such as the past reports, inspections, and studies conducted by FERC, the licensee, and independent consultants and determine whether or not a dam owner operated and maintained its dam safely. According to FERC staff, the safety review for relicensing is generally a summary of prior safety and inspection information, rather than an analysis of new safety information, unless the licensee proposes a change to the operation or structure. FERC’s review during relicensing for the high hazard and significant hazard dams we reviewed was generally consistent with its guidance and safety memo template, though the extent of its review of low hazard dams varied. (See fig. 3.) For example, for the 22 high and significant hazard dams we reviewed, the safety relicensing memos followed the template and nearly all included summaries of hydrology studies, stability analyses, prior FERC inspections, and applicable independent consultant reports. For the 20 low hazard dams, FERC staff noted that some requirements in the template are not applicable or have been exempted and therefore were not reviewed during relicensing. While low hazard dams were more inconsistently reviewed during relicensing, FERC staff also noted that there has been a recent emphasis to more closely review, replace, or conduct engineering studies, such as the stability study, for low hazard dams during relicensing. Moreover, FERC staff told us that the safety risks associated with these dams are minimal, as the failure of a low hazard dam, by definition, does not pose a threat to human life or economic activity. According to FERC staff, if a licensee proposed altering the dam or its operations in any way as part of its application for a new license, FERC staff would review the proposed change and may recommend adding articles to the new license prior to its issuance to ensure dam safety. FERC officials noted that, as part of their review, any structural or operational changes proposed by the licensee during relicensing are reviewed by FERC. These officials also noted that FERC generally recommends modifications to the licensees’ proposed changes prior to their approval and inclusion in the new license. However, FERC officials noted that, in some cases, additional information is needed prior to approving the structural or operational change to ensure there are no risks posed by the changes. In those instances, FERC may recommend that articles be added to the new license, that require the licensee to conduct additional engineering studies of the issue and submit them to FERC for review and approval. For example, during the relicensing of the Otter Creek project in Vermont in 2014, the licensee proposed changes to the project’s operation resulting from construction. As a result, FERC’s staff recommended adding a number of articles to the license, including that the licensee conduct studies to evaluate the effect of the change on safety and to ensure safety during construction. During relicensing, third parties—such as environmental organizations, nearby residents and communities, and other federal agencies, such as the U.S. Fish and Wildlife Service—may provide input on various topics related to the project, including safety. However, FERC officials said that very few third parties file studies or comments related to dam safety during relicensing. FERC’s template and guidance do not specifically require the consideration of such analyses as part of its safety review, and we did not identify any safety studies submitted by third parties for dams or reviewed by FERC in our sample. According to FERC officials, when stakeholders submit comments during relicensing, the comments tend to focus on environmental aspects of the project, such as adding passages for fish migration. Further, FERC is not required under the Federal Power Act to respond to any comments, including those related to dam safety, from third parties, according to FERC officials. However, according to FERC officials, courts have held that the Administrative Procedure Act precludes an agency from arbitrarily and capriciously ignoring issues raised in comments. Furthermore, these officials stated that if a court determines that FERC did not sufficiently address issues raised during the relicensing process, its orders are subject to being reversed and remanded by applicable United States courts of appeals. Moreover, FERC officials noted that the information needed to develop third party safety studies, such as the dam design drawings and engineering studies, are property of the licensee, rather than FERC. In addition, this information may not be readily available to third parties or the public if FERC designates it as critical energy infrastructure information, which would preclude its release to the general public. FERC staff we interviewed stated that there have been no instances where the Commission denied a new license to a licensee as a result of its safety review during relicensing. FERC staff stated that given the frequency of other inspections, including the FERC staff inspections, and independent consultant inspections, it is unlikely staff would find a previously unknown major safety issue during relicensing. FERC staff told us that rather than deny a license for safety deficiencies, FERC will keep a dam owner under the terms of a FERC license to better ensure the licensee remedies existing safety deficiencies. Specifically, FERC staff noted that under a license, FERC can ensure dam safety by (1) closely monitoring the deficiency’s remediation progress through its inspection program, (2) adding license terms in the new license tailored to the specific safety deficiency, and (3), as necessary, pursuing compliance and enforcement actions, such as civil penalties or stop work orders, to enforce the terms and conditions of the license. For example, prior to and during the relicensing of a FERC-licensed project in Wisconsin in 2014, FERC’s review identified that the spillway capacity was inadequate. While the project was relicensed in 2017 without changes to the spillway, FERC officials stated that they have been overseeing the plans and studies of the remediation of the spillway through their ongoing inspection program. However, if an imminent safety threat is identified during the relicensing review, FERC officials stated that they will order that the licensee take actions to remedy the issue immediately. Moreover, FERC officials noted that, if necessary, a license can be revoked for failure to comply with the terms of its license. FERC designed a multi-layered safety approach—which uses inspections, studies, and other assessments of individual dams—to reduce exposure to safety risks. However, as the spillway failure at the Oroville Dam project in 2017 demonstrated, it is not possible to eliminate all uncertainties and risks. As part of a continuing effort to ensure dam safety at licensed projects, FERC could complement its approach to evaluating the safety of individual dams by enhancing its capability to assess and identify the risks across its portfolio of licensed dams. Specifically, while FERC has collected and stored a substantial amount of information from its individual dam safety inspections, FERC’s approach to recording this information is inconsistent due to a lack of standard language and procedures. By clarifying its approach to the recording of information collected during inspections, FERC officials could help ensure that the information recorded is comparable when shared across its regions. Moreover, the absence of standard language and procedures to consistently record inspection information impedes a broader, portfolio- wide analysis of the extent of and characteristics associated with common safety deficiencies identified during FERC inspections. While FERC has not yet conducted such an analysis, a proactive assessment of common safety inspection deficiencies across FERC’s portfolio of licensed dams— similar to its identification of dam spillways with safety concerns following the Oroville Dam incident—could help FERC and its licensees identify safety risks prior to a safety incident and to develop approaches to mitigate those risks. We are making the following two recommendations to FERC: FERC should provide standard language and procedures to its staff on how to record information collected during inspections, including how and where to record information about safety deficiencies, in order to facilitate analysis of safety deficiencies across FERC’s portfolio of regulated dams. (Recommendation 1) FERC should use information from its inspections to assess safety risks across its portfolio of regulated dams to identify and prioritize safety risks at a national level. (Recommendation 2) We provided a draft of this report to FERC for review and comment. In its comments on the draft report, FERC said it generally agreed with the draft report’s findings and found the recommendations to be constructive. FERC said that it would direct staff to develop appropriate next steps to implement GAO’s recommendations. These comments are reproduced in appendix IV. In addition, FERC provided technical comments, which we incorporated as appropriate. As agreed with your offices, unless you publicly announce the contents of this report earlier, we plan no further distribution until 30 days from the report date. At that time, we will send copies to the Chairman of FERC and other interested parties. In addition, the report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at 202-512-2834 or vonaha@gao.gov. Contact points for our Office of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made major contributions to this report are listed in appendix V. FERC seeks to ensure licensees’ compliance with FERC regulations and license requirements, including remediating safety deficiencies, by using a mix of preventative strategies to help identify situations before they become problems and reactive strategies such as issuing penalties. As part of its efforts, FERC published a compliance handbook in 2015 that provides an overall guide to compliance and enforcement of a variety of license requirements, including dam safety. The handbook includes instructions for implementing FERC rules, regulations, policies, and programs designed to ensure effective compliance with license conditions, which include dam safety, to protect and enhance beneficial public uses of waterways. FERC developed a range of enforcement actions, that include holding workshops to encourage compliance and issuing guidance, that increase in severity depending on the non- compliance issue. (See fig. 4.) More broadly, FERC’s guidance directs officials to determine enforcement actions and time frames for those actions on a case-by-case basis, depending on the characteristics of the specific compliance issue. According to FERC officials, many of these safety compliance discussions are handled informally. In addition, their compliance approach emphasizes activities that assist, rather than force, licensees to achieve compliance, according to its guidance. These activities include facilitating open lines of communication with licensees, participating in technical workshops, and publishing brochures and guidance documents, among other efforts. Also, according to these officials, FERC works with licensees to provide guidance and warnings of possible non-compliance matters, in order to avoid usage of any enforcement tools, if possible. According to FERC officials, any safety issues that endanger the public will result in immediate penalty or removal of the dam from power generation, but this action is not lightly taken. Additionally, the length of time between when a safety deficiency is identified and is resolved varies substantially depending on the specific project. As stated earlier in this report, FERC works with licensees to determine a plan and schedule for investigating safety issues and making any needed modifications. However, FERC officials stated that the majority of safety compliance issues are resolved within a month. However, FERC officials stated that if a licensee repeatedly does not take steps to address a compliance issue, FERC will explore enforcement actions through a formal process. According to officials, FERC’s enforcement options are based on authorities provided under the Federal Power Act and such options are flexible because of the variation in hazards, consequences, and dams. According to FERC officials, to ensure compliance with safety regulations, if a settlement cannot be reached, FERC may, among other things, issue an order to show cause, issue civil penalties in the form of fines to licensees, impose stop work or cease power generation orders, revoke licenses, and seek injunctions in federal court. Nevertheless, FERC officials stated that there is no specific requirement for how quickly the compliance issues or deficiencies should be resolved and that some issues can take years to resolve. For example, in 2004, the current licensee of a hydroelectric project operating in Edenville, Michigan, acquired the project, which was found by FERC to be in a state of non-compliance at that time. FERC staff made numerous attempts to work with the licensee to resolve the compliance issues. However, they were unable to resolve these issues and as a result issued a cease generation order in 2017, followed in 2018 by a license revocation order. In practice, FERC’s use of these enforcement tools to resolve safety issues has been fairly limited, particularly in comparison to other license compliance issues, according to FERC officials. Since 2013, FERC has issued one civil penalty for a safety-related hydropower violation and has issued compliance orders on eight other projects for safety-related reasons, including orders to cease generation on three projects. For the 14 projects and 42 dams we reviewed, FERC licensees and their consultants used a variety of tools to develop engineering studies of dam performance (see table 3). These tools included programs and modeling tools developed by government agencies, such as the U.S. Army Corps of Engineers (the Corps), as well as commercially available modeling tools. FERC officials stated that they also used a number of the same tools used by its licensees and consultants. Similarly, for the 14 projects and 42 dams we reviewed, FERC licensees and their consultants used a variety of datasets to develop engineering studies of dam performance (see table 4). These datasets included data maintained and updated by various government agencies, including the United States Geological Survey and National Oceanic and Atmospheric Administration. FERC officials stated that they also used a number of the same datasets used by its licensees and consultants. This report assesses: (1) how FERC collects information from its dam safety inspections and the extent to which FERC analyzes it; (2) how FERC evaluates engineering studies of dam performance to analyze safety, and (3) the extent to which FERC reviews dam safety information during relicensing and the information FERC considers. This report also includes information on FERC actions to ensure licensee compliance with license requirements related to dam safety (app. I) and selected models and data sets used to develop and evaluate engineering studies of dam performance (app. II). For each of the objectives, we reviewed laws, regulations, FERC guidance, templates, and other documentation pertaining to FERC’s evaluation of dam safety. In addition, we reviewed an independent forensic team’s assessment of the causes of the Oroville Dam incident, including the report’s analysis of FERC’s approach to ensuring safety at the project, to understand any limitations of FERC’s approach identified by the report. We also reviewed dam safety documentation, including dam performance studies, FERC memorandums, the most recent completed inspection report, and other information, from a non-probability sample of 14 projects encompassing 42 dams relicensed from fiscal years 2014 through 2017. (See table 5.) We selected these projects and dams to include ones that were geographically dispersed, had varying potential risks associated with their potential failure, and had differences in the length of their relicensing process. We developed a data collection instrument to collect information from the dam safety documentation and analyzed data from the sample to evaluate the extent to which FERC followed its dam safety guidance across the selected projects. To develop the data collection instrument, we reviewed and incorporated FERC oversight requirements from its regulations, guidance, and templates. We conducted three pre-tests of the instrument, and revised the instrument after each pre-test. To ensure consistency and accuracy in the collection of this information, for each dam in the sample, one analyst conducted an initial review of the dam safety documentation; a second analyst reviewed the information independently; and the two analysts reconciled any differences. Following our review of the information from the dam safety documentation, we conducted semi-structured interviews with FERC engineering staff associated with each of the 14 projects and 42 dams to obtain information about FERC’s inspections, review of dam performance studies, and analysis of safety during the relicensing of these projects. Our interviews with these FERC staff provided insight into FERC’s dam safety oversight approach and are not generalizable to all projects. We also interviewed FERC officials responsible for dam safety about dam safety practices. In addition, to review how FERC collects information from its dam safety inspections and the extent to which FERC analyzes it, we also reviewed inspection data from FERC’s information management systems from fiscal years 2014 through 2017. To assess the reliability of these data, we reviewed guidance and interviewed FERC officials. We determined that the data were sufficiently reliable for our purposes. We compared FERC’s approach to collecting, recording and using safety information to federal internal control standards for the design of information systems and related control activities. We also reviewed our prior work on portfolio- level risk management. To evaluate how FERC evaluates engineering studies of dam performance to analyze dam safety, we reviewed FERC policies and guidance. We interviewed six independent consultants having experience inspecting and analyzing FERC-regulated dams to understand how engineering studies of dam performance are developed. We selected consultants who had submitted an inspection report to FERC recently (between December 2017 and February 2018) based on the geographic location of the project they reviewed and experience conducting these inspections, and the number of reports submitted to FERC over this time period. (See table 6.) Our interviews with these consultants provided insight into FERC’s approach to conducting and reviewing studies and are not generalizable to all projects or consultants. To evaluate the extent to which FERC reviews dam safety information during relicensing and the information it considers, we reviewed templates developed by FERC to assess safety during the relicensing and analyzed the extent to which staff followed guidance in these templates for the 14 projects and 42 dams in our sample. We also interviewed stakeholders, including the National Hydropower Association and Friends of the River to obtain general perspectives on FERC’s relicensing approach. Our interviews with these stakeholders provided insight into FERC’s approach to relicensing, and these views are not generalizable across all stakeholders. To review actions to ensure licensee compliance with license requirements related to dam safety, we reviewed FERC’s guidance related to compliance and enforcement and interviewed FERC officials responsible for implementation of the guidance. To review information on models and datasets used to develop and evaluate engineering studies of dam performance, we reviewed dam safety documentation associated with the projects in our sample (described previously), reviewed FERC documentation, and interviewed FERC officials. We conducted this performance audit from July 2017 to October 2018 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. Andrew Von Ah, (202) 512-2834 or vonaha@gao.gov. In addition to the contact named above, Mike Armes (Assistant Director); Matt Voit (Analyst-in-Charge); David Blanding; Brian Chung; Geoff Hamilton; Vondalee Hunt; Rich Johnson; Jon Melhus; Monique Nasrallah; Madhav Panwar; Malika Rice; Sandra Sokol; and Michelle Weathers made key contributions to this report.
The federal child nutrition programs provide assistance to schools and other institutions in the form of cash, commodity food, and administrative support (such as technical assistance and administrative funding) based on the provision of meals and snacks to children. In general, these programs were created (and amended over time) to both improve children's nutrition and provide support to the agriculture economy. Today, the child nutrition programs refer primarily to the following meal, snack, and milk reimbursement programs (these and other acronyms are listed in Appendix A ): National School Lunch Program (NSLP) (Richard B. Russell National School Lunch Act (42 U.S.C. 1751 et seq.)); School Breakfast Program (SBP) (Child Nutrition Act, Section 4 (42 U.S.C. 1773)); Child and Adult Care Food Program (CACFP) (Richard B. Russell National School Lunch Act, Section 17 (42 U.S.C. 1766)); Summer Food Service Program (SFSP) (Richard B. Russell National School Lunch Act, Section 13 (42 U.S.C. 1761)); and Special Milk Program (SMP) (Child Nutrition Act, Section 3 (42 U.S.C. 1772)). The programs provide financial support and/or foods to the institutions that prepare meals and snacks served outside of the home (unlike other food assistance programs such as the Supplemental Nutrition Assistance Program (SNAP, formerly the Food Stamp Program) where benefits are used to purchase food for home consumption). Though exact eligibility rules and pricing vary by program, in general the amount of federal reimbursement is greater for meals served to qualifying low-income individuals or at qualifying institutions, although most programs provide some subsidy for all food served. Participating children receive subsidized meals and snacks, which may be free or at reduced price. Forthcoming sections discuss how program-specific eligibility rules and funding operate. This report describes how each program operates under current law, focusing on eligibility rules, participation, and funding. This introductory section describes some of the background and principles that generally apply to all of the programs; subsequent sections go into further detail on the workings of each. Unless stated otherwise, participation and funding data come from USDA-FNS's "Keydata Reports." The child nutrition programs are most often dated back to the 1946 enactment of the National School Lunch Act, which created the National School Lunch Program, albeit in a different form than it operates today. Most of the child nutrition programs do not date back to 1946; they were added and amended in the decades to follow as policymakers expanded child nutrition programs' institutional settings and meals provided: The Special Milk Program was created in 1954, regularly extended, and made permanent in 1970. The School Breakfast Program was piloted in 1966, regularly extended, and eventually made permanent in 1975. A program for child care settings and summer programs was piloted in 1968, with separate programs authorized in 1975 and then made permanent in 1978. These are now the Child and Adult Care Food Program and Summer Food Service Program. The Fresh Fruit and Vegetable Program began as a pilot in 2002, was made permanent in 2004, and was expanded nationwide in 2008. The programs are now authorized under three major federal statutes: the Richard B. Russell National School Lunch Act (originally enacted as the National School Lunch Act in 1946), the Child Nutrition Act (originally enacted in 1966), and Section 32 of the act of August 24, 1935 (7 U.S.C. 612c). Congressional jurisdiction over the underlying three laws has typically been exercised by the Senate Agriculture, Nutrition, and Forestry Committee; the House Education and the Workforce Committee; and, to a limited extent (relating to commodity food assistance and Section 32 issues), the House Agriculture Committee. Congress periodically reviews and reauthorizes expiring authorities under these laws. The child nutrition programs were most recently reauthorized in 2010 through the Healthy, Hunger-Free Kids Act of 2010 (HHFKA, P.L. 111-296 ); some of the authorities created or extended in that law expired on September 30, 2015. WIC (the Special Supplemental Nutrition Program for Women, Infants, and Children) is also typically reauthorized with the child nutrition programs. WIC is not one of the child nutrition programs and is not discussed in this report. The 114 th Congress began but did not complete a 2016 child nutrition reauthorization (see CRS Report R44373, Tracking the Next Child Nutrition Reauthorization: An Overview ). There was no significant legislative activity with regard to reauthorization in the 115 th Congress. The U.S. Department of Agriculture's Food and Nutrition Service (USDA-FNS) administers the programs at the federal level. The programs are operated by a wide variety of local public and private providers and the degree of direct state involvement differs by program and state. At the state level, education, health, social services, and agriculture departments all have roles; at a minimum, they are responsible for approving and overseeing local providers such as schools, summer program sponsors, and child care centers and day care homes, as well as making sure they receive the federal support they are due. At the local level, program benefits are provided to millions of children (e.g., there were 30.0 million in the National School Lunch Program, the largest of the programs, in FY2017), through some 100,000 public and private schools and residential child care institutions, nearly 170,000 child care centers and family day care homes, and just over 50,000 summer program sites. All programs are available in the 50 states and the District of Columbia. Virtually all operate in Puerto Rico, Guam, and the Virgin Islands (and, in differing versions, in the Northern Marianas and American Samoa). This section summarizes the nature and extent to which the programs' funding is mandatory and discretionary, including a discussion of appropriated entitlement status. Table 3 lists child nutrition program and related expenditures. Most spending for child nutrition programs is provided in annual appropriations acts to fulfill the legal financial obligation established by the authorizing laws. That is, the level of spending for such programs, referred to as appropriated mandatory spending, is not controlled through the annual appropriations process, but instead is derived from the benefit and eligibility criteria specified in the authorizing laws. The appropriated mandatory funding is treated as mandatory spending. Further, if Congress does not appropriate the funds necessary to fund the program, eligible entities may have legal recourse. Congress typically considers the Administration's forecast for program needs in its appropriations decisions. For the majority of funding discussed in this report, the formula that controls the funding is not capped and fluctuates based on the reimbursement rates and the number of meals/snacks served in the programs. In the meal service programs, such as the National School Lunch Program, School Breakfast Program, summer programs, and assistance for child care centers and day care homes, federal aid is provided in the form of statutorily set subsidies (reimbursements) paid for each meal/snack served that meets federal nutrition guidelines. Although all (including full-price) meals/snacks served by participating providers are subsidized, those served free or at a reduced price to lower-income children are supported at higher rates. All federal meal/snack subsidy rates are indexed annually (each July) for inflation, as are the income eligibility thresholds for free and reduced-price meals/snacks. Subsequent sections discuss how a specific program's eligibility and reimbursements work. Most subsidies are cash payments to schools or other providers, but a smaller portion of aid is provided in the form of USDA-purchased commodity foods . Laws for three child nutrition programs (NSLP, CACFP, and SFSP) require the provision of commodity foods (or in some cases allow cash in lieu of commodity foods). Meal and snack service entails nonfood costs. Federal child nutrition per-meal/snack subsidies may be used to cover local providers' administrative and operating costs. However, the separate direct federal payments for administrative/operating costs ("State Administrative Expenses," discussed in the " Related Programs, Initiatives, and Support Activities " section) are limited. In addition to the open-ended, appropriated entitlement funds summarized above, the child nutrition programs' funding also includes certain other mandatory funding and a limited amount of discretionary funding. Some of the activities discussed in " Related Programs, Initiatives, and Support Activities ," such as Team Nutrition, are provided for with discretionary funding. Aside from the annually appropriated funding, the child nutrition programs are also supported by certain permanent appropriations and transfers. Notably, funding for the Fresh Fruit and Vegetable Program is funded by a transfer from USDA's Section 32 program, a permanent appropriation of 30% of the previous year's customs receipts. Federal subsidies do not necessarily cover the full cost of the meals and snacks offered by providers. States and localities help cover program costs, as do children's families by paying charges for nonfree or reduced-price meals/snacks. There is a nonfederal cost-sharing requirement for the school meals programs (discussed below), and some states supplement school funding through additional state per-meal reimbursements or other prescribed financing arrangements. Subsequent sections of this report delve into the details of how each of the child nutrition programs support the service of meals and snacks in institutional settings; first, it is useful to take a broader perspective of primary program elements. Table 1 is a top-level look at the different programs that displays distinguishing characteristics (what meals are provided, in what settings, to what ages) and recent program spending. Other relevant CRS reports in this area include CRS In Focus IF10266, An Introduction to Child Nutrition Reauthorization CRS Report R45486, Child Nutrition Programs: Current Issues CRS Report R42353, Domestic Food Assistance: Summary of Programs CRS Report R41354, Child Nutrition and WIC Reauthorization: P.L. 111-296 (summarizes the Healthy, Hunger-Free Kids Act of 2010) CRS Report R44373, Tracking the Next Child Nutrition Reauthorization: An Overview CRS Report R44588, Agriculture and Related Agencies: FY2017 Appropriations CRS Report RL34081, Farm and Food Support Under USDA's Section 32 Program Other relevant resources include USDA-FNS's website, https://www.fns.usda.gov/school-meals/child-nutrition-programs USDA-FNS's Healthy, Hunger-Free Kids Act page, http://www.fns.usda.gov/school-meals/healthy-hunger-free-kids-act The FNS page of the Federal Register , https://www.federalregister.gov/agencies/food-and-nutrition-service This section discusses the school meals programs: the National School Lunch Program (NSLP) and the School Breakfast Program (SBP). Principles and concepts common to both programs are discussed first; subsections then discuss features and data unique to the NSLP and SBP, respectively. The federal school meals programs provide federal support in the form of cash assistance and USDA commodity foods; both are provided according to statutory formulas based on the number of reimbursable meals served in schools. The subsidized meals are served by both public and private nonprofit elementary and secondary schools and residential child care institutions (RCCIs) that opt to enroll and guarantee to offer free or reduced-price meals to eligible low-income children. Both cash and commodity support to participating schools are calculated based on the number and price of meals served (e.g., lunch or breakfast, free or full price), but once the aid is received by the school it is used to support the overall school meal service budget, as determined by the school. This report focuses on the federal reimbursements and funding, but it should be noted that some states have provided state financing through additional state-specific funding. Federal law does not require schools to participate in the school meals programs. However, some states have mandated that schools provide lunch and/or breakfast, and some of these states require that their schools do so through NSLP and/or SBP. The program is open to public and private schools. A reimbursable meal requires compliance with federal school nutrition standards, which have changed throughout the history of the program based on nutritional science and children's nutritional needs. Food items not served as a complete meal meeting nutrition standards (e.g., a la carte offerings) are not reimbursable meals, and therefore are not eligible for federal per-meal, per-snack reimbursements. Following rulemaking to implement provisions in the Healthy, Hunger-Free Kids Act of 2010 ( P.L. 111-296 ), USDA updated the nutrition standards for reimbursable meals in January 2012 (see " Nutrition Standards " for more information). Schools serving meals that meet the updated nutrition standards are eligible for an increased reimbursement of 6 cents per lunch. USDA-FNS administers the school meals programs federally, and state agencies (typically state departments of education) oversee and transmit reimbursements through agreements with school food authorities (SFAs) (typically local educational agencies (LEAs); usually these are school districts). Figure 1 provides an overview of the roles and relationships between these levels of government. There is a cost-sharing requirement for the programs, which amounts to a contribution of approximately $200 million from the states. There also are states that choose to supplement federal reimbursements with their own state reimbursements. The school meals programs and related funding do not serve only low-income children. All students can receive a meal at a NSLP- or SBP-participating school, but how much the child pays for the meal and/or how much of a federal reimbursement the state receives will depend largely on whether the child qualifies for a "free," "reduced-price," or "paid" (i.e., advertised price) meal. Both NSLP and SBP use the same household income eligibility criteria and categorical eligibility rules. States and schools receive the largest reimbursements for free meals, smaller reimbursements for reduced-price meals, and the smallest (but still some federal financial support) for the full-price meals. There are three pathways through which a child can become certified to receive a free or reduced-price meal: 1. Household income eligibility for free and reduced-price meals (information typically collected via household application), 2. Categorical (or automatic) eligibility for free meals (information collected via household application or a direct certification process), and 3. School-wide free meals under the Community Eligibility Provision (CEP) , an option for eligible schools that is based on the share of students identified as eligible for free meals. Each of these pathways is discussed in more detail below. The income eligibility thresholds (shown in Table 2 ) are based on multipliers of the federal poverty guidelines. As the poverty guidelines are updated every year, so are the eligibility thresholds for NSLP and SBP. Free Meals: Children receive free meals if they have household income at or below 130% of the federal poverty guidelines; these meals receive the highest subsidy rate. (Reimbursements are approximately $3.30 per lunch served, less for breakfast.) Reduced-Price Meals: Children may receive reduced-price meals (charges of no more than 40 cents for a lunch or 30 cents for a breakfast) if their household income is above 130% and less than or equal to 185% of the federal poverty guidelines; these meals receive a subsidy rate that is 40 cents (NSLP) or 30 cents (SBP) below the free meal rate. (Reimbursements are approximately $2.90 per lunch served.) Paid Meals: A comparatively small per-meal reimbursement is provided for full-price or paid meals served to children whose families do not apply for assistance or whose family income does not qualify them for free or reduced-price meals. The paid meal price is set by the school but must comply with federal regulations. (Reimbursements are approximately 30 cents per lunch served.) The above reimbursement rates are approximate; exact current-year federal reimbursement rates for NSLP and SBP are listed in Table B -1 and Table B -3 , respectively. Households complete paper or online applications that collect relevant income and household size data, so that the school district can determine if children in the household are eligible for free meals, reduced-price meals, or neither. Though these income guidelines primarily influence funding and administration of NSLP and SBP, they also affect the eligibility rules for the SFSP, CACFP, and SMP (described further in subsequent sections). In addition to the eligibility thresholds listed above, the school meals programs also convey eligibility for free meals based on household participation in certain other need-tested programs or children's specified vulnerabilities (e.g., foster children). Per Section 12 of the National School Lunch Act, "a child shall be considered automatically eligible for a free lunch and breakfast ... without further application or eligibility determination, if the child is" in a household receiving benefits through SNAP (Supplemental Nutrition Assistance Program); FDPIR (Food Distribution Program on Indian Reservations, a program that operates in lieu of SNAP on some Indian reservations) benefits; or TANF (Temporary Assistance for Needy Families) cash assistance; enrolled in Head Start; in foster care; a migrant; a runaway; or homeless. For meals served to students certified in the above categories, the state/school receive a reimbursement at the free meal amount and children receive a free meal. (See Table B -1 and Table B -3 for school year 2018-2019 rates.) Some school districts collect information for these categorical eligibility rules via paper application. Others conduct a process called direct certification —a proactive process where government agencies typically cross-check their program rolls and certify a household's children for free school meals without the household having to complete a school meals application. Prior to 2004, states had the option to conduct direct certification of SNAP (then, the Food Stamp Program), TANF, and FDPIR participants. In the 2004 child nutrition reauthorization ( P.L. 108-265 ), states were required under federal law to conduct direct certification for SNAP participants, with nationwide implementation taking effect in school year 2008-2009. Conducting direct certification for TANF and FDPIR remains at the state's discretion. The Healthy, Hunger-Free Kids Act of 2010 (HHFKA; P.L. 111-296 ) made further policy changes to expand direct certification (discussed further in the next section). One of those changes was the initiation of a demonstration project to look at expanding categorical eligibility and direct certification to some Medicaid households. The law also funded performance incentive grants for high-performing states and authorized correcting action planning for low-performing states in direct certification activities. Under SNAP direct certification rules generally, schools enter into agreements with SNAP agencies to certify children in SNAP households as eligible for free school meals without requiring a separate application from the family. Direct certification systems match student enrollment lists against SNAP agency records, eliminating the need for action by the child's parents or guardians. Direct certification allows schools to make use of SNAP's more in-depth eligibility certification process; this can reduce errors that may occur in school lunch application eligibility procedures that are otherwise used. From a program access perspective, direct certification also reduces the number of applications a household must complete. Figure 2 , created by GAO and published in a May 2014 report, provides an overview of how school districts certify students for free and reduced-price meals under the income-based and category-based rules, via applications and direct certification. A USDA-FNS study of school year 2014-2015 estimates that 11.1 million students receiving free meals were directly certified—68% of all categorically eligible students receiving free meals. HHFKA also authorized the school meals Community Eligibility Provision (CEP), an option in NSLP and SBP law that allows eligible schools and school districts to offer free meals to all enrolled students based on the percentage of their students who are identified as automatically eligible from nonhousehold application sources (primarily direct certification through other programs). Based on the statutory parameters, USDA-FNS piloted CEP in various states over three school years and it expanded nationwide in school year 2014-2015. Eligible LEAs have until June 30 of each year to notify USDA-FNS if they will participate in CEP. According to a database maintained by the Food Research and Action Center, just over 20,700 schools in more than 3,500 school districts (LEAs) participated in CEP in SY2016-2017, an increase of approximately 2,500 schools compared to SY2015-2016. For a school (or school district, or group of schools within a district) to provide free meals to all children the school(s) must be eligible for CEP based on the share (40% or greater) of enrolled children that can be identified as categorically (or automatically) eligible for free meals, and the school must opt-in to CEP. Though CEP schools serve free meals to all students, they are not reimbursed at the "free meal" rate for every meal. Instead, the law provides a funding formula: the percentage of students identified as automatically eligible (the "identified student percentage" or ISP) is multiplied by a factor of 1.6 to estimate the proportion of students who would be eligible for free or reduced-price meals had they been certified via application. The result is the percentage of meals served that will be reimbursed at the free meal rate, with the remainder reimbursed at the far lower paid meal rate. For example, if a CEP school identifies that 40% of students are eligible for free meals, then 64% of the meals served will be reimbursed at the free meal rate and 36% at the paid meal rate. Schools that identify 62.5% or more students as eligible for free meals receive the free meal reimbursement for all meals served. Some of the considerations that may impact a school's decision to participate in CEP include whether the new funding formula would be beneficial for their school meal budget; an interest in reducing paperwork for families and schools; and an interest in providing more free meals, including meals to students who have not participated in the program before. The Healthy, Hunger-Free Kids Act of 2010 (HHFKA; P.L. 111-296 ) set in motion changes to the nutrition standards for school meals, requiring USDA to update the standards within a certain timeframe. The law required that the revised standards be based on recommendations from the Institute of Medicine (IOM) (now the Health and Medicine Division) at the National Academy of Sciences. The law also provided increased federal subsidies (6 cents per lunch) for schools meeting the new requirements and funding for technical assistance related to implementation. USDA published the final regulations in January 2012. The final rule sought to align school meal patterns with the 2010 Dietary Guidelines for Americans, and, generally consistent with IOM's recommendations, increased the amount of fruits, vegetables, whole grains, and low-fat or fat-free milk in school meals. The regulations also included calorie maximums and sodium limits to phase in over time, among other requirements. The nutrition standards largely took effect in SY2012-2013 for lunches and in SY2013-2014 for breakfasts. A few other requirements were scheduled to phase in over multiple school years. Some schools experienced difficulty implementing the new guidelines, and Congress and USDA have made changes to the 2012 final rule's whole grain, sodium, and milk requirements. For SY2019-2020 and onwards, schools are operating under a final rule published December 12, 2018. The HHFKA also gave USDA the authority to regulate other foods in the school nutrition environment. Sometimes called "competitive foods," these include foods and drinks sold in a la carte lines, vending machines, snack bars and concession stands, and fundraisers. Relying on recommendations made by a 2007 IOM report, USDA-FNS promulgated a proposed rule and then an interim final rule in June 2013, which went into effect for SY2014-2015. The interim final rule created nutrition guidelines for all non-meal foods and beverages that are sold during the school day (defined as midnight until 30 minutes after dismissal). The final rule, published on July 29, 2016, maintained the interim final rules with minor modifications. Under the final standards, these foods must meet whole-grain requirements; have certain primary ingredients; and meet calorie, sodium, and fat limits, among other requirements. Schools are limited to a list of no- and low-calorie beverages they may sell (with larger portion sizes and caffeine allowed in high schools). There are no limits on fundraisers selling foods that meet the interim final rule's guidelines. Fundraisers outside of the school day are not subject to the guidelines. HHFKA and the interim final rule provide states with discretion to exempt infrequent fundraisers selling foods or beverages that do not meet the nutrition standards. The rule does not limit foods brought from home, only foods sold at school during the school day. The federal standards are minimum standards; states and school districts are permitted to issue more stringent policies. In FY2017, NSLP subsidized 4.9 billion lunches to children in close to 96,000 schools and 3,200 residential child care institutions (RCCIs). Average daily participation was 30.0 million students (58% of children enrolled in participating schools and RCCIs). Of the participating students, 66.7% (20.0 million) received free lunches and 6.5% (2.0 million) received reduced-price lunches. The remainder were served full-price meals, though schools still receive a reimbursement for these meals. Figure 3 shows FY2017 participation data. FY2017 federal school lunch costs totaled approximately $13.6 billion (see Table 3 for the various components of this total). The vast majority of this funding is for per-meal reimbursements for free and reduced-price lunches. The HHFKA also provided an additional 6-cent per-lunch reimbursement to schools that provide meals that meet the updated nutritional guidelines requirements. This bonus is not provided for breakfast, but funds may be used to support schools' breakfast programs. NSLP lunch reimbursement rates are listed in Table B -1 . In addition to federal cash subsidies, schools participating in NSLP receive USDA-acquired commodity food s . Schools are entitled to a specific, inflation-indexed value of USDA commodity foods for each lunch they serve. Also, schools may receive donations of bonus commodities acquired by USDA in support of the farm economy. In FY2017, the value of federal commodity food aid to schools totaled nearly $1.4 billion. The per-meal rate for commodity food assistance is included in Table B-4 . While the vast majority of NSLP funding is for lunches served during the school day, NSLP may also be used to support snack service during the school year and to serve meals during the summer. These features are discussed in subsequent sections, " Summer Meals " and " After-School Meals and Snacks: CACFP, NSLP Options ." Reimbursement rates for snacks are listed in Table B -2 . The School Breakfast Program (SBP) provides per-meal cash subsidies for breakfasts served in schools. Participating schools receive subsidies based on their status as a severe need or nonsevere need institution. Schools can qualify as a severe need school if 40% or more of their lunches are served free or at reduced prices. See Table B -3 for SBP reimbursement rates. Figure 4 displays SBP participation data for FY2017. In that year, SBP subsidized over 2.4 billion breakfasts in over 88,000 schools and nearly 3,200 RCCIs. Average daily participation was 14.7 million children (30.1% of the students enrolled in participating schools and RCCIs). The majority of meals served through SBP are free or reduced-price. Of the participating students, 79.1% (11.6 million) received free meals and 5.7% (835,000) purchased reduced-price meals. Federal school breakfast costs for the fiscal year totaled approximately $4.3 billion (see Table 3 for the various components of this total). Significantly fewer schools and students participate in SBP than in NSLP. Participation in SBP tends to be lower for several reasons, including the traditionally required early arrival by students in order to receive a meal and eat before school starts. Some schools offer (and anti-hunger groups have encouraged) models of breakfast service that can result in greater SBP participation, such as Breakfast in the Classroom, where meals are delivered in the classroom; "grab and go" carts, where students receive a bagged breakfast that they bring to class, or serving breakfast later in the day in middle and high schools. Unlike NSLP, commodity food assistance is not a formal part of SBP funding; however, commodities provided through NSLP may be used for school breakfasts as well. In addition to the school meals programs discussed above, other federal child nutrition programs provide federal subsidies and commodity food assistance for schools and other institutions that offer meals and snacks to children in early childhood, summer, and after-school settings. This assistance is provided to (1) schools and other governmental institutions, (2) private for-profit and nonprofit child care centers, (3) family/group day care homes, and (4) nongovernmental institutions/organizations that offer outside-of-school programs for children. (Although this report focuses on the programs that serve children, one child nutrition program (CACFP) also serves day care centers for chronically impaired adults and elderly persons under the same general per-meal/snack subsidy terms.) The programs in the sections to follow serve comparatively fewer children and spend comparatively fewer federal funds than the school meal programs. CACFP subsidizes meals and snacks served in early childhood, day care, and after-school settings. CACFP provides subsidies for meals and snacks served at participating nonresidential child care centers, family day care homes, and (to a lesser extent) adult day care centers. The program also provides assistance for meals served at after-school programs. CACFP reimbursements are available for meals and snacks served to children age 12 or under, migrant children age 15 or under, children with disabilities of any age, and, in the case of adult care centers, chronically impaired and elderly adults. Children in early childhood settings are the overwhelming majority of those served by the program. CACFP provides federal reimbursements for breakfasts, lunches, suppers, and snacks served in participating centers (facilities or institutions) or day care homes (private homes). The eligibility and funding rules for CACFP meals and snacks depend first on whether the participating institution is a center or a day care home (the next two sections discuss the rules specific to centers and day care homes). According to FY2017 CACFP data, child care centers have an average daily attendance of about 56 children per center, day care homes have an average daily attendance of approximately 7 children per home, and adult day care centers typically care for an average of 48 chronically ill or elderly adults per center. Providers must demonstrate that they comply with government-established standards for other child care programs. Like in school meals, federal assistance is made up overwhelmingly of cash reimbursements calculated based on the number of meals/snacks served and federal per-meal/snack reimbursements rates, but a far smaller share of federal aid (4.3% in FY2017) is in the form of federal USDA commodity foods (or cash in lieu of foods). Federal CACFP reimbursements flow to individual providers either directly from the administering state agency (this is the case with many child/adult care centers able to handle their own CACFP administrative functions) or through "sponsors" who oversee and provide administrative support for a number of local providers (this is the case with some child/adult care centers and with all day care homes). In FY2017, total CACFP spending was over $3.5 billion, including cash reimbursement, commodity food assistance, and costs for sponsor audits. (See Table 3 for a further breakdown of CACFP costs.) This total also includes the after-school meals and snacks provided through CACFP's "at-risk after-school" pathway; this aspect of the program is discussed later in " After-School Meals and Snacks: CACFP, NSLP Options ." As with school foods, the HHFKA required USDA to update CACFP's meal patterns. USDA's final rule revised the meal patterns for both meals served in child care centers and day care homes, as well as preschool meals served through the NSLP and SBP, effective October 1, 2017. For infants (under 12 months of age), the new meal patterns eliminated juice, supported breastfeeding, and set guidelines for the introduction of solid foods, among other changes. For children ages one and older, the new meal patterns increased whole grains, fruits and vegetables, and low-fat and fat-free milk; limited sugar in cereals and yogurts; and prohibited frying, among other requirements. Child care centers in CACFP can be (1) public or private nonprofit centers, (2) Head Start centers, (3) for-profit proprietary centers (if they meet certain requirements as to the proportion of low-income children they enroll), and (4) shelters for homeless families. Adult day care centers include public or private nonprofit centers and for-profit proprietary centers (if they meet minimum requirements related to serving low-income disabled and elderly adults). In FY2017, over 65,000 child care centers with an average daily attendance of over 3.6 million children participated in CACFP. Over 2,700 adult care centers served nearly 132,000 adults through CACFP. Participating centers may receive daily reimbursements for up to either two meals and one snack or one meal and two snacks for each participant, so long as the meals and snacks meet federal nutrition standards. The eligibility rules for CACFP centers largely track those of NSLP: children in households at or below 130% of the current poverty line qualify for free meals/snacks while those between 130% and 185% of poverty qualify for reduced-price meals/snacks (see Table 2 ). In addition, participation in the same categorical eligibility programs as NSLP as well as foster child status convey eligibility for free meals in CACFP. Like school meals, eligibility is determined through paper applications or direct certification processes. Like school meals, all meals and snacks served in the centers are federally subsidized to some degree, even those that are paid. Different reimbursement amounts are provided for breakfasts, lunches/suppers, and snacks, and reimbursement rates are set in law and indexed for inflation annually. The largest subsidies are paid for meals and snacks served to participants with family income below 130% of the federal poverty income guidelines (the income limit for free school meals), and the smallest to those who have not met a means test. See Table B -5 for current CACFP center reimbursement rates. Unlike school meals, CACFP institutions are less likely to collect per-meal payments. Although federal assistance for day care centers differentiates by household income, centers have discretion on their pricing of meals. Centers may adjust their regular fees (tuition) to account for federal payments, but CACFP itself does not regulate these fees. In addition, centers can charge families separately for meals/snacks, so long as there are no charges for children meeting free-meal/snack income tests and limited charges for those meeting reduced-price income tests. Independent centers are those without sponsors handling administrative responsibilities. These centers must pay for administrative costs associated with CACFP out of nonfederal funds or a portion of their meal subsidy payments. For centers with sponsors, the sponsors may retain a proportion of the meal reimbursement payments they receive on behalf of their centers to cover such costs. CACFP-supported day care homes serve a smaller number of children than CACFP-supported centers , both in terms of the total number of children served and the average number of children per facility. Roughly 17% of children in CACFP (approximately 757,000 in FY2017 average daily attendance) are served through day care homes. In FY2017, approximately 103,000 homes (with just over 700 sponsors) received CACFP support. As with centers, payments to day care homes are provided for up to either two meals and one snack or one meal and two snacks a day for each child. Unlike centers, day care homes must participate under the auspices of a public or, more often, private nonprofit sponsor that typically has 100 or more homes under its supervision. CACFP day care home sponsors receive monthly administrative payments based on the number of homes for which they are responsible. Federal reimbursements for family day care homes differ by the home's status as "Tier I" or "Tier II." Unlike centers, day care homes receive cash reimbursements (but not commodity foods) that generally are not based on the child participants' household income. Instead, there are two distinct, annually indexed reimbursement rates that are based on area or operator eligibility criteria Tier I homes are located in low-income areas (defined as areas in which at least 50% of school-age and enrolled children qualify for free or reduced-price meals) or operated by low-income providers whose household income meets the free or reduced-price income standards. They receive higher subsidies for each meal/snack they serve. Tier II (lower) rates are by default those for homes that do not qualify for Tier I rates; however, Tier II providers may seek the higher Tier I subsidy rates for individual low-income children for whom financial information is collected and verified. (See Table B-6 for current Tier I and Tier II reimbursement rates.) Additionally, HHFKA introduced a number of additional ways (as compared to prior law) by which family day care homes can qualify as low-income and get Tier I rates for the entire home or for individual children. As with centers, there is no requirement that meals/snacks specifically identified as free or reduced-price be offered; however, unlike centers, federal rules prohibit any separate meal charges. Current law SFSP and the NSLP/SBP Seamless Summer Option provide meals in congregate settings nationwide; the related Summer Electronic Benefits Transfer (SEBTC or Summer EBT) demonstration project is an alternative to congregate settings. SFSP supports meals for children during the summer months. The program provides assistance to local public institutions and private nonprofit service institutions running summer youth/recreation programs, summer feeding projects, and camps. Assistance is primarily in the form of cash reimbursements for each meal or snack served; however, federally donated commodity foods are also offered. Participating service institutions are often entities that provide ongoing year-round service to the community including schools, local governments, camps, colleges and universities in the National Youth Sports program, and private nonprofit organizations like churches. Similar to the CACFP model, sponsors are institutions that manage the food preparation, financial, and administrative responsibilities of SFSP. Sites are the places where food is served and eaten. At times, a sponsor may also be a site. State agencies authorize sponsors, monitor and inspect sponsors and sites, and implement USDA policy. Unlike CACFP, sponsors are required for an institution's participation in SFSP as a site. In FY2017, nearly 5,500 sponsors with 50,000 food service sites participated in the SFSP and served an average of approximately 2.7 million children daily (according to July data). Participation of sites and children in SFSP has increased in recent years. Program costs for FY2017 totaled over $485 million, including cash assistance, commodity foods, administrative cost assistance, and health inspection costs. There are several options for eligibility and meal/snack service for SFSP sponsors (and their sites) Open sites provide summer food to all children in the community. These sites are certified based on area eligibility measures, where 50% or more of area children have family income that would make them eligible for free or reduced-price school meals (see Table 2 ). Closed or Enrolled sites provide summer meals/snacks free to all children enrolled at the site. The eligibility test for these sites is that 50% or more of the children enrolled in the sponsor's program must be eligible for free or reduced-price school meals based on household income. Closed/enrolled sites may also become eligible based on area eligibility measures noted above. Summer camps (that are not enrolled sites) receive subsidies only for those children with household eligibility for free or reduced-price school meals. Other programs specified in law , such as the National Youth Sports Program and centers for homeless or migrant children. Summer sponsors get operating cost (food, storage, labor) subsidies for all meals/snacks they serve—up to one meal and one snack, or two meals per child per day. In addition, sponsors receive payments for administrative costs, and states are provided with subsidies for administrative costs and health and meal-quality inspections. See Table B -7 for current SFSP reimbursement rates. Actual payments vary slightly (e.g., by about 5 cents for lunches) depending on the location of the site (e.g., rural vs. urban) and whether meals are prepared on-site or by a vendor. Although SFSP is the child nutrition program most associated with providing meals during summer months, it is not the only program option for providing these meals and snacks. The Seamless Summer Option, run through NSLP or SBP programs, is also a means through which food can be provided to students during summer months. Much like SFSP, Seamless Summer operates in summer sites (summer camps, sports programs, churches, private nonprofit organizations, etc.) and for a similar duration of time. Unlike SFSP, schools are the only eligible sponsors , although schools may operate the program at other sites. Reimbursement rates for Seamless Summer meals are the same as current NSLP/SBP rates. Beginning in summer 2011 and (as of the date of this report) each summer since, USDA-FNS has operated Summer Electronic Benefit Transfer for Children (SEBTC or "Summer EBT") demonstration projects in a limited number of states and Indian Tribal Organizations (ITOs). These Summer EBT projects provide electronic food benefits over summer months to households with children eligible for free or reduced-price school meals. Depending on the site and year, either $30 or $60 per month is provided, through a WIC or SNAP EBT card model. In the demonstration projects, these benefits were provided as a supplement to the Summer Food Service Program (SFSP) meals available in congregate settings. Summer EBT and other alternatives to congregate meals through SFSP were first authorized and funded by the FY2010 appropriations law ( P.L. 111-80 ). Although a number of alternatives were tested and evaluated, findings from Summer EBT were among the most promising, and Congress provided subsequent funding. Summer EBT evaluations showed significant impacts on reducing child food insecurity and improving nutritional intake.  Summer EBT was funded by P.L. 111-80 in the summers from 2011 to 2014. Projects have continued to operate and were annually funded by FY2015-FY2018 appropriations; most recently, the FY2018 appropriations law ( P.L. 115-141 ) provided $28 million. According to USDA-FNS, in summer 2016 Summer EBT served over 209,000 children in nine states and two tribal nations—an increase from the 11,400 children served when the demonstration began in summer 2011. Schools (and institutions like summer camps and child care facilities) that are not already participating in the other child nutrition programs can participate in the Special Milk Program. Schools may also administer SMP for their part-day sessions for kindergartners or pre-kindergartners. Under SMP, participating institutions provide milk to children for free and/or at a subsidized paid price, depending on how the enrolled institution opts to administer the program (see Table B -8 for current Special Milk reimbursement rates for each of these options) An institution that only sells milk will receive the same per-half pint federal reimbursement for each milk sold (approximately 20 cents). An institution that sells milk and provides free milk to eligible children (income eligibility is the same as free school meals, see Table 2 ), receives a reimbursement for the milk sold (approximately 20 cents) and a higher reimbursement for the free milks. An institution that does not sell milk provides milk free to all children and receives the same reimbursement for all milk (approximately 20 cents). This option is sometimes called nonpricing. In FY2017, over 41 million half-pints were subsidized, 9.5% of which were served free. Federal expenditures for this program were approximately $8.3 million in FY2017. States receive formula grants through the Fresh Fruit and Vegetable Program, under which state-selected schools receive funds to purchase and distribute fresh fruit and vegetable snacks to all children in attendance (regardless of family income). Money is distributed by a formula under which about half the funding is distributed equally to each state and the remainder is allocated by state population. States select participating schools (with an emphasis on those with a higher proportion of low-income children) and set annual per-student grant amounts (between $50 and $75). Funding is set by law at $150 million for school year 2011-2012 and inflation-indexed for every year after. In FY2017, states used approximately $184 million in FFVP funds. FFVP is funded by a mandatory transfer of funds from USDA's Section 32 program—a permanent appropriation of 30% of the previous year's customs receipts. This transfer is required by FFVP's authorizing laws (Section 19 of the Richard B. Russell National School Lunch Act and Section 4304 of P.L. 110-246 ). Up until FY2018's law, annual appropriations laws delayed a portion of the funds to the next fiscal year. After a pilot period, the Child Nutrition and WIC Reauthorization Act of 2004 ( P.L. 108-265 ) permanently authorized and funded FFVP for a limited number of states and Indian reservations. In recent years, FFVP has been amended by omnibus farm bill laws rather than through child nutrition reauthorizations. The 2008 farm bill ( P.L. 110-246 ) expanded FFVP's mandatory funding, specifically providing funds through Section 32, and enabled all states to participate in the program. The 2014 farm bill ( P.L. 113-79 ) essentially made no changes to this program but did include, and fund at $5 million in FY2014, a pilot project that requires USDA to test offering frozen, dried, and canned fruits and vegetables and publish an evaluation of the pilot. Four states (Alaska, Delaware, Kansas, and Maine) participated in the pilot in SY2014-2015 and the evaluation was published in 2017. Other proposals to expand fruits and vegetables offered in FFVP have been introduced in both the 114 th and 115 th Congress. Two of the child nutrition programs discussed in previous sections, the National School Lunch Program (NSLP) and Child and Adult Care Food Program (CACFP), provide federal support for snacks and meals served during after-school programs. NSLP provides reimbursements for after-school snacks; however, this option is open only to schools that already participate in NSLP. These schools may operate after-school snack-only programs during the school year, and can do so in two ways: (1) if low-income area eligibility criteria are met, provide free snacks in lower-income areas; or (2) if area eligibility criteria are not met, offer free, reduced-price, or fully paid-for snacks, based on household income eligibility (like lunches in NSLP). The vast majority of snacks provided through this program are through the first option. Through this program, approximately 206 million snacks were served in FY2017 (a daily average of nearly 1.3 million). This compares with nearly 4.9 billion lunches served (a daily average of 27.8 million). CACFP provides assistance for after-school food in two ways. First, centers and homes that participate in CACFP and provide after-school care may participate in traditional CACFP (the eligibility and administration described earlier). Second, centers in areas where at least half the children in the community are eligible for free or reduced-price school meals can opt to participate in the CACFP At-Risk Afterschool program, which provides free snacks and suppers. Expansion of the At-Risk After-School meals program was a major policy change included in HHFKA. Prior to the law, 13 states were permitted to offer CACFP At-Risk After-School meals (instead of just a snack); the law allowed all CACFP state agencies to offer such meals. In FY2017, the At-Risk Afterschool program served a total of approximately 242.6 million free meals and snacks to a daily average of more than 1.7 million children. Federal child nutrition laws authorize and program funding supports a range of additional programs, initiatives, and activities. Through State Administrative Expenses funding, states are entitled to federal grants to help cover administrative and oversight/monitoring costs associated with child nutrition programs. The national amount each year is equal to about 2% of child nutrition reimbursements. The majority of this money is allocated to states based on their share of spending on the covered programs; about 15% is allocated under a discretionary formula granting each state additional amounts for CACFP, commodity distribution, and Administrative Review efforts. In addition, states receive payments for their role in overseeing summer programs (about 2.5% of their summer program aid). States are free to apportion their federal administrative expense payments among child nutrition initiatives (including commodity distribution activities) as they see fit, and appropriated funding is available to states for two years. State Administrative Expense spending in FY2017 totaled approximately $279 million. Team Nutrition is a USDA-FNS program that includes a variety of school meals initiatives around nutrition education and the nutritional content of the foods children eat in schools. This includes Team Nutrition Training Grants, which provide funding to state agencies for training and technical assistance, such as help implementing USDA's nutrition requirements and the Dietary Guidelines for Americans. From 2004 to 2018, Team Nutrition also included the HealthierUS Schools Challenge (HUSSC), which originated in the 2004 reauthorization of the Child Nutrition Act. HUSSC was a voluntary certification initiative designed to recognize schools that have created a healthy school environment through the promotion of nutrition and physical activity. Farm-to-school programs broadly refer to "efforts that bring regionally and locally produced foods into school cafeterias," with a focus on enhancing child nutrition. The goals of these efforts include increasing fruit and vegetable consumption among students, supporting local farmers and rural communities, and providing nutrition and agriculture education to school districts and farmers. HHFKA amended existing child nutrition programs to establish mandatory funding of $5 million per year for competitive farm-to-school grants that support schools and nonprofit entities in establishing farm-to-school programs that improve a school's access to locally produced foods. The FY2018 appropriations law provided an additional $5 million in discretionary funding to remain available until expended. Grants may be used for training, supporting operations, planning, purchasing equipment, developing school gardens, developing partnerships, and implementing farm-to-school programs. USDA's Office of Community Food Systems provides additional resources on farm-to-school issues. Through an Administrative Review process (formerly referred to as Coordinated Review Effort (CRE)), USDA-FNS, in cooperation with state agencies, conducts periodic on-site NSLP school compliance and accountability evaluations to improve management and identify administrative, subsidy claim, and meal quality problems. State agencies are required to conduct administrative reviews of all school food authorities (SFAs) that operate the NSLP under their jurisdiction at least once during a three-year review cycle. Federal Administrative Review expenditures were approximately $9.9 million in FY2017. USDA-FNS and state agencies conduct many other child nutrition program support activities for which dedicated funding is provided. Among other examples, there is the Institute of Child Nutrition (ICN), which provides technical assistance, instruction, and materials related to nutrition and food service management; it receives $5 million a year in mandatory funding appropriated in statute. ICN is located at the University of Mississippi. USDA-FNS provides training on food safety education. Funding is also provided for USDA-FNS to conduct studies, provide training and technical assistance, and oversee payment accuracy. Appendix A. Acronyms Used in This Report Appendix B. Per-meal or Per-snack Reimbursement Rates for Child Nutrition Programs This appendix lists the specific reimbursement rates discussed in the earlier sections of the report. Reimbursement rates are adjusted for inflation for each school or calendar year according to terms laid out in the programs' authorizing laws. Each year, the new rates are announced in the Federal Register . 
T he federal government pays benefits to coal miners affected by coal workers' pneumoconiosis (CWP, commonly referred to as black lung disease) and other lung diseases linked to coal mining in cases where the responsible mine operators are not able to pay. Benefit payments and related administrative expenses are paid out of the Black Lung Disability Trust Fund. The primary source of revenue for the trust fund is an excise tax on coal produced and sold domestically. If excise tax revenue is not sufficient to finance Black Lung Program benefits, the trust fund may borrow from the general fund of the Treasury, which contains federal receipts not earmarked for a specific purpose. For 2018, the tax rates on coal were $1.10 per ton of underground-mined coal or $0.55 per ton of surface-mined coal, limited to 4.4% of the sales price. Starting in 2019, under current law, these tax rates are $0.50 per ton of underground-mined coal or $0.25 per ton of surface-mined coal, limited to 2% of the sales price. This decline in the excise tax rates will likely put additional financial strain on a trust fund that already borrows from the general fund to meet obligations. The decline in domestic coal production, recent increases in the rate of CWP, and bankruptcies in the coal sector also contribute to the financial strain on the trust fund. This report provides background information and policy options to help inform the debate surrounding the coal excise tax rate, and other considerations related to the Black Lung Disability Trust Fund. The report begins with an overview of the federal black lung program, providing information on black lung disease and benefits under the program. The report proceeds to examine Black Lung Disability Trust Fund revenues, focusing on the coal excise tax and its history. The report closes with a discussion of policy options, evaluating various revenue- and benefits-related policy options that could improve the fiscal outlook of the Black Lung Disability Trust Fund. The Black Lung Disability Trust Fund is used to finance the payment of federal Black Lung Program benefits under Part C of the Black Lung Benefits Act (BLBA) when a responsible coal operator does not meet its obligations under the law to pay benefits. Coal workers' pneumoconiosis (CWP, commonly referred to as black lung disease) is an interstitial lung disease caused by the inhalation of coal dust. Like in other types of pneumoconioses, the inhalation of coal dust results in the scarring of the lung tissue and affects the gas-exchanging ability of the lungs to remove carbon dioxide and take oxygen into the bloodstream. Exposure to coal dust over an extended period of time can lead to CWP and continued exposure can lead to the progression from the early stages of CWP referred to as "simple CWP," to more advanced stages of scarring referred to as "complicated CWP" or progressive massive fibrosis (PMF). There is no cure for CWP and PMF. CWP can lead to loss of lung function, the need for lung transplantation, and premature death. CWP can be identified by observing light spots, or opacities, in x-ray images of the lungs and can be classified using guidelines established by the International Labour Organization (ILO). Despite technological advances in mining dust control, mandatory chest x-rays for miners, free CWP surveillance offered to miners by the National Institute for Occupational Safety and Health (NIOSH), the enactment of numerous pieces of mine safety and health legislation, and the promulgation and enforcement of mine safety and health standards by the Mine Safety and Health Administration (MSHA), CWP persists in American coal miners, especially those in the Appalachian region. After reductions in rates of PMF in the 1990s, this advanced form of CWP has recently been found in Central Appalachia at rates not seen since the early 1970s. In 2017 researchers discovered, among coal miners mostly living in Kentucky and Virginia and served by three federally funded Black Lung Clinics in Virginia, what may be the largest cluster of PMF ever recorded. This cluster of miners with PMF includes a relatively high number of miners with less than 20 years of mining experience as well as cases of PMF in current miners. The occurrence of this advanced stage of CWP in short-tenured and current miners is noteworthy since MSHA standards require that any miner with evidence of CWP be given the option, without loss of compensation or other penalty, to work in an area of the mining operation in which the average concentration of coal dust in the air is continuously maintained at or below an established level that is lower than the permissible exposure level for all miners with the goal of preventing the progression of CWP. The federal Black Lung Program was created in 1969 with the enactment of Title IV of the Federal Coal Mine Health and Safety Act of 1969 (Coal Act, P.L. 91-173, later renamed the Federal Mine Safety and Health Act of 1977 by P.L. 95-164 ). Section 401 of the Coal Act provides the congressional justification for the federal Black Lung Program and cites the lack of benefits for disability and death caused by CWP provided by existing state workers' compensation systems as justification for the creation of a federal program. This section also states that the program is intended to be a cooperative effort between the federal government and the states. The Coal Act also established mandatory safety and health standards for coal mines, including standards limiting exposure of miners to coal dust and giving miners with CWP the option of being moved, without loss of compensation or penalty, to an area of the mine with lower dust concentrations. The Coal Act was later amended by the Black Lung Benefits Act of 1972 (BLBA, P.L. 92-303). The Coal Act established Part B of the federal Black Lung Program to provide cash benefits to miners totally disabled due to CWP and to the survivors of miners who die from CWP. Part B only applies to cases filed on or before December 31, 1973. Part B benefits are paid out of general revenue and were initially administered by the Social Security Administration (SSA). Today, with the exception of a small number of pending appellate cases, Part B benefits are administered by the Department of Labor (DOL), Office of Workers' Compensation Programs (OWCP). The Coal Act established Part C of the Federal Black Lung Program for cases filed after December 31, 1973, and was later amended by the BLBA. Under Part C of the BLBA, all claims for benefits for disability or death due to CWP are to be filed with each state's workers' compensation system, but only if such systems have been determined by DOL as providing benefits that are equivalent to or greater than the cash benefits provided by the federal government under Part B of the BLBA and the medical benefits provided to disabled longshore and harbor workers under the federal Longshore and Harbor Workers' Compensation Act (LHWCA). If a state's workers' compensation system is not determined by DOL to meet these standards, then Part C benefits are to be paid by the each miner's coal employer, or, if no such employer is available to pay benefits, by the federal government. In 1973, Maryland, Kentucky, Virginia, and West Virginia submitted their state workers' compensation laws to DOL for approval, but were denied. To date, no state workers' compensation system has been approved by DOL under Part C of the BLBA. Because no state's workers' compensation system has been determined to be sufficient to pay benefits under Part C, each operator of an underground coal mine is responsible for the payment of benefits to that operator's miners. Operators are required to provide for these benefits either by purchasing insurance for benefits or through self-insurance approved by DOL. A self-insured operator is required to purchase an indemnity bond or provide another form of security (such as a deposit of negotiable securities in a Federal Reserve Bank or the establishment of a trust) in an amount specified by DOL. In order to be approved for self-insurance, federal regulations require that a mine operator have been in business for at least the three previous years and have average assets over the previous three years that exceed current liabilities by the sum of expected benefit payments and annual premiums on the indemnity bond. When a claim for benefits is approved, benefits are to be paid by the "responsible" operator, which is generally the last coal operator to employ the miner. If a company has acquired the assets of a mine operator, then that company is considered a "successor operator" and is responsible for the payment of claims related to the original operator. The federal government pays benefits in cases in which the responsible operator no longer exists and has no successor operator, or is unable to pay benefits. The federal government pays benefits when an operator has not made payment within 30 days of a determination of eligibility or when benefits are otherwise due to be paid. Initially, under Part C of the Coal Act, these federal benefits were paid out of general revenue. However, pursuant to the Black Lung Benefits Revenue Act of 1977 ( P.L. 95-227 ), these benefits are now paid from the Black Lung Disability Trust Fund established by this law and primarily financed by an excise tax on coal. If a responsible operator can later be identified, the trust fund is authorized by law to seek to recover from this operator the amount of benefits paid by the trust fund and any interest earned on these amounts. The trust fund is also used for the following federal Black Lung Program-related expenses: the payment of benefits for miners whose last coal mine employment was before January 1, 1970; reimbursement to the Treasury for the costs of Part C benefits paid from general revenue before April 1, 1978, for periods of benefit eligibility after January 1, 1974; the repayment and payment of interest on advances made from the general fund to the trust fund; the payment of administrative expenses related to Part C of the BLBA and the coal excise tax incurred after March 1, 1978; and the reimbursement of coal operators who paid Part C benefits before April 1, 1978, for miners whose last coal mine employment ended before January 1, 1970. A miner is eligible for benefits if that miner is totally disabled due to pneumoconiosis arising out of coal mine employment. The survivors of a miner are eligible for benefits if the miner's death was due to pneumoconiosis arising out of coal mine employment. Benefits are only available to miners and their survivors. The BLBA defines a miner as any individual who works or has worked in or around a coal mine or coal preparation facility in the extraction or preparation of coal. Such term also includes an individual who works or has worked in coal mine construction or transportation in or around a coal mine, to the extent such individual was exposed to coal dust as a result of such employment. Thus, other workers who may be exposed to coal dust in their work, such as railroad workers or workers at coal-fired power plants are not eligible for benefits. Persons who live near coal mines or power plants are also not eligible for benefits even if they are exposed to coal dust. In addition, while a miner's family members may receive benefits as survivors and the number of family members can increase the amount of a miner's monthly benefits, family members may not claim benefits on their own due to exposure to coal dust in the home such as from cleaning the miner's soiled clothing. The BLBA defines pneumoconiosis for the purposes of benefit eligibility as "a chronic dust disease of the lung and its sequelae, including respiratory and pulmonary impairments, arising out of coal mine employment." The BLBA directs the Secretary of Labor to develop, through regulations, standards for determining if a miner is totally disabled due to pneumoconiosis or died due to pneumoconiosis. The federal Black Lung Program regulations provide that the definition of pneumoconiosis includes medical or "clinical" pneumoconiosis and statutory or "legal" pneumoconiosis. Clinical pneumoconiosis is defined as follows: "Clinical pneumoconiosis" consists of those diseases recognized by the medical community as pneumoconioses, i.e., the conditions characterized by permanent deposition of substantial amounts of particulate matter in the lungs and the fibrotic reaction of the lung tissue to that deposition caused by dust exposure in coal mine employment. This definition includes, but is not limited to, coal workers' pneumoconiosis, anthracosilicosis, anthracosis, anthrosilicosis, massive pulmonary fibrosis, silicosis or silicotuberculosis, arising out of coal mine employment. Legal pneumoconiosis is defined as any chronic lung disease or impairment and its sequelae arising out of coal mine employment. This definition includes, but is not limited to, any chronic restrictive or obstructive pulmonary disease arising out of coal mine employment. Through these definitions, DOL has established that benefits are available not just to miners with CWP, but also to those miners with other respiratory diseases arising out of coal mine employment such as chronic obstructive pulmonary disease (COPD) even though these diseases are not pneumoconioses and may be linked to other factors unrelated to exposure to coal dust such as cigarette smoking. The BLBA contains five presumptions used to determine if a miner is eligible for black lung benefits. Three of these presumptions are "rebuttable," meaning that, in the absence of any contrary evidence, eligibility is presumed. One presumption is "irrebutable" and eligibility for Black Lung program benefits is established if the statutory requirements of the presumption are met. Three of these presumptions apply to current Black Lung Program claims while two apply only to cases filed before the end of 1981. Table 1 provides a summary of the following five presumptions provided by the BLBA. 1. A rebuttable presumption that the pneumoconiosis of a miner who was employed in mining for at least 10 years was caused by his or her employment. 2. A rebuttable presumption that the death of a miner who worked in mining for at least 10 years and who died of any respirable disease, was due to pneumoconiosis. This presumption does not apply to claims filed on or after January 1, 1982, the effective date of the Black Lung Benefits Amendments of 1981 ( P.L. 97-119 ). 3. An irrebuttable presumption that a miner with any chronic lung disease which meets certain statutory tests or diagnoses is totally disabled due to pneumoconiosis or died due to pneumoconiosis. 4. A rebuttable presumption that a miner employed in mining for at least 15 years, and who has a chest x-ray that is interpreted as negative with respect to certain statutory standards but who has other evidence of a totally disabling respiratory or pulmonary impairment, is totally disabled due to pneumoconiosis or died due to pneumoconiosis. This presumption may only be rebutted by the Secretary of Labor establishing that the miner does not or did not have pneumoconiosis or that the miner's respiratory or pulmonary impairment did not arise out of connection to mine employment. 5. A presumption that a miner who died on or before March 1, 1978, and who was employed in mining for at least 25 years before June 30, 1971, died due to pneumoconiosis, unless it is established that at the time of the miner's death, he or she was not at least partially disabled due to pneumoconiosis. This presumption does not apply to claims filed on or after June 29, 1982, which is 180 days after the effective date of the Black Lung Benefits Amendments of 1981. This presumption is not listed in the law as either rebuttable or irrebuttable. The Patient Protection and Affordable Care Act (commonly referred to as the Affordable Care Act (ACA), P.L. 111-148 ) included two provisions that amended the BLBA to reinstate one of the eligibility presumptions and a provision affecting survivors' benefits. The effect of these changes was to increase the opportunity to establish eligibility through the statutory presumptions and make it easier for certain survivors to receive benefits. Pursuant to Section 202(a) of the Black Lung Benefits Amendments of 1981, the fourth presumption did not apply to cases filed on or after January 1, 1982. Section 1556(a) of the ACA removed the prohibition on applying the fourth presumption to cases filed on or after January 1, 1982. It is expected that this ACA provision will increase the number of miners eligible for benefits. The BLBA provides that, for Part C claims, the survivors of a miner who was determined to be eligible to receive benefits at the time of his or her death are not required to file new claims for benefits or revalidate any claim for benefits, thus permitting the payment of survivors' benefits in these cases even if the miner's death was not caused by pneumoconiosis. Pursuant to Section 203(a)(6) of the Black Lung Benefits Amendments of 1981, this provision did not apply to claims filed on or after January 1, 1982. Section 1556(b) of the ACA removed from this provision the exception for claims filed on or after January 1, 1982. It is expected that this ACA provision will increase the number of survivors eligible for benefits. The amendments to the BLBA provided in Section 1556 of the ACA apply to any claims filed under Part B or C of the act after January 1, 2005, that were pending on or after March 23, 2010, the date of enactment of the ACA. Eligible miners receiving benefits under Parts B and C are entitled to medical coverage for their pneumoconiosis and related disability. This medical coverage is provided at no cost to the miner and can generally be obtained from the miner's choice of medical providers. Eligible miners are also entitled to cash disability benefits. The basic benefit rate is set at 37.5% of the basic pay rate at GS-2, Step 1, on the federal pay schedule without any locality adjustment. If the miner has one dependent (a spouse or minor child) the miner is eligible for a benefit of 150% of the basic benefit. A miner with two dependents is eligible for 175% of the basic benefit and a miner with three or more dependents is eligible for 200% of the basic benefit. Benefits may also be paid to the divorced spouse of a miner if the marriage lasted at least 10 years and the divorced spouse was dependent on the miner for at least half of the spouse's support at the time of the miner's disability. A child is considered a dependent until the child marries, or reaches age 18, unless the child is either disabled using the Social Security Disability Insurance (SSDI) definition of disability or is under the age of 23 and a full-time student. The benefit rates are adjusted whenever there are changes to the federal employee pay schedules, but are not separately adjusted to reflect changes in the cost of living. Table 2 provides the benefit rates for 2019. Benefits are offset by state workers' compensation or other benefits paid on account of the miner's disability or death due to pneumoconiosis. Part C benefits, but not Part B benefits, are considered workers' compensation for the purposes of reducing a miner's SSDI benefits. The total amount paid in cash disability benefits has fallen over time, as illustrated in Figure 1 . More is paid in cash disability benefits than is paid in medical benefits. Certain survivors of a miner whose death was due to pneumoconiosis are eligible for cash benefits. In the case of a surviving spouse or divorced spouse, the spouse's benefit is equal to what the miner would have received and is based on the number of dependents of the spouse as provided in Table 2 . If there is no surviving spouse, then benefits are awarded to the surviving minor children in equal shares. If there are no surviving minor children, then benefits can be paid to the miner's dependent parents or dependent siblings. If there are no eligible survivors, no benefits are paid upon the miner's death and benefits do not go to the miner's estate or to any other person, including a person named by the miner in a will. The number of miners and survivors receiving benefits has declined over time, as illustrated in Figure 2 . The primary revenue source for the Black Lung Disability Trust Fund is a per-ton excise tax on coal. Historically, the coal excise tax has not generated enough revenue to meet the trust fund's obligations. Thus, additional funds have been provided from the general fund of the Treasury. The general fund includes governmental receipts not earmarked for a specific purpose, the proceeds of general borrowing, and is used for general governmental expenditures. Internal Revenue Code (IRC) Section 4121 imposes the black lung excise tax (BLET) on sales or use of domestically mined coal. Generally, a producer that sells the coal is liable for the tax. Producers that use their own domestically mined coal, such as integrated utilities or steel companies, are also liable for the tax. The tax rate depends on how coal is mined. Effective January 1, 2019, the tax on underground-mined coal is the lesser of (1) $0.50 per ton, or (2) 2% of the sale price. The tax on surface-mined coal is the lesser of (1) $0.25 per ton, or (2) 2% of the sales price. Before 2019, the tax rates were $1.10 per ton for coal from underground mines or $0.55 per ton for coal from surface mines, with the tax being no more than 4.4% of the sale price. In FY2017, $229 million was collected on coal mined underground (see Figure 3 ). Nearly all of this coal was taxed at the $1.10 per ton rate. In FY2017, $200 million was collected on surface-mined coal. Just over half of this coal was taxed at the $0.55 per ton rate, with the rest subject to the 4.4% of sales price maximum tax. On January 1, 2019, the BLET rates declined to their current levels. The rates that took effect January 1, 2019, would also have taken effect if the Black Lung Disability Trust Fund had repaid, with interest, all amounts borrowed from the General Fund of the Treasury. The tax is imposed on "coal from mines located in the United States" and does not apply to imported coal. The tax is designed to support the Black Lung Disability Trust Fund for domestic miners. Very little domestically consumed coal is imported. The BLET also does not apply to exported coal under the Export Clause of the United States Constitution. A credit or refund can be claimed if coal is taxed before it is exported. Black lung excise tax collections have generally declined in recent years (see Figure 3 ). In FY2009, more than $650 million was collected from the BLET. In FY2017, collections were about $429 million. The decline in BLET collections follows the general decline in U.S. coal production. As the price of coal rose in the 2000s, coal mined underground tended to pay the tax at a fixed rate of $1.10 per ton, as opposed to paying 4.4% of the sales price. In the years beyond 2018, coal excise tax receipts are expected to fall sharply, reflecting the decrease in the coal excise tax rate (see Figure 3 ). The excise tax on coal was established to help ensure the coal industry shared in the social costs imposed by black lung disease. Over time, the rate of the tax has been increased, in an effort to provide sufficient revenue to meet this objective. The Black Lung Benefits Revenue Act of 1977 ( P.L. 95-227 ) first imposed the Section 4121 excise tax on coal. When enacted, the tax was $0.50 per ton for coal from underground mines, and $0.25 per ton for coal from surface mines. The tax was limited to 2% of the sales price. The tax was effective for sales after March 31, 1978. Before P.L. 95-227 was enacted there was considerable debate surrounding how black lung benefits programs should be financed. Various mechanisms to shift the costs of the black lung benefits program to the coal industry and its customers were considered. These debates ultimately led to the establishment of the Black Lung Disability Trust Fund and the related excise tax on coal. There was also debate about how to structure the proposed tax. Some suggested a graduated tax, with higher rates imposed on coal with a higher British thermal unit (Btu) content, as such coal was believed to be more likely to cause black lung disease. There were concerns, however, that such a tax could be difficult to administer. Other proposals suggested that coal be subject to a uniform rate, with coal mined from underground deposits subject to a higher rate than other coal (including lignite). A concern with this approach was that coal prices vary substantially per ton for different types of coal (lignite is less expensive than anthracite), meaning that the tax as a percent of the sales price could differ substantially across different types of coal. One answer to this concern is to impose an ad valorem tax, or a tax based on the sales price. Another approach that was considered was to impose a "premium rate" at a level that would fully finance the Black Lung Disability Trust Fund, giving authority to the Department of Labor to adjust the fee as necessary. The tax as enacted was the lesser of the per-unit price or the ad valorem rate of 2%. In the early 1980s, it was observed that coal excise tax revenues were not sufficient to meet the trust fund's obligations. The Black Lung Benefits Revenue Act of 1981 ( P.L. 97-119 ) doubled the excise tax rates to $1.00 per ton for coal from underground mines, and $0.50 per ton for coal from surface mines, not to exceed 4% of the sales price. The higher rates were effective January 1, 1982. The doubled rates were temporary, and scheduled to revert to the previous rates on January 1, 1996. Further, the rates could be reduced earlier if the trust fund repaid all advances and interest from the general fund of the Treasury. A stated goal of this legislation was to eliminate the Black Lung Disability Trust Fund's debt. The Consolidated Omnibus Budget Reconciliation Act of 1985 ( P.L. 99-272 ) again increased the BLET rates to $1.10 for underground-mined coal, and $0.55 for surface-mined coal, not to exceed 4.4% of the sales price. The Omnibus Budget Reconciliation Act of 1987 ( P.L. 100-203 ) extended these rates through 2013. Increased excise tax rates on coal were again extended in 2008. Current-law rates were extended through 2018 as part of the Emergency Economic Stabilization Act of 2008 (EESA; P.L. 110-343 ). When extending the increased rates, Congress reiterated the original intent of establishing trust fund financing for black lung benefits, observing that it is "to reduce reliance on the Treasury and to recover costs from the mining industry." It was also observed that the program's expenses had continued to exceed revenues over time, and that the debt to the Treasury was not likely to be paid off by 2013. For these reasons, "the Congress believe[d] that it [was] appropriate to continue the tax on coal at the increased rates beyond the expiration date." When receipts of the trust fund are less than expenditures, advances are appropriated from the general fund of the Treasury to the trust fund. These advances are repayable, and interest charged on these advances is also payable to the general fund. The Consolidated Omnibus Budget Reconciliation Act of 1985 ( P.L. 99-272 ) provided a five-year forgiveness of interest on debt owed to the Treasury's general fund. As a result, the principal amount of trust fund debt outstanding was relatively unchanged throughout the late 1980s. The moratorium on interest payments ended September 30, 1990. Throughout the 1990s and into the 2000s, the cumulative end-of-year debt of the trust fund grew, and the trust fund continued to receive repayable advances from the general fund to cover expenses. The trust fund was subject to financial restructuring when the current excise tax rate was extended until January 1, 2019, in EESA. The Black Lung Disability Trust Fund debt was restructured in FY2009. Essentially, the partial forgiveness and restructuring allowed the trust fund to refinance outstanding repayable advances and unpaid interest on those advances. As a result of the partial forgiveness and refinancing, the cumulative debt was reduced from $10.4 billion at the end of FY2008 to $6.2 billion by the end of FY2009. At the time of the restructuring it was expected that the trust fund's debt would be fully eliminated by FY2040. The trust fund's cumulative debt has trended downward since the restructuring (see Figure 4 ). However, coal excise tax revenue has been less than anticipated in recent years. As a result, current projections suggest that the trust fund debt will rise over time when considering annual borrowing as well as legacy debt. The trust fund's debt is therefore not on a path to be eliminated. By FY2050, the Government Accountability Office (GAO) projects the trust fund's debt will be $15.4 billion without any changes in current policy. In addition to revenue from the BLET and repayable general fund advances, the trust fund receives revenue from the collection of certain fines, penalties, and interest paid by coal operators and miners and reimbursements from responsible operators. Part C of the BLBA authorizes the following fines and penalties for violations of the act: a civil penalty of up to $1,000 per day for a mine operator's failure to secure benefits through insurance or approved self-insurance; a fine of up to $1,000 upon conviction of the misdemeanor offense of knowingly destroying or transferring property of a mine operator with the intent to avoid the payment of benefits for which the mine operator is responsible; a fine of up to $1,000 upon conviction of the misdemeanor offense of making a false or misleading statement or representation for the purposes of obtaining benefits; and a civil penalty of up to $500 for a mine operator's failure to file a report on miners who are or may be entitled to benefits as required by DOL. The amount of these penalties and fines, as well as interest assessed, is paid into the trust fund. In FY2017, trust fund receipts from fines, penalties, and interest totaled $1.2 million. This is a small source of trust fund revenue relative to the coal excise tax, which generated $428.7 million in trust fund revenues in FY2017. The trust fund is authorized to begin paying benefits within 30 days if no responsible operator has begun payment. If, after paying benefits, DOL is able to identify a responsible operator, the trust fund may seek to collect from that operator the costs of benefits already paid by the trust fund and interest assessed on this amount. The amount of these collections is paid into the trust fund. In FY2017, $19.9 million was collected from responsible mine operators. The amount collected from responsible mine operators has fluctuated over time, but has averaged about 1% of total receipts since 1995. Various factors have contributed to the ongoing situation of trust fund expenditures exceeding trust fund revenues. Throughout the 1980s, black lung benefit payments and administrative expenditures exceeded trust fund revenue. As a result, the trust fund accumulated debt. As discussed above, over time, various efforts have been made to improve the fiscal condition of the trust fund. However, as of the end of FY2017, the trust fund remains in debt. The trust fund's cumulative debt at the end of FY2017 was $3.1 billion. The trust fund also borrowed $1.3 billion from the general fund that same year. Projections suggest that borrowing from the general fund will increase over the next few years, even as cumulative (or legacy) debt is paid down. Under the current excise tax rates, benefit payments and administrative expenses will be approximately equal to trust fund revenues in FY2020 through FY2022 (see Figure 5 ). However, revenues are not projected to be sufficient to repay debt, and expenses are projected to rise over time when debt and interest expenses are included. Specifically, by FY2022, it is projected that the trust fund will borrow $2.6 billion in repayable advances from the general fund. There are various policy options that Congress might consider to improve the fiscal condition of the Black Lung Disability Trust Fund. Broadly, increasing taxes on the coal industry (or maintaining 2018 rates) would pass the costs associated with paying black lung benefits onto the coal industry. Alternatively, forgiving trust fund interest or debt or financing black lung benefits out of general fund revenues would pass the costs of federal black lung benefits onto taxpayers in general. Another option would be to reduce federal black lung benefits. Additional revenue would likely need to be provided to the trust fund if the trust fund is to pay for past black lung benefits and maintain current benefit levels. Additional revenue may be needed even if past debt is forgiven (or assumed by the general fund), as anticipated trust fund revenues are not likely to be sufficient to cover anticipated trust fund expenditures. As discussed above, in the past, Congress and the President have opted to increase the excise tax on coal to address shortfalls in the Black Lung Disability Trust Fund. These increased rates have been temporary, and scheduled to revert back to the reduced rate if the trust fund's debt is eliminated. Congress has chosen to extend the increased rates beyond their scheduled expiration when the trust fund is in debt. One option would be to extend 2018 rates.. The GAO projects that if 2018 coal excise tax rates are extended, the trust fund will have a debt of $4.5 billion in 2050 (see "GAO Options for Improving Trust Fund Finances" below). GAO projections suggest that increasing 2018 tax rates by 25% would eliminate the trust fund's debt, leaving the trust fund with a surplus of $0.6 billion in 2050. An alternative way to raise revenue from the coal industry is to scale back or eliminate various tax expenditures, or tax preferences, from which the coal industry benefits. For example, coal producers benefit from being able to expense exploration and development costs and are able to recover costs using percentage depletion (depletion based on revenue from the sale of the mineral asset) instead of cost depletion (depletion based on the amount of the mineral asset exhausted and the amount invested in the asset). The Obama Administration regularly proposed repealing these tax incentives as part of the Administration's annual budget. It could be difficult to assign the revenues raised via the repeal of tax benefits to the trust fund. With an excise tax, it is straightforward to identify the revenue generated by the tax and earmark the revenue for a trust fund. It is not as straightforward to determine the amount of revenue that is raised through the repeal of an income tax expenditure, or direct the additional revenue raised because a certain preference is no longer in the code to a trust fund. Repeal of coal-industry tax benefits could, however, be used to offset the cost of a one-time transfer from the general fund to the trust fund. Revenue from various sources, including the general fund, could be used to supplement trust fund revenue generated from current sources. General fund revenues are not earmarked for a specific purpose, and there is generally no direct link between the source of general fund revenue and the government good or service provided. Black lung benefits were paid out of general revenue before the trust fund was established in 1977. Trust funds are generally established when there is a link between the government benefits or services being provided and the revenue source funding those benefits or services. The Black Lung Disability Trust Fund was established because Congress believed that the costs of the part C black lung program should be borne by the coal industry. Financing black lung benefits with general fund revenue would weaken the link between the industry and black lung benefits, while reducing the burden on the industry associated with paying for black lung benefits. In the past the Black Lung Disability Trust Fund's fiscal outlook has been improved through interest and debt forgiveness. As discussed above, in the late 1990s, there was a five-year forgiveness of interest on debt owed to the Treasury's general fund. More recently, debt was forgiven as part of the 2008 restructuring of the trust fund's debt. The GAO projects that if all current debt were forgiven, the trust fund would accumulate $2.3 billion in new debt by 2050. If all interest were forgiven, the trust fund debt is projected to be $5.8 billion by 2050. Forgiving the trust fund's interest or debt obligations would shift the burden of paying for black lung disability benefits from the coal industry to general taxpayers. However, a one-time appropriation to forgive interest or debt is a transparent option for satisfying the trust fund's obligations to the general fund. The primary expenditures of the trust fund are for the payment of Part C benefits to miners in cases in which there is no responsible operator. In order to reduce expenditures and improve the long-term financial health of the trust fund, Congress could consider several options to reduce the generosity and scope of benefits or increase the ability of the federal government to ensure that coal operators, even those who are in the bankruptcy process, pay benefits for their miners. A reduction in the amount of Part C benefits would result in lower Part C expenditures from both responsible coal operators and the trust fund. However, as compared to other workers' compensation benefits, Part C benefits are relatively low. The basic Part C benefit rate for a single miner is equal to 37.5% of the base rate of pay for federal employees at the GS-2, Step 1 level. For 2019 this benefit is just over $660 per month, or under $8,000 per year. In the majority of state workers' compensation programs, the basic benefit rate is set at two-thirds of the worker's pre-disability wage, subject to statutory minimums and maximums. The other workers' compensation programs administered by DOL, the LHWCA, and the Federal Employees' Compensation Act (FECA) use two-thirds of a worker's pre-disability wage as the basis for their benefits. A federal worker with a spouse or dependent in the FECA program is entitled to 75% of his or her pre-disability wage. The minimum benefit for total disability or death in the FECA program, 75% of GS-2, Step 1, is twice the amount of the Part C benefit rate. In addition, unlike the other federal workers' compensation programs and many state programs, there is no automatic adjustment to Part C benefits to reflect increases in the cost of living. Part C benefits instead increase only when federal pay rates are increased. The eligibility of miners and survivors to Part C benefits could be restricted to reduce expenditures from responsible operators and the trust fund. In 1981, Congress enacted several eligibility restrictions to miners and survivors as part of the Black Lung Benefits Revenue Act of 1981, to address concerns about the financial insolvency of the trust fund. Specifically, this law removed the following three eligibility presumptions for new claims going forward: A rebuttable presumption that the death of a miner who worked in mining for at least 10 years and who died of any respirable disease, was due to pneumoconiosis (listed as presumption 2 in Table 1 ). A rebuttable presumption that a miner employed in mining for at least 15 years, and who has a chest x-ray that is interpreted as negative with respect to certain statutory standards but who has other evidence of a totally disabling respiratory or pulmonary impairment, is totally disabled due to pneumoconiosis, or died due to pneumoconiosis. This presumption may only be rebutted by the Secretary of Labor establishing that the miner does not or did not have pneumoconiosis or that the miner's respiratory or pulmonary impairment did not arise out of connection to mine employment (presumption 4 in Table 1 ). A presumption that a miner who died on or before March 1, 1978, and who was employed in mining for at least 25 years before June 30, 1971, died due to pneumoconiosis, unless it is established that at the time of the miner's death, he or she was not at least partially disabled due to pneumoconiosis (presumption 5 in Table 1 ). In addition to removing three of the five existing eligibility presumptions, the 1981 law also removed the right of the survivors of a miner who is determined to be eligible for Part C benefits at the time of his or her death to receive survivors' benefits without filing a new claim, thus permitting the payment of survivors' benefits in the case of a current beneficiary, even if the beneficiary's death is not proven to be linked to pneumoconiosis. Two of the restrictions put in place by the 1981 legislation were later removed by the ACA. The ACA reinstated the fourth eligibility presumption and expanded rights for survivors' benefits, thus expanding eligibility for both miners and certain survivors. Under Part C of the BLBA, the federal government may recover the costs of benefits, and interest accrued on those benefits, paid by the trust fund from identified responsible operators. In addition, Part C allows the federal government to place a lien on the property and rights to property of an operator that refuses to pay the benefits and interest it owes to the trust fund. In the case of a bankruptcy or insolvency proceeding, this lien is to be treated in the same manner as a lien for taxes owed to the federal government. However, in a 2016 letter to the Comptroller General requesting a GAO review of the trust fund, Representatives Bobby Scott, Ranking Member of the House Committee on Education and the Workforce, and Sander Levin, Ranking Member of the House Committee on Ways and Means, claimed that the number of current and potential bankruptcies among coal operators is placing stress on the trust fund. Representatives Scott and Levin cited the example of Patriot Coal which, according to their letter, transferred $62 million in Part C liabilities to the trust fund when it became insolvent. In addition, this letter claims that insolvent coal operators may be able to avoid trust fund liens by continuing to make benefit payments until after the court in their bankruptcy cases has approved the sale of their assets to another company. Because the original company was never in default of its payments, no lien was filed, and these assets were able to be purchased by another company without any lien or future liability to the trust fund. Congress may examine the issue of the impact of coal operator bankruptcies and the interaction of bankruptcy law and the BLBA's lien provisions, to strengthen both the federal government's ability to ensure that responsible operators are paying for benefits and reduce the benefit expenditures of the trust fund.
Puerto Rico, which has approximately 3.3 million residents according to U.S. Census Bureau (Census) estimates, is the largest and most populous territory of the United States. As a territory, Puerto Rico is subject to congressional authority, though Congress has granted it broad authority over matters of internal governance—notably, by approving Puerto Rico’s constitution in 1952. Individuals born in Puerto Rico are U.S. citizens and can migrate freely to the states. Puerto Rico and its residents are generally subject to the same federal laws as the states and their residents, except in cases where specific exemptions have been made, such as with certain federal programs. For example, Puerto Rico residents generally have full access to Social Security and unemployment insurance; however, for some programs, such as Medicaid, federal funding in Puerto Rico is restricted as compared to funding in the states. Residents of Puerto Rico are exempt from paying federal income tax on income from sources in Puerto Rico. Residents are required to pay federal income tax on income from sources outside of Puerto Rico. They are also required to pay federal employment taxes, such as Social Security and Medicare taxes, on their income regardless of where it was earned. Puerto Rico residents are also ineligible for certain federal tax credits. Corporations located in Puerto Rico are generally subject to the same federal tax laws as corporations located in a foreign country. Corporations in Puerto Rico are generally exempt from federal taxes on profits except as such profits are effectively connected to a trade or business in the states, and so long as those profits remain held outside of the states. Additionally, these corporations were subject to a withholding tax on certain investment income from the United States not connected to a trade or business. Under the 2017 Public Law 115-97, starting in 2018 U.S. corporations that are shareholders in foreign corporations, such as those organized under Puerto Rico law, generally do not owe tax on dividends received from those foreign corporations. Prior to this law, dividend payments to U.S. corporate shareholders were considered taxable interest for the U.S. parent corporation. Prior to 1996, a federal corporate income tax credit—the possessions tax credit—was available to certain U.S. corporations that located in Puerto Rico. In general, the credit equaled the full amount of federal tax liability related to an eligible corporation’s income from its operations in a possession—including Puerto Rico—effectively making such income tax- free. In 1996, the tax credit was repealed, although corporations that were existing credit claimants were eligible to claim credits through 2005. Puerto Rico’s economy is in a prolonged period of economic contraction. According to data from Puerto Rico’s government, Puerto Rico’s economy grew in the 1990s and early 2000s. However, between 2005 and 2016— the latest year for which data were available as of March 1, 2018—Puerto Rico’s economy experienced year-over-year declines in real output in all but two years, as measured by real gross domestic product (GDP). From 2005 to 2016, Puerto Rico’s real GDP fell by more than 9 percent (from $82.8 billion to $75.0 billion in 2005 dollars). Puerto Rico’s gross national product (GNP) followed a similar pattern over the same period, declining by more than 11 percent from 2005 to 2016 (from $53.8 billion to $47.7 billion in 2005 dollars). Figure 1 shows Puerto Rico’s real GDP and GNP growth rates from 1991 through 2016. The decline in Puerto Rico’s output has, in more recent years, occurred in conjunction with a decline in Puerto Rico’s population. According to Census estimates, Puerto Rico’s population declined from a high of approximately 3.8 million people in 2004 to 3.3 million people in 2017, a decline of 12.8 percent. This population loss closely matched the decline in real output. From 2004 to 2016, Puerto Rico’s real GNP fell by 9.5 percent, while its real GNP per capita increased by 1.6 percent over the same time period. In addition to Puerto Rico’s declining population, the territory also has a lower share of employed persons compared to the United States as a whole. As of 2017, approximately 37 percent of Puerto Rico residents were employed compared to approximately 60 percent for the United States as a whole. Puerto Rico’s employment-to-population ratio reached highs in 2005 and 2006 when it was approximately 43 percent, according to data from the Federal Reserve Bank of St. Louis. According to data from the Bureau of Labor Statistics (BLS), between 2005 and 2017, Puerto Rico’s unemployment rate fluctuated between 10.2 percent and 17.0 percent, with an average of 13.1 percent. During the same period, the nationwide unemployment rate fluctuated between 4.1 percent and 10.0 percent, with an average of 6.5 percent. These factors have combined to leave Puerto Rico with a small and declining labor force. From January 2006 to December 2017—the latest month for which data were available as of March 1, 2018—Puerto Rico’s labor force decreased from approximately 1.4 million persons to 1.1 million persons, according to data from BLS. Puerto Rico’s government has operated with a deficit—where expenses exceed revenues—in each fiscal year since 2002, and its deficits grew over time (see figure 2). Puerto Rico’s governmental activities can be divided among the primary government and component units. Puerto Rico’s primary government provides and funds services such as public safety, education, health care, and economic development. Puerto Rico’s component units are legally separate entities for which its government is nonetheless financially accountable, and provide services such as public transportation, highways, electricity, and water. In fiscal year 2014, the latest for which audited financial data are available, the Puerto Rico government collected $32.5 billion in revenue, of which $19.3 billion was collected by the primary government, and $13.2 billion was collected by the component units. That year Puerto Rico’s government spent $38.7 billion, of which $22.0 billion was spent directly by the primary government, while $16.7 billion was spent by the government’s various component units. The Puerto Rico Electric Power Authority (PREPA), which operates the territory’s electricity generation and distribution infrastructure, represented the largest component unit expenditure in fiscal year 2014. Figures 3 and 4 show a breakdown of expenses for Puerto Rico’s primary government and its component units, respectively. Puerto Rico’s government spending accounts for more than a third of the territory’s GDP. In fiscal year 2014—the latest year for which audited spending data were available as of March 1, 2018—primary government expenditures of $22.0 billion represented 21 percent of the territory’s GDP. Including component spending, total public expenditures were $38.7 billion, which represented 38 percent of the territory’s GDP. By comparison, our prior work has shown that in 2014, total state and local government expenditures represented about 14 percent of GDP for the United States as a whole, excluding territories. Federal government expenditures were 20 percent of GDP for the United States as a whole in 2014. Puerto Rico’s total public debt as a share of its economy has grown over time. In 2002, the value of its debt was 42 percent of the territory’s GDP, and 67 percent of its GNP. Both of these ratios grew over time such that by 2014, Puerto Rico’s total public debt was 66 percent of the territory’s GDP and 99 percent of its GNP. Figure 5 compares Puerto Rico’s total public debt to its GDP and GNP, in both aggregate and per capita. As of the end of fiscal year 2014, the last year for which Puerto Rico issued audited financial statements, Puerto Rico had $67.8 billion in net public debt outstanding, or $68.1 billion excluding accounting adjustments that are not attributed in the financial statements to specific agencies. Of the $68.1 billion, $40.6 billion was owed by Puerto Rico’s primary government, and $27.6 billion was owed by its component units, as shown in figure 6 (these amounts do not sum to $68.1 billion because of rounding). The growth of Puerto Rico’s total debt resulted in greater annual debt servicing obligations. In fiscal year 2002, it cost Puerto Rico $2.7 billion to service its debt, representing about 12 percent of Puerto Rico’s $21.6 billion in total public revenue for that year. By fiscal year 2014, Puerto Rico’s annual debt service cost rose to $5.0 billion, representing just over 15 percent of Puerto Rico’s $32.5 billion in total public revenue for that year. Following years of expenditures that exceeded revenue, and a growing debt burden, in August 2015, Puerto Rico failed to make a scheduled bond payment. Since then, Puerto Rico has defaulted on over $1.5 billion in debt. In June 2016, Congress enacted and the President signed PROMESA in response to Puerto Rico’s fiscal crisis. PROMESA established a Financial Oversight and Management Board for Puerto Rico (Oversight Board), and granted it broad powers of fiscal and budgetary control over Puerto Rico. PROMESA also established a mechanism through which the Oversight Board could petition U.S. courts on Puerto Rico’s behalf to restructure debt. Under federal bankruptcy laws, Puerto Rico is otherwise prohibited from authorizing its municipalities and instrumentalities from petitioning U.S. courts to restructure debt. The Oversight Board petitioned the U.S. courts to restructure debt on behalf of Puerto Rico’s Highways and Transportation Authority and the Government Employees Retirement System on May 21, 2017 and on behalf of PREPA on July 2, 2017. In addition to its debt obligations, Puerto Rico also faces a large financial burden from its pension obligations for public employees. Puerto Rico’s public pension systems had unfunded liabilities of approximately $49 billion as of the end of fiscal year 2015, the most recent year for which data are available. Unfunded pension liabilities are similar to other kinds of debt because they constitute a promise to make a future payment or provide a benefit. Based on interviews with current and former Puerto Rico officials, federal officials, and other relevant experts, as well as a review of relevant literature, the factors that contributed to Puerto Rico’s financial condition and levels of debt related to: (1) Puerto Rico’s government running persistent deficits and (2) its use of debt to cope with deficits. As previously mentioned, Puerto Rico’s government has operated with a deficit in all years since 2002, and deficits grew over time. To cope with its deficits, Puerto Rico’s government issued debt to finance operations, rather than reduce its fiscal gap by cutting spending, raising taxes, or both. Through interviews with current and former Puerto Rico officials; federal officials; experts in Puerto Rico’s economy, the municipal securities markets, and state and local budgeting and debt management; as well as a review of relevant literature, we identified three groups of factors that contributed to Puerto Rico’s persistent deficits: (1) inadequate financial management and oversight practices, (2) policy decisions, and (3) prolonged economic contraction. Some of the factors in these groups may be interrelated. To cope with its persistent deficits, Puerto Rico issued debt to finance operations. In reviewing 20 of Puerto Rico’s largest bond issuances from 2000 to 2017, totaling around $31 billion, we found that 16 were issued exclusively to repay or refinance existing debt and to fund operations. According to ratings agency officials and experts in state and local government, states rarely issue debt to fund operations, and many states prohibit this practice. According to former Puerto Rico officials and experts on Puerto Rico’s economy, high demand for Puerto Rico debt and the Government Development Bank for Puerto Rico (GDB) facilitating rising debt levels enabled Puerto Rico to continue to use debt to finance operations. Puerto Rico issued a relatively large amount of debt, given the size of its population. Based on an analysis of fiscal year 2014 comprehensive annual financial reports of the 50 states and Puerto Rico, Puerto Rico had the second highest amount of outstanding debt among states and territories, while its population falls between the 29th and 30th most populous states. By comparison, California, the state with the largest amount of outstanding debt, is the most populated state. Various factors drove demand for Puerto Rico municipal bonds, even as the government’s financial condition deteriorated. Triple tax exemption: According to a former Puerto Rico official, Federal Reserve Bank of New York officials, and an expert on Puerto Rico’s economy, Puerto Rico’s municipal bonds were attractive to investors because interest on the bonds was not subjected to federal, state, or local taxes, regardless of where the investors resided. In contrast, investors may be required to pay state or local taxes on interest income earned from municipal securities issued by a state or municipality in which they do not reside. Investment grade bond ratings: Puerto Rico maintained investment grade bond ratings until February 2014, even as its financial condition was deteriorating. Credit ratings inform investment decisions by both institutional investors and broker dealers. According to a current Puerto Rico official and an expert on Puerto Rico’s economy, investment grade ratings for Puerto Rico municipal bonds may have driven demand for these securities in the states. Based on interviews with ratings agency officials and a review of rating agency criteria, we found that Puerto Rico may have maintained its investment grade rating for two reasons. First, Puerto Rico could not seek debt restructuring under federal bankruptcy laws, prior to the passage of PROMESA in 2016. According to rating agency officials, bonds with assumed bankruptcy protection tend to rate higher than those without such protection. Second, legal frameworks that prioritize debt service are often viewed as positive for credit ratings, according to rating agency criteria. In the event that the Puerto Rico government does not have sufficient resources to meet appropriations for a given fiscal year, Puerto Rico’s constitution requires that the government pay interest and amortization on the public debt before disbursing funds for other purposes in accordance with the order of priorities established by law. The prior Puerto Rico Governor cited this constitutional provision as providing the authority to redirect revenue streams from certain entities to the payment of general obligation debt. This redirection of revenue streams is commonly known as a clawback. Lack of transparency on its financial condition: Municipal market analysts told us that untimely financial information made it difficult for institutional and individual investors to assess Puerto Rico’s financial condition, which may have resulted in investors not being able to fully take the investment risks into account when purchasing Puerto Rico debt. According to one report, between 2010 and 2016 municipal issuers issued their audited financial statements an average of 200 days after the end of their fiscal years. However, between fiscal years 2002 and 2014, Puerto Rico issued its statements an average of 386 days after the end of its fiscal year, according to our analysis of Puerto Rico’s audited financial statements. Moreover, Puerto Rico had not issued its fiscal years 2015 and 2016 audited financial statements as of March 1, 2018, or 975 and 609 days after the end of those fiscal years, respectively. Estate tax structures: Puerto Rico residents had incentive to invest in municipal bonds issued in Puerto Rico over those issued in the United States because of federal and Puerto Rico estate tax structures. Current and former Puerto Rico officials told us that this incentive drove demand among Puerto Rico residents for bonds issued in Puerto Rico. For federal estate tax purposes, Puerto Rico residents are generally considered non-U.S. residents and non-citizens for all of their U.S.-based property, including investments. Estates of Puerto Rico residents are required to pay the prevailing federal estate tax— which ranges from 18 percent to 40 percent depending on the size of an estate—for any U.S.-based property valued over $60,000. In contrast, prior to 2017, all Puerto Rico-based property was only subject to the Puerto Rico estate tax of 10 percent. Puerto Rico’s estate tax was repealed in 2017. In addition to financing from the municipal bond markets, GDB also provided an intragovernmental source of financing. Prior to April 2016, GDB acted as a fiscal agent, trustee of funds, and intergovernmental lender for the Government of Puerto Rico. GDB issued loans to Puerto Rico’s government agencies and public corporations to support their operations. GDB provided loans to government entities valued at up to 60 percent of GDB’s total assets, as shown in Figure 11. In general, these entities did not fulfill the terms of their borrowing agreements with GDB, while they independently accessed the municipal bond market. Additionally, according to GDB’s audited financial statements, GDB did not reflect loan losses in its audited financial statements until 2014 because it presumed that Puerto Rico’s legislature would repay loans through the general fund or appropriations, as generally required by the acts that approved such loans. Facing non-repayment of public sector loans, GDB took on debt to maintain liquidity. According to GDB documents, repayment of amounts owed to GDB was a main reason for the creation of the Puerto Rico Sales Tax Financing Corporation (COFINA), an entity backed by a new sales tax, through which Puerto Rico issued some of its debt. Though initially intended as a means to repay GDB and other debt, COFINA bonds were also used to finance operations. Through our interviews and an assessment of relevant literature, we identified three potential federal actions that could help address some of the factors that contributed to unsustainable indebtedness in Puerto Rico. Consistent with the provision in PROMESA that was the statutory requirement for this work, we focused on actions that were non-fiscal in nature—that is, actions that would not increase the federal deficit. There are tradeoffs for policymakers to consider when deciding whether or how to implement any policy. For each action, we describe a specific challenge as it relates to debt accumulation in Puerto Rico, identify a possible federal response to the challenge, and describe other considerations for policymakers. To help address the factors that contributed to the high demand for Puerto Rico debt relative to other municipal debt, legislative and executive branch policymakers could further ensure that municipal securities issuers provide timely, ongoing, and complete disclosure materials to bondholders and the public. Specifically, Congress could authorize SEC to establish requirements for municipal issuers on the timing, frequency, and content of initial and continuing disclosure materials. In general, the municipal securities market is less regulated and transparent than other capital markets, such as equity markets. For example, SEC’s authority to directly establish or enforce initial and continuing disclosure requirements for issuers—including those in Puerto Rico—is limited. SEC requires that underwriters (sellers of municipal securities) reasonably determine that issuers have undertaken continuing disclosure agreements (CDA) to publicly disclose ongoing annual financial information, operating data, and notices of material events. However, federal securities laws do not provide SEC with the authority to impose penalties on municipal issuers for noncompliance with CDAs, which may limit any incentive for issuers to comply with SEC disclosure and reporting guidance. As a result, SEC has limited ability to compel issuers to provide continuing disclosure information. As previously discussed, the Puerto Rico government often issued its audited financial statements in an untimely manner, thus failing to meet its contractual obligations to provide continuing disclosures for securities it issued. SEC could not directly impose any consequences on Puerto Rico’s government for failing to adhere to the terms of, or enforce compliance with, the CDAs. Additionally, as previously discussed, municipal market analysts told us that untimely financial information made it difficult for institutional and individual investors to assess Puerto Rico’s financial condition. Timely disclosure of information would help investors make informed decisions about investing in municipal securities and help protect them against fraud involving the securities. These disclosures would be made to investors at the time of purchasing securities and throughout the term of the security, including when material changes to an issuer’s financial condition occur. According to SEC staff, enhanced authority could prompt more municipal issuers to disclose financial information, including audited financial statements, in a timelier manner. For example, SEC staff said that if the agency had required that issuers provide timely financial statements at the time of issuing a municipal security, this may have precluded Puerto Rico from issuing its $3.5 billion general obligation bond in 2014. However, any rulemaking SEC would or could take as a result of enhanced authority would depend on a number of factors, such as compliance with other SEC guidance and related laws. Since this action would apply to all U.S. municipal securities issuers, it has policy and implementation implications that extend well beyond Puerto Rico. For example, establishing and enforcing initial and continuing disclosure requirements for municipal securities issuers could place additional burdens on state and local issuers, and not all municipal issuers use standardized accounting and financial reporting methods. As a result, state and local governments may need to spend resources to adjust financial reporting systems to meet standardized reporting requirements. However, in a 2012 report proposing this action, SEC said it could mitigate this burden by considering content and frequency requirements that take into account, and possibly vary by, the size and nature of the municipal issuer, the frequency of issuance of securities, the type of municipal securities offered, and the amount of outstanding securities. To help address the factors that contributed to the high demand for Puerto Rico debt relative to other municipal debt, Congress could ensure that investors residing in Puerto Rico receive the same federal investor protections as investors residing in states. Specifically, Congress could subject all investment companies in Puerto Rico to the Investment Company Act of 1940, as amended (1940 Act). In recent years, the House and Senate separately have passed legislation that would achieve this action. Certain investment companies in Puerto Rico and other territories— specifically, those whose securities are sold solely to the residents of the territory in which they are located—are exempt from the 1940 Act’s requirements. The 1940 Act regulates investment companies, such as mutual funds that invest in securities of other issuers and issue their own securities to the investing public. It imposes several requirements on investment companies intended to protect investors. For example, it requires that investment companies register with SEC and disclose information to investors about the businesses and risks of the companies in which they invest, and the characteristics of the securities that they issue. It also restricts investment companies from engaging in certain types of transactions, such as purchasing municipal securities underwritten by affiliated companies. According to a former Puerto Rico official, some broker-dealers in Puerto Rico underwrote Puerto Rico municipal securities issuances and investment companies managed by affiliated companies of these underwriters purchased the securities, packaged them into funds, and marketed the funds to investors residing in Puerto Rico. This practice would be prohibited or restricted for investment companies subject to the 1940 Act, as it might result in investment companies not acting in the best interests of their investors. If all Puerto Rico investment companies had been subject to the 1940 Act, they would have been prohibited or restricted from investing in Puerto Rico municipal bonds underwritten by affiliated companies. Also, these investment companies may have further disclosed the risks involved in Puerto Rico municipal bonds to Puerto Rico investors. As a result, demand for Puerto Rico municipal bonds from Puerto Rico investment companies and residents may have been lower had the 1940 Act requirements applied to all Puerto Rico investment companies, and it may have been more difficult for the Puerto Rico government to issue debt to finance deficits. SEC staff told us that industry groups had raised objections to extending the 1940 Act provisions to all investment companies in Puerto Rico. These industry groups noted that, among other things, certain investment companies would have difficulty meeting the 1940 Act’s leverage and asset coverage requirements and adhering to some restrictions on affiliated transactions. However, SEC staff noted that under certain legislation that passed the House or Senate separately, as described above, Puerto Rico investment companies would have three years to come into compliance if they were newly subject to the 1940 Act. Further, under that legislation, after three years, investment companies in Puerto Rico could also request an additional three years to come into compliance. Regarding affiliated company restrictions, SEC has previously waived some requirements for investment companies if they are unable to obtain financing by selling securities to unaffiliated parties with an agreement to repurchase those securities at a higher price in the future, known as repurchase agreements. According to SEC staff, SEC would consider allowing companies in Puerto Rico to enter into reverse repurchase agreements with their affiliates if the 1940 Act applied to them. To help address the factors that contributed to the high demand for Puerto Rico debt relative to other municipal debt, Congress could remove the triple tax exemption for Puerto Rico’s municipal securities. This action would mean that interest income from Puerto Rico municipal securities earned by investors residing outside of Puerto Rico could be taxed by states and local governments, while still being exempt from federal income taxes, similar to the current tax treatment of municipal bond income in the states. As mentioned previously, former Puerto Rico officials and experts in municipal securities told us that the triple tax exemption fueled investor demand and enabled Puerto Rico to continue issuing bonds despite deteriorating financial conditions. Some of the demand for Puerto Rico municipal securities came from certain U.S. municipal bond funds. These funds concentrated their investments in one state to sell to investors within that state, but also included Puerto Rico bonds in their portfolios. Puerto Rico bond yields generally were higher than state bonds yields, according to industry experts. When added to a fund, the higher yields from Puerto Rico bonds would increase the overall return on investment yield of a fund. Modifying the triple tax exemption for Puerto Rico’s municipal securities might result in reduced demand for Puerto Rico’s debt. In response to reduced demand for its debt, Puerto Rico’s government may need to address any projected operating deficits by decreasing spending, raising revenues, or both. According to U.S. Treasury officials, this action could increase the proportionate share of investors in Puerto Rico debt that reside in Puerto Rico, because of reduced demand from investors in the states. In the event of a future debt crisis, this could result in a concentration of financial losses within Puerto Rico. Also, debt financing allows governments to make needed capital investments and provides liquidity to governments, and can be a more stable funding source to manage fiscal stress. Reduced market demand for Puerto Rico’s bonds could make access to debt financing difficult, as the Puerto Rico bond market may not support the Puerto Rico government’s future borrowing at reasonable interest rates, according to Treasury officials. Alternately, a variant of this action would be to retain the triple tax exemption for Puerto Rico debt only for bonds related to capital investments rather than for deficit financing, according to Treasury officials. Various provisions in PROMESA were intended to help Puerto Rico improve its fiscal condition. PROMESA requires that the Oversight Board certify fiscal plans for achieving fiscal responsibility and access to capital markets. The intent of the fiscal plans is to eliminate Puerto Rico’s structural deficits; create independent revenue estimates for the budget process; and improve Puerto Rico’s fiscal governance, accountability, and controls, among other things. From March 2017 to April 2017, the Oversight Board certified the fiscal plans the Government of Puerto Rico developed for the primary government and certain component units, such as PREPA. As a result of the effects of Hurricanes Irma and Maria, the Oversight Board requested that the Government develop updated fiscal plans. Although the Government of Puerto Rico developed and submitted updated fiscal plans, the Oversight Board did not certify them, with the exception of the plan for GDB. Instead, in April 2018, the Oversight Board certified fiscal plans it developed itself, as PROMESA allows. PROMESA also requires the Oversight Board to determine whether or not Puerto Rico’s annual budgets, developed by the Governor, comply with the fiscal plans prior to being submitted to Puerto Rico’s legislature for approval. Technical assistance is another area where the federal government has taken action to help Puerto Rico address its fiscal condition. In 2015, Congress first authorized Treasury to provide technical assistance to Puerto Rico, and has continued to reauthorize the technical assistance, most recently through September 30, 2018. For example, Treasury officials told us that they helped Puerto Rico’s Planning Board develop a more accurate macroeconomic forecast, which should enable Hacienda to develop more accurate revenue estimates and receipt forecasts. Treasury officials also told us that the agency began helping Puerto Rico improve its collection of delinquent taxes—for example, by helping Hacienda develop an office dealing with Puerto Rico’s largest and most sophisticated taxpayers, which are often multinational corporations. With Puerto Rico focused on hurricane recovery efforts, Treasury and the Puerto Rico government are reassessing the types of assistance that Treasury might provide in the future, according to Treasury officials. Current and former Puerto Rico government officials and experts on Puerto Rico’s economy also told us that the federal government could further help Puerto Rico address its persistent deficits through federal policy changes that are fiscal in nature. For example, it could change select federal program funding rules—at a cost to the federal government—such as eliminating the cap on Medicaid funding and calculating the federal matching rate similar to how the rate is calculated in the states. Likewise, the Congressional Task Force on Economic Growth in Puerto Rico (Congressional Task Force), as established by PROMESA, issued a report in December 2016 that recommended changes to federal laws and programs that would spur sustainable long- term economic growth in Puerto Rico, among other recommendations. In addition to federal actions that could address the factors that contributed to Puerto Rico’s fiscal condition and debt levels, the Puerto Rico government plans to take various actions. For example, according to current Puerto Rico officials and the Puerto Rico government’s April 2018 fiscal plan, the government is: Planning to implement an integrated new information technology system for financial management, to include modernized revenue management and accounting and payroll systems. Hacienda officials stated that they are in the process of developing a project schedule for this long-term effort. Developing a new public healthcare model in which Puerto Rico’s government pays for basic services and patients pay for premium services. The government will begin implementing the new healthcare model in fiscal year 2019 and expects to achieve annual savings of $841 million by fiscal year 2023. Collaborating with the private sector for future infrastructure and service projects, including for reconstruction efforts related to Hurricanes Irma and Maria, which it expects will stimulate Puerto Rico’s weakened economy. We also asked Puerto Rico officials about progress made toward addressing many of the factors we identified. However, they did not provide us this information. We provided a draft of this report for review to Treasury, SEC, the Federal Reserve Bank of New York, the Government of Puerto Rico, and the Oversight Board. Treasury and SEC provided technical comments, which we incorporated as appropriate. The Federal Reserve Bank of New York and the Oversight Board had no comments. We received written comments from the Government of Puerto Rico, which are reprinted in appendix II. In its comments, the Government of Puerto Rico generally agreed with the factors we identified that contributed to Puerto Rico’s financial condition and levels of debt. It also provided additional context on Puerto Rico’s accumulation of debt, such as Puerto Rico’s territorial status and its effect on federal programs in Puerto Rico and outmigration. The Government of Puerto Rico also noted that the federal actions we identified to address factors contributing to Puerto Rico’s unsustainable debt levels did not include potential actions that were fiscal in nature or that addressed Puerto Rico’s long-term economic viability. As we note in the report, we excluded fiscal actions from our scope, consistent with the provision in PROMESA that was the statutory requirement for this work. We excluded potential actions that could promote economic growth in Puerto Rico because these actions would address debt levels in Puerto Rico only indirectly and because the Congressional Task Force on Economic Growth in Puerto Rico already recommended actions for fostering economic growth in Puerto Rico in its December 2016 report. We are sending copies of the report to the appropriate congressional committees, the Government of Puerto Rico, the Secretary of the Treasury, the Chairman of the Securities and Exchange Commission, and other interested parties. In addition, this report is available at no charge on the GAO website at http://gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-6806 or krauseh@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix III. Our objectives were to describe (1) the factors that contributed to Puerto Rico’s financial condition and levels of debt; and (2) federal actions that could address the factors that contributed to Puerto Rico’s financial condition and levels of debt. Consistent with the provision in the Puerto Rico Oversight, Management, and Economic Stability Act (PROMESA) that was the statutory requirement for this work, we focused on actions that would not increase the federal deficit. For both objectives we interviewed current Puerto Rico officials from several agencies—the Puerto Rico Department of Treasury (Hacienda in Spanish), Government Development Bank for Puerto Rico (GDB), the Puerto Rico Office of Management and Budget (Spanish acronym OGP), Fiscal Agency and Financial Advisory Authority (FAFAA), and the Puerto Rico Electric Power Authority. We also interviewed 13 former Puerto Rico officials that held leadership positions at Hacienda, GDB, or OGP, or a combination thereof. These former officials served between 1997 and 2016 for various gubernatorial administrations associated with the two political parties in Puerto Rico that held the governorship during that period. We also interviewed officials from the U.S. Department of the Treasury (Treasury), the Securities and Exchange Commission (SEC), the Federal Reserve Bank of New York, and the Financial Oversight and Management Board for Puerto Rico (created by PROMESA). Additionally, we conducted another 13 interviews with experts on Puerto Rico’s economy, the municipal securities markets, state and territorial budgeting and debt management—including credit rating agencies—and with select industry groups in Puerto Rico. We selected the experts we interviewed based on their professional knowledge closely aligning with our engagement objectives, as demonstrated through published articles, congressional testimonies, and referrals from agency officials or other experts. To describe the factors that contributed to Puerto Rico’s financial condition and levels of debt, we reviewed our prior work related to Puerto Rico’s financial condition and levels of public debt. We also collected and analyzed additional financial data from Puerto Rico’s audited financial statements for the fiscal years 2002 to 2014, the last year for which audited financial statements were available. To determine how the Puerto Rico government used bond proceeds, we reviewed a nongeneralizable sample of Puerto Rico bonds prospectuses issued between 2000 and 2017 from the Electronic Municipal Market Access database of the Municipal Securities Rulemaking Board. We reviewed literature—including academic reports, congressional hearing transcripts, and credit rating agency reports—that described Puerto Rico’s economy and factors that contributed to Puerto Rico’s levels of debt. We also reviewed credit rating agency reports that described Puerto Rico’s municipal debt and the agencies’ methodologies for rating municipal debt. We also collected and reviewed Puerto Rico government documents related to budget formulation and execution, debt issuance, and financial management. We considered factors to include, but not be limited to, macroeconomic trends, federal policies, and actions taken by Puerto Rico government officials. Our review focused largely, though not exclusively, on conditions that contributed to the debt crisis during those years for which we collected financial data on Puerto Rico, fiscal years 2002 to 2014. Finally, we also conducted a thematic analysis of the summaries of our interviews to identify common patterns and ideas. Although these results are not generalizable to all current and former officials and experts with this subject-matter expertise, and do not necessarily represent the views of all the individuals we interviewed, the thematic analysis provided greater insight and considerations for the factors we identified. To describe federal actions that could address the factors that contributed to Puerto Rico’s financial condition and levels of debt, we reviewed our prior reports and documents from Treasury and SEC, conducted a literature review, and conducted various interviews. Specifically, we met with federal agencies with subject-matter expertise or whose scope of responsibilities related to these actions, as well as with current and former Puerto Rico officials and municipal securities experts. Consistent with PROMESA, we omitted from our scope: (1) actions that could increase the federal deficit (i.e., fiscal options), (2) actions that could be taken by the Puerto Rico government, (3) actions that could infringe upon Puerto Rico’s sovereignty and constitutional parameters, and (4) actions that would imperil America’s homeland and national security. We considered actions that could promote economic growth in Puerto Rico as outside of scope, as they could address debt levels in Puerto Rico indirectly, rather than directly, and because a study issued by the Congressional Task Force on Economic Growth in Puerto Rico already identified actions that Congress and executive agencies could take to foster economic growth in Puerto Rico. We also considered actions that could address Puerto Rico’s unfunded pension liability as outside of our scope. The actions we identified may also help avert future unsustainable debt levels in other territories; however, we did not assess whether and how each action would apply to other territories. We conducted this performance audit from January 2017 to May 2018 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. In addition to the contact named above, Jeff Arkin (Assistant Director), Amy Radovich (Analyst in Charge), Pedro Almoguera, Karen Cassidy, Daniel Mahoney, A.J. Stephens, and Justin Snover made significant contributions to this report.
CMS has four principal programs: Medicare, Medicaid, CHIP, and the health-insurance marketplaces. See table 1 for information about the four programs. As discussed earlier, Medicare and Medicaid are CMS’s largest programs and have been growing steadily (see fig. 1). CBO projects that, in 2026, under current law, Medicare spending will reach $1.3 trillion. Medicaid is also expected to continue to grow—program spending is projected to increase 66 percent to over $950 billion by fiscal year 2025, and more than half of the states have chosen to expand their Medicaid programs by covering certain low-income adults not historically eligible for Medicaid coverage, as authorized under the Patient Protection and Affordable Care Act of 2010 (PPACA). The two programs’ use of managed-care delivery systems to provide care has also increased. For example, the number and percentage of Medicare beneficiaries enrolled in Medicare Part C has grown steadily over the past several years, increasing from 8.7 million (20 percent of all Medicare beneficiaries) in calendar year 2007 to 17.5 million (32 percent of all Medicare beneficiaries) in calendar year 2015. As of July 1, 2015, nearly two-thirds of all Medicaid beneficiaries were enrolled in managed- care plans and about 40 percent of expenditures in fiscal year 2015 were for health-care services delivered through managed care. CMS receives appropriations to carry out antifraud activities through several funds including the Health Care Fraud and Abuse Control (HCFAC) program and the Medicaid Integrity Program. The HCFAC program was established under the Health Insurance Portability and Accountability Act of 1996 to coordinate federal, state, and local law- enforcement efforts to address health-care fraud and abuse and to conduct investigations and audits, among other things. In fiscal year 2016, CMS received $560 million through the HCFAC program appropriations. The Medicaid Integrity Program, established by the Deficit Reduction Act of 2005, supports contracts to audit and identify overpayments in Medicaid claims, and provides technical assistance for states’ program-integrity efforts. According to CMS, it received $75 million every year since fiscal year 2009 through the Medicaid Integrity Program appropriations. According to CMS, in fiscal year 2016, total program-integrity obligations to address fraud, waste, and abuse for Medicare and Medicaid were $1.45 billion. As mentioned previously, we designated Medicare and Medicaid as high- risk programs starting in 1990 and 2003, respectively, because their size, scope, and complexity make them vulnerable to fraud, waste, and abuse. Similarly, the Office of Management and Budget (OMB) designated all parts of Medicare as well as Medicaid “high-priority” programs because these programs report $750 million or more in estimated improper payments in a given year. We also highlighted challenges associated with improper payments in Medicare and Medicaid in our annual report on duplication and opportunities for cost savings in federal programs. Improper payments are a significant risk to the Medicare and Medicaid programs and can include payments made as a result of fraud. Improper payments are payments that are either made in an incorrect amount (overpayments and underpayments) or those that should not be made at all. For example, CMS estimated in fiscal year 2016 that the Medicare fee-for-service (FFS) improper payment rate was 11 percent (approximately $41 billion) and the Medicaid improper payment rate was 10.5 percent (approximately $36 billion). Improper payment measurement does not specifically identify or estimate improper payments due to fraud. Health-care fraud can take many forms, and a single case can involve more than one scheme. Schemes may include fraudulent billing for services not provided, services provided that were not medically necessary, and services intentionally billed at a higher level than appropriate. These fraud schemes may include compensating providers, beneficiaries, or others for participating in the fraud scheme. Fraud can be regionally focused or can target particular service areas such as home-health services, or durable medical equipment such as wheelchairs. Fraud may also have nonfinancial effects. For example, patients may be subjected to harmful or unnecessary services by fraudulent providers. Fraud can be perpetrated by different actors, such as providers, beneficiaries, health-insurance plans, as well as organized crime. Fraud and “fraud risk” are distinct concepts. Fraud is challenging to detect because of its deceptive nature. Additionally, once suspected fraud is identified, alleged fraud cases may be prosecuted. If the court determines that fraud took place, then fraudulent spending may be recovered. Fraud risk exists when individuals have an opportunity to engage in fraudulent activity, have an incentive or are under pressure to commit fraud, or are able to rationalize committing fraud. When fraud risks can be identified and mitigated, fraud may be less likely to occur. Although the occurrence of one or more cases of health-care fraud indicates there is a fraud risk, a fraud risk can exist even if fraud has not yet been identified or occurred. Suspicious billing patterns, certain types of health-care providers, or complexities in program design may indicate a risk of fraud. Information to help identify potential fraud risks may come from various sources, including whistleblowers, agency officials, contractors, law-enforcement agencies, beneficiaries, or providers. According to federal standards and guidance, executive-branch agency managers are responsible for managing fraud risks and implementing practices for combating those risks. Federal internal control standards call for agency management officials to assess the internal and external risks their entities face as they seek to achieve their objectives. The standards state that as part of this overall assessment, management should consider the potential for fraud when identifying, analyzing, and responding to risks. Risk management is a formal and disciplined practice for addressing risk and reducing it to an acceptable level. In July 2015, GAO issued the Fraud Risk Framework, which provides a comprehensive set of key components and leading practices that serve as a guide for agency managers to use when developing efforts to combat fraud in a strategic, risk-based way. The Fraud Risk Framework describes leading practices in four components: commit, assess, design and implement, and evaluate and adapt, as depicted in figure 2. The Fraud Reduction and Data Analytics Act of 2015, enacted in June 2016, requires OMB to establish guidelines for federal agencies to create controls to identify and assess fraud risks and design and implement antifraud control activities. The act further requires OMB to incorporate the leading practices from the Fraud Risk Framework in the guidelines. In July 2016, OMB published guidance about enterprise risk management and internal controls in federal executive departments and agencies. Among other things, this guidance affirms that managers should adhere to the leading practices identified in the Fraud Risk Framework. Further, the act requires federal agencies to submit to Congress a progress report each year for 3 consecutive years on the implementation of the controls established under OMB guidelines, among other things. CMS’s antifraud efforts for its four principal programs are part of the agency’s broader program-integrity approach to address fraud, waste, and abuse. CMS’s Center for Program Integrity (CPI) is the agency’s focal point for program integrity across the programs. According to CMS, its approach to program-integrity allows it to “address the whole spectrum of fraud, waste, and abuse.” For example, CMS describes its program- integrity activities as addressing unintentional errors resulting from providers being unaware of recent policy changes on one end of the spectrum, through somewhat more-serious patterns of abuse such as billing for a more-expensive service than was performed (known as upcoding), and finally up to serious fraudulent activities, such as billing for services that were not provided. CMS then aims to target its corrective actions to fit the risk. See figure 3 for CMS’s description of the spectrum of fraud, waste, and abuse that its program-integrity activities aim to address. Within its program-integrity activities, CMS has established several control activities that are specific to managing fraud risks, while others serve broader program-integrity purposes. According to CMS officials, the agency’s antifraud control activities mainly focus on providers in Medicare FFS. Officials told us that when CPI began operating, its primary focus was developing program integrity for Medicare FFS and, as a result, it is the most “mature” of all of CPI’s programs. CMS’s specific fraud control activities include, for example, the Fraud Prevention System (FPS), a predictive-analytics system that helps identify potentially fraudulent payments in Medicare FFS, and the Unified Program Integrity Contractors (UPIC), which detect and investigate aberrant provider behavior and potential fraud in Medicare and Medicaid. Other control activities serve broader program-integrity purposes such as to reduce improper payments resulting from error, waste, and abuse in addition to preventing or detecting potential fraud. For example, CMS provides education and outreach to Medicare providers and beneficiaries on issues identified through data analyses in order to reduce improper payments and to increase their awareness of fraud. HHS and CMS department- and agency-wide strategic plans guide CMS’s program-integrity activities—including antifraud activities. The program-integrity goals identified in the HHS strategic plan primarily focus on improper payments and are driven by statutory requirements. For example, the HHS strategic plan for fiscal years 2014–2018 includes performance goals of reducing the percentage of improper payments made under Medicare FFS and Medicare Parts C and D. One antifraud- focused goal in the HHS strategic plan is to increase the percentage of Medicare providers and suppliers identified as high risk that receive administrative actions, such as suspending payments to providers or revoking providers’ billing privileges. HHS and CMS department- and agency-wide strategic plans also include an emphasis on fraud prevention and early detection—a leading practice in the Fraud Risk Framework—and moving away from a “pay-and-chase” model. For example, the HHS strategic plan calls for “fostering early detection and prevention of improper payments by focusing on preventing bad actors from enrolling or remaining in Medicare and Medicaid” and to “use public-private partnerships to prevent and detect fraud across the health care industry by sharing fraud-related information and data between the public and private sectors.” As a part of this emphasis on prevention, CMS developed FPS in response to the Small Business Jobs Act of 2010, which required CMS to implement predictive-analytics technologies. Also, the Patient Protection and Affordable Care Act of 2010 (PPACA) included provisions to strengthen Medicare and Medicaid’s provider enrollment standards and procedures, among other program-integrity provisions. CMS works with an extensive and complex network of stakeholders to manage fraud risks in its four principal programs. In Medicaid and CHIP, CMS partners with and oversees the 50 states and the District of Columbia. Until the Deficit Reduction Act of 2005 expanded CMS’s role in Medicaid program integrity to provide effective federal support and assistance to states’ efforts to combat fraud, waste, and abuse, states were primarily responsible for Medicaid program integrity. Each state has its own Medicaid program-integrity unit, Medicaid Fraud Control Unit (MFCU), and state audit organization. CMS also uses numerous contractors to conduct the majority of its program-integrity activities. Since the enactment of Medicare in 1965, contractors have played an integral role in the administration of the program. The original Medicare program was designed so that the federal government contracted with health insurers or similar organizations experienced in handling physician and hospital claims to pay Medicare claims. Later, the Health Insurance Portability and Accountability Act of 1996 required the Secretary of Health and Human Services to enter into contracts to promote the integrity of the Medicare program. According to CMS officials, in fiscal year 2016 contractors received 92 percent of CMS’s program-integrity funding. Medicare and Medicaid program- integrity contractors play a variety of roles: (1) processing and reviewing claims, (2) conducting site visits of providers enrolling in Medicare, (3) auditing claims and recovering overpayments, (4) performing data analysis, and (5) investigating aberrant claims and provider behaviors, among other things. States also use contractors in many of these roles for managing program integrity. Additionally, multiple private health-insurance plans in Medicare Parts C and D and over 200 health-insurance plans in Medicaid managed care also carry out program-integrity activities. For the health-insurance marketplaces, CMS is responsible for operating the federally facilitated marketplace and overseeing the state-based marketplaces. CMS also developed the Federal Data Services Hub, which acts as a portal for exchanging information between state-based marketplaces, the federally facilitated marketplace, and state Medicaid agencies, among other entities, as well as other external partners, including other federal agencies, such as the Internal Revenue Service. Finally, law- enforcement groups, including the joint Department of Justice (DOJ) and HHS OIG Medicare Fraud Strike Force Teams, identify, investigate, and prosecute instances of fraud in CMS programs. See figure 4 for a depiction of CMS’s stakeholder network for managing fraud risks. This figure illustrates approximate numbers of stakeholders (through the concentration of dots), but not the extent of individual stakeholder roles. CMS provides oversight to, or partners with, these stakeholders to manage fraud risks. For oversight, CMS creates policies and guidance to direct stakeholders’ antifraud efforts, such as Medicare and Medicaid program-integrity manuals and the Medicaid Provider Enrollment Compendium. CMS also provides technical assistance to states in areas such as provider enrollment and data analysis. In areas where CMS does not have a primary role, it acts as a partner by collaborating and coordinating program-integrity and antifraud activities. For example, CMS is directly responsible for Medicare program integrity, but, in Medicaid and CHIP, states are the first line of program-integrity efforts. Similarly, CMS maintains control over Medicare FFS program integrity, but within Medicare managed care, it provides guidance for health- insurance plans to carry out their own program-integrity activities. In the health-insurance marketplaces, CMS reviews state-based marketplaces’ procedures for verifying applicant eligibility for coverage. For example, it conducts annual reviews of the state-based marketplaces, which include a review of states’ fraud, waste, and abuse policies. See figure 5 for a further description of CMS’s and various stakeholders’ roles and responsibilities in fraud risk management. CMS also facilitates collaboration among federal, state, and private entities for managing fraud risks. In 2012, CMS created the Healthcare Fraud Prevention Partnership (HFPP) to share information with public and private stakeholders and to conduct studies related to health-care fraud, waste, and abuse. According to CMS, as of October 2017, the HFPP included 89 public and private partners, including Medicare- and Medicaid-related federal and state agencies, law-enforcement agencies, private health-insurance plans (payers), and antifraud and other health- care organizations. The HFPP has conducted studies that pool and analyze multiple payers’ claims data to identify providers with patterns of suspect billing across payers. In a recent report, participants separately told us that the HFPP’s studies helped them to identify and take action against potentially fraudulent providers and payment vulnerabilities of which they might not otherwise have been aware, and fostered both formal and informal information sharing. CMS’s relationships with stakeholders were varied in terms of maturity and extent of information sharing, according to stakeholders we interviewed. While some relationships between CMS and stakeholders have been long-standing, some are developing, and others exist on an ad hoc basis. For example, CMS has had a long-standing relationship with state Medicaid program-integrity units, by collaborating through monthly meetings of the Medicaid Fraud and Abuse Technical Advisory Group, sending fraud alerts, and offering courses through the Medicaid Integrity Institute. However, in our interviews with state program-integrity units, and as we recently reported, some state Medicaid agencies shared concerns about the communication, level of policy guidance, and technical support provided by and received from CMS for managing fraud risks in Medicaid. This concern was echoed by state audit officials, with whom CMS recently initiated coordination to build relationships that would facilitate state auditing of Medicaid programs. CMS also has varying relationships with its law-enforcement partners. For example, the relationship between CMS and DOJ’s Health Care Fraud unit, which leads the DOJ and HHS OIG Medicare Fraud Strike Force Teams, has been ad hoc. According to CMS and DOJ officials, the interactions between the agencies have been based on specific fraud cases such as coordination of national takedowns when DOJ provided CMS with the names of providers committing fraud so that CMS could suspend them consistently with the timing of the enforcement efforts. According to CMS officials, they coordinate more with HHS OIG, working together on payment suspensions and revocations for OIG cases, or working with it to take administrative actions against large providers. CMS’s antifraud efforts partially align with the Fraud Risk Framework. Consistent with the framework, CMS has demonstrated commitment to combating fraud by creating a dedicated entity to lead antifraud efforts. It has also taken steps to establish a culture conducive to fraud risk management, although it could expand its antifraud training to include all employees. CMS has taken some steps to identify fraud risks in Medicare and Medicaid; however, it has not conducted a fraud risk assessment or developed a risk-based antifraud strategy for Medicare and Medicaid as defined in the Fraud Risk Framework. CMS has established monitoring and evaluation mechanisms for its program-integrity control activities that, if aligned with a risk-based antifraud strategy, could enhance the effectiveness of fraud risk management in Medicare and Medicaid. The commit component of the Fraud Risk Framework calls for an agency to commit to combating fraud by creating an organizational culture and structure conducive to fraud risk management. This component includes establishing a dedicated entity to lead fraud risk management activities. Within CMS, the Center for Program Integrity (CPI) serves as the dedicated entity for fraud, waste, and abuse issues in Medicare and Medicaid, which is consistent with the Fraud Risk Framework. CPI was established in 2010, in response to a November 2009 Executive Order on reducing improper payments and eliminating waste in federal programs. This formalized role, according to CMS officials, elevated the status of program-integrity efforts, which previously were carried out by other parts of CMS. As an executive-level Center—on the same level with five other executive-level Centers at CMS, such as the Center for Medicare and the Center for Medicaid and CHIP Services—CPI has a direct reporting line to executive-level management at CMS. The Fraud Risk Framework identifies a direct reporting line to senior-level managers within the agency as a leading practice. According to CMS officials, this elevated organizational status offers CPI heightened visibility across CMS, attention by CMS executive leadership, and involvement in executive- level conversations. Additionally, in 2014, CMS established a Program Integrity Board that has brought together senior officials across CMS Centers on a monthly basis to coordinate on fraud and program-integrity vulnerabilities. According to CPI officials, the board is one of the mechanisms through which CPI engages other executive-level offices at CMS. CPI chairs the meetings and typically develops meeting agendas to solicit information from and disseminate information to other CMS units or stakeholders. Further, the board may establish small working groups, known as integrated project teams, to address specific vulnerabilities. For example, according to CMS officials, in 2016 the board established a Marketplace integrated project team to resolve potential fraud eligibility and enrollment issues in the federally facilitated marketplace using the Fraud Risk Framework. CPI has further demonstrated commitment to addressing fraud, waste, and abuse through several organizational changes with the goal of improving coordination and communication of program-integrity activities across Medicare and Medicaid. Most recently, in 2014, CPI reorganized its structure to align functional areas across Medicare and Medicaid, where possible. Previously, separate units within CPI administered their own program-integrity activities for Medicare and Medicaid programs. For example, CPI established a Provider Enrollment and Oversight Group, responsible for provider screening and enrollment functions in both Medicare and Medicaid. According to CMS officials, if CPI employees identify an issue in provider enrollment in Medicare, the same CPI employees also consider how this issue applies to Medicaid. According to CMS officials, the reorganization has helped CPI to look at vulnerabilities in a crosscutting way and to facilitate communication across programs. Similarly, since 2016, CPI began shifting contracting functions from separate Medicare and Medicaid regional contractors that identify and investigate cases of potential fraud and conduct audits to five regional UPICs responsible for a range of program-integrity and fraud-specific activities in both Medicare FFS and Medicaid. According to CMS, the purpose of the UPICs is to coordinate provider investigations across Medicare and Medicaid, improve collaboration with states by providing a mutually beneficial service, and increase contractor accountability through coordinated oversight. CMS officials told us that UPIC integration is a cornerstone of CMS’s contract management strategy and would help to ensure communication and coordination across Medicare and Medicaid program-integrity efforts. CMS plans to award all the UPIC contracts by the end of 2017, ultimately phasing out the ZPICs and Medicaid Integrity Contractors. The commit component of the Fraud Risk Framework also includes creating an organizational culture to combat fraud at all levels of the agency. Consistent with the Fraud Risk Framework, CMS has promoted an antifraud culture by demonstrating a senior-level commitment to combating fraud through public statements, increased resource levels, and internal and external coordination. In addition to HHS and CMS strategic documents discussed earlier, CMS and CPI leaders have testified publicly about CMS’s commitment to preventing fraud and protecting taxpayers and beneficiaries. For example, CPI’s former Director testified in May 2016 before the House Committee on Energy and Commerce’s Subcommittee on Oversight and Investigations that “CMS is deeply committed to our efforts to prevent waste, fraud and abuse in Medicare and Medicaid programs, protecting both taxpayers and the beneficiaries that we serve.” More recently, CMS’s new Administrator testified in her February 2017 confirmation hearing regarding her intent to prioritize efforts around preventing fraud and abuse. CPI’s budget and resources have increased over time to support its ongoing program-integrity mission. According to CMS, program-integrity obligations for Medicare and Medicaid increased from about $1.02 billion in fiscal year 2010 to $1.45 billion in fiscal year 2016. According to CMS officials, the Health Care Fraud and Abuse Control (HCFAC) account, one of the primary sources of CPI funding, has never received a funding reduction. Additionally, in 2015, CPI received additional funding based on a discretionary cap adjustment to HCFAC. Similarly, CPI staff resources have increased over time. According to CMS, CPI’s full-time equivalent positions increased from 177 in 2011 to 419 in 2017. Consistent with leading practices in the Fraud Risk Framework to involve all levels of the agency in setting an antifraud tone, CPI has also worked collaboratively with other CMS Centers. In addition to engaging executive-level officials of other CMS Centers through the Program Integrity Board, CPI has worked collaboratively with other Centers within CMS to incorporate antifraud features into new program design or policy development and established regular communication at the staff level. For example: Center for Medicare and Medicaid Innovation (CMMI). When developing the Medicare Diabetes Prevention Program, CMMI officials told us they worked with CPI’s Provider Enrollment and Oversight Group and Governance Management Group to develop risk-based screening procedures for entities that would enroll in Medicare to provide diabetes-prevention services, among other activities. The program was expanded nationally in 2016, and CMS determined that an entity may enroll in Medicare as a program supplier if it satisfies enrollment requirements, including that the supplier must pass existing high categorical risk-level screening requirements. Center for Medicaid and CHIP Services (CMCS). CMCS officials told us they worked closely with CPI to issue Medicaid guidance and best practices to states on home and community-based services that incorporate program-integrity provisions. A senior CMCS official told us that, to address fraud, CMS has requested that states include provider information on claims to determine whether providers are meeting eligibility criteria. Center for Medicare (CM). In addition to building safeguards into programs and developing policies, CM officials told us that there are several standing meetings, on monthly, biweekly, and weekly bases, between groups within CM and CPI that discuss issues related to provider enrollment, FFS operations, and contractor management. A senior CM official also told us that there are ad hoc meetings taking place between CM and CPI: “We interact multiple times daily at different levels of the organization. Working closely is just a regular part of our business.” CMS has also demonstrated its commitment to addressing fraud, waste, and abuse to its stakeholders. Representatives of CMS’s extensive stakeholder network whom we interviewed—state officials, contractors, and officials from public and private entities—generally recognized the agency’s commitment to combating fraud. In our interviews with stakeholders, officials observed CMS’s increased commitment over time to address fraud, waste, and abuse and cited examples of specific CMS actions. State officials, for example, told us that the Medicaid Integrity Institute, a training center coordinated jointly by CMS and DOJ, has been a helpful resource for states to build capacity to address fraud and program integrity. CMS contractors told us that CMS’s commitment to combating fraud is incorporated into contractual requirements, such as requiring (1) data analysis for potential fraud leads and (2) fraud- awareness training for providers. Officials from entities that are members of the HFPP, specifically, a health-insurance plan and the National Health Care Anti-Fraud Association, added that CMS’s effort to establish the HFPP and its ongoing collaboration and information sharing reflect CMS’s commitment to combat fraud in Medicare and Medicaid. The Fraud Risk Framework identifies training as one way of demonstrating an agency’s commitment to combating fraud. Training and education intended to increase fraud awareness among stakeholders, managers, and employees, serves as a preventive measure to help create a culture of integrity and compliance within the agency. The Fraud Risk Framework discusses requiring all employees to attend training upon hiring and on an ongoing basis thereafter. To increase awareness of fraud risks in Medicare and Medicaid, CMS offers and requires training for stakeholder groups such as providers, beneficiaries, and health-insurance plans. Specifically, through its National Training Program and Medicare Learning Network, CMS makes available training materials on combating Medicare and Medicaid fraud, waste, and abuse. These materials help to identify and report fraud, waste, and abuse in CMS programs and are geared toward providers, beneficiaries, as well as trainers and other stakeholders. Separately, CMS requires health-insurance plans working with CMS to provide annual fraud, waste, and abuse training to their employees. However, CMS does not offer or require similar fraud-awareness training for the majority of its workforce. For a relatively small portion of its overall workforce—specifically, contracting officer representatives who are responsible for certain aspects of the acquisition function—CMS requires completion of fraud and abuse prevention training every 2 years. According to CMS, 638 of its contracting officer representatives (or about 10 percent of its overall workforce) completed such training in 2016 and 2017. Although CMS offers fraud-awareness training to others, the agency does not require fraud-awareness training for new hires or on a regular basis for all employees because the agency has focused on providing process-based internal controls training for its employees. While fraud-awareness training for contracting officer representatives is an important step in helping to promote fraud risk management, fraud- awareness training specific to CMS programs would be beneficial for all employees. Such training would not only be consistent with what CMS offers to or requires of its stakeholders and some of its employees, but would also help to keep the agency’s entire workforce continuously aware of fraud risks and examples of known fraud schemes, such as those identified in successful OIG investigations. Such training would also keep employees informed as they administer CMS programs or develop agency policies and procedures. Considering the vulnerability of Medicare and Medicaid programs to fraud, waste, and abuse, without regular required training CMS cannot be assured that its workforce of over 6,000 employees is continuously aware of risks facing its programs. Although CMS has shown commitment to combating fraud, at times CPI’s efforts to combat fraud compete with other mission priorities, such as (1) ensuring beneficiary access to health-care services and (2) limiting provider burden. CPI leadership has been aware of this inherent challenge. For example, at a congressional hearing in May 2016, CPI’s Director stated that “our efforts strike an important balance: protecting beneficiary access to necessary health care services and reducing the administrative burden on legitimate providers and suppliers, while ensuring that taxpayer dollars are not lost to fraud, waste, and abuse.” Beneficiary access to care. In accordance with its mission statement, providing and improving beneficiaries’ access to health care is a CMS priority. CMS’s commitment to providing access to high-quality care and coverage is reflected in the agency’s mission statement and is one of its four strategic goals. As a result, before taking administrative actions against a Medicare Part A provider, such as a hospice, or providers in rural areas, CMS officials told us that they first look at whether there is a sufficient number of providers in an area by running a provider search by provider county and adjacent counties and considering how heavily populated an area is with Medicare beneficiaries. According to these officials, rather than taking an administrative action against a provider that would limit beneficiaries’ access to services, the agency may enter into a corrective action plan with the provider. CMS officials told us that revoking a provider’s enrollment in Medicare, an option available to CMS in cases of provider noncompliance or misconduct, is rare. Administrative burden on providers. According to CMS documents and officials, concern over placing undue burden on providers—the majority of whom are presumed to be honest—provides a counterforce to implementing program-integrity control activities. CMS’s web page entitled Reducing Provider Burden states: “CMS is committed to reducing improper payments but must be mindful of provider burden because medical review is a resource-intensive process for both the healthcare provider and the Medicare review contractor.” Two CMS contractors told us that they scaled back or did not pursue audits of providers’ documentation because of provider burden or sensitivity considerations. One contractor removed providers from audit samples after some providers opposed having to supply multiple medical records. CPI officials told us that they want to reduce provider burden in a logical manner. For example, according to CMS officials, in the Medicare FFS Recovery Audit Program, CMS established limits on Additional Documentation Requests, which are requests for medical documentation supporting a claim being reviewed. CMS requires such documentation adjustments so that they align with a providers’ claim denial rates. Providers with low denial rates will have lower documentation requirements, while providers with high denial rates will have higher documentation requirements, thus adjusting provider burden based on demonstrated compliance. The assess component of the Fraud Risk Framework calls for federal managers to plan regular fraud risk assessments and to assess risks to determine a fraud risk profile. Identifying fraud risks is one of the steps included in the Fraud Risk Framework for assessing risks to determine a fraud risk profile. CMS has taken steps to identify some fraud risks through several control activities that target areas the agency has designated as higher risk within Medicare and Medicaid, including specific provider types, such as home health agencies, and specific geographic locations. As discussed earlier, CMS officials told us that CPI initially focused on developing control activities for Medicare FFS and considers these activities to be the most mature of all CPI efforts to address fraud risks. CMS has identified fraud risks in the following selected examples, which are not an exhaustive list of its control activities. Data analytics to assist investigations in Medicare FFS. In 2011, CMS implemented FPS, a data-analytic system that screens all Medicare FFS claims to identify health-care providers with suspect billing patterns for further investigation. Medicare FFS contractors—ZPICs and UPICs— have used FPS to identify and prioritize leads for investigations of potential fraud by high-risk Medicare FFS providers. Contractors told us that FPS allows them to quickly identify and triage leads. CMS’s guidance requires contractors to prioritize investigations with the greatest program impact or urgency and identifies required criteria for prioritizing investigations, such as patient abuse or harm, multistate fraud, and high dollar amount of potential overpayments. One contractor we interviewed developed a risk-prioritization model that incorporated CMS’s required criteria, such as patient harm, as well as additional criteria, such as provider spikes in billing, into a tool that automatically creates a provider risk score to help the contractor focus and prioritize investigative resources. Prior authorization for Medicare FFS services or supplies. CMS published a final rule in December 2015 that identifies a master list of durable medical equipment, prosthetics, orthotics, and supplies for which CMS can require prior authorization before suppliers submit a Medicare FFS claim. In this rule, CMS identified 135 items that are frequently subject to unnecessary utilization and stated that the agency expects the final rule to result in savings in the form of reduced unnecessary utilization, fraud, waste, and abuse. Under this program, prior authorization is a condition of payment for claims. CMS can choose which items on the master list to subject to prior authorization. For example, in March 2017, it began requiring prior authorization for selected power wheelchairs in four states and expanded the prior authorization program for these items to all states in July 2017. CMS also began to test the use of prior authorization on a voluntary basis through a series of fixed-length demonstrations for items and services that have been associated with high levels of improper payments, including high incidences of fraud in some cases, and unnecessary utilization in certain geographic areas. For example, CMS began implementing a voluntary prior authorization demonstration in September 2012 for other power mobility devices, such as power scooters, in seven states where historically there has been extensive evidence of fraud and improper payments. CMS expanded the demonstration to an additional 12 states in October 2014, for a total of 19 states. According to the initial Federal Register notice, CMS planned to use the demonstration to develop improved methods for investigation and prosecution of fraud to protect federal funds from fraudulent actions and the resulting improper payments. Under the demonstration, providers and suppliers are encouraged—but not required—to submit a request for prior authorization for certain items before they provide the item to the beneficiary and submit a claim for payment. Revised provider screening and enrollment processes for Medicare FFS and Medicaid FFS. In response to PPACA, in 2011 CMS implemented a revised screening process for providers and suppliers who enroll in Medicare and Medicaid based on identified provider risk categories. CMS placed all Medicare provider and supplier types into one of three risk categories—limited, moderate, or high—based on its assessment of the potential risk of fraud, waste, and abuse each provider and supplier type poses. For example, CMS designated prospective (newly enrolling) home health agencies and prospective suppliers of durable medical equipment, prosthetics, orthotics, and supplies in the high-risk category. According to the final rule and our interviews with CMS officials, CMS developed these risk-based categories based on its review and synthesis of various information sources about the fraud risks posed by each provider and supplier type, including (1) the agency’s experience with claims data used to identify potentially fraudulent billing practices, (2) expertise of contractors responsible for investigating and identifying Medicare fraud, and (3) GAO and OIG reports. CMS designated specific screening activities for each risk category, with increased requirements for moderate- and high-risk provider and supplier types. For example, moderate- and high-risk providers and suppliers must receive preenrollment site visits, and high-risk providers and suppliers also are subject to fingerprint-based criminal-background checks. As part of the revised screening process, beginning in September 2011, CMS also undertook its first program-wide effort to rescreen, or revalidate, the enrollment records of about 1.5 million existing Medicare FFS providers and suppliers, to determine whether they remain eligible to bill Medicare. Temporary provider enrollment moratoriums for certain providers and geographic areas for Medicare FFS and Medicaid FFS. CMS identified certain provider types and geographic areas as high risk for fraud and used its authority under PPACA to implement temporary moratoriums to suspend enrollment of such Medicare and Medicaid providers in those areas. For example, in July 2016, CMS extended temporary moratoriums statewide on the enrollment of new Medicare Part B nonemergency ambulance suppliers and Medicare home health agencies statewide in six states, as applicable. The statewide moratoriums also apply to Medicaid. According to the Federal Register notice, CMS imposed the temporary moratoriums based on qualitative and quantitative factors suggesting a high risk of fraud, waste, or abuse, such as law-enforcement expertise with emerging fraud trends and investigations. CMS’s data analysis also confirmed the agency’s determination of a high risk of fraud, waste, and abuse for these provider and supplier types within certain geographic areas, according to the notice. Medicaid state program integrity reviews and desk reviews. CMS tailored state Medicaid program-integrity reviews to areas it identified as high risk for improper payments, such as personal care services, which may also be at high risk for fraud. In March 2017, we reported that, from fiscal years 2014 through 2016, CMS conducted focused reviews of state program-integrity efforts in 31 states, reviewing 10 or 11 states annually. For each state, CMS tailored its focused reviews to the state’s managed care plans and relevant other high-risk areas, including provider enrollment and screening, nonemergency medical transportation, and personal care services. CMS and state officials we spoke with as part of that work told us that the tailored oversight had been beneficial and helped identify areas for improvement. CMS has also initiated desk reviews of state program-integrity efforts. According to CMS, these desk reviews allow the agency to provide states with customized program- integrity oversight. Vulnerability tracking system for Medicare. CPI recently initiated an effort to centralize and formalize a vulnerability tracking process for Medicare, which could support identification of specific fraud risks, both in Medicare and possibly Medicaid. As described by CPI officials, the process aims to collect information on fraud-related vulnerabilities from CMS employees, contractors, and other sources, such as GAO and HHS OIG reports. The assess component of the Fraud Risk Framework calls for federal managers to plan regular fraud risk assessments and assess risks to determine a fraud risk profile. Furthermore, federal internal control standards call for agency management to assess the internal and external risks their entities face as they seek to achieve their objectives. The standards state that, as part of this overall assessment, management should consider the potential for fraud when identifying, analyzing, and responding to risks. The Fraud Risk Framework states that, in planning the fraud risk assessment, effective managers tailor the fraud risk assessment to the program by, among other things, identifying appropriate tools, methods, and sources for gathering information about fraud risks and involving relevant stakeholders in the assessment process. Fraud risk assessments that align with the Fraud Risk Framework involve (1) identifying inherent fraud risks affecting the program, (2) assessing the likelihood and impact of those fraud risks, (3) determining fraud risk tolerance, (4) examining the suitability of existing fraud controls and prioritizing residual fraud risks, and (5) documenting the results. (See fig. 6.) Although, as discussed earlier, CMS has identified some fraud risks posed by providers in Medicare FFS and, to a lesser degree, Medicaid FFS, the agency has not conducted a fraud risk assessment for either the Medicare or Medicaid program. Such a risk assessment would provide the detailed information and insights needed to create a fraud risk profile, which, in turn, is the basis for creating an antifraud strategy. According to CMS officials, CMS has not conducted a fraud risk assessment for Medicare or Medicaid because, within CPI’s broader approach of preventing and eliminating improper payments, its focus has been on addressing specific vulnerabilities among provider groups that have shown themselves particularly prone to fraud, waste, and abuse. With this approach, however, it is unlikely that CMS will be able to design and implement the most-appropriate control activities to respond to the full portfolio of fraud risks. A fraud risk assessment consists of discrete activities that build upon each other. Specifically: Identifying inherent fraud risks affecting the program. As discussed earlier, CMS has taken steps to identify fraud risks. However, CMS has not used a process to identify inherent fraud risks from the universe of potential vulnerabilities facing Medicare and Medicaid programs, including threats from various sources. According to CPI officials, most of the agency’s fraud control activities are focused on fraud risks posed by providers. The Fraud Risk Framework discusses fully considering inherent fraud risks from internal and external sources in light of fraud risk factors such as incentives, opportunities, and rationalization to commit fraud. For example, according to CMS officials, the inherent design of the Medicare Part C program may pose fraud risks that are challenging to detect. A fraud risk assessment would help CMS identify all sources of fraudulent behaviors, beyond threats posed by providers, such as those posed by health-insurance plans, contractors, or employees. Assessing the likelihood and impact of fraud risks and determining fraud risk tolerance. CMS has taken steps to prioritize fraud risks in some areas, but it has not assessed the likelihood or impact of fraud risks or determined fraud risk tolerance across all parts of Medicare and Medicaid. Assessing the likelihood and impact of inherent fraud risks would involve consideration of the impact of fraud risks on program finances, reputation, and compliance. Without assessing the likelihood and impact of risks in Medicare or Medicaid or internally determining which fraud risks may fall under the tolerance threshold, CMS cannot be certain that it is aware of the most-significant fraud risks facing these programs and what risks it is willing to tolerate based on the programs’ size and complexity. Examining the suitability of existing fraud controls and prioritizing residual fraud risks. CMS has not assessed existing control activities or prioritized residual fraud risks. According to the Fraud Risk Framework, managers may consider the extent to which existing control activities—whether focused on prevention, detection, or response—mitigate the likelihood and impact of inherent risks and whether the remaining risks exceed managers’ tolerance. This analysis would help CMS to prioritize residual risks and to determine mitigation approaches. For example, CMS has not established preventive fraud control activities in Medicare Part C. Using a fraud risk assessment for Medicare Part C and closely examining existing fraud control activities and residual risks, CMS could be better positioned to address fraud risks facing this growing program and develop preventive control activities. Further, without assessing existing fraud control activities and prioritizing residual fraud risks, CMS cannot be assured that its current control activities are addressing the most-significant risks. Such analysis would also help CMS determine whether additional, preferably preventive, fraud controls are needed to mitigate residual risks, make adjustments to existing control activities, and potentially scale back or remove control activities that are addressing tolerable fraud risks. Documenting the risk-assessment results in a fraud risk profile. CMS has not developed a fraud risk profile that documents key findings and conclusions of the fraud risk assessment. According to the Fraud Risk Framework, the risk profile can also help agencies decide how to allocate resources to respond to residual fraud risks. Given the large size and complexity of Medicare and Medicaid, a documented fraud risk profile could support CMS’s resource-allocation decisions as well as facilitate the transfer of knowledge and continuity across CMS staff and changing administrations. Senior CPI officials told us that the agency plans to start a fraud risk assessment for Medicare and Medicaid after it completes a separate fraud risk assessment of the federally facilitated marketplace. This fraud risk assessment for the federally facilitated marketplace eligibility and enrollment process is being conducted in response to a recommendation we made in February 2016. In April 2017, CPI officials told us that this fraud risk assessment was largely completed, although in September 2017 CPI officials told us that the assessment was undergoing agency review. CPI officials told us that they have informed CM and CMCS officials that there will be future fraud risk assessments for Medicare and Medicaid; however, they could not provide estimated timelines or plans for conducting such assessments, such as the order or programmatic scope of the assessments. Once completed, CMS could use the federally facilitated marketplace fraud risk assessment and apply any lessons learned when planning for and designing fraud risk assessments for Medicare and Medicaid. According to the Fraud Risk Framework, factors such as size, resources, maturity of the agency or program, and experience in managing risks can influence how the entity plans the fraud risk assessment. Additionally, effective managers tailor the fraud risk assessment to the program when planning for it. The large scale and complexity of Medicare and Medicaid as well as time and resources involved in conducting a fraud risk assessment underscore the importance of a well-planned and tailored approach to identifying the assessment’s programmatic scope. Planning and tailoring may involve decisions to conduct a fraud risk assessment for Medicare and Medicaid programs as a whole or divided into several subassessments to reflect their various component parts (e.g., Medicare FFS, Medicaid managed care) as well as determining the timing and order of assessments (e.g., concurrently or consecutively for Medicare and Medicaid). CMS’s existing fraud risk identification efforts as well as communication channels with stakeholders could serve as a foundation for developing a fraud risk assessment for Medicare and Medicaid. The leading practices identified in the Fraud Risk Framework discuss the importance of identifying appropriate tools, methods, and sources for gathering information about fraud risks and involving relevant stakeholders in the assessment process. CMS’s fraud risk identification efforts discussed earlier could provide key information about fraud risks and their likelihood and impact. Further, existing relationships and communication channels across CMS and its extensive network of stakeholders could support building a comprehensive understanding of known and potential fraud risks for the purposes of a fraud risk assessment. For example, the fraud vulnerabilities identified through data analysis and information sharing with states, health-insurance plans, law-enforcement organizations, and contractors through the HFPP could inform a fraud risk assessment. CPI’s Command Center missions—facilitated collaboration sessions that bring together experts from various disciplines to improve the processes for fraud prevention in Medicare and Medicaid—could bring together experts to identify potential or emerging fraud vulnerabilities or to brainstorm approaches to mitigate residual fraud risks. As CMS makes plans to move forward with a fraud risk assessment for Medicare and Medicaid, it will be important to consider the frequency with which the fraud risk assessment would need to be updated. While, according to the Fraud Risk Framework, the time intervals between updates can vary based on the programmatic and operating environment, assessing fraud risks on an ongoing basis is important to ensure that control activities are continuously addressing fraud risks. The constantly evolving fraud schemes, the size of the programs in terms of beneficiaries and expenditures, as well as continual changes in Medicare and Medicaid programs—such as development of innovative payment models and increasing managed-care enrollment—call for constant vigilance and regular updates to the fraud risk assessment. The design and implement component of the Fraud Risk Framework calls for federal managers to design and implement a strategy with specific control activities to mitigate assessed fraud risks and collaborate to help ensure effective implementation. According to the Fraud Risk Framework, effective managers develop and document an antifraud strategy that describes the program’s approach for addressing the prioritized fraud risks identified during the fraud risk assessment, also referred to as a risk-based antifraud strategy. A risk- based antifraud strategy describes existing fraud control activities as well as any new fraud control activities a program may adopt to address residual fraud risks. In developing a strategy and antifraud control activities, effective managers focus on fraud prevention over detection, develop a plan for responding to identified instances of fraud, establish collaborative relationships with stakeholders, and create incentives to help effectively implement the strategy. Additionally, as part of a documented strategy, management identifies roles and responsibilities of those involved in fraud risk management activities; describes control activities as well as plans for monitoring and evaluation, creates timelines, and communicates the antifraud strategy to employees and stakeholders, among other things. As discussed earlier, CMS has some control activities in place to identify fraud risk in Medicare and Medicaid, particularly in the FFS program. However, CMS has not developed and documented a risk-based antifraud strategy to guide its design and implementation of new antifraud activities and to better align and coordinate its existing activities to ensure it is targeting and mitigating the most-significant fraud risks. Antifraud strategy. CMS officials told us that CPI does not have a documented risk-based antifraud strategy. Although CMS has developed several documents that describe efforts to address fraud, the agency has not developed a risk-based antifraud strategy for Medicare and Medicaid because, as discussed earlier, it has not conducted a fraud risk assessment that would serve as a foundation for such strategy. In 2016, CPI identified five strategic objectives for program integrity, which include antifraud elements and an emphasis on prevention. However, according to CMS officials, these objectives were identified from discussions with CMS leadership and various stakeholders and not through a fraud risk assessment process to identify inherent fraud risks from the universe of potential vulnerabilities, as described earlier and called for in the leading practices. These strategic objectives were presented at an antifraud conference in 2016, but were not announced publicly until the release of the Annual Report to Congress on the Medicare and Medicaid Integrity Programs for Fiscal Year 2015 in June 2017. Stakeholder relationships and communication. CMS has established relationships and communicated with stakeholders, but, without an antifraud strategy, stakeholders we spoke with lacked a common understanding of CMS’s strategic approach. Prior work on practices that can help federal agencies collaborate effectively calls for a strategy that is shared with stakeholders to promote trust and understanding. Once an antifraud strategy is developed, the Fraud Risk Framework calls for managers to collaborate to ensure effective implementation. Although some CMS stakeholders were able to describe various CMS program- integrity priorities and activities, such as home health being a fraud risk priority, the stakeholders could not communicate, articulate, or cite a common CMS strategic approach to address fraud risks in its programs. Incentives. The Fraud Risk Framework discusses creating incentives to help ensure effective implementation of the antifraud strategy once it is developed. Currently, some incentives within stakeholder relationships may complicate CMS’s antifraud efforts. As discussed earlier, CMS is a partner and provides oversight to states’ program-integrity functions. Officials from one state told us that they were reluctant to share their program vulnerabilities because CMS would use this information to later audit the state. Among contractors, CMS encourages information sharing through conferences and workshops; however, competition for CMS business among contractors can be a disincentive to information sharing. CMS officials acknowledged this concern and said that they expect contractors to share information related to fraud schemes, outcomes of investigations, and tips for addressing fraud, but not proprietary information such as algorithms to risk-score providers. Without developing and documenting an antifraud strategy based on a fraud risk assessment, as called for in the design and implement component of the Fraud Risk Framework, CMS cannot ensure that it has a coordinated approach to address the range of fraud risks and to appropriately target and allocate resources for the most-significant risks. Considering fraud risks to which the Medicare and Medicaid programs are most vulnerable, in light of the malicious intent of those who aim to exploit the programs, would help CMS to examine its current control activities and potentially design new ones with recognition of fraudulent behavior it aims to prevent. This focus on fraud is distinct from a broader view of program integrity and improper payments by considering the intentions and incentives of those who aim to deceive rather than well-intentioned providers who make mistakes. Also, continued growth of the programs, such as growth of Medicare Part C and Medicaid managed care, call for consideration of preventive fraud control activities across the entire network of entities involved. Further, considering the large size and complexity of Medicare and Medicaid and the extensive stakeholder network involved in managing fraud in the programs, a strategic approach to managing fraud risks within the programs is essential to ensure that a number of existing control activities and numerous stakeholder relationships and incentives are being aligned to produce desired results. Once developed, an antifraud strategy that is clearly articulated to various CMS stakeholders would help CMS to address fraud risks in a more coordinated and deliberate fashion. Thinking strategically about existing control activities, resources, tools, and information systems could help CMS to leverage resources while continuing to integrate Medicare and Medicaid program-integrity efforts along functional lines. A strategic approach grounded in a comprehensive assessment of fraud risks could also help CMS to identify future enhancements for existing control activities, such as new preventive capabilities for FPS or additional fraud factors in provider enrollment and revalidation, such as provider risk scoring, to stay in step with evolving fraud risks. The evaluate and adapt component of the Fraud Risk Framework calls for federal managers to evaluate outcomes using a risk-based approach and adapt activities to improve fraud risk management. Furthermore, according to federal internal control standards, managers should establish and operate monitoring activities to monitor the internal control system and evaluate the results, which may be compared against an established baseline. Ongoing monitoring and periodic evaluations provide assurances to managers that they are effectively preventing, detecting, and responding to potential fraud. CMS has established monitoring and evaluation mechanisms for its program-integrity activities that it could incorporate into an antifraud strategy. In Medicare, CMS has taken steps to measure the rate of fraud in a particular service area. We have previously reported that agencies may face challenges measuring outcomes of fraud risk management activities in a reliable way. These challenges include the difficulty of measuring the extent of deterred fraud, isolating potential fraud from legitimate activity or other forms of improper payments, and determining the amount of undetected fraud. Despite these challenges, CMS has taken steps to estimate a fraud baseline—meaning the rate of probable fraud—in the home health benefit. In fiscal year 2016, CMS conducted a pretest in the Miami-Dade area of Florida to evaluate its potential measurement approach that could later be used in a nationwide study of probable fraud among home health agencies. The pretest was not a random sample and was not intended to produce a rate of fraud, but instead was intended to test the interview instruments and data-collection methodology CMS might use in a study nationwide. CMS and its contractor collected information from home health agencies, the attending providers, and Medicare beneficiaries in the Miami-Dade area in order to test these interview instruments. CMS completed this pretest, but, according to CMS officials, the agency does not yet have plans to roll out a nationwide study that would estimate a probable fraud rate for the Medicare FFS home health benefit. In its 2015 annual report to Congress, CMS stated that “documenting the baseline amount of fraud in Medicare is of critical importance, as it allows officials to evaluate the success of ongoing fraud prevention activities.” CMS officials working on the pilot told us that having an estimate of the rate of fraud in home health benefits would allow CMS to reliably assess its efforts at eliminating or reducing fraud. Without a baseline, officials said, the agency cannot know whether its antifraud efforts are as effective as they could be. We previously reported that the lack of a baseline for the amount of health-care fraud that exists limits CMS’s ability to determine whether its activities are effectively reducing health care fraud and abuse. A baseline estimate could provide an understanding of the extent of fraud and, with additional information on program activities, could help to inform decision making related to allocation of resources to combat health-care fraud. As described in the Fraud Risk Framework, in the absence of a fraud baseline, agencies can gather additional information on the short-term or intermediate outcomes of some antifraud initiatives, which may be more readily measured. For example, CMS has developed some performance measures to provide a basis for monitoring its progress towards meeting the program-integrity goals set in the HHS Strategic Plan and Annual Performance Plan. Specifically, CMS measures whether it is meeting its goal of “increasing the percentage of Medicare FFS providers and suppliers identified as high risk that receive an administrative action.” CMS does not set specific antifraud goals for other parts of Medicare or Medicaid; other CMS performance measures relate to measuring or reducing improper payments in CHIP, Medicaid, and the various parts of Medicare. CMS uses return-on-investment and savings estimates to measure the effectiveness of its Medicare program-integrity activities and FPS. For example, CMS uses return-on-investment to measure the effectiveness of FPS and, in response to a recommendation we made in 2012, CMS developed outcome-based performance targets and milestones for FPS. CMS has also conducted individual evaluations of its program-integrity activities, such as an interim evaluation of the prior-authorization demonstration for power mobility devices that began in 2012 and is currently implemented in 19 states. Commensurate with greater maturity of control activities in Medicare FFS compared to other parts of Medicare and Medicaid, monitoring and evaluation activities for Medicare Parts C and D and Medicaid are more limited. For example, CMS calculates savings for its program-integrity activities in Medicare Parts C and D, but not a full return-on-investment. CMS officials told us that calculating costs for specific activities is challenging because of overlapping activities among contractors. CMS officials said they continue to refine methods and develop new savings estimates for additional program-integrity activities. According to the Fraud Risk Framework, effective managers develop a strategy and evaluate outcomes using a risk-based approach. In developing an effective strategy and antifraud activities, managers consider the benefits and costs of control activities. Ongoing monitoring and periodic evaluations provide reasonable assurance to managers that they are effectively preventing, detecting, and responding to potential fraud. Monitoring and evaluation activities can also support managers’ decisions about allocating resources, and help them to demonstrate their continued commitment to effectively managing fraud risks. As CMS takes steps to develop an antifraud strategy, it could include plans for refining and building on existing methods such as return-on- investment or savings measures, and setting appropriate targets to evaluate the effectiveness of all of CMS’s antifraud efforts. Such a strategy would help CMS to efficiently allocate program-integrity resources and to ensure that the agency is effectively preventing, detecting, and responding to potential fraud. For example, while doing so would involve challenges, CMS’s strategy could detail plans to advance efforts to measure a potential fraud rate through baseline and periodic measures. Fraud rate measurement efforts could also inform risk assessment activities, identify currently unknown fraud risks, align resources to priority risks, and develop effective outcome metrics for antifraud controls. Such a strategy would also help CMS ensure that it has effective performance measures in place to assess its antifraud efforts beyond those related to providers in Medicare FFS, and establish appropriate targets to measure the agency’s progress in addressing fraud risks. As CMS makes plans to move forward with a strategy and to further develop evaluation and monitoring mechanisms, it will be important to share its efforts with stakeholders. The Fraud Risk Framework states that effective managers communicate lessons learned from fraud risk management activities to stakeholders. For example, CMS could be a leader to states in measuring the effectiveness of program-integrity efforts. Officials in three of the four states we spoke with expressed interest in receiving CMS guidance on how to measure the effectiveness of their Medicaid program-integrity efforts, such as by providing models for how to calculate return-on-investment. Medicare and Medicaid provide health insurance to over 129 million Americans, but the size—in terms of number of beneficiaries and amount of expenditures—as well as complexity of these programs make them inherently susceptible to fraud and improper payments. CMS currently manages these risks across its programs as part of a broader approach to identifying and controlling for multiple sources of improper payments and by developing relationships with an extensive network of stakeholders. In Medicare and Medicaid specifically, we note that CMS has taken many important steps toward implementing a strategic approach for managing fraud. However, the agency could benefit by more fully aligning its efforts with the four components of the Fraud Risk Framework. CMS is well positioned to leverage its fraud risk management efforts— such as demonstrated leadership for combating fraud, existing control activities, and stakeholder relationships—to provide additional antifraud training, as well as to develop an antifraud strategy based on fraud risk assessments for Medicare and Medicaid. We recognize that the effort may be challenging, given the size and complexity of Medicare and Medicaid, and the need to balance antifraud activities with CMS’s other mission priorities. However, by not employing the actions identified in the Fraud Risk Framework and incorporating them in its approach to managing fraud risks, CMS is missing a significant opportunity to better ensure employee vigilance against fraud, and to organize and focus its many antifraud and program-integrity activities and related resources into a comprehensive strategy. Such a strategy would (1) provide reasonable assurance that CMS is targeting the most-significant fraud risks in its programs and (2) help protect the government’s substantial and growing investments in these programs. We are making the following three recommendations to CMS: The Administrator of CMS should provide fraud-awareness training relevant to risks facing CMS programs and require new hires to undergo such training and all employees to undergo training on a recurring basis. (Recommendation 1) The Administrator of CMS should conduct fraud risk assessments for Medicare and Medicaid to include respective fraud risk profiles and plans for regularly updating the assessments and profiles. (Recommendation 2) The Administrator of CMS should, using the results of the fraud risk assessments for Medicare and Medicaid, create, document, implement, and communicate an antifraud strategy that is aligned with and responsive to regularly assessed fraud risks. This strategy should include an approach for monitoring and evaluation. (Recommendation 3) We provided a draft of this report to HHS and DOJ for comment. HHS provided written comments, which are reprinted in appendix I. DOJ did not have comments. HHS and DOJ also provided technical comments, which we incorporated as appropriate. In commenting on this report, HHS agreed with our three recommendations. Specifically, in response to our first recommendation to provide required fraud-awareness training to all employees, HHS stated that it will develop and implement a fraud-awareness training plan to ensure all CMS employees receive training. Regarding our second recommendation to conduct fraud risk assessments for Medicare and Medicaid, HHS stated that it is currently conducting a fraud risk assessment on the federally facilitated marketplace and, when this assessment is complete, will apply the lessons learned in assessing this program to fraud risk assessments of Medicare and Medicaid. In response to our third recommendation to create, document, implement, and communicate an antifraud strategy that is aligned with and responsive to regularly assessed fraud risks, HHS stated that it will develop respective risk-based antifraud strategies after completing fraud risk assessments for Medicare and Medicaid. We are sending copies of this report to the Acting Secretary of Health and Human Services, the Administrator of CMS, the Assistant Attorney General for Administration at DOJ, as well as appropriate congressional committees and other interested parties. In addition, this report is available at no charge on the GAO website at http://www.gao.gov. If you or your staff members have any questions about this report, please contact me at (202) 512-6722 or bagdoyans@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made contributions to this report are listed in appendix II. In addition to the contact named above, Tonita Gillich (Assistant Director), Irina Carnevale (Analyst-in-Charge), Michael Duane, Laura Sutton Elsberg, and Catrin Jones made key contributions to this report. Also contributing to the report were Lori Achman, James Ashley, Colin Fallon, Leslie V. Gordon, Maria McMullen, Sabrina Streagle, and Shana Wallace.
The RAD program was authorized by Congress and signed into law by the President in November 2011 under the Consolidated and Further Continuing Appropriations Act, 2012 with amendments in 2014, 2015, 2016, and 2017. The RAD program consists of two components. The first component of the RAD program—and the focus of our review— provides PHAs the opportunity to convert units subsidized under HUD’s public housing program and owned by the PHAs to properties with long- term (typically, 15–20 years) project-based voucher (PBV) or project- based rental assistance (PBRA) contracts. These are two forms of Section 8 rental assistance that tie the assistance to the unit to provide subsidized housing to low-income residents. In a RAD conversion, PHA- owned public housing properties can be owned by the PHA, transferred to new public or nonprofit owners, or transferred to private, for-profit owners when necessary to access LIHTC financing, if the PHA preserves its interest in the property in a HUD-approved manner. The second component of RAD converts privately owned properties with expiring subsidies under old rental assistance programs to PBV or PBRA in order to preserve affordability and encourage property rehabilitation. The goals of the RAD program include preserving the affordability of federally assisted rental properties and improving their physical and financial condition. Specifically, postconversion owners (PHAs, nonprofits, or for-profit entities) can leverage the subsidy payments under the newly converted contracts to raise capital through private debt and equity investments, or conventional private debt, to make improvements. The RAD program provides added flexibility for PHAs to access private and public funding sources to supplement public housing funding. These financing sources may include debt financing through public or private lenders; mortgage financing insured by FHA; PHA operating reserves; replacement housing factor funds; seller or take-back financing; deferred developer fees; equity investment generated by the availability of 4 percent and 9 percent LIHTC; or other private or philanthropic sources. PHAs also may pursue various options for their conversions, which often depend on property needs and available financing, including property rehabilitation or new construction. Additionally, PHAs may undertake conversion involving no property rehabilitation or new construction to meet certain financial goals or for future rehabilitation or new construction, as long as the PHA can demonstrate to HUD that the property does not need immediate rehabilitation and can be physically and financially maintained for the term of the Section 8 Housing Assistance Payment contract (HAP contract). The RAD authorizing legislation and RAD Notice also specify requirements for ownership and control of converted properties. That is, converted properties must have public or nonprofit ownership or control, with limited exceptions. The RAD authorizing legislation, RAD Notice, HAP contracts, and RAD Use Agreement also establish procedures to help ensure that public housing remains a public asset should challenges arise, such as default, bankruptcy, or foreclosure. Oversight of RAD conversion and properties is primarily divided among three HUD offices. The Office of Recapitalization is responsible for administering the conversion process but generally does not oversee converted properties. Before conversion, the Office of Public and Indian Housing oversees the properties. After conversion, oversight remains with Public and Indian Housing for properties that convert to PBV contracts and transfers to the Office of Multifamily Housing Programs for PBRA. The RAD program has been implemented and expanded in phases. Since its authorization, the RAD unit cap gradually increased from 60,000 units in 2011 to 225,000 units in May 2017. The RAD program is currently fully subscribed with all 225,000 units allocated. As of September 30, 2017, 689 conversions were closed that involved a total of 74,709 units (see fig. 1 for a breakdown by fiscal year). Additionally, 706 conversions involving 79,078 units were in the process of structuring conversion plans. The remaining conversions under the cap were allocated to specific properties and in the process of having commitments issued or reserved under multi-phase or portfolio awards, according to HUD officials. RAD conversions begin with the submission of an application by PHAs after which they are notified of selection. The PHA is then required to submit a financing plan within 180 days or a later deadline based on the nature of the financing proposed. A RAD conversion is considered closed when the HAP contract is signed and financial documents are executed. The properties are considered converted to Section 8 assisted housing on the effective date of the HAP, which is generally the first day of the following month. Once the RAD conversion is closed, the PHA or ownership entity can move forward with its submitted proposals or RAD-related rehabilitation or new construction and is responsible for complying with RAD requirements and associated contracts. In some cases, rehabilitation can take place in advance of conversion closing if public housing funds are being used. Most RAD conversions involved some type of construction. Our analysis of HUD data showed that as of September 30, 2017 417 of 689 closed conversions (61 percent) involved planned rehabilitation to the property, 86 (12 percent) new construction, and 186 (27 percent) no construction; and 361 of 706 active RAD conversions (51 percent) involved planned rehabilitation, 89 (13 percent) new construction, and 256 (36 percent) no construction. HUD officials stated that they approve conversions that involve no immediate planned rehabilitation or new construction as long as the property has no immediate needs to be addressed. Such conversions allow PHAs to better position themselves to access additional capital to address future rehabilitation or construction plans. Our review of 31 conversion files also showed that the scope of proposed physical changes varied among RAD conversions. For properties that included scope of work narratives, physical changes included renovations to mitigate hazardous materials, aesthetic renovations, code and accessibility compliance, and construction of new buildings, among other changes. Financing for RAD conversions involved multiple public and private sources, but many conversions used LIHTC. Our analysis of HUD data showed that as of September 30, 2017, 173 of 689 closed RAD conversions (25 percent) utilized 4 percent LIHTC, 99 (14 percent) utilized 9-percent LIHTC, and 416 (60 percent) did not use LIHTC. By dollar amount, major financing sources were 4 percent LIHTC at $2.4 billion; new first mortgages at $1.8 billion; and 9 percent LIHTC at $1.1 billion. Construction costs constituted the highest-dollar use of financing for RAD conversions, but not all conversions incurred construction costs, as discussed earlier. On average, construction costs per closed conversion were $6.4 million (ranging from no construction costs to $236 million) and nearly $60,000 per-unit converted to RAD. Construction costs represented the highest-dollar use of financing for closed RAD conversions at $4.4 billion followed by building and land acquisition costs, and developer fees. For more information on financing sources and uses, see appendix II. PHA officials and developers we interviewed cited various factors that influence financing sources needed for RAD conversions. For example, property needs assessments help establish the level of rehabilitation or new construction that would address the capital needs of the property. In turn, needs assessments can derive from physical assessment results and incorporate federal, state, or local compliance requirements. For instance, rehabilitation or construction would need to address the accessibility requirements of the Americans with Disabilities Act and local building codes, among other requirements. PHA officials and developers we interviewed also said they had to consider competition or access to financing for RAD conversions. For example, PHAs noted that tax credit applications and other financing had to be competitive. Some PHAs we interviewed also noted that while the 9 percent LIHTC provides more equity to finance low-income units (finances 70 percent of the costs of the units), there is more competition for the 9 percent LIHTC, while the 4 percent LIHTC can be automatically awarded for certain deals involving tax exempt bonds and federally subsidized projects. Thus, while some PHAs and developers might prefer to obtain 9 percent LIHTC, they often apply for 4 percent LIHTC to increase the chances of obtaining some tax credit equity. For example, one particular PHA that had used both 4 percent and 9 percent LIHTCs noted that in one transaction it had to compete against 74 applicants for 25 available awards of 9 percent credits. The RAD authorizing statute requires HUD to assess and publish findings regarding the amount of private capital leveraged as a result RAD conversions. A leverage ratio relates the dollars other sources provide to the dollars a program provides to an institution or a project. HUD uses various quantitative, qualitative, and processing and efficiency metrics to measure conversion outcomes. To meet the RAD statutory requirement, HUD published an overall RAD leverage ratio that has fluctuated between 19:1 and 9:1 since 2014. HUD’s most recent leverage ratio in fiscal year 2017 was 19:1, nearly double what the agency reported the prior year. We asked HUD officials why the leverage ratio nearly doubled between 2016 and 2017 and received conflicting information during the course of our audit. Initially, officials noted that the ratio was intended to replicate the methodology used by PD&R in its September 2016 report. Subsequently, the officials clarified that they did not follow PD&R’s methodology for categorizing financial source data. Specifically, officials did not review or make manual adjustments to the financial data PHAs entered in open source fields to ensure sources actually represented public, private, or other funding categories when calculating the leverage ratio. Finally, they noted that they disagreed with the methodology used in the PD&R September 2016 report and stated that there are various ways to calculate leverage. For the purposes of announcing the most recent leverage ratio in 2017, HUD officials decided that a leverage ratio comparing federally appropriated public housing resources would reflect the amount of financing leveraged had RAD not existed. We found, and officials from HUD acknowledged, three limitations to the RAD leverage calculation. First, HUD generally had data on funding sources and amounts a RAD conversion proposed to use (at the time of its application to HUD and at the time of closing of construction financing) rather than data after construction is completed on funding sources and amounts. HUD officials stated that they were reviewing final closing packages to confirm that the data reflect the latest reported information on sources and uses of funds for each conversion at closing. However, sources and uses of funds and amounts at the time the RAD conversion is closed may differ from amounts upon completion of construction. In October 2017, HUD implemented procedures to verify completion of planned construction activities and costs, which we discuss later in this report. Second, HUD’s leverage ratio, published in 2017, did not manually adjust funding source data to accurately account for all sources in calculating the leverage ratio for RAD. Specifically, HUD did not isolate funding sources that were federally appropriated, contributed by the PHA, or contributed by state or local municipalities to calculate leverage. For example, among approximately $2 billion from other financial sources, HUD included Moving to Work (MTW) funding (which may include public housing capital funds, public housing operating funds, and voucher funds) and tax credit equity as leveraged sources. However, these are not necessarily private sources, which we explain later in this report. As a result, HUD’s current calculation does not reflect the amount of private- sector leveraging. HUD calculated and published a RAD leverage ratio in May of 2017 using the following formula: Total leverage ratio = (total dollars from all sources – public housing dollars) To calculate the RAD leverage ratio, HUD uses some but not all financial source data it collects (see app. II for a list of data fields collected by HUD). For example, HUD mistakenly excluded data that capture private funds, reducing the amount of total sources in the numerator. HUD calculates “public housing dollars” by adding data that capture replacement factor funds, public housing operating reserve funds, and prior-year public housing capital funds. HUD considers tax credit equity, new first mortgages, and “other funding” data to be non-public housing dollars (see app. II for a list of fields in HUD’s calculation). PHAs enter a description and amount for other funding sources in “other funding” data fields (see app. II). For example, a PHA may enter a federal financial source in one of the open-entry “other funding” data fields, requiring a manual adjustment to properly account for the financial source. According to HUD, additional fields were included in mid-2016 to better differentiate certain sources such as from the HOME Investment Partnerships Program (HOME) and seller take-back financing. Prior to this point, these financial sources were placed into “other” fields, and the standard resource desk report had not been updated until mid-2017 to include all of these fields. Third, HUD does not categorize and report its leveraging by private and public sources. According to HUD officials, informative leverage methodologies could calculate the ratio based on the leveraging of public housing program funds, the leveraging of all federally appropriated funds, or the leveraging of PHA funds (i.e., sources in the transaction that have come from the PHA itself even if not federally appropriated through the public housing program), among other methodologies. The RAD authorizing statute requires HUD to assess and publish findings on the amount of private-sector leveraging. In addition, Standards for Internal Control in the Federal Government require agencies to communicate quality information with external parties, such as other government entities, to make informed decisions and evaluate the entity’s performance in achieving key objectives. HUD also does not use final (postcompletion) funding data in another metric of RAD leveraging. Specifically, in June 2017 HUD publicly reported that RAD “has leveraged more than $4 billion in capital investment in order to make critical repairs and improvements.” HUD calculates this figure by summing the construction costs—a subcomponent of total costs—with data from the time a conversion closes and not upon completion of construction. HUD officials we spoke with clarified that this metric solely reports construction investments and does not reflect any conclusion regarding private leverage of public funds. But, HUD publically characterized this measure in different ways, including as the amount of “public-private investment in distressed public housing,” the amount of “construction achieved under RAD,” and the amount of “new private and public funds leveraged by RAD.” HUD’s 2016 interim report calculated and published multiple leverage ratios, but chose to highlight a RAD leverage ratio that is consistent with ratios used for other HUD programs. However, the ratio does not specifically follow the prescribed ratio language in the authorizing statute because the report states that the ratio represents the amount of private and public external sources invested for every dollar invested by PHAs but the statutory language only discusses private-sector leveraging. Officials further noted that the statute does not require a particular methodology and HUD relies on PD&R—and its independent contractor— to determine the appropriate methodology for purposes of compliance with the statute. Lastly, the statute does not preclude the use of other leverage metrics for other purposes, such as using the ratio to measure the amount of nonpublic housing funds leveraged in RAD transactions that would not be available to the property absent RAD. As a result, HUD’s leverage metrics announced in May 2017 do not accurately reflect the amount of private-sector leveraging achieved through RAD, do include public funding as private sources, and inconsistently measured sources that were federally appropriated or contributed by PHAs, potentially under- or over-reporting the program’s performance. Additionally, in October 2017, HUD began implementing procedures to collect data after construction is completed and is not yet able to calculate a leverage metric using final (postcompletion) financial sources rather than the financial sources collected at closing. The lack of a consistent metric for private leveraging could also lead to inconsistent reporting of the leverage ratio, as has occurred in prior years. We recalculated RAD leverage ratios in a number of different ways, including to correct errors we identified during our review. For example, HUD’s 2016 interim report noted that data on closed transactions do not provide detailed description of “other sources,” requiring a crosswalk between applications and closed transactions to develop estimates for the allocation of “other sources” across financial source categories. Abbreviated descriptions are provided in the form of notes that are not always clear and consistent; therefore public housing sources may include federally appropriated sources, as well state, city, or county sources. Through our estimates, we found that the overall leverage ratio could range from 7.44:1 for a ratio recalculating HUD’s leverage ratio to 1.23:1 for a ratio estimating private-sector leveraging. Recalculation with HUD methodology and financial source recategorization. As discussed previously, HUD’s methodology does not account for all financial data collected by HUD and includes “other” funding sources erroneously considered as leveraged funds. Thus, we manually adjusted RAD funding source data and found that nearly $1.2 billion were erroneously considered leveraged funds because they are not private funds. For example, HUD included MTW funds; public housing operating reserves; public housing capital funds; replacement housing factor funds; other federal funds; other state, local, or county funds; and take-back financing funds as leveraged financial sources. For more information, see appendix II. We obtained documentation from HUD to replicate their methodology and recategorized financial sources that corrected errors in the data, and found that the RAD leverage ratio was less than half of HUD’s most recently publicly reported leverage ratio (19:1), approximately 7.44:1 (see app. II). Recalculation to exclude LIHTC and other federal sources. We previously reported that LIHTCs are considered a federal source because tax credit equity represents foregone federal tax revenue and, therefore, are a direct cost to the government. Accordingly, we recalculated the RAD leverage ratio by excluding all federal funding sources and obtained a ratio of approximately 1.43:1 (see app. II). Recalculation of private-sector leveraging. Lastly, the RAD authorizing statute requires HUD to assess and publish findings on the amount of private-sector leveraging, but HUD’s current calculation does not present the amount of private-sector leveraging and does not include all available data (for example, the “Other Private” funds collected by HUD). We estimated the amount of private-sector leveraging by grouping public housing sources, other public sources, and private sources, resulting in a leverage ratio of approximately 1.23:1 (see app. II). In October 2017, HUD implemented procedures to certify completion after developers finish RAD-approved rehabilitation or construction. Previously, HUD had a limited ability to monitor and evaluate final (postcompletion) physical and financial changes in RAD projects with existing data. According to HUD officials, HUD did not implement completion certification procedures before October 2017 because it had been addressing what it considered to be the highest risks first (such as clarifying requirements for RAD participants, resident safeguards, and other procedural and administrative requirements). HUD’s October 2017 completion certification procedures include instructions for owners to report final construction costs and documentation on completion of repairs or construction within 45 days of the completion date recorded in the RAD Conversion Commitment. More specifically, HUD requires owners to list a final construction cost amount—a subcomponent of total costs—in the RAD resource desk, describe variances from the approved construction cost amount in a comment box, and describe how increases in costs were addressed. Additionally, a third-party must certify that the repairs in the scope of work were completed by providing an attestation to HUD. However, HUD’s procedures do not require documentation from the owners to support the final total cost figures, which include not only construction costs but also building and land acquisition costs, and developer fees, among others as noted earlier in this report. These procedures also do not require a certification from owners on all financing sources and costs recorded in the RAD Conversion Commitment. Standards for Internal Control in the Federal Government require that management implement control activities through documented policies and procedures to provide reasonable assurance that the objectives of the agency will be achieved, and also communicate quality information with external parties to make informed decisions and evaluate the entity’s performance in achieving key objectives. While HUD now has certification completion procedures in place, this process provides the agency limited financial information from owners. As a result, HUD is unable to report metrics that reflect final (postcompletion) RAD financial outcomes after construction is completed. Furthermore, HUD is limited in its ability to effectively oversee conversion budget and cost variances, and expenditures that require HUD approval. Lastly, the RAD authorizing statute requires that the Secretary of HUD demonstrate the feasibility of the RAD conversion model to recapitalize and operate public housing properties under various situations and by leveraging other sources of funding to recapitalize properties. Without metrics that reflect the final (postcompletion) financial outcomes of RAD after construction is completed, HUD and congressional decisionmakers are unable to make informed decisions concerning the RAD program. HUD has not systematically tracked or analyzed household data on residents in RAD-converted units that are available from its public housing or Section 8 databases or from PHAs or other postconversion owners—the main sources of resident data for the RAD program. In addition, HUD has not yet developed monitoring procedures for all the resident safeguards in the RAD program. Finally, residents told us of some concerns about information they received on RAD conversions, communications opportunities, and the relocation process. HUD officials told us that the agency does not systematically track or analyze household-level data on residents in RAD-converted units across existing program databases (HUD maintains household data for the public housing and Section 8 rental assistance programs in two databases). In particular, HUD does not track changes in household characteristics before and after conversion, such as changes in rent, as well as relocations or displacement of individual households. However, according to HUD officials, their databases are not designed to track the impact of RAD conversion on residents and they are unable to electronically link household information submitted before RAD conversion to information submitted after conversion. Once a property is converted, the property and corresponding household information are removed from the public housing database. Owners of converted properties are to use software to manually enter household information into the databases for the Section 8 program when submitting tenant certifications and information for assistance payments. This procedure is the standard for administration of all project-based Section 8 properties. HUD officials stated that they have explored the possibility of transferring household data from one system to another at the time of a property’s conversion. While HUD has not systematically analyzed household information from its public housing and Section 8 databases, we were able to perform a limited analysis. We requested and received data from HUD on the households affected by RAD. Using the data provided that were current as of June 2017, we were able to identify about 26,000 households that lived in units that were converted to a PBV subsidy, but we were unable to identify the total number of households converted to a PBRA subsidy. Based on our analysis of 26,000 PBV households, we found about 2,700 (about 11 percent of) households were headed by an about 6,800 (about 26 percent of) households were headed by an individual with a disability; about 2,700 households (about 10 percent of) households were headed by an elderly person who also had a disability; over half (about 14,000 or 54 percent) of the households were headed by an individual identified as black; close to 11,000 households (about 41 percent) were identified as white; and about 1,000 households (about 4 percent) were identified as Asian. Close to 3,100 households (about 12 percent) were headed by an individual identified as Hispanic; about half (about 49 percent) of the PBV households were single- person households; the median annual income of PBV households both before and after RAD conversion was about $10,000; and about 5,300 (about 20 percent) of households were paying a flat rent rather than income-based rent before RAD conversion. However, the data on PBV households were not comprehensive. For example, while about 10,000 residents (about 57 percent) experienced a rent increase following RAD conversion under PBV, we could not determine if the rent increase was the result of an increase in resident income. We also could not determine changes in location among the PBV households following RAD conversion. Rather than relying on the public housing and Section 8 databases for tracking household information during conversion, HUD officials indicated that the agency will rely on locally maintained resident logs, which contain household information collected by property owners, as the starting point when HUD determines a compliance review is warranted. The logs will be the primary way the agency collects household information for compliance reviews under the RAD program, according to HUD officials. In November 2016, HUD issued a notice, which requires the PHA or other postconversion owner to maintain a log about every household at a converting project, including information on race and ethnicity, household size, and disability. The notice also requires owners to track residence status throughout the relocation process, including whether the resident has returned, moved elsewhere, was permanently relocated or evicted; relocation dates; and details on any temporary housing and moving assistance provided. Owners are required to make the information available to HUD upon request for audits and other purposes. According to HUD officials, the agency expects the information in the resident logs to be more robust than what they would collect through the public housing and Section 8 databases, which do not track residents while they are relocated. HUD officials stated that the agency plans to review selected resident logs as part of an ongoing limited compliance review of about 90 RAD conversion projects. HUD officials told us they are developing procedures for performing compliance reviews—such as developing a mechanism to review a sample of logs on a periodic basis—but they have not yet done so because they have been focusing on developing procedures for activities that present a high risk to the program as described in the following section. HUD has not established a time frame for developing these procedures. However, HUD officials indicated that they plan to select resident logs for review based on risk of noncompliance and do not plan to analyze program-wide information currently collected in the public housing and Section 8 databases for program monitoring. HUD officials also noted that that PD&R is planning to track a sample of residents through its evaluation of the program, which we previously mentioned. While HUD has decided to rely on resident logs because of the difficulty of tracking household information across its program databases, using resident logs to assess the effects of the RAD program on residents has limitations. While the resident logs would contain detailed household information, they were not required prior to November 2016 and may not contain information on households converted before that date (RAD conversions started in 2013). HUD’s public housing and Section 8 databases contain information on such households. Second, as previously mentioned, HUD plans to review resident logs only when there is a risk of noncompliance, but they collect household information in their databases on a rolling basis. Standards for Internal Control in the Federal Government require agencies to use quality information to achieve their objectives, and obtain and evaluate relevant and reliable data in a timely manner for use in effective monitoring. Without a comprehensive review of household information—one based on information in HUD data systems as well as resident logs—HUD cannot reasonably assess the effects of ongoing and completed RAD conversions on residents and compliance with resident safeguards, as discussed in the next section. HUD has not yet developed monitoring procedures for certain resident safeguards under the RAD program. RAD requirements include those intended to ensure that residents whose units are converted through RAD are informed about the conversion process; can continue to live in a converted property following RAD conversion; are afforded certain protections carried over from the public housing are afforded a phase-in of any rent increases under Section 8 program requirements. Currently, based on HUD notice requirements, PHAs must document compliance with three safeguards (PHA plan amendments, resident notification, and procedural rights) in their RAD application and other conversion paperwork. For example, PHAs must submit comprehensive written responses to resident comments received in connection with the required resident meetings with their RAD application. For one safeguard, PHAs are not required to report to HUD but must retain documentation of compliance to be made available to HUD as part of the monitoring for the program. For others, the HUD notice does not specify reporting and monitoring requirements. Based on our review of files for selected conversions, which we previously discussed, we found PHAs generally submitted documentation of their efforts to inform residents about RAD conversion, such as providing evidence to HUD of meetings with residents and written responses to resident questions as required. However, the specific documents for these requirements were not available from HUD in all cases. HUD’s review of amendments to PHA plans was documented in all but one of the conversions we reviewed. Documentation requirements for resident relocations have changed since RAD was introduced, which made the documentation more difficult to assess. HUD developed and started implementing procedures in October 2017 that require owners to certify and provide data supporting compliance with the resident right-to-return requirements. For example, owners must certify the number of residents who exercised their right to return to a converted property compared with the number of residents who did not return. HUD is also developing standard operating procedures to review each conversion for compliance with RAD relocation provisions. Specifically, the procedures would describe the review steps required at different stages of the conversion process, a process for identifying risks, and how to address instances of noncompliance with RAD requirements. Additionally, HUD noted that they have 2 compliance reviews under way including 1 involving a set of HUD requirements that affect relocations of more than 1 year and the limited compliance review of 90 projects that we previously described. HUD officials noted that they are developing additional guidance in other areas. First, HUD officials indicated that as part of an overall update of RAD standard operating procedures, they are developing additional protocols on resident notification and how residents’ comments are addressed through conversion planning. Second, the agency had not been consistently collecting required documentation on “house rules,” which describe the conditions and procedures for evicting residents and terminating assistance at RAD PBRA properties, so it has developed and implemented additional legal review procedures as part of the implementation of RAD resident eviction and grievance procedural rights requirements. According to HUD officials, they have been focusing primarily on right-to-return and relocation requirements because they represent areas of highest risk. HUD has not developed separate monitoring procedures for other resident safeguards—the phase-in of tenant rent increases, resident representation through tenant organizations, and choice mobility requirements. However, HUD officials told us that they plan to assess how administrative data can be used to monitor choice mobility as part of the planning for a separate PD&R evaluation of this safeguard. HUD officials also indicated that there are procedures for residents to report complaints to HUD if resident representation and organization requirements are not met. Standards for Internal Control in the Federal Government require agencies to implement control activities through documented policies and procedures to provide reasonable assurance that agency objectives will be achieved. These standards also require agencies to design procedures to achieve goals and objectives, and identify, analyze, and respond to risks related to achieving the defined objectives. Table 1 includes a description and information on implementation of resident safeguards that most directly affect residents’ experience with the conversion process and ability to live at the property following conversion. Appendix III describes these and other RAD resident safeguards. HUD officials indicated that the safeguards for the phase-in of tenant rent increases, resident representation, procedural rights, and choice mobility presented a lower risk than the right-to-return requirements, so they were a lower priority, and in some cases were addressed through general monitoring of the Section 8 program. For choice mobility options, HUD indicated that its data systems are not designed to track whether residents are able to exercise these options, such as tracking whether residents left a property to exercise choice mobility or for other reasons. All but two of the resident safeguards do not take effect until after a property has been converted and is part of the Section 8 program. For example, residents are only eligible to use vouchers through choice mobility after they have lived in the converted property for 1 or 2 years depending on the assistance contract involved (PBV or PBRA). Moreover, certain RAD safeguards are not typically available for Section 8 residents. For example, RAD establishes resident representation provisions and procedural rights that are more in line with public housing rather than Section 8 requirements. While HUD has indicated that the Section 8 program has experience administering different types of assistance contracts, RAD nonetheless creates separate requirements for certain provisions from the public housing and Section 8 programs. As previously mentioned, RAD conversions have been completed at an increasing pace in the last 5 years. However, because HUD has not yet developed separate monitoring procedures for certain requirements—the phase-in of tenant rent increases, resident representation through tenant organizations, and choice mobility requirements, many of which take effect after a conversion—and without using all available household data, the agency will not be able to reasonably ensure that these safeguards were implemented. Residents who participated in our focus groups expressed some concerns about information they received on RAD conversions, communications opportunities, and the relocation process. Residents indicated that they were notified about RAD conversion in a variety of ways. Residents in 5 of 14 focus groups found the information presented to them on RAD to be helpful. Residents in 7 of 14 focus groups indicated that the information they received was not helpful. Across these focus groups, a range of concerns was expressed, including that the information provided was not always clear or reflective of the final changes resulting from RAD conversion, and that the PHA and management were not always forthcoming with information about the RAD changes. Residents in some focus groups also indicated that they were not involved in the RAD conversion. Residents in 5 of 14 groups indicated that they were not given the opportunity to provide input into the RAD changes, while residents in 6 of 14 groups indicated that their concerns were not addressed and their suggestions were not incorporated. Residents also described problems with relocations. Some of the concerns expressed by resident focus groups on relocation related to the location of the temporary units (3 of 14 focus groups), the timing of relocation or amount of notice given (7 of 14 focus groups), and moving issues (such as items damaged during moves). Residents were asked to describe ways in which RAD conversion improved or harmed their living conditions. Residents in several focus groups indicated that RAD improved their living conditions, including both the condition (7 of 14 focus groups) and appearance of their units or the property in which they lived (6 of 14 focus groups). Some of the changes residents liked included the installation of new appliances, mold and pest removal, and safety and energy efficiency improvements. However, residents in several of the focus groups identified problems with their living conditions following RAD conversion. The problems residents identified included security concerns (10 of 14 focus groups); renovations that were of poor quality (6 of 14 focus groups); and other problems with the units (10 of 14 focus groups), such as pest problems; decreased amenities (8 of 14 focus groups), such as the removal of common areas or in-unit washing machines; and issues with property management (11 of 14 focus groups). For example, in several instances, residents stated that new managers or owners in place following RAD conversion were not responsive to their needs or concerns. During our site visits, residents described other experiences with RAD conversion. Residents in all of the groups identified being notified about RAD. Residents in 9 of 14 focus groups indicated that their rent was the same following RAD conversion. Residents in a few focus groups indicated that their rent had increased because of changes in their income or conversion from a flat rent. However, residents in a few focus groups experienced challenges in how their income was certified for the purpose of calculating rents, such as problems with requests for information (2 of 14 focus groups) and other issues with the process (4 of 14 focus groups). For example, residents reported having to provide the same paperwork multiple times. No instances in which residents were permanently involuntarily displaced were reported. One resident organization expressed concerns about fewer eviction protections and resident representation after RAD conversion. We spoke with 18 PHAs, some of which cited benefits as well as several challenges of RAD participation and some noted HUD responsiveness to their circumstances and concerns. According to many of the PHAs we spoke with, benefits of participating in the RAD program included reducing administrative requirements in Section 8 programs and opening avenues for additional sources of funding. In particular, many of the PHAs noted that RAD allowed them to access tax credit equity and other funding to complete the bulk of their repairs and renovations at once. Over half of the PHAs we spoke with also found HUD to be flexible and responsive to individual PHA circumstances. The majority of PHAs we spoke with indicated that remaining in the public housing program was not tenable because funding for the public housing program was not enough to meet their long-term capital needs. PHAs we contacted also noted several challenges of participating in RAD: financing constraints, timing challenges, and evolving requirements. Financing constraints. Some PHAs noted that program rent requirements can limit PHA participation in RAD. Each year, HUD calculates a contract rent—the total rent for a unit, including operating subsidy and resident contribution. PHAs must use the contract rent to calculate Section 8 subsidies for properties converting under RAD. According to HUD and several PHAs, contract rents for RAD-converted Section 8 units are lower than rents in traditional Section 8 assisted units, and are almost always lower than market-rate rents. Several PHAs and HUD officials have described the difficulty of converting units from the public housing program with this rent limitation. For example, when the cost of needed rehabilitation or construction is high, low allowable contract rents might not be sufficient to access appropriate capital for the conversion. In certain localities, PHAs have found solutions to augment rents and have used RAD flexibilities to allow them to convert and plan for operating expenses. For example, the PHA in Tacoma, Washington, used the Moving to Work program flexibilities to increase contract rents and housing officials in San Francisco used an allowable procedure to transfer RAD assistance from converted buildings to properties throughout its portfolio (each is a blend of traditional project-based vouchers with higher contract rents and RAD assistance). In Montgomery County, Maryland, the PHA similarly included RAD assistance in some mixed-finance properties that contain other high-rent subsidies and market-rate rents. Timing challenges. Some PHAs said they faced major challenges in coordinating RAD timelines with HUD, lenders, or other parties or with the requirements of the LIHTC process. HUD officials acknowledged that PHAs with more complex transactions, including those involved in the LIHTC process, struggle to implement their conversion plans within RAD time frames. HUD officials noted that because there is a statutory cap on the number of units that can be converted under RAD, they have established time frames to stay under the cap and ensure that PHAs that are planning to convert are ready to participate in the program. Additionally, according to HUD, it has made technical assistance available to all PHAs that receive a Commitment to enter into a Housing Assistance Payment contract during the RAD process to help ensure their readiness for RAD closing and to meet remaining conversion deadlines. On the other hand, some PHAs expressed concern to us about delays in the conversion process that put them at risk for missing state LIHTC deadlines. HUD officials described putting conversions on a fast-track on a case-by-case basis to meet LIHTC deadlines. For example, in one case a PHA relocated residents before closing and without HUD approval. HUD required the PHA to fund an escrow account until it was able to determine any payments that might need to be made to residents and any other necessary corrective action. This was done so that HUD could look into the issue while mitigating additional harm to the residents and continuing to move the PHA toward closing and aligned with tax credit application deadlines. The timing of conversion can also create gaps in the payment of Section 8 funds to PHAs. Section 8 funding should begin in January of the year following conversion. PHAs rely on annual public housing subsidies for the conversion year—public housing program funds are paid to PHAs annually and are not recaptured by HUD following RAD conversion. However, according to some PHAs we interviewed, Section 8 funding did not begin on time. For example, in Baltimore, Maryland, subsidy flow after conversion had not begun as of June of the following year. HUD officials told us inadequate guidance from HUD and confusion from PHAs regarding the necessary steps to request payment in a timely manner have been the major cause of the problems. HUD has tried to remedy delays and updated its notice to provide clearer guidance on the timing of subsidy flow around the time of conversion to Section 8. Moreover, HUD officials indicated that there has been confusion among PHAs on how to request funds, so HUD is currently revising and updating the guidance on steps PHAs must take to request payment under the PBRA program. HUD officials also indicated that it has begun monitoring whether new participants are taking the steps needed well before their first request for funding. Some PHAs we contacted also mentioned difficulty in coordinating with HUD on fulfilling internal RAD requirements and reviews. According to some, the different offices involved in RAD conversions within HUD were not well aligned and had different interpretations of the rules. For example, some RAD conversions require a civil rights review by HUD’s Office of Fair Housing and Equal Opportunity Office, including those transactions that require new construction or resident relocations. Some PHAs indicated that such reviews occurred too late in the conversion process even after other HUD offices had approved the conversion. HUD officials acknowledge that different HUD offices have different objectives in the RAD process. HUD officials indicated that the agency is trying to coordinate more effectively among these offices and streamline the conversion process as much as possible. Evolving requirements. While the majority of PHAs with which we spoke said that HUD provided clear, sufficient, and timely information, some PHAs noted that it also was challenging to adapt to evolving requirements. Some PHAs noted that as HUD identified problems in the early years of the program, it would change the guidance in response. For example, HUD officials explained that it had clarified fair housing review requirements in response to PHA concerns that the fair housing review occurred too late in the process and could affect successful conversion of projects. The most recent RAD notice (effective January 2017) is the third version since 2013 and revisions have involved substantial changes. For example, this notice provided PHAs with greater flexibilities on the funding sources they can use to raise initial contract rents and the ways they can demonstrate ownership and control of a converted property. In addition, HUD introduced a notice in November 2016 to strengthen resident protections. Some PHAs told us they found the pace or timing of the evolving requirements difficult to manage and also noted confusion about conversion instructions and guidance due to changing requirements. For example, one PHA indicated that the agency had problems reporting information into a new RAD data field in HUD’s Voucher Management System because there was no guidance at the time on how to complete this field. However, HUD has since included additional instructions in the user’s manual that became effective in April 2017. The Committee has included language to establish procedures that will ensure that public housing remains a public asset in the that event that the project experiences problems, such as default or foreclosure. In each RAD conversion, HUD and the property owner execute a use agreement, which specifies affordability and use restrictions for the property. The use agreement generally exists concurrently with the HAP contract, which is executed to govern the provision of either the PBRA or PBV subsidy for the unit. The use agreement must be recorded in a superior position to new or existing financing or other encumbrances on the converted property. Under a Section 8 HAP contract, residents pay 30 percent of adjusted household income. In the absence of the HAP contract, the use agreement is set up to control the amount paid: If the HAP contract is removed due to breach, noncompliance, or insufficiency of appropriations, under the use agreement new households in all units previously covered under the HAP contract must have incomes at or below 80 percent of the area median income for households of the size occupying an appropriately sized unit for their family size at the time of admission, and rents may not exceed 30 percent of 80 percent of area median income for the remainder of the term of the use agreement. For new residents at or below 80 percent of the area median income, under the use agreement the resident rent contribution without a HAP contract generally would be higher than that paid under a HAP contract, which is based on household income instead of the universally determined area median income. Although the use agreement maintains some level of affordability, the owner receives no subsidy under PBRA or PBV without a HAP contract and resident rent contribution is not tied to individual household income but rather based on a universal area income calculation (see fig. 3). According to HUD officials, other program requirements support the goal of long-term preservation: HAP contracts are executed for 20 years for PBRA or 15–20 years for PBV properties and compliance with all affordability requirements in the HAP and statute and regulation governing the PBRA and PBV programs must be maintained while the contract is in force. According to the authorizing statute, PHAs (for PBV contracts) and HUD (for PBRA contracts) shall offer and project owners shall accept a renewal contract at the expiration of the initial HAP contract and at each subsequent renewal. Each renewal contract will be subject to a RAD use agreement, governing the use of the property consistent with HUD requirements. According to the RAD notice, the project owner also is to establish and maintain a replacement reserve to aid in funding extraordinary maintenance and repair and replacement of capital items. The reserve account must be built up to and maintained at a level determined by HUD to be sufficient to meet projected requirements. According to HUD officials, during the conversion, HUD staff review each capital needs assessment to try to determine whether a property’s capital needs can be addressed over the forthcoming 20-year period. We reviewed 31 completed conversion files, the set of documentation required by HUD to enable a PHA to convert units from public housing to a Section 8 subsidy, and associated RAD contracts. In each file, key contractual protections appeared consistent with program requirements. Specifically, in all cases executed use agreements (which included requirements to limit residency eligibility to households making less than 80 percent of area median income) were included and not altered from the HUD template. In most files we reviewed, we found foreclosure riders were included and that they stated that use agreements would survive foreclosure, meaning that any new owners would take ownership subject to the agreements. Executed HAP contracts, requiring that residents’ contributions be set at 30 percent of adjusted household income, also were present in all files we reviewed. According to HUD officials, PHAs, and two housing groups we spoke with, provisions in the RAD use agreement to keep units affordable appear to be strong, with use and affordability protections designed to survive foreclosure, but the strength of provisions cannot yet be fully determined because the provisions have not yet been tested in foreclosure proceedings or in courts. According to HUD officials, as of October 2017 no RAD properties had entered foreclosure. The RAD authorizing statute requires that ownership be transferred to a capable public entity or, if not one, a capable entity as determined by HUD, or if necessary to fulfill LIHTC requirements for the property, to a HUD-approved for-profit entity (provided the PHA retained sufficient interest in the property). HUD also subjects any subsequent transfer of the property to HUD review and requires the successor ownership to meet these same requirements. As stated in the use agreement, a lien holder must give HUD notice prior to declaring a default and provide HUD concurrent notice with any written filing of foreclosure (providing that the foreclosure sale must not be sooner than 60 days after the notice), but the use agreement does not prohibit a lien holder from foreclosing on the lien or accepting a deed in lieu of foreclosure. The RAD use agreement, which is recorded superior to other liens and places use and affordability restrictions on the property, survives foreclosure. With or without a HAP contract in place, the lender or new owner must maintain the units for low- income households according to the terms of the use agreement. Therefore, according to HUD officials, the lender or new owner has an incentive to identify an appropriate owner and secure HUD approval to avoid a default under the HAP contract, which provides a Section 8 subsidy to the owner. That is, if no HAP contract were in place, the owner would collect only the tenant rent contribution (30 percent of 80 percent of area median income), rather than the tenant rent contribution plus the subsidy. HUD has discretion to enforce or waive certain use and affordability protections. According to the authorizing statute, in the case of foreclosure, bankruptcy, or termination and transfer of assistance for material violation or substantial default, the priority for ownership or control must be provided to a capable public entity, or, if no such entity can be found, to a capable entity as determined by the Secretary of HUD. Additionally, the statute allows the transfer of property to for-profit entities to facilitate the use of LIHTC financing, with requirements to maintain the PHA’s interest, which was discussed above. As of September 30, 2017, about 40 percent of RAD conversions involved LIHTC financing. According to the RAD notice, in the event of a default of a property’s use agreement or HAP contract, HUD may terminate the HAP contract and transfer assistance to another location to retain affordable units. HUD will determine the appropriate location and owner entity for the transferred assistance consistent with statutory goals and requirements for RAD. The RAD use agreement will remain in effect even in the case of abatement or termination of the HAP contract for the term the contract would have run, unless HUD agreed differently in writing. In this case, the RAD notice limits HUD discretion to terminate the use agreement to only cases involving a transfer of assistance to another property. HUD has not yet developed procedures to monitor RAD projects for risks to long-term affordability of units, including default or foreclosure. HUD officials described an ongoing effort to develop oversight procedures it would need to reasonably ensure compliance with RAD agreements and avoid risks to long-term affordability once conversions closed and units moved to Section 8 but, as previously discussed, the agency has not yet completed this effort or fully implemented a monitoring system. HUD officials told us they also planned to develop protocols to more closely monitor properties at risk of foreclosure, including developing indicators, procedures, roles, and responsibilities within HUD, but they have not finalized the design of procedures or fully implemented them. To develop protocols, HUD created an asset management working group in September 2016. The officials also stressed that no one can take possession of or foreclose on a property without HUD involvement and approval. For example, HUD officials said they expect few foreclosures among RAD-converted properties because lenders tend to communicate with the agency early so that it can become involved to prevent foreclosure. HUD officials pointed to a robust structure to oversee program properties in the PBRA program, but stated PBV property oversight continues to be developed by the Office of Public and Indian Housing. According to Standards for Internal Control in the Federal Government, agencies should design procedures to achieve goals and objectives, such as the preservation of unit affordability, and respond to risks, in this case the risk of default or foreclosure or noncompliance with program requirements. Additionally, management should identify, analyze, and respond to risks related to achieving its goals and objectives. According to HUD officials, the agency had not yet fully developed and implemented oversight procedures for postconversion monitoring because since 2012, the agency has focused on RAD start-up and review and oversight procedures for the conversion process. HUD officials also said that many projects would receive ongoing monitoring from other parties, which also could serve as a safeguard for unit affordability and help ensure the appropriate financial and physical condition of the property after RAD conversion. For example, just under half of all RAD properties use LIHTC financing as part of financing packages, which can also include local and state bonds. According to HUD officials, oversight by tax credit allocating agencies, investors, and lenders, while not alone sufficient, helps secure affordable units in a property for the long-term. However, tax credit allocating agencies, investors, and lenders are not signatories to the HAP contract or use agreement and have no formal role in reasonably ensuring that properties meet requirements exclusive to RAD. Although other entities may exercise some oversight of properties, by not developing and implementing procedures for ongoing oversight, HUD in its role as program administrator will not be able to reasonably ensure that properties adhere to requirements or meet basic program goals. Furthermore, without such monitoring HUD would be limited in its ability to identify and assist with properties at risk of foreclosure. RAD was created to demonstrate the feasibility of converting public housing units to other rental assistance programs to help preserve affordable rental units and address the significant backlog of capital needs in the public housing program. However, demonstrating the feasibility of RAD conversion is contingent on collecting and assessing quality information about the conversion projects. HUD has an opportunity to improve the demonstration’s metrics. For instance, implementing robust postclosing oversight and collecting information on financial outcomes upon completion of construction would not only improve HUD’s oversight capabilities but also allow it to report quality information. Moreover, limitations in HUD’s methodology for calculating leverage ratios for RAD may obscure the effect of funding sources used to help fund RAD conversions, potentially under- or over-reporting the program’s capital leveraging. By collecting comprehensive information on final (postcompletion) financing sources and costs and developing quality metrics, HUD would be better positioned to more accurately report the results of the demonstration program. Additionally, a focus on the conversion process itself (and less on its results), and limitations in HUD’s data have contributed to limited monitoring by HUD in other areas. Specifically, by not developing and implementing monitoring procedures to assess the effect of RAD on residents HUD cannot ensure compliance with resident safeguards. Further, HUD collects and maintains household data for the public housing and Section 8 programs, yet it does not systematically use this information to ensure that resident safeguards are in place. Finally, HUD could benefit from additional procedures to assess RAD properties for risks to long-term preservation to be able to respond to property default or foreclosure. We are making the following five recommendations to HUD: HUD’s Assistant Secretary for Housing should include provisions in its postclosing monitoring procedures to collect comprehensive high quality data on financial outcomes upon completion of construction, which could include requiring third-party certification of and collecting supporting documentation for all financing sources and costs. (Recommendation 1) HUD’s Assistant Secretary for Housing should improve the accuracy of RAD leverage metrics—such as better selecting inputs to the leverage ratio calculation and clearly identifying what the leverage ratio measures—and calculate a private-sector leverage ratio. (Recommendation 2) HUD’s Assistant Secretary for Housing should prioritize the development and implementation of monitoring procedures to ensure that resident safeguards are implemented. (Recommendation 3) HUD’s Assistant Secretary for Housing should determine how it can use available program-wide data from public housing and Section 8 databases, in addition to resident logs, for analysis of the use and enforcement of RAD resident protections. (Recommendation 4) HUD’s Assistant Secretary for Housing should prioritize the development and implementation of procedures to assess risks to the preservation of unit affordability. (Recommendation 5) We provided a draft of this report to HUD for comment. HUD provided written comments on the draft report, which are summarized below and reproduced in appendix IV. HUD also provided technical comments, which we incorporated as appropriate. In its comment letter, HUD stated that it agreed with our findings that HUD can improve metrics used to assess program impact and build on existing oversight structures. HUD described actions it intends to take to implement our recommendations to the extent possible and consistent with resource limitations. More specifically, HUD agreed with our first recommendation to ensure it collects comprehensive quality data on financial outcomes in its postclosing monitoring procedures (which could include supporting documentation for all financing sources and costs). HUD agreed it should routinely collect an updated list of funding sources and uses and related documentation when projects had cost overruns or other significant changes. HUD intends to review and revise, as appropriate, required postcompletion certifications. HUD added that in most cases, funding sources and uses do not materially change between closing and construction completion. HUD stated that securing the postclosing information in such cases might be of minimal benefit relative to the additional reporting burden. However, it is not clear how HUD would determine if projects had significant changes in costs or uses because HUD lacks postcompletion information that would show the magnitude of changes. In relation to reporting burden, HUD already has implemented procedures to collect limited financial information following the completion of construction in October 2017. We believe any additional reporting would not be disproportionate to the benefits of improving HUD's oversight capabilities through project completion and enhancing its reporting to more accurately reflect the results of the demonstration program. For our second recommendation to improve the accuracy of RAD leverage metrics and calculate a private-sector leverage ratio, HUD agreed that RAD leverage metrics can be improved. HUD will ensure that the private-sector leverage ratio required by statute is clearly identified and included in its RAD evaluation. HUD also intends to identify a small number of relevant leverage ratios with distinct methodologies and will routinely publish these ratios with clear identification and explanations. In relation to our finding of misidentified funding sources, HUD plans to re- examine its chart of accounts and review prior transaction records to address errors and properly classify transaction sources. In response to our third recommendation to prioritize the development and implementation of monitoring procedures for resident safeguards, HUD agreed that it is important to better document and expedite development and implementation of monitoring procedures. HUD also agreed that additional monitoring was needed to ensure the right of residents to request and move with a tenant-based voucher after a period of residency (choice-mobility). HUD noted that its Office of Policy Development and Research is seeking funding for additional research on RAD with a focus on the use and effect of choice-mobility options, which would inform HUD's monitoring efforts. Finally, while HUD said that we did not find the safeguards to be weak or inadequate, we did not perform an audit designed to assess the safeguards and therefore cannot opine on their adequacy. On the basis of our findings, we found that HUD’s implementation of these safeguards could be strengthened. Regarding our fourth recommendation that HUD determine how it can use available program-wide data and resident logs for analysis of RAD resident protections, HUD agreed to examine how it could use its existing data systems to further enhance its monitoring efforts. HUD added that the systems have limitations, so that the agency also uses other mechanisms to track and monitor implementation of resident protections. For our fifth recommendation to prioritize the development and implementation of procedures to assess risks to the preservation of unit affordability, HUD agreed that it is important to assess and mitigate risks to unit affordability. HUD stated that it employs robust underwriting standards prior to permitting conversion, and relies on existing procedures to conduct ongoing oversight of Project-Based Rental Assistance (PBRA) properties, which we discussed in the draft. However, as we noted, HUD has not yet developed procedures to more closely monitor RAD properties at risk of foreclosure, though it plans to establish indicators of foreclosure risk and oversight roles and responsibilities within HUD. HUD said that since the summer of 2017, it has been evaluating what additional oversight procedures might be needed for RAD Project-Based Voucher properties. HUD also described plans to augment its existing oversight procedures to preserve affordable units in the event of foreclosure by developing protocols in the following areas: transfer of property ownership to a capable entity, transfer of the rental assistance to another site, and protection of residents in the event a Housing Assistance Payment contract was terminated. As agreed with your office, unless you publicly announce the contents of this report earlier, we plan no further distribution until 30 days from the report date. At that time, we will send copies to the Secretary of Housing and Urban Development and other interested parties. In addition, the report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-8678 or garciadiazd@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs are listed on the last page of this report. GAO staff who made major contributions to this report are listed in appendix IV. This report examines aspects of the Department of Housing and Urban Development’s (HUD) Rental Assistance Demonstration (RAD) program. More specifically, this report addresses (1) HUD’s assessment of the physical and financial outcomes of RAD conversion to date; (2) how RAD conversions affected residents and what safeguards were in place to protect them, including while temporarily relocated and during conversion; (3) what challenges, if any, public housing agencies (PHA) faced in implementing RAD; and (4) the extent to which RAD provisions are designed to help preserve the long-term affordability of units. To address all four objectives, we analyzed agency documentation and interviewed officials from HUD. The documentation we reviewed included policies and procedures for RAD; manuals describing HUD data systems; draft policies and procedures for implementing postclosing oversight; and reports on RAD performance. We interviewed HUD headquarters officials from the Office of Recapitalization within the Office of Housing, which oversees the administration of RAD, and the Office of Policy Development and Research (PD&R). We also interviewed PHA officials and developers involved in RAD transactions, as well as selected experts and other stakeholders to obtain their perspectives on RAD. Additionally, we conducted a literature search to identify publications related to RAD. We visited a nonprobability sample of eight PHAs in Maricopa County, Arizona; Alameda County, California; Montgomery County, Maryland; and in the cities of San Francisco, California; Baltimore, Maryland; New Bern, North Carolina; El Paso, Texas; and Tacoma, Washington, to observe housing units before, during, or after renovation when possible as well as common areas that had planned or undergone renovation. We selected sites to include varying PHA sizes, RAD subsidy types, planned rehabilitation and resident relocation, numbers and sizes of RAD transactions, closing dates, constructions costs, and geographic locations across the United States. At each site, we conducted semistructured interviews with PHA officials and, when available, developers (5 sites). We also conducted one or two focus-group interviews with groups of 6– 15 residents who lived at the converted properties to obtain their perspectives and experiences. In each location, we asked the PHAs to invite residents to participate in the focus groups based on their availability. We also met with the Resident Advisory Board in each location that had one. For 7 of 8 site visits, we selected two RAD properties to conduct resident focus groups (in Alameda County, California we held one focus group). We conducted a content analysis based on resident focus group interviews to describe resident experiences and the RAD program’s effects on residents. Utilizing the selection criteria noted above, we conducted semistructured telephonic interviews with an additional nonprobability sample of 10 PHAs in Fresno, California; Fort Collins, Colorado; Dekalb County, Georgia; Chicago, Illinois; Ypsilanti, Michigan; Cuyahoga County, Ohio; Philadelphia; Pennsylvania; Spartanburg, South Carolina; McKinney, Texas; and Yakima, Washington. Because we selected a non-probability sample of PHAs to visit and interview, the information we obtained cannot be generalized more broadly to all PHAs. However, it provides context on RAD particularly on implementation challenges and perspectives on physical and financial impacts, long-term affordability, and resident protections. We also selected the following 11 individuals and organizations as experts and stakeholders: 1. Council of Large Public Housing Authorities 2. National Association of Housing and Redevelopment Officials 3. Center on Budget and Policy Priorities 4. Public Housing Authorities Directors Association 5. National Housing Law Project 6. Community Legal Services of Philadelphia 7. Maryland Legal Aid 8. Disability Rights Maryland 9. Jaime Alison Lee, Associate Professor of Law and Director, Community Development Clinic, University of Baltimore School of Law 10. Yumiko Aratani, Assistant Professor, Columbia University Mailman 11. University of California, Berkeley, Terner Center for Housing We interviewed experts and stakeholders on resident impacts and implementation challenges associated with RAD. The entities may not represent all views on these topics, but their views provide insights on RAD. To select these individuals and groups, we met with three major PHA associations and two resident advocacy groups, and asked for referrals for organizations or individuals with expertise in RAD. We also selected a nonprobability, random sample of 31 RAD conversion files to review. Utilizing HUD RAD Resource Desk data, we randomly selected 31 RAD files for properties that had closed conversion as of June 30, 2017 and that planned to incur construction costs. We used the files to help us determine physical changes to RAD conversions and the impacts of RAD on residents through, for example, relocation. We excluded RAD conversions with no construction costs from the random sample because they would not have physical changes and no resident relocation would occur before or during our review. To address our first objective on the physical and financial outcomes of RAD conversion to date and how HUD measured these outcomes, we first obtained and analyzed HUD data on RAD conversions since RAD’s authorization (from fiscal years 2013 through 2017). We assessed the reliability of these data by reviewing system documentation, interviewing knowledgeable officials about system controls, and conducting electronic testing. We determined that the data were sufficiently reliable for the purposes of describing rehabilitation and new construction in RAD projects and evaluating RAD leveraging metrics. We included in our analysis all RAD conversions that were active or closed. We used these data to determine the number of closed RAD conversions, associated financial sources and uses, subsidy types, and type of construction (rehabilitation, new construction, and no rehabilitation or new construction). In addition, during our interviews with PHAs and developers, we obtained their perspectives on potential contributing factors to financial decisions and type of construction pursued through RAD conversion. As noted earlier, we also reviewed 31 randomly selected files of converted properties with construction costs to describe property physical changes in RAD conversions. Furthermore, we reviewed HUD documents, such as HUD and PD&R evaluations, publications, and policies and procedures to gain additional context for how HUD measures RAD outcomes. We also interviewed HUD officials, including PD&R and Office of Recapitalization officials, on RAD data and metrics, as well as other performance monitoring activities. We further analyzed data from the HUD RAD Resource Desk to determine how these data support HUD’s metrics and performance monitoring activities. As previously mentioned, we determined that these HUD data were sufficiently reliable for the purposes of this report. Specifically, we assessed and calculated RAD leverage ratio and construction activity. We assessed HUD’s performance monitoring activities and reporting against the RAD authorizing statute, Standards for Internal Control in the Federal Government. To recalculate estimates of the RAD leverage metric, we obtained documentation from the Office of Recapitalization to review the methodology used to calculate their most recent leverage ratio. We aligned the methodology they provided with RAD Resource Desk Transaction Log data that was downloaded on August 7, 2017. We replicated HUD’s methodology and matched the data utilized with the descriptors from the Transaction Log. To isolate financial sources and manually adjust the “other source” data, we compiled matched descriptors and funding amounts and categorized each observation based on the funding source description, as a federal source, state/county/city source, or PHA source, among others. For additional information and results, see appendix II. To determine how RAD affected residents in converted units, we analyzed HUD public housing and Section 8 household data before and after conversion (demographic characteristics of residents and changes in rent, income, and location). Specifically, we examined data from 2013— when the first transactions closed—through June 30, 2017. HUD compiled and provided custom extracts of data on households in RAD- converted properties from the Inventory Management System/Public and Indian Housing Information Center (IMS/PIC) (public housing and Section 8 PBV) and Tenant Rental Assistance Certification System (Section 8 PBRA). We assessed the reliability of the data extracts provided by HUD by (1) performing electronic testing of required data elements, (2) reviewing existing information about the data and the system that produced them, and (3) interviewing agency officials knowledgeable about the data. We determined the data on PBV households were sufficiently reliable for the purposes of our reporting objectives, but that the data on PBRA households was not sufficiently reliable for purposes of describing some characteristics of RAD households. For example, in trying to determine participation in the RAD program by year, we received several thousand PBRA entries that preceded the establishment of the RAD program. Moreover, as we previously mentioned, the postconversion household data for PBRA conversions is in a separate data system, so some variables, such as those related to race, ethnicity, rent, and income, differ from the other household data for that program. Because of these limitations, the data for PBRA households were not reliable for purposes of comparing RAD household characteristics before and after conversion as we had intended. To describe safeguards for residents and help ascertain how HUD implemented protections, we reviewed legal protections and requirements in HUD notices, reviewed selected conversion files, and interviewed HUD officials about monitoring and compliance processes. Finally, as previously described, we held focus groups with residents to better understand any effects on their living conditions and quality of life. To determine challenges PHAs faced in implementing RAD, we reviewed HUD guidance and related documents for PHAs in the program. We also interviewed eight PHAs during our site visits and spoke with another 10 PHAs by telephone about the benefits and challenges of participating in the RAD program. To examine provisions designed to help preserve long-term affordability of units, we reviewed the RAD authorizing statute and amendments and HUD notices and interviewed HUD staff to verify our understanding of agency affordability protections. For a sample of 31 randomly selected properties, we examined templates for contractual agreements for RAD closings and analyzed closing documents and contracts to determine if agreements matched program requirements. We interviewed HUD staff and staff of 18 PHAs to obtain viewpoints on the potential strengths or weaknesses of preservation in the case of default or foreclosure. We conducted this performance audit from February 2016 to February 2018 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. The Department of Housing and Urban Development’s (HUD) Office of Recapitalization collects financial sources and use data from Rental Assistance Demonstration (RAD) participants. Table 2 lists the financial source fields collected by HUD. Table 3 lists the financial cost fields collected by HUD. Table 4 provides additional financial source detail pertaining to HUD’s leverage ratio calculation. Table 5 and Table 6 show the total financial source amounts collected by HUD. Specifically, Table 5 shows total financial source amounts prior to recategorization, while Table 6 shows total financial source amounts after manual adjustments. Manual adjustments included isolating funding source observations in “other funding” fields 1-6 and incorporating them into existing fields, as appropriate. Table 7 replicates HUD’s methodology for calculating the RAD leverage metrics after manual adjustments in HUD data. See Table 4, above, to compare changes in each category. Table 8 recalculates the leverage ratio by deducting federal sources as leveraged sources. Table 9 recalculates the leverage ratio by deducting public sources as leveraged sources (compare to Table 8 above). The Rental Assistance Demonstration (RAD) program has numerous requirements intended to ensure residents whose units are converted through RAD receive certain protections. The following is a description of these safeguards and their reporting and monitoring requirements. The Government Accountability Office, the audit, evaluation, and investigative arm of Congress, exists to support Congress in meeting its constitutional responsibilities and to help improve the performance and accountability of the federal government for the American people. GAO examines the use of public funds; evaluates federal programs and policies; and provides analyses, recommendations, and other assistance to help Congress make informed oversight, policy, and funding decisions. GAO’s commitment to good government is reflected in its core values of accountability, integrity, and reliability. The fastest and easiest way to obtain copies of GAO documents at no cost is through GAO’s website (https://www.gao.gov). Each weekday afternoon, GAO posts on its website newly released reports, testimony, and correspondence. To have GAO e-mail you a list of newly posted products, go to https://www.gao.gov and select “E-mail Updates.” The price of each GAO publication reflects GAO’s actual cost of production and distribution and depends on the number of pages in the publication and whether the publication is printed in color or black and white. Pricing and ordering information is posted on GAO’s website, https://www.gao.gov/ordering.htm. Place orders by calling (202) 512-6000, toll free (866) 801-7077, or TDD (202) 512-2537. Orders may be paid for using American Express, Discover Card, MasterCard, Visa, check, or money order. Call for additional information. Connect with GAO on Facebook, Flickr, Twitter, and YouTube. Subscribe to our RSS Feeds or E-mail Updates. Listen to our Podcasts. Visit GAO on the web at https://www.gao.gov. James-Christian Blockwood, Managing Director, spel@gao.gov, (202) 512-4707 U.S. Government Accountability Office, 441 G Street NW, Room 7814, Washington, DC 20548 Please Print on Recycled Paper. In addition to the individual named above, Paul Schmidt (Assistant Director), Julie Trinder-Clements (Analyst in Charge), Meghana Acharya, Enyinnaya David Aja, Alyssia Borsella, Juan J. Garcia, Ron La Due Lake, Amanda Miller, Marc Molino, Barbara Roesmann, Jessica Sandler, MaryLynn Sergent, Rachel Stoiko, and William Woods made major contributions to this report.
Agencies generally acquire equipment from commercial vendors and through GSA, which contracts for the equipment from commercial vendors. In acquiring heavy equipment from a commercial vendor or GSA, agencies can purchase or lease the equipment. Generally, agencies use the term “lease” to refer to acquisitions that are time-limited and therefore distinct from purchases. The term “lease” is used to refer to both long-term and short-term leases. For example, the three agencies we reviewed in-depth use the term “rental” to refer to short-term leases of varying time periods. According to Air Force officials, they define rentals as leases that are less than 120 days while FWS and NPS officials said they generally use the term rental to refer to leases that are a year or less. For the purposes of this report, we use the term “rental” to refer to short-term leases defined as rentals by the agency and “long-term lease” to refer to a lease that is not considered a rental by the agency. (See fig. 1.) In 2013, GSA began offering heavy equipment through its Short-Term Rental program, which had previously been limited to passenger vehicles, in part to eliminate ownership and maintenance cost for infrequently used heavy equipment. Under this program, agencies can request a short-term equipment rental (less than a year) from GSA, and GSA will work with a network of commercial vendors to provide the requested heavy equipment. Unlike for some other types of federal property, there are no central reporting requirements for agencies’ inventories of heavy equipment. However, each federal agency is required to maintain inventory controls for its property, which includes heavy equipment. Agencies maintain inventory data through the use of agency-specific databases, and each agency can set its own requirements for what data are required and how these data are maintained. For example, while an agency may choose to maintain data in a headquarters database, it could also choose to maintain data at the local level. As another example, an agency may decide to track and maintain data on the utilization of its heavy equipment (such as the hours used) or may choose not to have such data or require any particular utilization levels. The Federal Acquisition Regulation (FAR) governs the acquisition process of executive branch agencies when acquiring certain goods and services, including heavy equipment. Under the FAR, agencies should consider whether to lease equipment instead of purchasing it based on several factors. Specifically, the FAR provides that agency officials should evaluate cost and other factors by conducting a “lease-versus-purchase” analysis before acquiring heavy equipment. Additionally, DOD’s regulations require its component agencies to prepare a justification supporting lease-versus-purchase decisions if the equipment is to be leased for more than 60 days. Twenty agencies reported data on their owned heavy equipment, including the (1) number, (2) types, (3) acquisition year, and (4) location of agencies’ owned heavy equipment in their inventories as of June 2017. The 20 agencies reported owning over 136,000 heavy equipment items. DOD reported owning most of this heavy equipment—over 100,000 items, about 74 percent. (See app. I for more information on agencies’ ownership of these items.) The Department of Agriculture reported owning the second highest number of heavy equipment items—almost 9,000 items, about 6 percent. (See fig. 2.) Four agencies—the Nuclear Regulatory Commission, the Department of Housing and Urban Development, the Office of Personnel Management, and the Agency for International Development—reported owning five or fewer heavy equipment items each. The 20 agencies reported owning various types of heavy equipment, such as cranes, backhoes, and road maintenance equipment in five categories: (1) construction, mining, excavating, and highway maintenance equipment; (2) airfield-specialized trucks and trailers; (3) self-propelled warehouse trucks and tractors; (4) tractors; and (5) soil preparation and harvesting equipment. Thirty-eight percent (almost 52,000 items) were in the construction, mining, excavating, and highway maintenance category (see fig. 3). Fifteen of the 20 agencies reported owning at least some items in this category. Twenty-four percent (over 33,000 items) were in the airfield- specialized trucks and trailers category, generally used to service and re-position aircraft on runways. DOD reported owning 99 percent (over 32,000) of these items, while 9 other agencies, including the Department of Labor and the National Aeronautics and Space Administration, reported owning the other one percent (317 items). Twenty-two percent (over 29,000 items) were in the self-propelled warehouse trucks and tractors category, which includes equipment such as forklift trucks. All 20 agencies reported owning at least one item in this category, and five agencies—the Agency for International Development, Department of Housing and Urban Development, the Environmental Protection Agency, the Nuclear Regulatory Commission, and the Office of Personnel Management—reported owning only items in this category. (For additional information on agencies’ ownership of heavy equipment in various categories, see app. I.) The twenty agencies reported acquiring their owned heavy equipment between 1944 and 2017, with an average of about 13 years since acquisition (see fig. 4). One heavy equipment manager we interviewed reported that a dump truck can last 10 to 15 years, whereas other types of equipment can last for decades if regularly used and well-maintained. The 20 agencies reported that over 117,000 heavy equipment items (86 percent) were located within the United States or its territories. Of these, about one-fifth (over 26,000) were located in California and Virginia, the two states with the most heavy equipment (see fig. 5). Of the equipment located outside of the United States and its territories, 94 percent was owned by the Department of Defense. The rest was owned by the Department of State (714 items in 141 countries from Afghanistan to Zimbabwe) and the National Science Foundation (237 items in areas such as Antarctica). The twenty agencies reported spending over $7.4 billion in 2016 dollars to acquire the heavy equipment they own (see table 1). However, actual spending was higher because this inflation-adjusted figure excludes over 37,000 heavy equipment items for which the agencies did not report acquisition cost or acquisition year, or both. Without this information, we could not determine the inflation-adjusted cost and therefore did not include the cost of these items in our calculation. The Army owns almost all of these items, having not reported acquisition cost or acquisition year, or both, for 36,589 heavy equipment items because, according to Army officials, the data were not available centrally but may have been available at individual Army units and would have been resource- intensive to obtain. The heavy equipment items reported by the 20 agencies ranged in acquisition cost from zero dollars to over $2 million in 2016 dollars, with an average acquisition cost in 2016 dollars of about $78,000, excluding assets with a reported acquisition cost of $0. Of the items which we adjusted to 2016 dollars and for which non-zero acquisition costs were provided: 94 percent cost less than $250,000 and accounted for 57 percent of the total adjusted acquisition costs (See fig. 6.) 6 percent of items cost more than $250,000 and accounted for 43 percent of the adjusted acquisition costs. (See fig. 6.) High-cost items included a $779,000 hydraulic crane acquired by the National Aeronautics and Space Administration in 1997 ($1.2 million in 2016 dollars), a $1.4 million ultra-deep drilling simulator acquired by the Department of Energy in 2009 ($1.6 million in 2016 dollars), and several $2.2 million well-drilling machines acquired by the Air Force in 2013 ($2.3 million in 2016 dollars). In calendar years 2012 through 2016, the Air Force, FWS, and NPS purchased almost 3,500 pieces of heavy equipment through GSA and private vendors at a total cost of about $360 million to support mission needs. (See table 2.) These agencies also spent over $5 million on long- term leases and rentals during this time period. The Air Force spent over $300 million to purchase over 2,600 heavy equipment assets in calendar years 2012 through 2016 that were used to support and maintain its bases globally. For example, according to Air Force officials, heavy equipment is often used to maintain runways and service and reposition aircraft on runways. While the majority of Air Force heavy equipment purchased in this time period is located in the United States, 41 percent of this heavy equipment is located outside the United States and its territories in 17 foreign countries to support global military bases. The Air Force could not provide complete information on its heavy equipment leases for fiscal years 2012 through 2016. Specifically, the Air Force provided data on 33 commercial heavy equipment leases that were ongoing as of August 2017 but could not provide cost data for these leases because this information is not tracked centrally. Additionally, the Air Force could not provide any data on leases that occurred previously because, according to Air Force officials, lease records are removed from the Air Force database upon termination of the lease. Officials said that rentals are generally handled locally and obtaining complete data would require a data call to over 300 base contracting offices. Air Force officials stated that rentals are generally used in unique situations involving short- term needs such as responding to natural disasters. For example, following Hurricane Sandy, staff at Langley Air Force Base in Virginia used rental equipment to clean up and repair the base. Although Air Force did not provide complete information on rentals, data we obtained from GSA’s Short-Term Rental program indicated that Air Force rented heavy equipment in 46 transactions not reflected in the Air Force data we received totaling over $3.7 million since GSA began offering heavy equipment through its Short-Term Rental program, which had previously been limited to passenger vehicles, in part program in 2013. FWS spent over $32 million to purchase 348 heavy equipment assets from calendar years 2012 through 2016. FWS used its heavy equipment to maintain refuge areas throughout the United States and its territories, including maintaining roads and nature trails. FWS also used heavy equipment to respond to inclement weather and natural disasters. Most of the heavy equipment items purchased by FWS were in the construction, mining, excavating, and highway maintenance equipment category and include items such as excavators, which were used for moving soil, supplies, and other resources. FWS officials reported that they did not have any long-term leases for any heavy equipment in fiscal years 2012 through 2016 because they encourage equipment sharing and rentals to avoid long-term leases whenever possible. FWS officials provided data on 228 rentals for this time period with a total cost of over $1 million. Information regarding these rentals is contained in an Interior-wide property management system, the Financial Business Management System (FBMS). FWS officials told us that they have not rented heavy equipment through GSA’s program because they have found lower prices through local equipment rental companies. NPS spent over $27 million to purchase 471 heavy equipment assets from calendar years 2012 through 2016. NPS uses heavy equipment— located throughout the United States and its territories—to maintain national parks and respond to inclement weather and natural disasters. For example, NPS used heavy equipment such as dump trucks, snow plows, road graders, and wheel loaders to clear and salt the George Washington Memorial Parkway in Washington, D.C., following snow and ice storms. Most of the heavy equipment items purchased by NPS were in the construction, mining, excavating, and highway maintenance equipment category and include items such as excavators, which are used for moving soil, supplies, and other resources. NPS reported spending about $360,000 on 230 long-term leases and rentals in fiscal years 2012 through 2016, not including rentals through GSA’s Short-Term Rental program, which had previously been limited to passenger vehicles, in part program. As with FWS, NPS leases and rentals are contained in FBMS, which is Interior’s property management system. Data we obtained from GSA’s Short-Term Rental program, which had previously been limited to passenger vehicles, in part program indicated that NPS rented heavy equipment in 26 transactions totaling over $200,000 since GSA began offering heavy equipment through its Short-Term Rental program, which had previously been limited to passenger vehicles, in part program in 2013, for a potential total cost of over $560,000 for these long-term leases and rentals. As mentioned earlier, the FAR provides that executive branch agencies seeking to acquire equipment should consider whether it is more economical to lease equipment rather than purchase it and identifies factors agencies should consider in this analysis, such as estimated length of the period that the equipment is to be used, the extent of use in that time period, and maintenance costs. This analysis is commonly referred to as a lease-versus-purchase analysis. While the FAR does not specifically require that agencies document their lease-versus-purchase analyses, according to federal internal control standards, management should clearly document all transactions and other significant events in a manner that allows the documentation to be readily available for examination and also communicate quality information to enable staff to complete their responsibilities. As discussed below, we found that most acquisitions we reviewed from FWS, NPS, and the Air Force did not contain any documentation of a lease-versus-purchase analysis. Specifically, officials were unable to provide documentation of a lease-versus-purchase analysis for six of the eight acquisitions we reviewed. FWS officials were able to provide documentation for the other two. Officials told us that a lease-versus- purchase analysis was not conducted for five of the six acquisitions and did not know if such analysis was conducted for the other acquisition. According to agency officials, the main reason why analyses were not conducted or documented for these six acquisitions is that the circumstances in which such analyses were to be performed or documented were not always clear to FWS, NPS, and Air Force officials. In addition to the FAR, Interior has agency guidance stating that bureaus should conduct and document lease-versus-purchase analyses. This July 2013 guidance—that FWS and NPS are to follow—states that requesters of equipment valued at $15,000 or greater should perform a lease-versus- purchase analysis when requesting heavy equipment. According to the guidance, this analysis should address criteria in the FAR and include a discussion of the financial and operating advantages of alternate approaches that would help contracting officials determine the final appropriate acquisition method. At the time the guidance was issued, Interior also provided a lease-versus-purchase analysis tool to aid officials in conducting this analysis. Additionally, in April 2016, Interior issued a policy to implement the July 2013 guidance. The 2016 policy clarifies that program offices are required to complete Interior’s lease-versus-purchase analysis tool and provide the completed analysis to the relevant contracting officer. Within Interior, bureaus are responsible for ensuring that procurement requirements are met, including the requirements and directives outlined in Interior’s 2013 guidance and 2016 policy on lease-versus-purchase analyses, according to agency officials. Within FWS, local procurement specialists prepare procurement requests and ensure that procurement requirements are met and that all viable options have been considered. Regional equipment managers review these procurement requests, decide whether to purchase or lease the requested equipment, and prepare the lease-versus-purchase analysis tool if the procurement specialist has indicated that it is required. Within NPS, local procurement specialists are responsible for ensuring that all procurements adhere to relevant requirements and directives, including documenting the lease- versus-purchase analysis. Of the three FWS heavy equipment acquisitions we reviewed for which the 2013 Interior guidance was applicable, one included a completed lease-versus-purchase analysis tool; one documented the rationale for purchasing rather than leasing, although it did not include Interior’s lease- versus-purchase analysis tool; and one did not include any documentation related to a lease-versus-purchase analysis. (See table 3.) Regarding the acquisition for which no documentation of a lease-versus- purchase analysis was provided—a 12-month lease of an excavator and associated labor costs for over $19,000—FWS officials initially told us that a lease-versus-purchase analysis was not required because the equipment lease was less than $15,000, and Interior’s guidance required a lease-versus-purchase analysis for procurements of equipment valued at $15,000 or greater. However, we found the guidance did not specify whether the $15,000 threshold includes the cost of labor. We also found that Interior’s guidance did not specify if a lease-versus-purchase analysis was required if the total cost of a rental is less than the purchase price. FWS officials acknowledged that Interior guidance is not clear and that it would be helpful for Interior to clarify whether these leases require a lease-versus-purchase analysis. NPS officials were unable to provide documentation of a lease-versus- purchase analysis for the single heavy equipment acquisition we reviewed—the purchase of a wheeled tractor in 2015 for $43,177. According to these officials, they could not do so because of personnel turnover in the contracting office that would have documented the analysis. In addition, they told us that they believe that such analyses are not always completed for heavy equipment acquisitions because responsibility for completing these analyses is unclear. Specifically, they told us that it was unclear whether the responsibility lies with the official requesting the equipment, the contracting personnel who facilitate the acquisition, or the property personnel who manage inventory data. However, when we discussed our findings with Interior and NPS officials, NPS officials were made aware of the 2016 Interior policy that specifically requires program offices—the officials requesting the equipment—to complete the lease-versus-purchase analysis and provide documentation of this analysis to the contracting officer. As a result, NPS officials told us at the end of our review that program office officials will now be required to complete the lease-versus-purchase analysis tool and document this analysis. According to Air Force officials responsible for managing heavy equipment, financial or budget personnel at individual bases are responsible for conducting lease-versus-purchase analyses, also called economic analyses, to support purchase and lease requests. Air Force fleet officials told us that they then review these requests from a fleet perspective, considering factors such as whether the cost information provided in the request is from a reputable source, expected maintenance costs, and whether a requesting base has the capability to maintain the requested equipment. However, they said they do not check to ensure that a lease-versus-purchase analysis was completed or review the analysis. Equipment rentals can be approved at individual bases. In our review of four Air Force heavy equipment acquisitions, we found no instances in which Air Force officials documented a lease-versus- purchase analysis (see table 4). For the acquisitions that we reviewed, Air Force officials told us they did not believe a lease-versus-purchase analysis was required because the new equipment was either replacing old equipment that was previously approved or could be deployed. Accordingly, the Air Force purchased two forklifts in 2013 without conducting lease-versus-purchase analyses because the forklifts were replacing old forklifts that were authorized in 1997 and 2005. Furthermore, Air Force officials told us that both of these forklifts could be deployed and indicated that lease-versus-purchase analyses are not required for deployable equipment. However, the Air Force does not have guidance that describes the circumstances that require either a lease-versus-purchase analysis or documentation of the rationale for not completing such analysis. Although we identified several instances in which officials in the three selected agencies did not document lease-versus-purchase analyses, officials from these agencies stated that they consider mission needs and equipment availability, among other factors, when making these decisions. For example, Air Force officials told us following Hurricane Sandy, staff at Langley Air Force Base in Virginia used rental equipment to clean and repair the base because the equipment was needed immediately to ensure the base could meet its mission. Moreover, availability of heavy equipment for lease or rental, which can be affected by factors such as geography and competition for equipment, is a key consideration. For example, FWS officials told us that the specialized heavy equipment sometimes needed may not be available for long-term lease or rent in remote areas such as Alaska and the Midway Islands, so the agency purchases the equipment. In addition, some agency officials told us that they may purchase heavy equipment even if that equipment is needed only sporadically if there is likely to be high demand for rental equipment. For example, following inclement weather or a natural disaster, demand for certain heavy equipment rentals can be high and equipment may not be available to rent when it is needed. While we recognize that mission needs and other factors are important considerations, without greater clarity regarding when to conduct or document lease-versus-purchase analyses, officials at FWS, NPS, and Air Force may not be conducting such analyses when appropriate and may not always make the best acquisition decisions. These agencies could be overspending on leased equipment that would be more cost- effective if purchased or overspending to purchase equipment when it would be more cost-effective to lease or rent. Moreover, without documenting decisions on whether to purchase or lease equipment, they lack information that could be used to inform future acquisition decisions for similar types of equipment or projects. Air Force guidance requires that fleet managers collect utilization data for both vehicles and heavy equipment items, such as the number of hours used, miles traveled, and maintenance costs. The Air Force provided us with utilization data for over 18,000 heavy equipment items and uses such data to inform periodic base validations. Specifically, Air Force officials said that every 3 to 5 years each Air Force base reviews the on- base equipment to ensure that the installation has the appropriate heavy equipment to complete its mission and reviews utilization data to identify items that are underutilized. If heavy equipment is considered underutilized, the equipment is relocated—either moved to another location or sent to the Defense Logistics Agency for reuse or transfer to another agency. According to Air Force officials the Air Force has relocated over 700 heavy equipment items based on the results of the validation process and other factors such as replacing older items and agency needs since 2014. Similarly, FWS guidance for managing heavy equipment utilization sets forth minimum utilization hours for certain types of heavy equipment and describes requirements for reporting utilization data. FWS provided us with utilization data on over 3,000 heavy equipment items. According to officials, condition assessments of heavy equipment are required by FWS guidance every 3 to 5 years. According to FWS officials, condition assessments inform regional-level decision making about whether to move equipment to another FWS location or dispose of the equipment. In contrast, NPS does not require the collection of utilization data to evaluate heavy equipment use and does not have guidance for managing heavy equipment utilization. However, NPS officials told us that they recognize the need for such guidance. NPS officials shared with us draft guidance that they have developed, which would require collection of utilization data for heavy equipment such as hours or days of usage each month. According to NPS officials, they plan to send the guidance to the NPS policy office for final review in March 2018. Until this guidance is completed and published, NPS is taking interim actions to manage the utilization of its heavy equipment. For example, NPS officials stated that they have asked NPS locations to collect and post monthly utilization data, discussed the collection of utilization data at fleet meetings, and distributed job aids to support this effort. During the course of our review, NPS officials provided us with some utilization data for about 1,400 of the more than 2,400 NPS heavy equipment items. Specifically, for the 1,459 heavy equipment items for which NPS provided utilization data, 541 items had utilization data for each month. For the remaining 918 items, utilization data were reported for some, but not all months. The federal government has spent billions of dollars to acquire heavy equipment. There is no requirement that agencies report on the inventory of this equipment, as there is no standard definition of heavy equipment. When deciding how to acquire this equipment, agencies’ should conduct a lease-versus-purchase analysis as provided in the FAR, which is a critical mechanism to ensure agencies are acquiring the equipment in the most cost-effective manner. Because FWS, NPS and the Air Force were unclear when such an analysis was required, they did not consistently conduct or document analyses of whether it was more economical to purchase or lease heavy equipment. In the absence of clarity on the circumstances in which lease-versus-purchase analyses for heavy equipment acquisitions are to be conducted and documented, the agencies may not be spending funds on heavy equipment cost- effectively. We are making two recommendations—one to the Air Force and one to the Department of the Interior. The Secretary of the Air Force should develop guidance to clarify the circumstances in which lease-versus-purchase analyses for heavy equipment acquisitions are to be conducted and documented. (Recommendation 1) The Secretary of the Interior should further clarify in guidance the circumstances in which lease-versus-purchase analyses for heavy equipment acquisitions are to be conducted and documented. (Recommendation 2) We provided a draft of this report to the Departments of Agriculture, Defense, Energy, Homeland Security, Housing and Urban Development, the Interior, Justice, Labor, State, and Veterans Affairs; General Services Administration; National Aeronautics and Space Administration; National Science Foundation; Nuclear Regulatory Commission; Office of Personnel Management; and U.S. Agency for International Development. The departments of Agriculture, Energy, Homeland Security, Housing and Urban Development, Justice, State and Veterans Affairs, as well as the General Services Administration, National Aeronautics and Space Administration, National Science Foundation, Nuclear Regulatory Commission, Office of Personnel Management; and U.S. Agency for International Development did not have comments. The Department of Labor provided technical comments, which we incorporated as appropriate. In written comments, reproduced in appendix III, the Department of Defense stated that it concurred with our recommendation and plans to issue a bulletin to Air Force contracting officials. In written comments, reproduced in appendix IV, the Department of the Interior stated that it concurred with our recommendation and plans to implement it. If you or members of your staff have any questions about this report, please contact me at (202) 512-2834 or RectanusL@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. Major contributors to this report are listed in appendix V. Specialized Trucks and Trailers 37 . Self-Propelled Warehouse Trucks and Tractors 1,733 3 . . . . . . . . . . . . . . . . . . . Specialized Trucks and Trailers 7 . Self-Propelled Warehouse Trucks and Tractors 2,925 134 . . . . . . . . . . . . . . . . . . Specialized Trucks and Trailers . Self-Propelled Warehouse Trucks and Tractors 146 . . . . . . 7 . . . - 109 . . . Self-Propelled Warehouse Trucks and Tractors 575 64 40 . . . . . . . . . . . 4 . . . . . . . . . Nuclear Regulatory Commission Office of Personnel Management Social Security Administration United States Agency for International Development Grand Total . . . . This report addresses: (1) the number, type, and cost of heavy equipment items that are owned by the 24 CFO Act agencies; (2) the heavy equipment items selected agencies have recently acquired and how selected agencies decided to purchase or lease this equipment; and (3) how selected agencies manage the utilization of their heavy equipment. To identify the number, type, and cost of heavy equipment owned by federal agencies, we first interviewed officials at the General Services Administration to determine whether there were government-wide reporting requirements for owned heavy equipment and learned that there are no such requirements. We then obtained and analyzed data on agencies’ spending on equipment purchases and leases from the Federal Procurement Data System–Next Generation (FPDS-NG), which contains government-wide data on agencies’ contracts. However, in reviewing the data available and identifying issues with the reliability of the data, we determined that data on contracts would not be sufficient to answer the question of what heavy equipment the 24 CFO Act agencies own. We therefore conducted a data collection effort to obtain heavy equipment inventory information from the 24 CFO Act agencies, which are the Departments of Agriculture, Commerce, Defense, Education, Energy, Health and Human Services, Homeland Security, Housing and Urban Development, the Interior, Justice, Labor, State, Transportation, the Treasury, and Veterans Affairs; Environmental Protection Agency; General Services Administration; National Aeronautics and Space Administration; National Science Foundation; Nuclear Regulatory Commission; Office of Personnel Management; Small Business Administration; Social Security Administration; and Agency for International Development. Because there is no generally accepted definition of heavy equipment, we identified 12 federal supply classes in which the majority of items are self- propelled equipment but not passenger vehicles or items that are specific to combat and tactical purposes, as these items are generally not considered to be heavy equipment. (See table 5.) We then vetted the appropriateness of these selected supply classes with Interior, FWS, NPS, and Air Force agency officials, as well as with representatives from a fleet management consultancy and a rental company, and they generally agreed that items in selected federal supply classes are considered heavy equipment. Federal supply classes are used in FPDS- NG and are widely used in agencies’ inventory systems. Overall, about 90 percent of the heavy equipment items that agencies reported were assigned a federal supply class in the agency’s inventory data. In discussing heavy equipment categories in the report, we use the category titles below. To identify points of contact at the 24 CFO Act agencies, we obtained GSA’s list of contact information for agencies’ national utilization officers, who are agency property officers who coordinate with GSA. As a preliminary step, we contacted these individuals at each of the 24 CFO Act agencies and asked them to either confirm that they were the appropriate contacts or provide contact information for the appropriate contact and to inform us if they do not own heavy equipment. Officials at 4 agencies—Department of Education, Department of the Treasury, General Services Administration, and Small Business Administration— indicated that the agency did not own any items in the relevant federal supply classes. Officials at 16 of these agencies indicated that they would be able to respond on a departmental level because the relevant inventory data are maintained centrally, while officials at 4 agencies indicated that we would need to obtain responses from officials at some other level because the relevant inventory data are not maintained centrally. (See table 7 for a list of organizations within the 20 CFO Act agencies that indicated they own relevant equipment and responded to our data collection effort.) After identifying contacts responsible for agencies’ heavy-equipment inventory data, we prepared data collection instruments for requesting information on heavy equipment and tested these documents with representatives from 4 of the 20 CFO Act agencies that indicated they own heavy equipment to ensure that the documents were clear and logical and that respondents would be able to provide the requested data and answer the questions without undue burden. These agency representatives were selected to provide a variety of spending on federal supply group 38 equipment as reported in FPDS-NG, civilian and military agencies, and different levels at which the agency would be responding to the data collection effort (e.g., at the departmental level or at a sub- departmental level). Our data collection instrument requested the following data on respondent organizations’ owned assets in 12 federal supply classes as of June 2017: Respondents provided data on original acquisition costs in nominal terms, with some acquisitions occurring over 50 years ago. In order to provide a fixed point of reference for appropriate comparison, we present in our report inflation-adjusted acquisition costs using calendar year 2016 as the reference. To adjust these dollar amounts for inflation, we used the Bureau of Labor Statistic’s Producer Price Index by Commodity for Machinery and Equipment: Construction Machinery and Equipment (WPU112), compiled by the Federal Reserve Bank of St. Louis. We conducted the data collection effort from July 2017 through October 2017 and received responses from all 20 agencies that indicated they own heavy equipment. In order to assess the reliability of agencies’ reported data, we collected and reviewed agencies’ responses regarding descriptions of their inventory systems, frequency of data entry, agency uses of the data, and agencies’ opinions on potential limitations of the use of their data in our analysis. We conducted some data cleaning, which included examining the data for obvious errors and eliminating outliers. We did not verify the data or responses received; the results of our data collection effort are used only for descriptive purposes and are not generalizable beyond the 24 CFO Act agencies. Based on the steps we took, we found these data to be sufficiently reliable for our purposes. To determine the heavy equipment items that selected agencies recently acquired and how these agencies decided whether to purchase or lease this equipment, we first used data from the FPDS-NG to identify agencies that appeared to have the highest obligations for construction or heavy equipment, or both, and used this information, along with other factors, to select DOD and Interior. At the time, in the absence of a generally accepted definition of heavy equipment, we reviewed data related to federal supply group 38—construction, mining, excavating, and highway maintenance equipment—because (1) we had not yet defined heavy equipment for the purposes of our review; (2) agency officials had told us that most of what could be considered heavy equipment was in this federal supply group; and (3) our analysis of data from usaspending.gov showed that about 80 percent of spending on items that may be considered heavy equipment were in this federal supply group. In meeting with officials at these departments, we learned that agencies within each department manage heavy equipment independently, so we requested current inventory data for Interior bureaus and the DOD military departments and selected three agencies that had among the largest inventories of construction and/or heavy equipment at the time, among other criteria: the U.S. Air Force (Air Force); the Fish and Wildlife Service (FWS); and the National Park Service (NPS). We then used information from our data collection effort—which included the number, type, cost, acquisition year and other data elements—to determine heavy equipment items that these agencies acquired during 2012 through 2016. We interviewed agency officials to determine what lease data were available from the three selected agencies. We assessed the reliability of these data with agency official interviews and reviewed the data for completeness and potential outliers. We determined that the data provided were sufficiently reliable for the purposes of documenting leased and rental heavy equipment. We also obtained data from GSA’s Short- Term Rental program, which had previously been limited to passenger vehicles, in part program for August 2012, when the first item was rented under this program, to February 2017, when GSA provided the data. We used these data to identify selected agencies’ rentals of heavy equipment through GSA’s Short-Term Rental program, which had previously been limited to passenger vehicles, in part program and associated costs. We interviewed officials from GSA’s Short-Term Rental program to discuss the program history as well as the reliability of their data on these rented heavy equipment items. We determined that the data were sufficiently reliable for our purposes. To determine how the three selected agencies decide whether to purchase or lease heavy equipment, we interviewed fleet and property managers at these selected agencies and asked them to describe their process for making these decisions as well as to identify relevant federal and agency regulations and guidance. We reviewed relevant federal and agency regulations and guidance regarding how agencies should make these decisions, including: Federal Acquisition Regulation, Office of Management Budget’s A-94, Guidelines and Discount Rates for Benefit- Cost Analysis of Federal Programs, Defense Federal Acquisition Regulation Supplement, Air Force Manual 65-506, Air Force Guidance Memorandum to Air Force Instruction 65-501, and Interior’s Guidance On Lease Versus Purchase Analysis and Capital Lease Determination for Equipment Leases. We also reviewed the Standards for Internal Control in the Federal Government for guidance on documentation as well as past GAO work that reviewed agencies’ lease-versus-purchase analyses. To determine whether the three selected federal agencies documented lease-versus-purchase decisions for selected acquisitions and adhered to relevant agency guidance, we selected and reviewed a non-generalizable sample of 10 heavy equipment acquisitions—two purchases each from the Air Force, FWS, and NPS, and two leases each from the Air Force and FWS. Specifically, we used inventory data obtained through our data collection effort, described above, to randomly select two heavy equipment purchases from each selected agency using the following criteria: calendar years 2012 through 2016; the two federal supply classes most prevalent in each selected agency’s heavy equipment inventory, as determined by the data collection effort described above; and for NPS and FWS, acquisition costs of over $15,000. In addition, we used lease data provided by the Air Force and FWS to randomly selected two heavy equipment leases per agency. Because NPS could not provide data on heavy equipment leases, we did not select or review any NPS lease decisions. To select the Air Force and FWS leases we used the following criteria: fiscal years 2012 through 2016; for the Air Force, which included federal supply classes in the lease data provided, the two federal supply classes most prevalent in the lease data and for FWS, which did not include federal supply class in the lease data provided, the two federal supply classes most prevalent in the purchase data; and for FWS, leases over $15,000. After selecting these acquisitions, we determined that one FWS lease and one NPS purchase we selected pre-dated Interior’s 2013 guidance on lease-versus-purchase analysis and excluded these acquisitions from our analysis for a total of eight acquisitions. In reviewing agencies’ documentation related to these acquisitions, we developed a data collection instrument to assess the extent to which agencies documented lease-versus-purchase analyses and, in the case of FWS and NPS, adhered to relevant Interior guidance. We supplemented our review of these acquisition decisions with additional information by interviewing officials at the three selected agencies and requesting additional information to understand specific circumstances surrounding each procurement. Our findings are not generalizable across the federal government or within each selected department. To determine how selected agencies manage heavy equipment utilization, we interviewed officials at the three selected agencies to identify departmental and agency-specific guidance and policies and to determine whether utilization requirements exist. We reviewed guidance identified by these officials, including Interior and Air Force vehicle guidance, both of which apply to heavy equipment, and FWS’s Heavy Equipment Utilization and Replacement Handbook. We also compared their practices to relevant Standards for Internal Control in the Federal Government. For the selected agencies with guidance for managing heavy equipment—Air Force and FWS—we reviewed the guidance to determine if and how selected agencies measured and documented heavy equipment utilization. For example, we reviewed whether selected agencies developed reports for managing heavy equipment utilization such as Air Force validation reports and FWS conditional assessment reports. We also reviewed Air Force, FWS, and NPS utilization data for heavy equipment but we did not independently calculate or verify the utilization rate for individual heavy equipment items because each heavy equipment item (backhoe, forklift, tractor, etc.,) has different utilization requirements depending on various factors such as the brand, model, or age of equipment. However, we did request information about agency procedures to develop and verify utilization rates. We assessed the reliability of the utilization data with agency official interviews and a review of the data for completeness and potential outliers. We determined that the data were sufficiently reliable for the purposes of providing evidence of utilization data collection for heavy equipment assets. We also visited the NPS George Washington Memorial Parkway to interview equipment maintenance officials regarding the procurement and management of heavy equipment and to document photos of heavy equipment. We selected this site because of its range of heavy equipment and close proximity to the Capital region. We conducted this performance audit from October 2016 to February 2018 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. In addition to the individual named above, John W. Shumann (Assistant Director), Rebecca Rygg (Analyst in Charge), Nelsie Alcoser, Melissa Bodeau, Terence Lam, Ying Long, Josh Ormond, Kelly Rubin, Crystal Wesco, and Elizabeth Wood made key contributions to this report.
Since 2001, DOD’s total workforce has changed in size and composition. DOD’s military, civilian, and contractor workforces peaked around 2011 and have since decreased in size, as shown in figure 1. Several factors have contributed to changes in the size of the workforces including varying levels of U.S. involvement in the conflicts in Iraq and Afghanistan, military to civilian and contractor conversions, contractor insourcing, and the growth in certain workforces such as acquisition and cyber. DOD’s management of its workforce is governed by several workforce management statutes, including sections 129, 129a, and 2463 of Title 10 of the United States Code. Section 129 directs that DOD civilian personnel be managed each fiscal year on the basis of, and consistent with, total-force management policies and procedures established under section 129a, the workload required to carry out the functions and activities of the department, and the funds made available to the department each fiscal year. Section 129a directs the Secretary of Defense to establish policies and procedures for determining the most appropriate and cost-efficient mix of military, civilian, and contracted services to perform the mission of the department. Finally, Section 2463 directs the Under Secretary of Defense for Personnel and Readiness to devise and implement guidelines and procedures to ensure that consideration is given to using, on a regular basis, DOD civilian employees to perform new functions and functions performed by contractors that could be performed by DOD civilian employees. DOD Instruction 1100.22, Policy and Procedures for Determining Workforce Mix (April 12, 2010) (Change 1, Dec. 1, 2017) establishes policy, assigns responsibilities, and prescribes procedures for determining the appropriate workforce mix of the military, civilian, and contracted services. The instruction provides criteria for workforce-mix decisions and directs DOD components to conduct a cost comparison to determine the low-cost provider for all new or expanding mission requirements and for functions that have been contracted but could be performed by DOD civilian employees. In addition, over the past 10 years DOD has taken steps to better understand the costs associated with its workforces. For example, we found in September 2013 that DOD had improved its methodology for estimating and comparing the full cost of work performed by military and civilian personnel and contractor support, but the methodology continued to have certain limitations, such as the lack of guidance for certain cost elements related to overhead. We made five recommendations, including for DOD to assess the advantages and disadvantages of allowing the continued use of different cost-estimation tools across the department or directing department-wide application of one tool, and revise its guidance in accordance with the findings of its assessment. DOD implemented this recommendation but has not yet implemented the other four recommendations although it concurred or generally concurred with them. DOD’s Cost-Comparison Report addressed three elements and partially addressed one element concerning the accounting for the fully-burdened, or full, cost of federal civilian and service contractor personnel performing functions at the selected installations, as shown in table 1. DOD concluded that for the 21,000 federal civilians and service contractors compared, neither federal civilians nor service contractors were predominately more or less expensive, with the costs being dependent upon the function being performed, location, and level of expertise. DOD noted that the results were not generalizable across the department. Each of the elements and our assessment are discussed below. We believe that DOD addressed the reporting element to assess performance of functions performed by civilian and contractor personnel by developing a methodology to assess performance of functions performed by federal civilians and service contractors at organizations within nine geographic regions including two locations outside the continental United States. Organizations included in DOD’s methodology include the following: Fort Belvoir Community Hospital Defense Threat Reduction Agency US Army Intelligence and Security Command Aviation and Missile Research, Development, and Engineering Center Naval Medical Center San Diego Space and Naval Warfare Systems Command Ogden Air Logistics Complex 75th Air Base Wing Naval Facilities Engineering Command Tripler Army Medical Center DOD’s methodology included the following: Selecting installations and organizations: DOD used data from the Defense Civilian Personnel Data System to identify military installations with large reported numbers of federal civilians. According to DOD officials, they eliminated from consideration those installations that had no reported contractors. From this subset of installations, DOD selected organizations to represent all three military departments and diverse geographical locations, to include two locations outside the continental United States. Assessing the functions performed by civilians and contractors to identify federal civilians and service contractors performing similar functions: DOD assessed the performance of functions at these selected locations to identify federal civilians and service contractors performing similar functions as there is no direct mapping or perfect match between existing taxonomies used to quantify federal civilian positions and contracted services. Further, DOD reported that the day-to-day functions performed by federal civilian employees do not always directly correlate to the designated occupational series or the job title for their position. For example, an individual with an occupational series assigned as an accountant may actually perform work more consistent with that of a financial analyst. According to DOD’s Cost-Comparison Report, DOD did not rely on occupational series names or job titles alone to determine the actual work being performed by federal civilians. Specifically, DOD conducted site visits with each organization and relied on local managers’ direct knowledge of the actual tasks that their federal civilians and service contractor personnel performed. According to DOD’s Cost-Comparison Report, DOD determined that personnel need to perform at least 80 percent common tasks to be able to make a comparison. For the organizations selected, DOD compared the costs of all federal civilians and service contractors identified as performing similar functions. The challenges DOD identified in DOD’s Cost-Comparison Report on determining the functions performed by contractor personnel are similar to those we encountered in our prior work on DOD’s efforts to compile and review of an inventory of contracted services. Section 2330a of Title 10 of the U.S. Code directs the Secretary of Defense to annually prepare an inventory of activities performed during the preceding fiscal year pursuant to staff augmentation contracts. Section 2330a also directs the secretary of each military department and head of each defense agency responsible for activities in the inventory to, within 90 days after the Secretary of Defense submits the inventory, review the contracts and activities in the inventory for which that secretary or agency head is responsible, in part to identify activities that should be considered for conversion. Our prior work has identified, among other issues, that the absence of a complete and accurate inventory of contracted services hinders DOD’s management of these services. According to DOD officials, the Office of the Under Secretary of Defense (Personnel and Readiness) has also recognized the challenges associated with the various taxonomies and lexicons associated with articulating the size and composition of federal civilian, military, and contracted services workforces, and has efforts underway with the goal of better aligning those to enable more holistic total force management of all sources of labor. According to DOD officials, by improving available workforce data, DOD can support better-informed leadership decisions, improve accuracy of analyses, and provide consistent explanations of the department’s workforce resources. DOD officials told us that this effort has an estimated completion of December 2018. We believe that DOD partially addressed the reporting element to account for the full cost of civilian and contractor personnel by providing an accounting of the labor costs of selected federal civilian and service contractor full-time equivalents for personnel performing similar functions at government-owned facilities during calendar year 2015, but excluding certain non-labor costs from its cost calculations. According to DOD officials, 2015 was the last year for which complete data were available. DOD developed a methodology for identifying labor costs associated with federal civilian and service contractor full-time equivalents during calendar year 2015 at government-owned facilities for its cost comparisons. Based on reviews of applicable guidance and consultations with the Office of the Under Secretary of Defense – Comptroller, DOD included numerous federal civilian costs collected from several sources in DOD’s Cost Comparison Report, as shown in table 2. In addition, to assure data quality, DOD officials told us that they took steps to identify data errors in the data collected including identifying missing data fields and data entries that might indicate data errors. For example, DOD officials told us that they verified that they had pay records for every pay period in calendar year 2015 by identifying potential errors and outliers and sharing these with the Defense Finance and Accounting Service and the selected DOD organizations for review. Officials also stated that DOD sent its complete calculated data sets to each organization for review against their own pay records and that all errors were corrected or outliers were explained. Additionally, according to our analysis, DOD excluded overtime from its costs related to federal civilians in accordance with Office of Management and Budget Circular A-11. However, DOD included overtime pay in its report separately for context and noted that overtime pay is a significant part of civilian compensation for some organizations. Officials noted that those funded via a working capital fund arrangements, such as depots, use overtime to handle surges in demand throughout the year. DOD noted in its report that selected service contracts at government facilities and developed three methodologies to identify labor costs associated with service contractor full-time equivalents during calendar year 2015, as shown in table 3. DOD stated in its report that identifying service contractor full-time equivalents is a significant challenge because the level of detail available in each contract varied such that DOD could not employ a single methodology, and unlike federal civilian pay data, there is no centralized database on service-contractor pay. DOD reported that contracts are rarely written to address the cost-per-contractor as a full-time equivalent, and some contracts do not differentiate between labor and non-labor costs. DOD noted in its report that the negotiated price of the contract includes direct costs, including labor and non-labor costs, and indirect costs such as overhead. Further, the contract costs include service contractor profit. Based on our review of DOD’s Cost-Comparison Report, DOD used non- excludable contract costs as a basis in two of its methodologies. These costs to DOD are associated with labor, and include pay and benefits provided to service contractor personnel, contractor profit, and overhead the contractor included in the cost of the contract. When the number of service contractor full-time equivalents and full costs for a contract was known, DOD used the first method, dividing contract costs by the number of service contractor full-time equivalents to arrive at the cost per service contractor full-time equivalent. When the number of billable hours was known, DOD used the second method, multiplying the ratio of contract costs divided by billable hours by a standard number of annual billable hours. For contracts in which the labor rate was known but costs could not be disaggregated, DOD multiplied the labor rate by a standard 1,880 annual billable hours unless a contract specified the labor rate as a number of annual billable hours. For example, Defense Logistics Agency contractor-labor rates for wage grade equivalent contractor full-time equivalents are based on 2,080 annual labor hours. We assessed DOD’s report as partially addressing the reporting element to account for the full cost of federal civilian and contractor personnel because DOD excluded certain non-labor costs from its costs calculations—(1) direct non-labor costs for government owned facilities and government provided supplies, (2) indirect costs for general and administrative and overhead for civilians, and (3) costs to manage contracts—from its costs calculations. Senate Report 114-49 stated that DOD is to include an accounting of the full cost of DOD federal civilian and service contractors performing similar functions, including facility overhead. DOD stated in its report that the methodology utilized to compare the costs of federal civilian and service contractor full-time equivalents was consistent with DOD Instruction (DODI) 7041.04, Estimating and Comparing the Full Costs of Civilian and Active Duty Military Manpower and Contract Support (July 3, 2013), hereafter referred to DODI 7041.04. However, DODI 7041.04 states that the full cost of personnel should include direct and indirect non-labor costs, such as those referenced previously. DOD officials stated that they considered including non-labor costs in their calculations but did not because they believe these costs would add approximately the same to both federal civilian and service contractor costs. DODI 7041.04 instructs that if a function is performed on government property, the costs of goods, services, and benefits that are common costs may be excluded provided the number of government and contactor personnel is equivalent. DODI 7041.04 further instructs that when the number of government and contractor personnel differs, adjustments must be made to the cost estimates to account for the difference in number of government and contractor personnel. While there were some instances where it was the case that DOD’s cost estimates involved an equal number of civilian and contractor personnel performing functions on government property, there were many instances in where the personnel numbers differed and common costs should not have been excluded. For example, in DOD’s comparisons of federal civilians and service contractors at Fort Belvoir Community Hospital, DOD conducted comparisons of 19 functions where 2 functions had equal numbers of federal civilian and service contractors and 17 functions had differing numbers of federal civilian and service contractors. In one comparison, the number of contractors was over three times the number of civilians. DOD officials also stated that they believe their methodology is in accordance with DODI 7041.04 because DODI 7041.04 states that the cost elements in the instruction can be modified or augmented in each specific case as necessary, but DOD components should be prepared to support such decisions with sufficient justification. We acknowledge that DODI 7041.04 states that the cost elements can be modified, but by excluding non-labor costs in its cost comparisons, DOD did not account for the full cost of federal civilians and service contractors as requested in the mandate. We believe that DOD addressed the reporting element to compare costs by comparing its calculated costs of selected federal civilians and service contractors performing similar functions at selected installations. DOD reported that its results represent selected personnel performing functions within selected organizations and are not generalizable across the department. DOD concluded that for the federal civilian and contractor full-time equivalents included in the study, the costs varied by organization, location, and function being performed. DOD presented comparisons of federal civilian and service contractor full-time equivalents costs and expressed these results as a cost ratio. However, it is not clear how the results would be different if all costs that encompass full costs of personnel would have been included in DOD’s comparisons. See tables 4 and 5 below for examples of greater costs for the performance of functions by federal civilians or service contractors at Fort Belvoir Community Hospital in Fort Belvoir, Virginia. We believe that DOD addressed the reporting element by assessing the flexible employment authorities for the employment and retention of federal civilian employees at the same 17 organizations used for the cost comparison. Specifically, DOD sent questionnaires to DOD hiring officials and human resource professionals to collect information on flexible employment authorities. DOD included a broad spectrum of organizational missions in its query of management and human resource officials regarding the use and availability of flexible hiring authorities. Noting that this assessment is more subjective than the others in DOD’s Cost-Comparison Report, DOD queried senior leaders, middle managers, front-line supervisors and human resource professionals regarding which authorities are being used and the effectiveness of each. According to DOD’s report, in this way, DOD was able to gauge the extent to which each type of authority was used as well as the satisfaction with and effectiveness of each. DOD’s Cost-Comparison Report made several conclusions regarding flexible hiring authorities and made one recommendation. The findings included that there was a variance in the authorities used between organizations, management unfamiliarity with all available authorities, and a belief among managers that expanded use of some authorities is needed to produce more quality hires. DOD’s Cost- Comparison Report recommended DOD and OPM should explore opportunities to refine, consolidate, or reduce unused, inefficient, or cumbersome hiring authorities. We provided a draft of this report to DOD for review and comment. In written comments, DOD non-concurred with our assessment that DOD partially addressed the mandated reporting element to provide an accounting of the fully-burdened cost of federal civilian and service contractor personnel performing functions at the selected installations to include training, benefits, reimbursable costs, and facility overhead. DOD’s comments are reproduced in their entirely in appendix I. DOD also provided technical comments, which we incorporated as appropriate. DOD stated that we presented the three reporting elements identified in the congressional mandate absent the full context and congressional intent. Specifically, DOD stated that in the congressional mandate, the list of elements to be included in the report is not a stand-alone list and DOD stated that we present the elements as a stand-alone list. DOD further stated that the list of elements in the mandate is preceded by a paragraph that we did not reproduce in our report, but which provides context and congressional intent for the reporting elements. We do not believe that the language omitted from our report changes the meaning of the reporting elements to be included in DOD’s cost comparison report because the paragraph omitted clearly states that the purpose of the report is to provide the results of a study that includes a comparison of the fully-burdened cost of the performance of functions by DOD civilian personnel with the fully-burdened cost of the performance by DOD contractors. The paragraph preceding the reporting elements and the elements reads as follows: The committee directs the Secretary of Defense to submit to the Committees on Armed Services of the Senate and the House of Representatives, and to the Comptroller General of the United States, a report setting forth the results of a study, conducted by the Secretary for the purposes of the report, of a comparison of the fully-burdened cost of performance of functions by Department of Defense (DOD) civilian personnel with the fully-burdened cost of the performance of functions by DOD contractors by no later the February 1, 2016. The study shall include: (1) An assessment of performance of such functions at six DOD installations selected by the Secretary for purposes of the study from among DOD installations at which functions are performed by an appropriate mix of civilian personnel and contractors, with four such installations to be located in the continental United States and two such installations to be located outside the continental United States; (2) An accounting of the fully-burdened cost of DOD civilian personnel and contractors performing functions for DOD (including costs associated with training, benefits, reimbursable costs under chapter 43 of title 41, United States Code, and facility overhead) in order to permit a direct comparison between the cost of performance of functions by DOD civilian personnel and the cost of the performance of functions by contractors; (3) A comparison of the cost of performance of the full range of functions, required expertise, and managerial qualities required to adequately perform the function to be compared, including: a. Secretarial, clerical, or administrative duties, including data entry; b. Mid-level managers and other personnel possessing special expertise or professional qualifications; c. Managers and other leadership; and d. Personnel responsible for producing congressionally-directed reports. The committee recommends that, in conducting the study, the Secretary should take into account the policy that inherently governmental functions vital to the national security of the United States may not be performed by contractor personnel. The report required shall include an assessment of the flexible employment authorities available to the Secretary for the employment and retention of civilian employees of the DOD, including an identification of such additional flexible employment authorities as the Secretary considers appropriate to shape the civilian personnel workforce of the DOD. Not later than 120 days after receipt of such report, the Comptroller General shall submit to Congress a report that includes an assessment of the adequacy and sufficiency of the report submitted by the Secretary, including any recommendations for policy or statutory change as the Comptroller deems appropriate. As we reported, DOD noted in its cost comparison report that it identified labor costs used in its comparisons. However, DOD did not include direct and indirect non-labor costs and DODI 7041.04 states that the full cost of personnel should include these non-labor costs as we discussed earlier in the report. Therefore, DOD only partially addressed the reporting provision. In addition, DOD stated that we omit relevant language related to congressional intent for the second reporting element (i.e., an accounting of the fully-burdened cost of DOD civilian personnel and contractors). DOD stated that the text, “. . . in order to permit a direct comparison between the cost of performance of functions by DOD civilian personnel and the cost of the performance of the function by contractors,” conveys the congressional intent that the study is for comparison and our exclusion of the text in our restatement of the element omitted language indicating relevant Congressional intent. We do not believe that the language omitted in our report changed the meaning of the reporting element, which is that DOD was to include an accounting of the fully- burdened costs of federal civilians and service contractors in its cost comparisons. DOD further stated that we did not assess the second reporting element (i.e., an accounting of the fully-burdened cost of DOD civilian personnel and contractors) as it is directly stated but rather that we assessed the element by redefining it and then asserting that DOD partially addressed it. DOD noted that the direct language of the second reporting element is for DOD to include an “accounting” of the fully burdened cost of DOD civilian personnel and contractors. DOD asserted that we misinterpreted the meaning of “accounting” when we determined that DOD partially addressed the mandate because it did not “calculate” certain non-labor costs. We disagree. As we discuss in our report, DOD did account for the labor costs associated with federal civilian and service contractors by gathering labor cost data from several sources, but it did not include non- labor costs in its cost calculations. In order to account for the fully burdened costs of federal civilians and service contractors, as directed to do so by the preamble to the reporting elements, as well as the second reporting element, DOD should have included all labor and non-labor costs in the cost calculations. DOD also stated that our assessment incorrectly implies that to “account” for costs is equivalent to “calculating” costs as evidenced by the following quote from our draft report, "We acknowledge that DODI 7041.04 states that the cost elements can be modified, but by excluding non-labor costs in its cost comparisons, DOD did not account for the full cost of federal civilians and service contractors as requested in the mandate." DOD stated that although DOD did not “calculate” some non-labor costs, they did “account” for them in accordance with DODI 7041.04 and as directed in the congressional mandate. DOD asserted that in multiple places, DODI 7041.04 states that common costs "are excluded" and "may be excluded" from cost comparisons. DOD provided facility costs as an example of non-labor costs accounted for but not calculated in its cost comparisons. DOD stated that in its report, all of the civilian positions and contractor functions are performed at government-owned facilities. Thus, facility costs are common costs and may be excluded. DOD stated that their report accounted for facility costs by recognizing that such costs exist and are common costs, thus, DOD properly excluded such costs in accordance with DODI 7041.04, and their report satisfied the Congressional mandate. We disagree. As mentioned above, the preamble to the mandated reporting elements and the second reporting element specifically directed that DOD account for the fully-burdened cost of DOD civilian and contractor personnel. Because there are multiple costs associated with civilian and contractor personnel, calculations are necessary in order to account for the full cost of these workforces. DODI 7041.04 instructs that if a function is performed on government property, the costs of goods, services, and benefits that are common costs may be excluded provided the number of government and contactor personnel is equivalent. While there were some instances where it was the case that DOD’s cost estimates involved an equal number of civilian and contractor personnel performing functions on government property, there were many instances where the personnel numbers differed and common costs should not have been excluded. For example, in DOD’s comparisons of federal civilians and service contractors at Fort Belvoir Community Hospital, DOD conducted comparisons of 19 functions where 2 functions had equal numbers of federal civilian and service contractors and 17 functions had differing numbers of federal civilian and service contractors. In one comparison, the number of contractors was over three times the number of civilians. DODI 7041.04 further instructs that when the number of government and contractor personnel differs, adjustments must be made to the cost estimates to account for the difference in number of government and contractor personnel. DOD did not make these adjustments in is calculations and as result non-labor costs should not have been excluded; therefore, DOD did not account for the fully- burdened costs, as directed by Congress. We are sending copies of this report to the appropriate congressional committees. We are also sending copies to the Secretary of Defense, the Director of the Office of Cost assessment and Program Evaluation and other interested parties. This report will also be available at no charge on our Web site at http://www.gao.gov. Should you or your staff have any questions concerning this report, please contact Brenda S. Farrell at (202) 512-3604 or farrellb@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix II. In addition to the contact named above, Vincent Balloon, Assistant Director; Timothy Carr, Felicia Lopez, Clarice Ransom, Michael Silver, and Norris “Traye” Smith made key contributions to this report. Department of Defense: Actions Needed to Address Five Key Mission Challenges, GAO-17-369 (Washington, D.C.: June 13, 2017) DOD Civilian and Contractor Workforces: Additional Cost Savings Data and Efficiencies Plan Are Needed, GAO-17-128 (Washington, D.C.: October 12, 2016) Federal Hiring: OPM Needs to Improve Management and Oversight of Hiring Authorities, GAO-16-521 (Washington, D.C.: August 2, 2016) DOD Service Acquisition: Improved Use of Available Data Needed to Better Manage and Forecast Service Contract Requirements, GAO-16-119 (Washington, D.C.: February 18, 2016) Civilian and Contractor Workforces: Complete Information Needed to Assess DOD’s Progress for Reductions and Associated Savings, GAO-16-172 (Washington, D.C.: December 23, 2015) DOD Inventory of Contracted Services: Actions Needed to Help Ensure Inventory Data Are Complete and Accurate, GAO-16-46 (Washington, D.C.: November 18, 2015) Sequestration: Comprehensive and Updated Cost Savings Would Better Inform DOD Decision Makers if Future Civilian Furloughs Occur, GAO-14-529 (Washington, D.C.: June 17, 2014) Human Capital: Opportunities Exist to Further Improve DOD’s Methodology for Estimating the Costs of Its Workforces, GAO-13-792 (Washington, D.C.: September 25, 2013) Human Capital: Additional Steps Needed to Help Determine the Right Size and Composition of DOD’s Total Workforce, GAO-13-470 (Washington, D.C.: May 29, 2013) Defense Outsourcing: Better Data Needed to Support Overhead Rates for A-76 Studies, GAO/NSIAD-98-62 (Washington, D.C.: Feb. 27, 1998)
To help manage its multi-billion dollar acquisition investments, DHS has established policies and processes for acquisition management, requirements development, test and evaluation, and resource allocation. The department uses these policies and processes to deliver systems that are intended to close critical capability gaps, helping enable DHS to execute its missions and achieve its goals. DHS policies and processes for managing its major acquisition programs are primarily set forth in its Acquisition Management Directive 102-01 and Acquisition Management Instruction 102-01-001. DHS issued the initial version of this directive in November 2008 in an effort to establish an acquisition management system that effectively provides required capability to operators in support of the department’s missions. DHS’s Under Secretary for Management is currently designated as the department’s Chief Acquisition Officer and, as such, is responsible for managing the implementation of the department’s acquisition policies. DHS’s Under Secretary for Management serves as the acquisition decision authority for the department’s largest acquisition programs, those with LCCEs of $1 billion or greater. Component Acquisition Executives—the most senior acquisition management officials within each of DHS’s components—may be delegated acquisition decision authority for programs with cost estimates between $300 million and less than $1 billion. Table 1 identifies how DHS has categorized the 28 major acquisition programs we review in this report, and table 7 in appendix III specifically identifies the programs within each level. DHS acquisition management policy establishes that a major acquisition program’s decision authority shall review the program at a series of predetermined acquisition decision events to assess whether the major program is ready to proceed through the acquisition life-cycle phases. Depending on the program, these events can occur within months of each other, or be spread over several years. Figure 1 depicts the acquisition life cycle established in DHS acquisition management policy. An important aspect of an acquisition decision event is the decision authority’s review and approval of key acquisition documents. See table 2 for a description of the type of key acquisition documents requiring department-level approval before a program moves to the next acquisition phase. DHS acquisition management policy establishes that the APB is the agreement between program, component, and department-level officials establishing how systems will perform, when they will be delivered, and what they will cost. Specifically, the APB establishes a program’s schedule, costs, and key performance parameters. DHS defines key performance parameters as a program’s most important and non- negotiable requirements that a system must meet to fulfill its fundamental purpose. For example, a key performance parameter for an aircraft may be airspeed and a key performance parameter for a surveillance system may be detection range. The APB schedule, costs, and key performance parameters are defined in terms of an objective and minimum threshold value. According to DHS policy, if a program fails to meet any schedule, cost, or performance threshold approved in the APB, it is considered to be in breach. Programs in breach are required to notify their acquisition decision authority and develop a remediation plan that outlines a time frame for the program to return to its APB parameters, re-baseline—that is, establish new schedule, cost, or performance goals—or have a DHS-led program review that results in recommendations for a revised baseline. In addition to the acquisition decision authority, other bodies and senior officials support DHS’s acquisition management function: The Acquisition Review Board reviews major acquisition programs for proper management, oversight, accountability, and alignment with the department’s strategic functions at acquisition decision events and other meetings as needed. The board is chaired by the acquisition decision authority or a designee and consists of individuals who manage DHS’s mission objectives, resources, and contracts. The Office of Program Accountability and Risk Management (PARM) is responsible for DHS’s overall acquisition governance process, supports the Acquisition Review Board, and reports directly to the Under Secretary for Management. PARM develops and updates program management policies and practices, reviews major programs, provides guidance for workforce planning activities, provides support to program managers, and collects program performance data. Components, such as U.S. Customs and Border Protection, the Transportation Security Administration, and the U.S. Coast Guard sponsor specific acquisition programs. The head of each component is responsible for oversight of major acquisition programs once the programs complete delivery of all planned capabilities to end users. Component Acquisition Executives within the components are responsible for overseeing the execution of their respective portfolios. Program management offices, also within the components, are responsible for planning and executing DHS’s individual programs. They are expected to do so within the cost, schedule, and performance parameters established in their APBs. If they cannot do so, programs are considered to be in breach and must take specific steps, as noted above. Figure 2 depicts the relationship between acquisition managers at the department, component, and program level. DHS established a Joint Requirements Council (JRC) to develop and lead a component-driven joint requirements process for the department. The JRC has issued policies outlining a process for analyzing and validating capability gaps, needs, and requirements. The JRC consists of a chair and 14 members who are senior executives or officers that represent key DHS headquarters offices and seven of the department’s operational components. The JRC chair rotates annually among the seven operational components. JRC members represent the views of their components or office leadership, endorse and prioritize validated capability needs and operational requirements (user-defined performance parameters outlining what a system must do), and make recommendations that are supported by analytical rigor. Figure 3 depicts the current headquarters and component members of the JRC. The JRC provides input to two senior-level entities: The Acquisition Review Board—as a member, the JRC chair advises the board on capability gaps, needs, and requirements at key milestones in the acquisition life cycle. The Deputy’s Management Action Group, which the Secretary established in April 2014, is a decision-making body that is chaired by the Deputy Secretary. Its membership consists of the DHS Chief of Staff, DHS Under Secretaries, senior operational component deputies and select support component deputies, and the Chief Financial Officer. The group provides recommendations to the Deputy Secretary for consideration in the annual resource allocation process that reflects DHS’s investment priorities. The group reviews JRC- validated capability needs and recommendations, provides direction and guidance to the JRC, and endorses or directs related follow-on JRC activities. The JRC is responsible for validating proposed capability needs and requirements for all major acquisitions, as well as for programs that are joint or of interest to the Deputy’s Management Action Group, regardless of level. See table 3 for a description of the key requirements documents requiring JRC validation. In general, the DHS requirements development process moves from broad mission needs and capability gaps to operational requirements. See figure 4. In May 2009, DHS established policies that describe processes for testing the capabilities delivered by the department’s major acquisition programs. The primary purpose of test and evaluation is to provide timely, accurate information to managers, decision makers, and other stakeholders to reduce programmatic, financial, schedule, and performance risks. We provide an overview of each of the 28 programs’ test activities in the individual program assessments presented in appendix I. DHS testing policy assigns specific responsibilities to particular individuals and entities throughout the department: Program managers have overall responsibility for planning and executing their programs’ testing strategies, including scheduling and funding test activities and delivering systems for testing. They are also responsible for controlling developmental testing, which is used to assist in the development and maturation of products, manufacturing, or support processes. Developmental testing includes engineering- type tests used to verify that design risks are minimized, substantiate achievement of contract technical performance, and certify readiness for operational testing. Operational test agents are responsible for planning, conducting, and reporting on operational test and evaluation, which is intended to identify whether a system can meet its key performance parameters and provide an evaluation of the operational effectiveness, suitability, and cybersecurity of a system in a realistic environment. Operational effectiveness refers to the overall ability of a system to provide a desired capability when used by representative personnel. Operational suitability refers to the degree to which a system can be placed into field use and sustained satisfactorily. The operational test agents may be organic to the component, another government agency, or a contractor, but must be independent of the developer in order to present credible, objective, and unbiased conclusions. The Director, Office of Test and Evaluation is responsible for approving major acquisition programs’ operational test agent and test and evaluation master plans, among other things. A program’s test and evaluation master plan must describe the developmental and operational testing needed to determine technical performance and operational effectiveness, suitability, and cybersecurity. As appropriate, the Director is also responsible for observing operational tests, reviewing operational test agents’ reports, and assessing the reports. Prior to a program’s acquisition decision event 3, the Director provides the program’s acquisition decision authority a letter of assessment that includes an appraisal of the program’s operational test, a concurrence or non-concurrence with the operational test agent’s evaluation, and any further independent analysis. As an acquisition program proceeds through its life cycle, the testing emphasis moves gradually from developmental testing to operational testing. See figure 5. DHS has established a planning, programming, budgeting, and execution process to allocate resources to acquisition programs and other entities throughout the department. DHS uses this process to produce the department’s annual budget request and multi-year funding plans presented in the FYHSP, a database that contains, among other things, 5-year funding plans for DHS’s major acquisition programs. According to DHS guidance, the 5-year plans should allow the department to achieve its goals more efficiently than an incremental approach based on 1-year plans. DHS guidance also states that the FYHSP articulates how the department will achieve its strategic goals within fiscal constraints. At the outset of the annual resource allocation process, the department’s Offices of Policy and Chief Financial Officer provide planning and fiscal guidance, respectively, to the department’s components. In accordance with this guidance, the components should submit 5-year funding plans to the Chief Financial Officer. These plans are subsequently reviewed by DHS’s senior leaders, including the DHS Secretary and Deputy Secretary. DHS’s senior leaders are expected to modify the plans in accordance with their priorities and assessments, and they document their decisions in formal resource allocation decision memorandums. DHS submits the revised funding plans to the Office of Management and Budget, which uses them to inform the President’s annual budget request—a document sent to Congress requesting new budget authority for federal programs, among other things. In some cases, the funding appropriated to certain accounts in a given fiscal year can be carried over to subsequent fiscal years. Figure 6 depicts DHS’s annual resource allocation process. Federal law requires DHS to submit an annual FYHSP report to Congress at or about the same time as the President’s budget request. This report presents the 5-year funding plans in the FYHSP database at that time. Two offices within DHS’s Office of the Chief Financial Officer support the annual resource allocation process: The Office of Program Analysis and Evaluation (PA&E) is responsible for establishing policies for the annual resource allocation process and overseeing the development of the FYHSP. In this role, PA&E develops the Chief Financial Officer’s planning and fiscal guidance, reviews the components’ 5-year funding plans, advises DHS’s senior leaders on resource allocation issues, maintains the FYHSP database, and submits the annual FYHSP report to Congress. The Cost Analysis Division is responsible for reviewing, analyzing, and evaluating acquisition programs’ LCCEs to ensure the cost of DHS programs are presented accurately and completely, in support of resource requests. This division also supports affordability assessments of the department’s budget, in coordination with PA&E, and develops independent cost estimates for major acquisition programs upon request by DHS’s Under Secretary for Management or Chief Financial Officer. Of the 24 programs we assessed with approved schedule and cost goals, 10 were on track to meet those goals during 2017. The other 14 programs were not on track because they changed or breached their schedule goals, cost goals, or both. We found that most programs updated their cost estimates in response to requirements DHS established in January 2016 that are intended to provide decision makers with more timely information. These actions are in accordance with GAO’s best practice to regularly update cost estimates and we plan to use these updated estimates to measure programs’ cost changes going forward. Based on our April 2014 recommendation, DHS revised the format of its fiscal year 2018–2022 FYHSP report to Congress to include acquisition affordability tables for select major acquisition programs. However, the report shows—and our analysis of programs’ current cost estimates confirms— that some programs face acquisition funding gaps in fiscal year 2018. We also reviewed 4 programs that were early in the acquisition process and planned to establish department-approved schedule and cost goals in calendar year 2017. However, these programs were delayed in getting department approval for their initial APBs for various reasons and, therefore, we excluded them from our assessment of whether programs were on track to meet their schedule and cost goals during 2017. DHS leadership subsequently approved initial APBs for 2 particularly complex and costly programs—a border wall system along the southwest U.S. border and the Coast Guard’s Heavy Polar Icebreaker—in January 2018. We plan to assess these programs in next year’s review, but provide more details on all 4 additional programs we reviewed in the individual assessments in appendix I. Table 4 summarizes our findings and we present more detailed information after the table. From January 2017 to January 2018, 10 of the 24 programs we assessed with department-approved APBs were on track to meet their schedule and cost goals. This is fewer than our last annual review in which we found that 17 of the 26 programs we assessed were on track during 2016. Three of the 10 programs on track during 2017 were on track against initial schedule and cost goals; that is, the schedule and cost estimates in the baseline DHS leadership initially approved after the department’s acquisition management policy went into effect in November 2008. The other 7 programs had re-baselined prior to January 2017 and were on track against revised schedules and cost estimates that reflected past schedule slips, cost growth, or both. However, some of the programs on track in 2017 identified risks that may lead to schedule slips or cost growth in the future. For example, officials from the Technology Infrastructure Modernization program told us that staffing challenges may impede their ability to execute the program in accordance with its current APB. We also identified 2 programs that are in the process of re-baselining or plan to re-baseline in the near future to account for significant program changes or to add capabilities. For example, the Next Generation Networks Priority Services program plans to update its APB to establish schedule, cost, and performance goals for the next increment, which is intended to address landline capabilities for providing government officials emergency telecommunication services. During 2017, 14 of the 24 programs we assessed with department- approved APBs were not on track. Twelve of these programs had at least one major acquisition milestone that slipped, including 6 of these programs that also changed or breached their cost goals. Two additional programs changed or breached only their cost goals. As of January 2018, 6 of the 12 programs that experienced a schedule slip were in breach and had not yet revised their goals. Therefore, the magnitude of the schedule slips is unknown. For the remaining 6 programs, the change in schedule during 2017 ranged from a delay of 6 months to 66 months. Figure 7 identifies the programs that experienced schedule slips and the extent to which their major milestones slipped in 2017, as well as—for additional context—in prior years. While there are various reasons for schedule delays, the result is that end users may not get needed capabilities when they originally anticipated. Examples of the reasons why these key milestones slipped in 2017 include the following: New requirements: For example, the Passenger Screening Program re-baselined in May 2017 for the fifth time since its initial APB was approved in January 2012. This latest re-baseline was to remediate a 17-month breach caused by delays in incorporating new cybersecurity requirements in one of the program’s transportation security equipment technologies, known as the Credential Authentication Technology. The program now plans to achieve full operational capability for this system by December 2023—more than 9 years later than it initially planned. In another example, the Tactical Communications Modernization program re-baselined in November 2017—4 months after the program notified DHS leadership that it would not achieve full operational capability as planned. The reason for this re-baseline was to resolve issues related to federal information security requirements. The program now plans to achieve this milestone by March 2019, which is more than a year later than its initial APB threshold. Technical challenges: For example, the Continuous Diagnostics and Mitigation program re-baselined in June 2017 to account for significant coverage gaps identified during the deployment of phase 1 sensors and to establish cost, schedule, and performance goals for phase 3 tools. The program’s full operational capability date slipped almost 4 years after this milestone was redefined as the point in time at which phase 1–3 tools are available to all participating civilian agencies. Additionally, the Automated Commercial Environment program declared a schedule breach in April 2017—its second in less than a year—after encountering difficulties developing its remaining functionality. These difficulties have caused further delays to the program’s final acquisition milestone decision. External factors: Officials from the Logistics Supply Chain Management System program notified DHS leadership in September 2017 that the program would not complete all required activities to achieve acquisition decision event 3 and subsequent events, including full operational capability. The primary reason for the delay was because program staff were deployed to support response and recovery efforts during the 2017 hurricane season. Additionally, the Medium Lift Helicopter program experienced delays in getting key acquisition documents approved in time to achieve its acquisition decision event 3. These delays were attributed, in part, to DHS leadership directing Customs and Border Protection to develop a comprehensive border plan that included the helicopter’s capabilities. We elaborate on the reasons for all 12 programs’ schedule slips in the individual assessments in appendix I. Of the 14 programs not on track during 2017, 8 revised or breached their established cost goals. Four of these 8 programs revised their cost goals when they re-baselined to address new requirements and technical challenges, among other things. When the Passenger Screening Program re-baselined in May 2017, the program’s APB threshold for its life-cycle costs increased $418 million (8 percent) over its previous APB. However, the revised threshold is $1 billion below the threshold established in the program’s initial APB, which was approved in January 2012. From 2012 to 2015, the program’s scope was reduced in response to funding constraints. However, emerging threats drove the program to increase capability requirements, which has subsequently increased costs. When the Continuous Diagnostics and Mitigation program re- baselined in June 2017, the APB threshold for life-cycle costs decreased by $15 million (1 percent). However, the program shifted some acquisition costs to operations and maintenance (O&M) to be consistent with DHS’s new common appropriations structure. This, in addition to other changes, increased the APB threshold for O&M by $631 million (3,712 percent). When the National Security Cutter program re-baselined in November 2017 to account for a ninth ship—as directed by Congress—the APB cost thresholds for acquisition and O&M increased by $453 million (8 percent) and $123 million (1 percent), respectively. When the Immigration and Customs Enforcement’s TECS Modernization program re-baselined in November 2017 in preparation for acquisition decision event 3, the APB cost thresholds increased overall. Specifically, the acquisition cost threshold decreased by $14 million (6 percent) when the program included actual costs through fiscal year 2016, among other things, and the O&M cost threshold increased by $147 million (92 percent) when the program extended the estimate by 4 years and included support costs for an additional 11 years. The other 4 programs breached their established cost goals during 2017. The Medium Lift Helicopter and Electronic Baggage Screening programs breached certain APB cost thresholds when they shifted costs between categories, such as O&M to acquisitions or vice versa, to be consistent with DHS’s new common appropriations structure. The Tactical Communications Modernization program experienced a cost breach primarily because of increases in costs for contractor labor and support for facilities and infrastructure. The program’s APB cost threshold for O&M increased by $110 million (23 percent) when it re-baselined in November 2017. The Automated Commercial Environment program experienced a cost breach because it had to extend its contracts to address the development difficulties discussed above. The magnitude of the program’s cost goal changes is not yet known because the program does not plan to revise its APB until August 2018. We elaborate on the reasons for all 8 programs’ cost goal changes or breaches in the individual program assessments in appendix I. In January 2016, based on several of our past recommendations, DHS required major acquisition programs to begin submitting to headquarters (1) detailed data on program affordability, such as updates to the program’s LCCE and funding source information, to help inform the department’s annual resource allocation process, and (2) an annual LCCE update. These requirements are intended to provide more timely information that may improve DHS’s efforts to address acquisition program affordability issues, as well as internal and external oversight of programs’ progress against its cost goals. These actions are in accordance with GAO’s cost estimating best practices, which state that cost estimates should be updated with actual costs so that they are always relevant and current. As a result, we have used these sources to provide the programs’ current estimate in the individual assessments in appendix I, as appropriate, and plan to use these data sources to measure programs’ cost changes going forward. According to officials from the Cost Analysis Division, a program’s annual LCCE update should inform the affordability submission to support the annual resource allocation process and can be completed at any point during the fiscal year leading up to this process. We examined documentation to ascertain whether the programs we reviewed complied with the two requirements. For the 24 programs we assessed with department-approved APBs, we found the following: All 24 programs submitted the detailed data on program affordability to headquarters by June 2017 to inform the fiscal year 2019 resource allocation cycle. Most programs’ submissions accounted for changes since the program’s last LCCE was approved by DHS’s Chief Financial Officer, except three. For example, the Long Range Surveillance Aircraft program’s submission reflected no updates from its November 2011 LCCE because the program was in the process of re-baselining to account for significant changes. The program began re-baselining nearly 3 years ago and has been delayed for various reasons, including challenges with the vendor hired to complete a revision of the program’s LCCE. Eighteen of the 24 programs submitted annual LCCE updates. Three programs—Automated Commercial Environment, H-65, and Transformation—did not submit an annual LCCE update because they were in breach. The other 3 programs—all within the Coast Guard—did not submit an annual LCCE because, according to Coast Guard officials, they have limited internal cost estimating capability and rely on outside sources for this service, which led to delays in completing the annual LCCEs for these programs. Coast Guard officials said they are reviewing options to resolve these delays and improve the Coast Guard’s cost estimating capability. Cost Analysis Division officials anticipate the Coast Guard will increase compliance with the annual LCCE requirement in fiscal year 2018. They also plan to update the annual LCCE template to include additional information, such as comparisons of the updated estimates to the program’s APB cost goals and projected funding. In addition, DHS revised the format of its FYHSP report to Congress, improving insight into major programs’ acquisition funding, but decreasing insight into O&M funding. In April 2014, we found that DHS could better communicate its funding needs for acquisition programs to Congress and recommended that DHS enhance the content for future FYHSP reports by presenting programs’ annual cost estimates and any anticipated funding gaps, among other things. DHS concurred with the recommendation and, for the first time, included acquisition affordability tables that presented programs’ annual acquisition cost estimates compared to projected acquisition funding for select major acquisition programs in its FYHSP report for fiscal years 2018–2022. However, DHS no longer reported O&M funding for individual programs. DHS reported in the FYHSP that it focused on acquisition information because O&M funding estimates are generally stable year-to-year and components manage O&M in various ways, such as by individual program or across a portfolio of programs. By removing O&M funding information in the FYHSP for all programs, DHS presents an incomplete picture of programs’ full funding needs and affordability. In April 2018, we assessed the extent to which DHS had accounted for O&M costs and funding in greater detail and recommended that DHS reverse the exclusion of O&M funding at the acquisition program level in its FYHSP report to Congress for all components. DHS officials stated that they plan to re-introduce O&M funding for major acquisition programs in the FYHSP report for fiscal years 2019–2023 based on multiple internal discussions about the best way to present a more comprehensive view of programs’ total costs and feedback from key stakeholders, such as the Office of Management and Budget. Based on the information presented in the FYHSP report for fiscal years 2018–2022, DHS’s acquisition portfolio is not affordable over the next 5 years. For example, the report contained acquisition affordability tables for 18 of the 24 programs we assessed that have approved APBs. Of these 18 programs, 9 were projected to have an acquisition affordability gap in fiscal year 2018. However, some of these projections are outdated since the FYHSP report—which was issued in September 2017—relied on cost information as of April 2016. Therefore, we updated these tables using the programs’ current acquisition cost estimate presented in the individual assessments in appendix I. Based on our assessment of programs’ current cost estimates, we also found that a total of 9 programs are projected to have an acquisition affordability gap in fiscal year 2018. However, 3 of these 9 programs were different programs than those identified based on the FYHSP report. Of the 9 programs we identified with a projected acquisition affordability gap in fiscal year 2018, we found the following: Five programs identified other funding, such as funding from previous fiscal years that remained available for obligation—known as carryover funding—which would address their projected acquisition funding gap. For example, in the FYHSP report, DHS projected allocating approximately $16 million in funding for the Technology Infrastructure Modernization program in fiscal year 2018 to cover an estimated $16 million in acquisition costs. However, in its November 2017 annual LCCE update, this program’s acquisition cost increased to almost $30 million, resulting in a projected acquisition affordability gap of almost 45 percent. The program plans to realign $57 million in O&M carryover funding to cover this and any future acquisition shortfalls. Four programs did not identify other funding that would address their projected acquisition funding gap, which increases the likelihood that they will cost more and take longer to deliver capabilities to end users than expected. For example, in the FYHSP report, DHS projected allocating $109 million in funding for the Non-Intrusive Inspection Systems program in fiscal year 2018 to cover an estimated $103 million in acquisition costs. However, in its April 2017 annual LCCE update, this program’s acquisition costs increased to nearly $186 million, resulting in a projected acquisition affordability gap of 41 percent. The program identified only $2.5 million in fiscal year 2017 acquisition carryover funding. Further, 5 of the 24 programs we assessed were not included in the fiscal years 2018–2022 FYHSP report because they were no longer expected to receive acquisition funding. Officials from 3 of these 5 programs projected funding gaps that could cause future program execution challenges, such as schedule slips or cost growth. For example, the National Bio and Agro-Defense Facility anticipates a projected funding shortfall of approximately $90 million over the next 5 years, which officials said could delay a number of activities to make the facility operational. We elaborate on programs’ affordability over the next 5 years in the individual program assessments in appendix I. We assessed DHS’s policies outlining the department’s processes for acquisition management, resource allocation, and requirements and found that, when considered collectively, they generally reflect key portfolio management practices. In March 2007, we examined the practices that private sector entities use to achieve a balanced mix of new projects and found that successful commercial companies use a disciplined and integrated approach to prioritize needs and allocate resources when making investments. This approach, known as portfolio management, requires companies to view each of their investments as contributing to a collective whole, rather than as independent and unrelated. With this perspective, companies can effectively (1) identify and prioritize opportunities, and (2) allocate available resources to support the highest priority—or most promising—opportunities. Based on this and other work, we identified four key practice areas for portfolio management in September 2012. We previously assessed DHS’s acquisition management and resource allocation policies against our key portfolio management practices in September 2012 and April 2014, respectively. We found that the policies in place at the time of our reviews did not fully reflect all of the key portfolio management practices and recommended that DHS revise its policies to do so. DHS concurred with our recommendations and subsequently took actions to mature and solidify the department’s portfolio management processes and policies. In April 2014, the Secretary of Homeland Security issued a memorandum titled Strengthening Departmental Unity of Effort, which aimed to strengthen DHS’s structures and processes to improve departmental cohesiveness and operational effectiveness, among other things. The memorandum identified several initial focus areas intended to build organizational capacity, one of which centered on improving and integrating the department’s processes for acquisition oversight, resource allocation, and joint requirements analysis. To improve these processes, the memorandum directed senior DHS leaders to update the existing acquisition management and resource allocation processes, as well as lead an expedited review to provide alternatives for developing and facilitating a component-driven joint requirements process, which ultimately led to the re-establishment of the JRC. In response to our recommendations and the Unity of Effort memorandum, DHS issued new policies outlining the acquisition management, resource allocation, and requirements processes in 2016. We assessed these policies and found that, when considered collectively, they generally reflect the key portfolio management practices, as shown in table 5. Because DHS’s new policies were issued in 2016, we did not specifically assess DHS’s implementation of them. However, we did review documentation resulting from the acquisition management, resource allocation, and requirements processes since January 2016 to get a sense of how the department began implementation. Examples of how DHS’s policies reflect the key portfolio management practices and their implementation status are outlined below. Clearly define and empower leadership: the policies identify the roles and responsibilities for decision makers in the acquisition management, resource allocation, and requirements processes, as well as establish cross-functional teams to support those decision makers. For example, to fulfill the role of acquisition decision authority, the Under Secretary for Management is supported by the Acquisition Review Board, which consists of key DHS senior leaders responsible for managing the department’s finances, contracts, and testing, among other things. We reviewed the memorandums issued since January 2016 that document Acquisition Review Board decisions and found that, through this group, DHS has taken steps to manage across programs through its acquisition management process. For example, after reviewing the status of several individual Customs and Border Protection programs in 2016, the Acquisition Review Board identified the need for a comprehensive border plan that depicts the component’s current land, maritime, and air domain awareness capabilities. In October 2016, the Deputy Under Secretary for Management—who was serving as acquisition decision authority at the time—directed Customs and Border Protection to develop such a plan. The plan is to consist of separate analyses for each of the three domains—starting with land— that reflect end users’ capability requirements for systems, such as Integrated Fixed Towers, Multi-Role Enforcement Aircraft, and Medium Lift Helicopter, that address relevant domain threats. As of February 2018, Customs and Border Protection had not yet completed the analysis for land domain awareness capabilities. Establish standard assessment criteria and demonstrate comprehensive knowledge of the portfolio: the policies establish standard criteria for assessing major acquisition programs through the acquisition management, resource allocation, and requirements processes. For example, the updated resource allocation handbook established that PA&E conduct annual assessments of all major investments using standard criteria in five main categories— contribution to DHS’s mission, program health, risk, resources, and governance—to assess the portfolio of investments and present alternatives for leadership decision. PA&E officials told us they used these criteria when assessing components’ resource allocation requests during development of the President’s fiscal year 2018 budget to develop funding options for the Deputy’s Management Action Group, which is responsible for making resource allocation recommendations for the Secretary’s approval. PA&E presented its funding options by DHS mission, which, according to officials associated with the Deputy’s Management Action Group, allowed the group to make cross-component allocation decisions that directly aligned with the department’s strategic goals. We could not verify these officials’ assertions based on the documentation we were provided, but will continue to monitor PA&E’s assessment of major acquisition programs against the standard criteria as the department’s implementation of its resource allocation policies matures. In addition, PARM formally established its Acquisition Program Health Assessments in October 2016 after more than a year of development and pilot efforts. These assessments are intended to monitor major acquisition programs quarterly (both on an individual program level and in aggregate) by rating programs against standard criteria in several categories—such as program management, financial management, and human capital—that DHS deemed important for successful program execution. We reviewed the quarterly reports issued from January 2016 to April 2017 and found that they primarily focused on individual programs. The portfolio-level information contained in these reports was limited to program results grouped in various categories, such as by component, by acquisition life-cycle phase, and by investment type (e.g., information technology). PARM officials said they plan to use the health assessments as a portfolio management tool in the future and are working to determine how to best to analyze and present portfolio-level data. We will continue to track PARM’s implementation of the health assessment process moving forward through GAO’s High Risk work to determine DHS’s progress in demonstrating that major acquisition programs are on track to achieve their established goals. Prioritize investments by integrating the requirements, acquisition, and budget processes: the policies identify areas where DHS’s requirements, acquisition management, and resource allocation processes are integrated and establish processes for prioritizing investments. For example, the updated resource allocation policies require reviews of DHS’s major acquisition portfolio during this annual process. When the portfolio faces a funding gap, programs are to be returned to their respective components for scope or funding adjustments, or prioritized by department leadership to identify an affordable set of programs. For the fiscal year 2018 resource allocation cycle, PA&E officials provided an example where DHS leadership directed components to identify funding from alternative sources to fund specific purposes related to DHS’s mission to prevent terrorism and enhance security. However, as previously discussed, the resulting FYHSP report for fiscal years 2018–2022 showed that DHS’s portfolio of major acquisition programs is not affordable over the next 5 years. In addition, the requirements policies established the Joint Assessment of Requirements, an annual process to prioritize emerging and existing requirements to inform the department’s resource allocation decisions. As we found in October 2016, the JRC plans to implement the Joint Assessment of Requirements through a 3-year phased approach that is expected to be fully implemented in time to inform DHS’s fiscal year 2021 budget request. In fiscal year 2016, the JRC completed the first phase, which included (1) developing initial criteria to evaluate emerging requirements, and (2) evaluating and prioritizing a sample of those requirements against the initial criteria. Based on these results, JRC officials told us in September 2017 that they are working to develop assessment metrics for the criteria as part of the next phase. We will continue to track the JRC’s progress through GAO’s High Risk work to determine DHS’s progress to effectively operate the JRC. Continually make go/no go decisions to rebalance the portfolio: the requirements policies outlining the Joint Assessment of Requirements process also reflected the key practices to conduct reviews (1) annually to make requirement scoping adjustments as priorities change and (2) when new investments are identified. However, as previously discussed, the JRC is still in the process of implementing this process. We consider this overall key practice area to be partially met because DHS’s policies do not reflect the key practice (3) to reassess programs that breach established thresholds within the context of the portfolio to determine if the program remains relevant and affordable. PARM officials told us that—in practice—DHS reassesses programs in the context of their component’s overall acquisition portfolio based on a certification of funds memorandum submitted to DHS’s Chief Financial Officer when programs re-baseline as a result of a cost, schedule, or performance breach. The memorandum is intended to enable the Acquisition Review Board to discuss affordability by certifying a program’s funding levels and identifying trade-offs necessary to address any projected funding gaps. We previously found that the certification of funds memorandum was an effective tool for DHS leadership to assess program affordability. However, DHS’s acquisition management policy requires components to submit this memorandum prior to most acquisition decision events, but not when a program re-baselines as a result of a cost, schedule, or performance breach. During our review of programs’ progress against schedule and cost goals in 2017, we found one instance where a component did not follow the practice to submit this memorandum when one of its programs re-baselined as a result of a breach. Specifically, Customs and Border Protection did not submit a certification of funds memorandum when the Tactical Communications Modernization program re-baselined in November 2017 as a result of a schedule and cost breach. Nevertheless, DHS leadership approved the program’s revised APB and removed it from breach status, even though DHS’s Chief Financial Officer identified that the program’s revised LCCE was not affordable. PARM officials stated that this instance was an oversight because, at the time, the department was still determining when certification of funds memorandums should be submitted. According to the federal standards for internal control, documentation of internal control practices is necessary so that they can be implemented effectively. By amending its acquisition management policy to require a certification when a program re-baselines as a result of a cost, schedule, or performance breach, DHS can ensure that leadership receives the necessary information to reassess that program’s affordability in the context of a larger portfolio. PARM officials stated that, moving forward, components will be required to submit a certification of funds memorandum for each program when a new APB is submitted for DHS leadership approval. In contrast, the acquisition management policy does reflect the key practice (4) to use information gathered from post-implementation reviews to fine tune investment processes and the portfolio to achieve strategic outcomes. For example, DHS’s acquisition management policy requires programs to conduct post-implementation reviews 6 to 18 months after initial operational capability to identify and document any deployment or implementation and coordination issues, how they were resolved, and how they could be prevented in the future. These reviews are intended to help identify capability gaps that may inform future acquisitions, among other things. However, PARM officials said that they do not consider the results of the post-implementation reviews when managing the department’s current acquisition portfolio because these reviews are typically conducted after program oversight shifts from PARM to the component. While post-implementation reviews are conducted later in the acquisition life cycle, the insights they provide could be leveraged by other programs in the acquisition portfolio, not just the program under review. For example, the Integrated Fixed Towers program completed a post-implementation review in June 2016 after its initial deployment of capabilities to the Arizona border. The review found that changes in illegal traffic patterns as a result of the program’s deployment may be predicted, and other technologies may be able to compensate for changes in these patterns. This information could help other programs under development plan for similar outcomes or enable DHS to change deployment plans for existing programs to address changes in threats. PARM has an opportunity to use the results from programs’ post- implementation reviews since it is responsible for overseeing the department’s acquisition portfolio by monitoring each investment’s cost, schedule, and performance against established baselines. Federal standards for internal control state that management should obtain data on a timely basis so that they can be used for effective monitoring and that separate evaluations may provide feedback on the effectiveness of ongoing monitoring. By leveraging the results from post-implementation reviews in its monitoring efforts, PARM may be better able to ensure that programs in the current acquisition portfolio achieve their baselines. PARM officials stated they have generally focused on leveraging information gathered from canceled acquisition programs, such as where and why plans went wrong. However, they agreed that they could better leverage post- implementation review information gathered from programs that complete planned capability deployments. DHS’s mission to safeguard the American people and homeland requires a broad portfolio of acquisitions. However, the performance of DHS’s major acquisition portfolio during 2017 did not improve compared to our last review because we found that more programs will require more time and may require more money to complete than initially planned. DHS is collecting more timely cost estimate information on its acquisition programs to make more informed investment decisions. Yet DHS continues to face challenges in funding its acquisition portfolio, which highlights the need for disciplined policies that reflect best practices to ensure that the department does not pursue more programs than it can afford. DHS leadership has taken positive steps in recent years by strengthening its policies for acquisition management and resource allocation, and establishing policies related to requirements. Collectively, these policies reflect an integrated approach to managing investments. However, opportunities remain to further strengthen the acquisition management policy by documenting DHS’s current practice to reassess programs that breach their established cost, schedule, or performance thresholds to ensure they are still worth pursuing within the context of the portfolio. Additionally, leveraging information learned once programs complete deployment across the acquisition portfolio could help ensure that programs stay on track against their baselines in the first place. This is particularly relevant because DHS is initiating a number of complex and costly acquisition programs, such as development of a wall system along the southwest border and the Coast Guard’s Heavy Polar Icebreaker, which could benefit from this type of information. We are making the following two recommendations to DHS: The Under Secretary for Management should update DHS’s acquisition management policy to require components to submit a certification of funds memorandum when a major acquisition program re-baselines in response to a breach. (Recommendation 1) The Under Secretary for Management should require PARM to assess the results of major acquisition programs’ post-implementation reviews and identify opportunities to improve performance across the acquisition portfolio. (Recommendation 2) We provided a draft of this report to DHS for review and comment. In its comments, reproduced in appendix IV, DHS concurred with both of our recommendations and identified actions it planned to take to address them. DHS also provided technical comments, which we incorporated as appropriate. We are sending copies of this report to the appropriate congressional committees and the Secretary of Homeland Security. In addition, the report is available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-4841 or makm@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix V. This appendix presents individual assessments for each of the 28 programs we reviewed. Each assessment presents information current as of January 2018. They include standard elements, such as an image, a program description, and summaries of the program’s progress in meeting cost and schedule goals, performance and testing activities, and program management-related issues, such as staffing. Each assessment also includes the following figures: Fiscal Years 2018–2022 Affordability. This figure compares the funding plan presented in the Future Years Homeland Security Program report to Congress for fiscal years 2018–2022 to the program’s current cost estimate. We use this funding plan because the data are approved by the Department of Homeland Security (DHS) and Office of Management and Budget, and was submitted to Congress to inform the fiscal year 2018 budget process. The figure only presents acquisition funding because DHS did not report operations and maintenance (O&M) funding for individual programs in its funding plan to Congress. In addition, the data do not account for other potential funding sources, such as carryover. Acquisition Program Baseline (APB) vs. Current Estimate. This figure compares the program’s cost thresholds from the initial APB approved after DHS’s acquisition management policy went into effect in November 2008 and the program’s current DHS-approved APB to the program’s expected costs as of January 2018. The source for the current estimate is the most recent cost data we collected (i.e., a department-approved life-cycle cost estimate, updated life-cycle cost estimates submitted during the resource allocation process to inform the fiscal year 2019 budget request, or a fiscal year 2017 annual life- cycle cost estimate update). Schedule Changes. This figure consists of two timelines that identify key milestones for the program. The first timeline is based on the initial APB DHS leadership approved after the department’s current acquisition management policy went into effect. The second timeline identifies when the program expected to reach its major milestones as of January 2018 and includes milestones introduced after the program’s initial APB. Dates shown are based on the program’s APB threshold dates or updates provided by the program office. Test Status. This table identifies key recent and upcoming test events. It also includes DHS’s Director, Office of Test and Evaluation’s assessment of programs’ test results, if an assessment was conducted. Staffing Profile. This figure identifies the total number of staff a program needs (measured in full time equivalents) including how many are considered critical and how many staff the program actually has. Lastly, each program assessment summarizes comments provided by the program office and identifies whether the program provided technical comments. AUTOMATED COMMERCIAL ENVIRONMENT (ACE) CUSTOMS AND BORDER PROTECTION (CBP) The ACE program is developing software that will electronically collect and process information submitted by the international trade community. ACE is intended to provide private and public sector stakeholders access to information, enhance the government’s ability to determine whether cargo should be admitted into the United States, and increase the efficiency of operations at U.S. ports by eliminating manual and duplicative trade processes, and enabling faster decision making. Final deployment and operational testing of ACE functionality delayed. Program plans to identify an approach to address collections functionality in March 2018. We last reported on this program in March 2018 and April 2017 (GAO-18-271, GAO-17-346SP). CBP declared a cost and schedule breach in April 2017—5 months after re-baselining the program in response to a prior breach—because of difficulties developing the collections aspect of ACE’s remaining functionality, which collects and processes duties owed on imported goods. CBP reported that its officials were not versed in the complexities of collections in the legacy system and underestimated the level of effort required to integrate collections capabilities into ACE. As a result, the program delayed final deployment of ACE functionality several times and missed the deadlines for completing the remaining milestones in its current acquisition program baseline (APB), including achieving acquisition decision event (ADE) 3 and full operational capability (FOC) by the revised dates of June 2017 and September 2017, respectively. Additional coding and testing to complete ACE development also required contract extensions that exceeded the current APB cost thresholds. The program subsequently decoupled collections from ACE’s remaining functionality to permit deployment of the other post-release capabilities—such as liquidations and reconciliation—using a phased approach between September 2017 and February 2018. In November 2017, CBP officials estimated that efforts to decouple collections from post-release functionality would be an additional $32 million in acquisition costs. CBP officials plan to cover these costs with $18 million in fiscal year 2017 carryover funding and by reprogramming $14 million from ACE disaster recovery funding. CBP is in the process of determining a path forward for collections, which is due to Department of Homeland Security (DHS) leadership by the end of March 2018. CBP then plans to update the program’s acquisition documentation, including APB and life- cycle cost estimate, by August 2018. Until then, the time frame for completing ACE’s remaining milestones and true cost of the program, including the cost to complete collections development is unknown. The program was not included in DHS’s funding plan to Congress for fiscal years 2018 to 2022 because DHS did not report operations and maintenance (O&M) funding for individual programs. CBP officials anticipate receiving approximately $535 million in O&M funding over this 5-year period. Customs and Border Protection (CBP) AUTOMATED COMMERCIAL ENVIRONMENT (ACE) When DHS leadership re-baselined ACE’s cost, schedule, and performance parameters in 2013, the program adopted an agile software development methodology to accelerate software creation and increase flexibility in the development process. As of October 2017, the ACE program office oversees 11 agile teams that conduct development and O&M activities. CBP officials said they extended the program’s agile development contracts in 2017 to permit further development of the collections function. In identifying a path forward for collections, CBP officials stated there are three main options: 1. leave collections in the legacy system, 2. continue to pursue development and deployment in ACE, or 3. move collections to a different program altogether. The program previously experienced a schedule breach in June 2016 because it delayed events to address external stakeholders’ concerns about transitioning to ACE. According to CBP officials, CBP has signed a memorandum of understanding with each of the 22 partner agencies responsible for clearing or licensing cargo that provides access to ACE. As of February 2018, 21 of the partner agencies had transitioned to ACE and the program was piloting a solution for the remaining partner. In September 2017, CBP reported that ACE continued to lack a director of testing and evaluation. CBP officials said they do not plan to fill this vacancy despite plans to conduct further testing because existing staff have successfully covered the workload and a large portion of testing has already been completed. CBP officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. CUSTOMS AND BORDER PROTECTION (CBP) The Biometric Entry-Exit Program is developing capabilities to enhance traveler identification upon departure from the U.S. at air, land, and sea ports of entries by collecting biometric data, such as fingerprints and facial recognition. The program plans to match this data to biometric data obtained from travelers upon their arrival into the U.S. to identify foreign nationals that stay in the U.S. beyond their authorized periods of admission and verify the identities of travelers leaving the U.S. CBP completed four biometric pilot programs and selected a solution for development. DHS has explored biometric exit capabilities since 2009, but was directed to expedite implementation in March 2017. GAO last reported on this program in February 2017 (GAO- 17-170). In June 2017, the Department of Homeland Security’s (DHS) Under Secretary for Management (USM) granted the Biometric Entry-Exit Program acquisition decision event (ADE) 1 approval after CBP completed several pilot initiatives to study the feasibility of proposed biometric exit solutions at air and land ports of entry. The USM also authorized the program to continue testing a pilot exit solution at Hartsfield-Jackson Atlanta International Airport and conduct technology demonstrations as needed, but directed the program to achieve ADE 2A prior to deploying a solution to the 20 U.S. airports with the most international flights. CBP officials initially planned to achieve ADE 2A approval in September 2017—the point at which the program would establish cost, schedule, and performance goals in a DHS-approved acquisition program baseline (APB)—and pursue separate ADE 2B decisions to initiate development of a biometric solution for each type of port of entry, starting with air. As of December 2017, the program had yet to conduct its ADE 2A because CBP officials have had to resolve several issues identified by the Joint Requirements Council that has delayed approval of the program’s operational requirements document (ORD). In January 2018, CBP officials said the program plans to conduct ADE 2A in February or March 2018 and is aiming for ADE 2B for the biometric air solution in December 2018. In December 2015, Congress established an account to be used for the development and implementation of the biometric entry-exit system starting in 2017. Specifically, Congress provided that half the amount collected from fee increases for certain visa applications from fiscal years 2016 through 2025—up to $1 billion—would be available to DHS until expended. In February 2017, DHS leadership approved the program to use about $73 million of this funding in fiscal year 2017 for information technology investments and programmatic and operational support, among other things. In September 2017, DHS’s Chief Financial Officer approved the program’s life-cycle cost estimate (LCCE), which CBP expects to refine as the program progresses to meet the fee-funding limit. According to CBP officials, the current funding structure poses challenges because the fees will fluctuate based on immigration rates. Customs and Border Protection (CBP) of a traveler to different sources—one technology compared the photo to the traveler’s passport upon entrance to the U.S.; the other technology compared the photo to a gallery of photos based on the outbound flight manifest during an airline’s boarding process. According to CBP officials, the facial recognition technology that matched photos during an airline’s boarding process was the most viable approach and served as the foundation for its development of the ADE 2A acquisition documents. Officials stated a similar approach may be feasible for land border crossings, but will require further planning. In January 2018, CBP officials stated they were developing a test and evaluation master plan—which will outline the developmental and operational test approach—for the biometric exit air solution. DHS’s Director, Office of Test and Evaluation will need to review and approve this plan prior to the program’s ADE 2B. Since 1996, several federal statutes have required development of an entry and exit system for foreign nationals. DHS has been exploring biometric exit capabilities since 2009 and an Executive Order issued in March 2017 directed DHS to expedite the implementation of the biometric entry-exit system. The Biometric Entry-Exit Program plans to develop a capability to match a traveler’s biometric data against data contained in existing DHS biometric data repositories— primarily the National Protection and Program Directorate’s IDENT system. DHS is in the process of replacing and modernizing IDENT through the Homeland Advanced Recognition Technology (HART) program because IDENT is at risk of failure. However, HART has experienced delays, which could affect the Biometric Entry-Exit Program’s development progress. For the air biometric solution, CBP plans to pursue a public/private partnership in which airlines and airports invest in the equipment to collect biometric data. According to CBP officials, this approach could reduce program costs and improve the passenger boarding process. In August 2017, CBP officials told GAO that several airlines have expressed interest in partnering with the program, including one that expanded CBP’s pilot of facial recognition matching for outbound flights to additional gates at the Hartsfield-Jackson Atlanta International Airport. CBP officials reported a staffing gap of 14 full time equivalent staff which the program plans to fill once partnerships with airlines are established. CBP officials stated that authorized funds are collected from visa fee increases that expire in fiscal year 2025. Beyond 2025, officials stated that additional funding will need to be appropriated or the fee increases extended to continue the program. They added that fee collections are currently below forecasted levels and may come under the current $1 billion limit. CBP officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. CUSTOMS AND BORDER PROTECTION (CBP) The border wall system is intended to prevent the illegal entry of people, drugs, and other contraband by enhancing and adding to the 654 miles of existing barriers along the U.S. southwest border. CBP plans to create a border enforcement zone between a primary barrier—such as a fence—and a secondary barrier. To establish the enforcement zone, the wall system may also include detection technology, surveillance cameras, lighting, and roads for maintenance and patrolling. CBP has evaluated prototypes for new barrier designs, but risks with planned detection technologies exist. CBP is leveraging staff and the contracting strategy from prior border fencing programs. GAO last reported on the existing Southwest border barriers in February 2017 (GAO-17-331). In April 2017, Department of Homeland Security (DHS) leadership granted CBP permission to procure barrier prototypes to inform new design standards and approved the construction of the first segment of the wall system. CBP subsequently awarded 8 task orders with a total value of over $3 million for the development of prototypes and selected San Diego as the first segment. CBP plans to replace an existing 14 miles of primary and secondary barriers in San Diego. DHS plans to use fiscal year 2017 funding for the replacement of the primary barrier, which it plans to rebuild to existing design standards. DHS has requested funding for replacement of the secondary barrier beginning in fiscal year 2018 that it plans to rebuild to new design standards once established. DHS leadership plans to approve acquisition documentation—including an acquisition program baseline (APB) and a life-cycle cost estimate (LCCE)—for each segment to determine affordability prior to authorizing construction. However, CBP officials said they do not plan to develop an APB for the San Diego segment because DHS already approved construction. In January 2018, DHS leadership approved an APB establishing cost, schedule, and performance goals for a second segment in the Rio Grande Valley (RGV), which will extend an existing barrier by 60 miles. To inform leadership’s decision, DHS headquarters conducted an independent cost estimate, which CBP adopted as the program’s LCCE. The LCCE includes costs for both the San Diego and RGV segments. However, DHS officials stated that the amounts in the LCCE are not releasable until CBP evaluates the prototypes, determines, and designs a final solution for the San Diego secondary barrier, and updates the LCCE—which is not expected to be complete until June 2018. The costs presented here are only for the RGV segment. CBP reported that construction of the RGV segment would be sufficiently funded if it receives $1.3 billion of acquisition funding in fiscal year 2018. However, CBP identified a shortfall in operations and maintenance (O&M) funding from fiscal years 2019 to 2022 that it plans to cover with existing funding from the Tactical Infrastructure program, which will be responsible for maintenance of the wall system as segments are complete. If funded, the program expects to achieve full operational capability for the RGV segment in March 2023. Customs and Border Protection (CBP) The Border Wall System Program was initiated in response to an Executive Order issued in January 2017 stating that the executive branch is to secure the southern border through the immediate construction of a physical wall on the southern border of the U.S. To expedite the acquisition planning process, CBP officials said they leveraged expertise from staff that worked on previous border fencing programs and were familiar with implementation challenges, such as land access. CBP intends to prioritize segments based on threat levels, land ownership, and geography, among other things. From fiscal years 2007 to 2015, CBP spent approximately $2.3 billion to construct pedestrian and vehicle fencing along the southwest border. CBP’s Tactical Infrastructure program is responsible for sustaining this fencing and other infrastructure—such as gates, roads, and bridges— over its lifetime. CBP plans to continue coordinating with the U.S. Army Corps of Engineers (USACE) for engineering support and for awarding and oversight of construction contracts. CBP anticipates that all contract awards issued by USACE in support of the RGV segment will be firm fixed price. If appropriations are received, the program plans to award construction contracts for the first portion of RGV in May 2018 and for the secondary barrier in San Diego in August 2018. In February 2018, CBP officials stated that staffing the program office is a challenge because funding has not yet been received. CBP officials said that existing work for the program is being handled by current CBP staff. CBP officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. INTEGRATED FIXED TOWERS (IFT) CUSTOMS AND BORDER PROTECTION (CBP) The IFT program helps the Border Patrol detect, track, identify, and classify illegal entries in remote areas. IFT consists of fixed surveillance tower systems equipped with ground surveillance radar, daylight and infrared cameras, and communications systems linking the towers to command and control centers. CBP plans to deliver or upgrade approximately 53 IFT systems across six areas of responsibility (AoR) in Arizona: Nogales, Douglas, Sonoita, Ajo, Tucson, and Casa Grande. System acceptance test completed in Douglas AoR and requirements were met. Program is adequately staffed, but simultaneous deployments in the future may have a negative impact. GAO last reported on this program in November and April 2017 (GAO-18-119, GAO-17-346SP). In December 2017, CBP declared a schedule breach of the IFT program’s current acquisition program baseline (APB) because the program did not receive the funding needed to complete planned deployments on time to achieve its full operational capability (FOC) date of September 2020. The program’s FOC date previously slipped 5 years because of delays in the initial contract award process and funding shortfalls. CBP completed IFT deployments to the Douglas AoR in June 2017 and anticipates completing deployments to the Sonoita AoR in December 2017, as scheduled. However, in September 2017, CBP officials stated that they requested—but did not receive—additional funding from the Department of Homeland Security (DHS) to address new IFT requirements, including camera upgrades and replacement of existing tower systems deployed under a legacy program. In January 2015, Border Patrol requested the program prioritize replacement of the legacy systems in the Tucson and Ajo AoRs because the technology was obsolete and more expensive to maintain than the IFT technology planned for deployment in other AoRs. Without additional funding, CBP officials stated that they would be unable to exercise the contract options for the remaining AoRs on time. In June 2017, the program updated its life-cycle cost estimate (LCCE), which is slightly less than its current APB cost thresholds. This LCCE update includes estimated costs for the new requirements. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained operations and maintenance (O&M) funding for individual programs. CBP identified $8 million in acquisition carryover funding for fiscal year 2018 and officials anticipate receiving $126 million in O&M funding to cover $100 million in O&M costs over the next 5 years. The program plans to submit a revised APB to DHS leadership by June 2018. However, the FOC date may be further delayed because of land access issues. CBP officials told GAO that they have not yet reached an agreement with the Tohono O’odham Nation—a sovereign Native American Nation—to access tribal lands, which these officials said is necessary for the construction of IFTs in the Ajo and Casa Grande AoRs. 10/15 Initial operational capability (Nogales) Customs and Border Protection (CBP) INTEGRATED FIXED TOWERS (IFT) When CBP initiated the IFT program, it decided to procure a non-developmental system, and it required that prospective contractors demonstrate their systems prior to CBP awarding the contract. The program awarded the contract to EFW, Inc. in February 2014, but the award was protested. GAO sustained the protest and CBP had to reevaluate the offerors’ proposals before it again decided to award the contract to EFW, Inc. As a result, EFW, Inc. could not initiate work at the deployment sites until fiscal year 2015. According to CBP officials, the number of IFT systems deployed to a single AoR is subject to change based on assessments by the Border Patrol. DHS leadership directed CBP to develop a comprehensive border plan in October 2016 that includes IFT capabilities and—when preparing for the last budget cycle—the program estimated costs for expansion to the southwest border beginning in fiscal year 2019. In September 2017, CBP officials told GAO that they did not have any current staffing gaps. However, CBP officials added that if the program receives full funding and reaches an agreement with the Tohono O’odham Nation to initiate IFT deployments to the Ajo and Casa Grande AoRs, while concurrently deploying capability to the Sonoita and Tucson sectors, they will be short on government and contracted staff. CBP officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. MEDIUM LIFT HELICOPTER (UH-60) CUSTOMS AND BORDER PROTECTION (CBP) UH-60 is a medium-lift helicopter that CBP uses for law enforcement and border security operations, air and mobility support and transport, search and rescue, and other missions. CBP’s UH-60 fleet consists of 20 aircraft acquired from the U.S. Army in three different models. CBP previously acquired 4 modern UH-60M aircraft and converted 6 of its older 16 UH-60A aircraft into more capable UH-60L models. CBP is replacing the remaining 10 UH-60A with reconfigured Army HH-60L aircraft. CBP test agent and the Army completed testing of reconfigured HH-60L prototype. CBP has initiated efforts to acquire additional converted HH-60L aircraft from the Army. GAO last reported on this program in April 2017 (GAO-17-346SP). The program breached the cost and schedule goals in its acquisition program baseline (APB) and, as of December 2017, CBP officials stated they were in the process of developing the breach notification required under the Department of Homeland Security’s (DHS) acquisition policy. In its annual life-cycle cost estimate (LCCE) update, the program shifted some operations and maintenance (O&M) costs to acquisitions to be consistent with DHS’s new appropriation structure. For example, the program shifted costs for recurring upgrades from O&M to acquisition because these upgrades require development and production. As a result, the program’s updated acquisition cost estimate exceeded the APB acquisition cost threshold, which constitutes a cost breach under DHS’s acquisition policy. CBP officials stated that they did not initially declare a cost breach because the program’s total LCCE was within the APB threshold. The program also did not hold its acquisition decision event (ADE) 3 by the APB deadline of September 2017. The ADE 3 is intended to approve the transfer of CBP’s remaining UH-60A aircraft for reconfigured Army HH60-L aircraft based on an evaluation of a reconfigured prototype. According to CBP officials, the program did not complete the required acquisition documentation by the ADE 3 deadline, in part, because DHS leadership directed CBP to develop a comprehensive border plan in October 2016 that includes UH-60 capabilities. It is unclear when the ADE 3 will occur because, as of December 2017, several documents were pending validation by the Joint Requirements Council. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained O&M funding for individual programs. In addition, CBP officials previously told GAO that UH-60 O&M is funded through a separate, central funding account for all of CBP’s air and marine assets. CBP officials stated that the projected acquisition funding gap in fiscal years 2019 and 2020 is primarily for replacing obsolete parts that were previously considered O&M. According to these officials, the Army conducts an annual obsolescence study that will help CBP identify and prioritize replacements across the UH-60 fleet based on available funding levels. Customs and Border Protection (CBP) MEDIUM LIFT HELICOPTER (UH-60) CBP previously acquired UH-60 as a part of its Strategic Air and Marine Program (StAMP). In July 2016, DHS leadership designated UH-60 as a separate and distinct major acquisition program. CBP initially planned to convert all 16 of its UH-60A aircraft into UH-60L models, but changed its strategy once it learned the Army planned to divest several HH-60L aircraft that could more easily be converted into UH-60L aircraft for CBP missions. CBP officials anticipated the new strategy could reduce the program’s costs by an estimated $70 million, accelerate its schedule, and result in newer aircraft since the Army’s HH-60L airframes had fewer operating hours than CBP’s existing UH-60A aircraft. In September 2017, CBP officials told GAO they had initiated efforts to acquire additional HH-60L aircraft by conducting a study of current capability gaps and drafting a mission need statement. As of September 2017, program officials confirmed that they maintain a consolidated program office where the same staff from StAMP continue to support all remaining acquisitions, including the UH-60. However, these officials stated that they plan to realign staff to a dedicated asset over time. Program officials also stated that the program has hired a dedicated cost estimator and would like to hire additional staff to focus on procuring spare parts and common component issues, such as radio replacements, for CBP’s air and marine assets. CBP officials reiterated that the changes in acquisition costs were primarily a result of cost realignment and that the program’s total life-cycle cost is still within the initial APB LCCE goals. CBP officials also stated that—to supplement Army test data—the program’s OTA participated in the flight tests and will provide a formal report on the results. MULTI-ROLE ENFORCEMENT AIRCRAFT (MEA) CUSTOMS AND BORDER PROTECTION (CBP) MEA are fixed-wing, multi-engine aircraft that can be configured to perform multiple missions including maritime, air, and land interdiction, as well as signals detection to support law enforcement. The current MEA configuration is equipped with marine search radar and an electro-optical/infrared sensor to support maritime and land surveillance and airborne tracking missions. MEA will replace CBP’s fleet of aging C-12, PA-42, and BE-20 aircraft. Testing of new configuration planned for May 2018, but requirements not yet defined. Began retrofitting accepted MEA with new mission system in fiscal year 2017. GAO last reported on this program in April 2017 (GAO-17- 346SP). According to CBP officials, the program is on track to meet the cost and schedule goals in its current acquisition program baseline (APB) for 16 maritime interdiction MEA and is actively pursuing additional aircraft. In April 2016, CBP developed a report that identified capability needs in three mission areas and proposed increasing the program’s total to 38 aircraft by adding 13 air and 6 land interdiction MEA, and 3 signals detection MEA. The Joint Requirements Council endorsed CBP’s findings, but recommended CBP develop a number of requirements documents—including an operational requirements document—to fully validate the findings. As of September 2017, CBP officials told GAO they were in the process of updating these documents to focus on air interdiction capabilities—the next MEA configuration. These officials stated that completing these documents has been delayed, in part, because Department of Homeland Security (DHS) leadership directed CBP to develop a comprehensive border plan in October 2016 that includes MEA capabilities. Despite not yet completing all the updated documents, DHS leadership approved CBP’s request to procure MEA 17 in September 2017 after the congressional conferees agreed to an additional aircraft beyond DHS’s budget request. CBP anticipates delivery of MEA 17 by September 2018, which is within the program’s full operational capability (FOC) date. However, if the program receives approval to acquire additional aircraft, the FOC date will be extended. The program completed an annual life-cycle cost estimate update, which exceeds the program’s current APB cost thresholds, because it reflects costs for all 38 aircraft, among other reasons. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained operations and maintenance (O&M) funding for individual programs. In addition, CBP officials previously told GAO that MEA’s O&M is funded through a separate, central funding account for all of CBP’s air and marine assets. In September 2017, CBP officials said that the program was fully funded for 17 aircraft but had some affordability challenges with spare parts, which they are working with CBP and DHS headquarters to address. Customs and Border Protection (CBP) MULTI-ROLE ENFORCEMENT AIRCRAFT (MEA) CBP is replacing the mission system processor on the MEA with a system used by the U.S. Navy and U.S. Coast Guard that is intended to enhance operator interface and sensor management, as well as replace obsolete equipment. CBP’s OTA tested a prototype of the processor during an operational assessment in July 2015. The OTA found that the MEA had resolved issues found during prior testing, but also made 29 additional recommendations and findings to improve the aircraft and new mission system’s effectiveness. DHS’s Director, Office of Test and Evaluation (DOT&E) concurred with the OTA’s findings. CBP previously acquired MEA as a part of its Strategic Air and Marine Program (StAMP). In July 2016, DHS leadership designated MEA as a separate and distinct major acquisition program. CBP initially planned to procure 50 MEA and awarded the first production contract in September 2009. However, the aircraft did not perform well during testing. In October 2014, DHS leadership said CBP could not procure or accept transfer of additional MEA without approval. CBP procured 12 aircraft under the initial contract and—with DHS approval—CBP awarded a new indefinite delivery, indefinite quantity contract in September 2016 for 1 base year and four 1-year options to support procurement of additional aircraft. In December 2017, CBP officials said the program had received 12 aircraft and awarded contracts for 5 more. According to program officials, MEA 13-16 will be delivered with the new mission system and CBP began retrofitting previously delivered aircraft in fiscal year 2017. As of September 2017, program officials confirmed that they maintain a consolidated program office where the same staff from StAMP continue to support all remaining acquisitions, including MEA. However, these officials stated that they plan to re-align staff to a dedicated asset over time. Program officials also stated that the program has hired a dedicated cost estimator and would like to hire additional staff to focus on procuring spare parts and common component issues, such as radio replacements, for CBP’s air and marine assets. CBP officials stated that delays in receiving approval of the program’s requirements documents may pose a risk to exercising options for additional MEA on an existing contract, which could stop production and increase contract costs associated with procuring future aircraft. CBP officials added that air and marine requirements officers continue to produce documentation requested by the Joint Requirements Council to provide sufficient context for the mission need and border security. CBP officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. CUSTOMS AND BORDER PROTECTION (CBP) The NII Systems Program supports CBP’s interdiction of weapons of mass destruction, contraband such as narcotics, and illegal aliens being smuggled into the United States, while facilitating the flow of legitimate commerce. CBP officers use large- and small-scale NII systems at air, sea, and land ports of entry; border checkpoints; and international mail facilities to examine the contents of containers, railcars, vehicles, baggage, and mail. CBP initiated efforts for future NII requirements and procurements. 66 percent staffing gap contributed to delays in NII deployments. GAO last reported on this program in April 2017 (GAO-17-346SP). The NII Systems Program is on track to meet its approved schedule and cost goals. The estimates in the program’s annual life-cycle cost estimate (LCCE) update continued to decrease overall compared to its approved acquisition program baseline (APB) cost thresholds. Specifically, compared to the prior year’s estimate, the program’s acquisition costs decreased by $96 million and operations and maintenance (O&M) costs increased by $22 million. However, the LCCE update only estimated costs through fiscal year 2026—9 years short of the program’s final year. The LCCE primarily decreased because of a reduction of 1,977 planned additional and replacement NII systems. CBP officials said fewer large- and small-scale systems are needed because some systems have longer estimated lives than expected, and systems procured have better capability. CBP officials do not anticipate that the reduction in quantities will have an adverse effect on operations because they stated that the new systems can provide dual purpose capabilities (i.e., one system can replace multiple separate systems). The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained O&M funding for individual programs. CBP officials anticipate receiving approximately $605 million of O&M funding over this 5-year period to cover about $626 million in estimated O&M costs, which includes $100 million to operate and maintain radiation detection equipment acquired by the Domestic Nuclear Detection Office. These officials also identified $37 million in carryover funding to cover the remaining $21 million of O&M estimated costs. However, the program is projected to have a $266 million acquisition funding gap from fiscal years 2018 to 2022.The program has a plan to address funding shortfalls but, according to CBP officials, it has not yet needed to implement the strategies in this plan because of several factors, including cost reductions achieved through combined life-cycle contracts and lower-than-expected actual technology costs in fiscal year 2016. Customs and Border Protection (CBP) trucks as they are driven through the inspection portals—low dose X-ray to inspect the truck cab and high dose X-ray to inspect the cargo trailer. In March 2017, the Joint Requirements Council validated a capability analysis report that assessed current capability gaps in NII operations to assist with identifying potential upgrades to existing systems and developing requirements for future systems. According to program officials, CBP plans to review and update, as necessary, the mission need statement in fiscal year 2018. Additionally, program officials are preparing a consolidated acquisition plan for future procurements. These officials said CBP has not yet determined whether future procurements would be included into the current NII Systems Program of record or constitute a new acquisition program. CBP’s ability to successfully execute the existing NII Systems Program and plan for future efforts may be at risk because of understaffing. As of January 2018, the NII Systems Program continued to face a staffing gap of approximately 66 percent, including critical vacancies such as the acquisition program manager and a logistics program manager. Officials also noted that a lack of adequate personnel to procure, test, and deploy NII systems forces the program to prioritize its acquisitions, which can result in delays of NII deployments and testing efforts. For example, one manufacturer increased its output rate of NII systems, but the program did not have the staff to accept the systems at the increased rate. Officials anticipate the program may remain understaffed until CBP completes a reorganization that started more than a year ago, in which acquisition programs are realigned from a mission-support office to their operational entity. CBP officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. REMOTE VIDEO SURVEILLANCE SYSTEM (RVSS) CUSTOMS AND BORDER PROTECTION (CBP) The RVSS program helps the Border Patrol detect, track, identify and classify illegal entries across U.S borders. RVSS consists of daylight and infrared video cameras mounted on fixed towers and buildings with communications systems that link to command and control centers. From 1995 to 2005, CBP deployed approximately 310 RVSS towers along the U.S. northern and southern borders, and initiated efforts to upgrade legacy RVSS towers in Arizona in 2011. Program does not plan to conduct additional operational testing on future deployments. Once funded, program plans to award a new contract for deployments in sectors along the southwest border. GAO last reported on this program in November 2017 (GAO-18-119). In April 2016, Department of Homeland Security (DHS) leadership elevated RVSS from a level 3 program—which focused on upgrading legacy RVSS in Arizona—to a level 1 program after approving CBP’s plan to expand deployments to the Rio Grande Valley (RGV) sector and adding an additional 6 sectors along the southwest border. At this time, DHS leadership approved the program to move forward with deployments to two RGV stations, which can be completed as options under the program’s existing contract. However, the program was required to re-baseline to account for its expanded scope and conduct an acquisition decision event (ADE) to obtain approval for additional deployments. As of January 2018, the program had not yet conducted its ADE or obtained DHS approval for an acquisition program baseline (APB) that established cost, schedule, and performance goals for the expanded program. In September 2017, CBP officials told us that they had drafted the APB and other required documentation, such as a life-cycle cost estimate (LCCE), but were unsure when the ADE would occur because the program had not received funding for the additional deployments. In addition, the ADE may have been delayed because DHS leadership directed CBP to develop a comprehensive border plan in October 2016 that includes RVSS capabilities. In September 2017, DHS leadership approved the RVSS’s revised LCCE which totaled nearly $4 billion for all program costs from fiscal years 2011 through 2042, including expansion along the southwest border and new initiatives such as a pilot for relocatable RVSS towers. DHS conducted an independent cost estimate for the program, which DHS cost estimating officials stated was within 2 percent of the program’s LCCE. RVSS was not included in DHS’s funding plan to Congress for fiscal years 2018 to 2022 because it had not yet been elevated to a level 1 program at the time the plan was developed. CBP officials stated that the program has received acquisition funding to cover the approved RGV deployments. However, CBP officials told GAO that the program may also assume responsibility for maintaining all legacy RVSS, but has not received adequate operations and maintenance funding to do so. Customs and Border Protection (CBP) REMOTE VIDEO SURVEILLANCE SYSTEM (RVSS) In July 2013, CBP awarded a firm fixed-price contract for a commercially available, non-developmental system. This contract covered the program’s initial scope to deploy upgraded RVSS in Arizona and two stations within the RGV sector, which can be completed as options. According to CBP officials, the program will need to award a new contract to cover expansion to the remaining six sectors along the southwest border. In September 2017, CBP officials said that the request for proposals for the new contract had been drafted but it cannot be released until the program receives funding. CBP officials told GAO that RVSS is coordinating with CBP’s Border Wall System Program on some planned deployments within the RGV sector. For example, CBP is considering moving 2 of the planned RVSS towers to be co-located with the planned barrier, which officials stated may provide better surveillance. If the Border Wall System Program does not receive funding, CBP officials said the towers will be placed in the originally planned locations. CBP officials stated that the RVSS program requires additional staff for contracting activities, maintenance activities for legacy RVSS, and for relocatable tower pilot deployments. To mitigate the staffing gap, CBP officials said they prioritize responsibilities of current personnel to meet program execution needs. CBP officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. CUSTOMS AND BORDER PROTECTION (CBP) The TACCOM program is intended to upgrade land mobile radio infrastructure and equipment to support approximately 95,000 users at CBP and other federal agencies. It is replacing obsolete radio systems with modern digital systems across various sectors located in 19 different service areas, linking these service areas to one another through a nationwide network, and building new communications towers to expand coverage in 5 of the 19 service areas. Issues related to security requirements have delayed full operational capability by more than a year. Program is being re-organized under Border Patrol, but still faces staffing challenges. GAO last reported on this program in April 2017 (GAO-17-346SP). In November 2017, Department of Homeland Security (DHS) leadership re-baselined the TACCOM program, removing it from breach status after the program experienced a schedule slip and cost growth. In July 2017, CBP officials notified DHS leadership that the program would not achieve full operational capability (FOC) as planned due to issues related to federal information security requirements. The program now plans to achieve FOC by March 2019—more than a year later than its initial acquisition program baseline (APB) deadline. According to CBP officials, FOC will include planned upgrades to the San Diego system, which requires transitioning management of the legacy system from the Department of Justice to DHS. In August 2017, CBP officials stated that both agencies were reviewing an agreement with plans to complete the transition in fiscal year 2018. CBP officials stated that the program realized it would exceed its initial APB cost thresholds as it was developing its annual life-cycle cost estimate (LCCE) update and subsequently submitted a revised LCCE for DHS leadership approval. The program’s costs primarily grew because of increases in costs for contractor labor and support for facilities and infrastructure. CBP officials said the program’s initial estimates were immature; however, DHS leadership approved the initial LCCE in December 2015—4 years after the program began sustaining capabilities. DHS’s Chief Financial Officer (CFO) approved the program’s revised LCCE in November 2017, but noted that the program’s estimate exceeded its available funding and requested that the program address the affordability gap before it was re-baselined. CBP officials said that they are conducting an affordability analysis, which they anticipate will be completed by March 2018. Nevertheless, DHS leadership approved the program’s re-baseline in November 2017. CBP officials subsequently identified errors in the approved APB cost threshold tables and provided revised amounts, which are presented here. The program was not included in DHS’s funding plan to Congress for fiscal years 2018 to 2022 because DHS did not report operations and maintenance (O&M) funding for individual programs. CBP officials anticipate receiving approximately $120 million in O&M funding over this 5-year period. Customs and Border Protection (CBP) CBP officials told GAO that in January 2018, the program will move from a mission support office to a joint program office under Border Patrol as a part of CBP’s reorganization that started more than a year ago. The goal of this move is to make CBP land mobile radio capabilities seamless by combining the mission critical voice functions of Air and Marine Operations, the Border Patrol, and the Office of Field Operations—the TACCOM program’s primary customers—under one organizational leader, the Border Patrol Chief. CBP officials anticipate that the current TACCOM program structure will remain in place after this move with the exception of the program’s engineers, which will move to CBP’s Office of Information and Technology but be assigned to support TACCOM full time. In August 2017, CBP officials told GAO they were in the process of hiring staff to fill the program’s vacant positions. They added that the fiscal year 2019 budget contains plans for additional infrastructure enhancements, which will require technical staff to assist in the planning and execution of these efforts and may put additional strain on the program’s limited government technical staff. They noted that the hiring and retention of qualified land mobile radio engineers and information technology technical staff is a challenge because of competition with the private sector, among other factors. In addition to maintenance of the CBP Land Mobile Radio System that provides critical communication needs for CBP agents and officers protecting U.S. borders, CBP officials stated the TACCOM program is providing infrastructure, such as building an engineering lab to facilitate design, development, test, and evaluation activities, to support improvements in CBP’s current and future Land Mobile Radio Systems. CBP officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. CUSTOMS AND BORDER PROTECTION (CBP) TECS (not an acronym) is a law-enforcement information system that has been in place since the 1980s and helps CBP officials determine the admissibility of persons entering the United States at border crossings, ports of entry, and prescreening sites located abroad. CBP initiated efforts to modernize TECS to provide users with enhanced capabilities for accessing and managing data. Immigration and Customs Enforcement has a separate TECS Modernization program. System operationally effective and suitable, but cybersecurity testing needed. CBP working to address and prevent major system outages. GAO last reported on this program in April 2017 (GAO-17-346SP). In July 2017, Department of Homeland Security (DHS) leadership granted the program acquisition decision event (ADE) 3 approval, but required CBP to conduct follow-on operational test and evaluation (OT&E) before declaring full operational capability (FOC). This is more than a 2-year delay from CBP’s initial FOC date and a 9-month delay from its most recent revised FOC date. DHS approved the fourth version of the program’s acquisition program baseline (APB) in July 2016. In this APB, CBP split FOC into two separate operational capability milestones at its data centers to better reflect the program’s activities. CBP delivered operational capability at the primary data center in Decemberas scheduled—which provides redundant TECS access to minimize downtime during system maintenance or unscheduled outages. However, not all test results were available in time for the program’s ADE 3 decision, which contributed to DHS leadership’s decision to delay declaring FOC. 2016, which included transitioning all TECS users to the modernized system. CBP delivered operational capability at the secondary data center in June 2017—The program updated its life-cycle cost estimate (LCCE) for ADE 3, which is within its current APB cost thresholds. However, the LCCE only included costs through fiscal year 2021—7 years short of DHS’s guidance that states program cost estimates should cover at least 10 years from the FOC date. Nevertheless, DHS granted the program ADE 3 approval without an understanding of the program’s full life-cycle costs, as required by its acquisition policy. CBP officials plan to update the LCCE by the end of calendar year 2018 to include costs for future years and other items, such as costs associated with follow-on OT&E and moving the data centers to a cloud environment—a CBP-wide initiative. The program was not included in DHS’s funding plan to Congress for fiscal years 2018 to 2022 because DHS did not report operations and maintenance (O&M) funding for individual programs. CBP officials anticipate receiving approximately $205 million in O&M funding over the next 4 years and have identified carryover for each year. However, CBP officials said there may be a small funding gap starting in fiscal year 2020, but they expect to achieve savings by migrating the data centers to a cloud environment. Customs and Border Protection (CBP) Since the program has completed development, CBP is focused on ensuring that the modernized TECS system works as intended by addressing operational issues as they are identified. For example, on January 2, 2017, a primary TECS Modernization application experienced a major outage that resulted in long airport delays. In August 2017, CBP officials said they continually monitor system health through a 24/7 operations center and have established a group dedicated to addressing the issues related to the January 2, 2017, outage. In September 2017, DHS’s Office of Inspector General (OIG) found that nearly 100 outages, periods of latency, or degraded service were reported for three TECS Modernization applications between June 2016 and March 2017. The OIG also found that CBP’s monthly reports on TECS system availability did not include periods of slowness or service interruptions that were caused by external factors. For example, the January 2, 2017, incident was identified in CBP outage reports, but was not captured in the monthly report because it was caused by a change to an external feed to the TECS system. CBP officials clarified that the monthly reports only account for interruptions that result in a full loss of operations for all TECS system users. The OIG recommended that CBP develop a plan to address factors that contributed to challenges regarding availability of primary traveler screening applications, among other things. CBP concurred with the recommendations. On January 1, 2018, the TECS system experienced another major outage that caused long airport delays; CBP officials said this incident is under review. CBP officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. LOGISTICS SUPPLY CHAIN MANAGEMENT SYSTEM (LSCMS) FEDERAL EMERGENCY MANAGEMENT AGENCY (FEMA) LSCMS is a computer-based tracking system that FEMA officials use to track shipments during disaster-response efforts. It is largely based on commercial-off-the- shelf software. FEMA initially deployed LSCMS in 2005, and initiated efforts to enhance the system in 2009. According to FEMA officials, LSCMS can identify when a shipment leaves a warehouse and the location of a shipment after it reaches a FEMA staging area near a disaster location. FEMA now anticipates reaching full operational capability by June 2019, up to 6 months late. Recent testing shows progress, but additional operational testing delayed to May 2018. GAO last reported on this program in April 2017 (GAO-17-346SP). In November 2017, Department of Homeland Security (DHS) leadership approved a revised acquisition program baseline (APB) after the LSCMS program experienced a schedule breach. In September 2017, FEMA officials notified DHS leadership that it would not complete all required activities—including follow-on operational test and evaluation (OT&E)—to achieve acquisition decision event (ADE) 3 and full operational capability (FOC) by its initial APB dates of September 2018 and December 2018, respectively. According to FEMA officials, the delay was primarily caused by the need to deploy LSCMS program personnel in support of response and recovery efforts during the 2017 hurricane season. The program now plans to achieve FOC by June 2019—up to 6 months later than initially planned. DHS leadership authorized LSCMS to resume all development and acquisition efforts in March 2016 after a nearly 2-year program pause following program management issues. In October 2017, FEMA officials told GAO that they had completed several development efforts—such as integration with DHS’s asset management system—and were in the process of adding Electronic Data Interchange (EDI) to allow LSCMS to interface with its partners’ information systems. The program’s annual life-cycle cost estimate (LCCE) update continued to be within its APB cost thresholds. However, the program’s APB thresholds are not adjusted to account for risk, which increases the chance that the program could experience a cost breach. As of November 2017, FEMA officials did not anticipate that its schedule delays would lead to a cost breach. Federal Emergency Management Agency (FEMA) LOGISTICS SUPPLY CHAIN MANAGEMENT SYSTEM (LSCMS) The LSCMS program previously experienced significant execution challenges because of poor governance. FEMA initially deployed the enhanced LSCMS in 2013 without DHS leadership approval, a DOT&E letter of assessment, or a DHS-approved APB documenting the program’s costs, schedule, and performance parameters, as required by DHS’s acquisition policy. DHS’s Office of Inspector General also found that neither DHS nor FEMA leadership ensured the program office identified all mission needs before selecting a solution. In response, DHS leadership paused all LSCMS development efforts in April 2014 until the program addressed these issues, among others. FEMA subsequently completed an analysis of alternatives and developed an APB based on this assessment. DHS leadership approved the APB in December 2015 and authorized FEMA to resume all LSCMS development and acquisition efforts in March 2016. In October 2017, FEMA officials told GAO that the LSCMS program had minimal staffing shortages and was working to recruit additional staff. Officials previously attributed the program’s governance and testing challenges, in part, to staffing shortages and we previously found that it only had 7 of the 22.5 full time equivalents it needed in fiscal year 2014. Although the program has obtained more staff since then, FEMA officials noted in October 2017 that during disasters—such as 2017 hurricanes Harvey, Irma, and Maria—LSCMS program personnel are deployed to support response and recovery efforts, which leave program positions vacant for the duration of the deployment. FEMA officials stated that during the response to hurricanes Harvey, Irma and Maria in 2017, LSCMS processed supply chain transactions that exceeded the total number of transactions from the preceding 12 years—which includes the response to Hurricane Katrina. They added that the program provided support for nearly 130 million meals in 2017 compared to a total of approximately 84 million from the 12 previous years. FEMA officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. IMMIGRATION AND CUSTOMS ENFORCEMENT (ICE) Since the 1980s, TECS (not an acronym) has provided case management, intelligence reporting, and information sharing capabilities to support ICE’s mission to investigate and enforce border control, customs, and immigration laws. ICE initiated efforts to modernize TECS in 2009 to replace aging functionality and provide end users with additional functionality to meet mission needs. Customs and Border Protection (CBP) executes a separate TECS Modernization program. Conducted additional testing of a revised key performance parameter and cybersecurity. Program has improved integration with external systems. GAO last reported on this program in April 2017 (GAO-17-346SP). In November 2017, Department of Homeland Security (DHS) leadership approved a revised life-cycle cost estimate (LCCE) and acquisition program baseline (APB) in preparation for the program’s acquisition decision event (ADE) 3 following deployment of final functionality. According to ICE officials, the program completed deployment of full operational capability (FOC) functionality in August 2017—4 months earlier than initially planned. FOC functionality included enhancements to case management capabilities, such as improved system search capabilities. The functionality was deployed in conjunction with enhancements and fixes for initial operational capability (IOC) functionality. The program achieved IOC in June 2016, which entailed delivering 80 percent of the modernized TECS functionality and successfully transitioning ICE off the legacy system. The overall cost thresholds in the current APB increased compared to the program’s prior APB from July 2016. Specifically, the acquisition cost threshold decreased by $14 million and the operations and maintenance (O&M) cost threshold increased by $147 million. These costs changed for various reasons, such as the following: The acquisition cost threshold decreased when ICE included actual costs through fiscal year 2016 and accounted for funding shortfalls. ICE officials told GAO that the program experienced a funding shortfall in fiscal year 2017 that led it to adjust spending under multiple contracts and shift some costs to fiscal year 2018. The O&M cost threshold increased when ICE extended the estimate from fiscal years 2024 to 2028 and continued contractor and systems engineering support for an additional 11 years. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained O&M funding for individual programs. ICE officials anticipate receiving approximately $94 million in O&M funding to cover an estimated $105 million in O&M costs over this 5-year period. ICE officials said that they are pursuing strategies to reduce future O&M costs, such as awarding a competitive contract in March 2018 for O&M activities and any future enhancements. ICE officials continue to work closely with CBP to provide users access to various systems through the modernized TECS system. The program previously worked to resolve technical problems with CBP support services that emerged during final integration testing of the ICE and CBP modernized TECS systems, which contributed to a 3-month delay in achieving IOC. Users reported during initial OT&E that the modernized ICE TECS system was an improvement over the legacy system but they requested better integration with external systems, such as CBP’s Seized Assets and Case Tracking System (SEACATS), which they use to determine the disposition of seized assets for case management and reporting purposes. According to ICE officials, CBP subsequently decided to modernize SEACATS. ICE officials stated that they have coordinated closely with CBP to integrate the two modernized systems and ensure un-interrupted access to SEACATS for TECS users. For example, ICE developed a workaround so that TECS users maintain access to the latest seizure data available from the modernized SEACATS. ICE officials added that they continue to make improvements in interfaces with other external systems as prioritized by end users. In July 2017, ICE reported that the program was fully staffed. ICE officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. CONTINUOUS DIAGNOSTICS AND MITIGATION (CDM) NATIONAL PROTECTION AND PROGRAMS DIRECTORATE (NPPD) The CDM program aims to strengthen the cybersecurity of the federal government’s networks at more than 65 participating civilian agencies by providing tools and dashboards that continually monitor and report on network vulnerabilities. Tools are delivered in four phases: phase 1 and 2 tools report vulnerabilities in hardware and software, and user access controls, respectively; phase 3 tools will report on efforts to prevent attacks; and phase 4 tools will provide encryption to protect network data. Program revised its key performance parameters and test and evaluation master plan as a part of its rebaseline. Program plans to change its acquisition strategy and continues to face workforce challenges. GAO last reported on this program in April 2017 (GAO-17-346SP). In June 2017, Department of Homeland Security (DHS) leadership re-baselined the CDM program for the third time to approve initiating development of phase 3 and to address challenges encountered during phase 1. Specifically, contractors previously found large gaps—ranging from 19 to 384 percent—in the actual number of devices needing phase 1 tools than what was originally reported by 12 agencies. The operations and maintenance (O&M) cost thresholds increased by $631 million when the program shifted some potential acquisition costs to beThe program’s new acquisition program baseline (APB) modified the program’s cost, schedule, and performance parameters. For example: consistent with DHS’s new appropriation structure, among other things. The O&M cost thresholds previously decreased by $1.2 billion, in part, because DHS leadership determined the program would only fund CDM tools for the first 2 years after deployment. The acquisition costs did not increase despite phase 1 challenges, in part, because coverage for the U.S. Postal Service— The program’s full operational capability (FOC) date slipped almost 4 years after which had the largest gap in estimated devices—will no longer be funded by the CDM program. it was redefined from deployment of phase 1-3 tools at 5 agencies to the availability of these tools to all participating agencies. However, the program’s costs will increase and its FOC date may slip further once the program establishes goals for phase 4. NPPD officials said they were unable to complete planning efforts for phase 4 in time to incorporate it into the most recent APB revision and, therefore, plan to re-baseline the CDM program again in 2018. The CDM program identified a potential acquisition affordability gap in fiscal year 2018 based on its revised life-cycle cost estimate, which it addressed by adjusting the phase 3 schedule to shift some acquisition costs out to fiscal year 2020. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained O&M funding for individual programs. However, the program anticipates receiving approximately $281 million in O&M funding over the 5-year period. 12/16 Phase 1 initial operational capability (IOC) National Protection and Programs Directorate (NPPD) CONTINUOUS DIAGNOSTICS AND MITIGATION (CDM) The CDM program updated its acquisition plan as a part of its re-baselining efforts, which reflects a change in strategy for procuring CDM tools and integration services for participating agencies through the General Services Administration (GSA). Previously, the CDM program issued task orders for these tools and services through blanket purchase agreements established under vendors’ GSA Federal Supply Schedule contracts. These agreements are set to expire in August 2018. Going forward, the program plans to use an existing GSA government-wide acquisition contract—known as Alliant—to obtain CDM tools and services. According to NPPD officials, the new acquisition strategy is intended to provide greater flexibility in contracting for current capabilities and to support future capabilities. It will also allow participating agencies to order additional CDM-approved products or services from GSA’s schedule for information technology equipment, software, and services; however, as of September 2017, NPPD officials stated they were in the process of determining how this process will work. NPPD officials said that the program continues to face workforce challenges related to managing the program’s change in contracts and planning for phase 4. In February 2018, NPPD officials stated that they had on-boarded 5 staff to help address the program’s reported fiscal year 2017 gap of 16 full time equivalents. They noted that another 5 candidates were in the hiring process and that NPPD continues to work with officials from DHS’s Office of the Chief Security Officer to reduce continued challenges in onboarding new staff due to the lengthy security clearance process. In addition to activities outlined in this assessment, NPPD officials stated that the CDM program continues to manage its budget to ensure program costs match available funding, and is leveraging the collective buying power of federal agencies and strategic sourcing to achieve government cost savings on CDM products. NPPD officials also stated that, as of December 2017, CDM has deployed agency dashboards to 23 agencies and was conducting and testing information exchanges of data between agency dashboards and the federal dashboard. HOMELAND ADVANCED RECOGNITION TECHNOLOGY (HART) NATIONAL PROTECTION AND PROGRAMS DIRECTORATE (NPPD) HART will replace and modernize the Department of Homeland Security’s (DHS) legacy biometric identification system—known as IDENT—which shares information on foreign nationals with U.S. government and foreign partners to facilitate legitimate travel, trade, and immigration. NPPD plans to develop HART in four increments: increments 1 and 2 will replace and enhance IDENT functionality; increments 3 and 4 will provide additional biometric services, as well as a web portal and new tools for analysis and reporting. Key performance parameters will be demonstrated as capability is developed. Program has developed mitigation plans to address workforce risks. GAO last reported on this program in April 2017 (GAO-17-346SP). In June 2017, NPPD declared a schedule breach when it determined the HART program would not be able to meet its initial acquisition program baseline (APB) milestones. DHS leadership approved the program’s APB in April 2016 and authorized the program to initiate development efforts for increments 1 and 2 in October 2016. NPPD officials attribute the schedule slip to multiple delays in awarding the contract for increments 1 and 2 as a result of issues with the request for proposals (RFP). The program released the RFP in February 2017 and awarded the contract in September 2017—approximately 9 months later than NPPD officials had planned. However, the program experienced additional delays after a bid protest to the contract award was filed with GAO in October 2017. GAO subsequently denied the protest and NPPD officials said the program plans to initiate work with the contractor in March 2018. HART initially planned to achieve initial operational capability (IOC) with the deployment of increment 1 in December 2018, at which point program officials anticipated beginning to transition users from IDENT to HART. However, it is unclear when this will now occur, which is a significant challenge because IDENT is at risk of failure and may be unable to fully support requirements related to new programs— such as Customs and Border Protection’s Biometric Entry-Exit. As a result, delays in HART could contribute to delays in other DHS acquisition programs. The program updated its life-cycle cost estimate (LCCE) in June 2017 to inform the budget process. This LCCE is within its current APB cost thresholds, but does not account for the contractor’s solution. The program plans to update its LCCE and other acquisition documentation, such as its APB, after initiating work with the contractor. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained operations and maintenance (O&M) funding for individual programs. However, the program anticipates receiving approximately $1.3 billion in O&M funding to cover $1.5 billion in O&M costs. NPPD officials explained that the current O&M cost estimate includes costs for maintaining IDENT. Future LCCE updates will reflect delivery of services through HART, which NPPD officials anticipate will be more cost effective. National Protection and Programs Directorate (NPPD) HOMELAND ADVANCED RECOGNITION TECHNOLOGY (HART) NPPD officials told GAO they are currently planning for increments 3 and 4 and plan to refine the cost, schedule, and performance goals for these increments in its next APB. NPPD plans to pursue a separate contract for the development and delivery of increments 3 and 4. However, the program will require DHS leadership approval prior to initiating these development efforts. In September 2017, NPPD officials told GAO they had hired two staff and planned to hire additional staff to address the program’s staffing gap of 5.5 full time equivalents. In response to DHS leadership’s direction, the program coordinated with DHS’s Chief Technology Officer to assess the skills and functions of staff necessary to execute the program and to develop the HART staffing plan. In its June 2017 staffing plan, the program identified workforce risks, including the potential for experiencing insufficient technical skillsets and inadequate resources to simultaneously execute development of HART and operate IDENT. To mitigate these risks, the program plans to develop a training plan to address the gap in skills, leverage support within the program by cross- training staff, and issue contracts for additional support as needed, among other things. However, if the program does not have adequate staff to complete these efforts, it may experience further schedule delays. NPPD officials stated that the program’s schedule delays pose a challenge because IDENT remains at risk of failure despite incremental improvements to extend its service life and may be unable to fully support new customer requirements or requirements related to new programs. They added that the program has a risk management process, which it is using to manage a variety of identified risks—including several related to workforce. They noted that these risks have not yet materialized. NPPD officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. NATIONAL CYBERSECURITY PROTECTION SYSTEM (NCPS) NATIONAL PROTECTION AND PROGRAMS DIRECTORATE (NPPD) NCPS is intended to defend the federal civilian government from cyber threats. NCPS develops and delivers capabilities through a series of “blocks.” Blocks 1.0, 2.0, and 2.1 are fully deployed and provide intrusion-detection and analytic capabilities across the government. The NCPS program is currently deploying EINSTEIN 3 Accelerated (EA) to provide intrusion-prevention capabilities and plans to deliver block 2.2 to improve information sharing across agencies. A at 95 percent of agencies and departments. GAO last reported on this program in April 2017 (GAO-17-346SP). NPPD officials said the program is on track to meet the schedule and cost goals in its current acquisition program baseline (APB), which reflected changes resulting from the adoption of some of the Department of Homeland Security’s (DHS) Homeland Security Information Network (HSIN) capabilities for block 2.2 rather than developing custom solutions. However, challenges in completing test plans delayed testing: Initial operational test and evaluation (OT&E) for EA transition to sustainment— slipped from September 2016 to May 2017. The initial test event for block 2.2—intended to inform the ADE 2C for deploying additional block 2.2 capabilities—slipped from March 2017 to September 2017. As of August 2017, NPPD officials said NCPS had adopted all planned HSIN capabilities but one because of security concerns, which HSIN is addressing by piloting a new tool. The program updated its life-cycle cost estimate (LCCE) in June 2017 to inform the budget process, which is within its current APB cost thresholds. However, the program plans to update the LCCE again to support the EA, and costs through fiscal year 2022. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan no longer contained O&M funding for individual programs. NPPD officials anticipate receiving $1.8 billion in O&M funding over this 5-year period. The program is also projected to have an $83 million surplus in acquisition funding over this 5-year period, which NPPD officials anticipate will be less once the LCCE revision is complete. National Protection and Programs Directorate (NPPD) NATIONAL CYBERSECURITY PROTECTION SYSTEM (NCPS) A intrusion-prevention capabilities have been primarily provided through sole source contracts with internet service providers (ISP) and a contract to provide basic intrusion-prevention services. In December 2015, Congress required DHS to make available for use by federal agencies, certain capabilities, such as those provided by NCPS’s EA at approximately 93 percent of civilian federal agencies and departments and, in January 2018, NPPD officials said NCPS was up to 95 percent. According to NPPD officials, the program first focused on integrating EA for individual agencies and departments, but stated that they continue to work with all agencies and departments to provide EA services and approximately 95 percent of the federal civilian .gov user population is protected by at least one EA and an OA of NCPS block 2.2 information sharing capabilities in 2017. NPPD officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. NEXT GENERATION NETWORKS PRIORITY SERVICES (NGN-PS) NATIONAL PROTECTION AND PROGRAMS DIRECTORATE (NPPD) NGN-PS is intended to address an emerging capability gap in the government’s emergency telecommunications service, which prioritizes select officials’ phone calls when networks are overwhelmed. NPPD executes NGN-PS through commercial telecommunications service providers, which addresses the government’s requirements as they modernize their own networks. NPPD is executing NGN-PS in two phases—(1) voice and (2) data and video. Initial operational capability for voice phase wireless capabilities achieved in August 2017. Acquisition of data and video phase capabilities to begin in September 2021. GAO last reported on this program in April 2017 (GAO-17-346SP). In November 2017, the Department of Homeland Security’s (DHS) Chief Financial Officer approved a revised life-cycle cost estimate (LCCE) for NGN-PS, which includes costs for the entire program’s voice phase and eliminates operations and maintenance (O&M) costs. The program removed O&M costs because capabilities acquired through NGN-PS are transferred to and funded through NPPD’s Priority Telecommunications Service (PTS) once they become operational. NGN-PS is currently focused on delivering its voice phase, which is divided into three increments: Increment 1 maintains current priority service on long distance calls as commercial service providers update their networks; Increment 2 delivers wireless capabilities; and Increment 3 is intended to address landline capabilities. The program’s previous LCCE and current acquisition program baseline (APB) only include costs associated with increments 1 and 2. NPPD officials told GAO they plan to update the program’s APB in January 2018 to include costs, schedule, and performance goals for increment 3 and expect to receive DHS leadership approval to initiate development by August 2018. NGN-PS remains on track to meet its cost and schedule goals for the first two increments of the voice phase. The program’s full operational capability (FOC) for increment 1 previously slipped from June 2017 to March 2019, which NPPD officials attributed to funding shortfalls. NGN-PS achieved initial operational capability (IOC) for increment 2 wireless capabilities in August 2017 when priority service via cellular towers was demonstrated by the program’s largest service provider. The program projects an acquisition affordability gap of $92 million from fiscal years 2018 to 2022. However, DHS’s current funding plan does not include funding for increment 3, which accounts for the funding shortfall in fiscal years 2021 and 2022. NPPD officials said they anticipate receiving an additional $79 million in acquisition funding over this 2-year period, but will continue to prioritize capabilities if additional funding is not provided. These officials also said the program has achieved cost savings on increments 1 and 2 that will mitigate some of the projected shortfall in fiscal years 2018 and 2019. National Protection and Programs Directorate (NPPD) NEXT GENERATION NETWORKS PRIORITY SERVICES (NGN-PS) NGN-PS was established in response to an Executive Order requiring the federal government to have the ability to communicate at all times during all circumstances to ensure national security and manage emergencies. A Presidential Policy Directive issued in July 2016 superseded previous directives requiring continuous communication services for select government officials. According to NPPD officials, the new directive validates the program’s requirements for the voice phase and was used to develop requirements for the video and data phase. The program expects to begin the acquisition of the phase 2 for video and data in September 2021. In July 2017, NPPD reported that the program needed a systems engineer and was mitigating the vacancy with contracted support staff. The program also identified a need for an additional systems engineer and program support staff starting in fiscal year 2019 to support the start of increment 3. In August 2017, NPPD officials told GAO they continue to face challenges hiring and retaining engineers with adequate experience because of competition with the private sector. The program has historically mitigated staffing gaps by leveraging support from contracted and PTS program staff, as needed. In addition to activities identified in this assessment, NPPD officials stated that the program has received Joint Requirements Council validation of the phase 2 concept of operations and DHS leadership approval of the phase 2 operational requirements document. As of January 2018, the updated APB was in the approval process. NPPD officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. NATIONAL BIO AND AGRO-DEFENSE FACILITY (NBAF) SCIENCE AND TECHNOLOGY DIRECTORATE (S&T) The NBAF program is constructing a state-of-the-art laboratory in Manhattan, Kansas to replace the Plum Island Animal Disease Center. The facility will enable the Department of Homeland Security (DHS) and the Department of Agriculture (USDA) to conduct research, develop vaccines, and provide enhanced diagnostic capabilities to protect against foreign animal, emerging, and zoonotic diseases that threaten the nation’s food supply, agricultural economy, and public health. Commissioning process underway, but performance will not be demonstrated until construction is complete. NBAF adequately staffed, but staffing needs will change as operational stand-up activities begin. GAO last reported on this program in April 2017 (GAO-17-346SP). The program’s annual life-cycle cost estimate (LCCE) update is within its current acquisition program baseline (APB) cost thresholds and, according to NBAF officials, the program remains on track to meet its schedule goals. In August 2017, NBAF officials said that construction activities thus far—such as pouring concrete for the main laboratory and steel framing—have proceeded as anticipated and will continue through December 2020. NBAF officials told GAO the program has already received full acquisition funding for facility construction efforts through federal appropriations and gift funds from the state of Kansas. As construction continues, the program plans to begin operational stand-up activities for the facility. However, a potential affordability gap may delay the program’s ability to complete these stand-up activities, which are needed to begin conducting laboratory operations. The program was not included in DHS’s funding plan to Congress for fiscal years 2018 to 2022 because DHS did not report operations and maintenance (O&M) funding for individual programs. However, NBAF officials anticipate receiving only $149 million in O&M funding to cover an estimated $239 million in O&M costs over the next 5 years, resulting in a projected shortfall of approximately $90 million. NBAF officials stated the O&M funding gap could delay a number of operational stand-up activities, including plans to award a management operations and research support contract in October 2018, the purchase of laboratory and information technology equipment, and hiring of operations management staff. According to NBAF officials, if operational stand-up activities are delayed, there is a risk the facility will not be fully operational by December 2022, as is currently planned. This may delay the transition from the Plum Island Animal Disease Center, which is nearing the end of its useful life. NBAF officials reported that S&T plans to communicate the program’s future funding needs to DHS leadership through the annual budget process. If the program does not receive the funding it requests, these officials stated that S&T will prioritize the operational stand-up activities that best reduce the risk of schedule delays. Science and Technology Directorate (S&T) NATIONAL BIO AND AGRO-DEFENSE FACILITY (NBAF) NBAF officials reported that they coordinate regularly with key stakeholders. For example, they hold regular coordination meetings with USDA officials to discuss NBAF operations, including operational stand-up activities and future procurement. The NBAF program office has also begun outreach to the federal regulators responsible for awarding the registrations needed for NBAF to conduct laboratory operations to begin planning for this authorization process. The NBAF program office is currently fully staffed. However, NBAF officials reported the program’s staffing needs will change in the coming years, as the program progresses through construction and begins operational stand-up of the facility. For example, over the next 5 years, the program will need to hire an operations director, bio-risk manager, chief information officer, and facility manager, among others, for NBAF operations management. However, the projected O&M funding shortfall during this same period could affect the program’s ability to hire new staff when needed and complete operational stand-up activities on time. NBAF officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. ELECTRONIC BAGGAGE SCREENING PROGRAM (EBSP) TRANSPORTATION SECURITY ADMINISTRATION (TSA) Established in response to the terrorist attacks of September 11, 2001, EBSP tests, procures, and deploys transportation security equipment, such as explosives trace detectors and explosives detection systems, across approximately 440 U.S. airports to ensure 100 percent of checked baggage is screened for explosives. EBSP is primarily focused on delivering new systems with enhanced screening capabilities and developing software upgrades for existing systems. Program is incorporating requirements to address cybersecurity risk for existing systems. EBSP plans to pursue a new procurement approach in 2018, and staffing challenges exist. GAO last reported on this program in April 2017 (GAO-17-346SP). In the program’s annual life-cycle cost estimate update, its operations and maintenance (O&M) costs exceeded the acquisition program baseline (APB) cost threshold, which constitutes a breach under the Department of Homeland Security’s (DHS) acquisition policy. The O&M costs increased when TSA accounted for updated maintenance costs and quantities, and shifted salaries from acquisition to O&M to align with DHS’s new appropriation structure. TSA officials said they did not submit a breach notification because they considered the movement of salaries to be an administrative change. The program plans to update its APB in calendar year 2018 to reflect a new plan for procuring equipment under its current acquisition strategy. TSA officials said this APB will also reflect the cost changes. In May 2016, DHS leadership approved a revised APB for EBSP, which reflects its current acquisition strategy to competitively procure systems on an ongoing basis using qualified product lists. The program’s revised APB cost thresholds decreased compared to its initial APB, which TSA officials attributed to various reasons, including shortening the program’s end date by 3 years and lower than anticipated actual costs, among other things. TSA officials told GAO that one of their primary challenges is funding, and the program is projected to face a $72 million acquisition funding shortfall in fiscal year 2018. TSA identified $70 million in carryover funding to address this gap. To mitigate anticipated funding gaps in future years, TSA officials said they may shift projects from one fiscal year to another or cancel them altogether, which may result in the delay or elimination of screening capabilities. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained O&M funding for individual programs. TSA anticipates receiving $980 million in O&M funding over this 5-year period to cover $1 billion in O&M costs. TSA officials anticipate achieving the program’s final APB milestone—initial operational capability (IOC) for systems that detect additional materials and provide an advanced threat detection algorithm—by its revised threshold date. Previously, EBSP planned to award contracts for these systems in September 2015 and September 2018, respectively. Transportation Security Administration (TSA) ELECTRONIC BAGGAGE SCREENING PROGRAM (EBSP) As of December 2017, EBSP had deployed 1,664 explosives detection systems and 2,638 explosives trace detectors nationwide. In 2018, EBSP plans to pursue a new competitive procurement approach to replace and update existing systems that will include: New contract vehicles to better align EBSP procurement activities with the program’s strategic roadmap. Updates to EBSP’s vendor qualification process to allow for vendor collaboration before testing. Transitioning from procuring systems with different sizes and speeds to two types: (1) inline systems that integrate with a baggage handling system and are linked through a network and (2) standalone systems that may be integrated with a baggage handling system, but not linked to a network. The program is in the process of updating its acquisition documentation to reflect this new procurement approach and TSA officials anticipate opening a qualified products list for new systems starting in June 2018. TSA officials said that staffing remains a challenge for the program because of cuts in government and contracted mission support staff and critical vacancies, including a division director. In September 2017, TSA reported that existing personnel across the program have assumed responsibilities of these positions, but workloads are unsustainable at current staffing levels. TSA officials stated that EBSP continues to procure, test, and deploy equipment and capabilities to recapitalize older equipment, improve security screening capability at airports, and enhance the detection capabilities of the fleet. They added that TSA employs extensive testing to verify the suitability and effectiveness of equipment to meet requirements. Moving forward, EBSP intends to establish IOC milestones for new technologies and capabilities, while allowing TSA the flexibility to make risk-based decisions. TSA officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. PASSENGER SCREENING PROGRAM (PSP) TRANSPORTATION SECURITY ADMINISTRATION (TSA) The Department of Homeland Security (DHS) established PSP in response to the terrorist attacks of September 11, 2001. PSP identifies, tests, procures, deploys, and sustains transportation security equipment across approximately 440 U.S. airports to help TSA officers identify threats concealed on people and in their carryon items. The program aims to increase threat detection capabilities, improve the efficiency of passenger screening, and balance passenger privacy and security. Started testing on the Credential Authentication Technology in TSA Precheck lanes during 2017. Critical staffing vacancies persist and may delay followon acquisition planning efforts. GAO last reported on this program in April 2017 (GAO-17-346SP). In May 2017, the DHS Under Secretary for Management (USM) approved the sixth version of the PSP acquisition program baseline (APB) and subsequently removed the program from breach status. In January 2016, TSA declared a schedule breach of a key milestone—acquisition decision event (ADE) 3—for the Credential Authentication Technology (CAT) because of delays in incorporating new cybersecurity requirements. Consistent with previous versions of the program’s APB, the new baseline modified the program’s cost, schedule, and performance parameters. For example, the program established the following: Separate CAT milestone dates for TSA Precheck and standard lanes. TSA officials stated there is no capability difference between screening lanes, but an initial focus on TSA Precheck lanes will assist with demonstrating CAT requirements and resolving past testing issues that contributed to an initial 4-year delay to CAT’s full operational capability (FOC) date. PSP now plans to reach FOC for CAT more than 5 years later than its revised target of June 2018 and more than 9 years later than initially planned. New FOC dates for other technologies, which TSA officials said are expected to be more realistic about delivery dates and account for changes in some FOC quantities. For example, TSA requested and received approval in September 2017 to increase FOC quantities for second generation Advanced Technology (AT-2) TierI systems to meet increasing passenger volume and expected airport growth. In May 2017, the USM also directed the program to revise its life-cycle cost estimate (LCCE) in response to less-than-expected funding levels. The new LCCE also shifted some acquisition costs to operations and maintenance (O&M) to be consistent with DHS’s new appropriation structure. TSA officials believe the new funding profile will be sufficient to sustain legacy PSP equipment, but will significantly limit the program’s ability to enhance existing equipment capabilities and support operational needs. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained O&M funding for individual programs. TSA anticipates receiving $906 million in O&M funding over this 5-year period to cover $923 million in O&M costs. 05/17 APB version 6.0 approved 03/20 CAT ADE 3 (precheck lanes) 09/21 CAT ADE 3 (standard lanes) 12/21 CAT FOC (precheck lanes) 12/23 CAT FOC (standard lanes) Transportation Security Administration (TSA) PASSENGER SCREENING PROGRAM (PSP) Automated screening lanes operational utility assessment AT-2 tier II follow-on operational test & evaluation (OT&E) TSA employs two acquisition strategies to acquire PSP systems: Qualified Product List (QPL) approach—used for proven technologies when capability requirements are rigid and contractors’ systems are mature. Any contractors’ systems that demonstrate they meet the capability requirements are added to the QPL. TSA has used this approach to acquire the second generation AT-2 systems, Bottled Liquid Scanners, and Explosive Trace Detectors. Low Rate Initial Production (LRIP) approach—used when capability requirements are flexible and contractors’ systems are evolving. Under this approach, PSP uses a series of development contracts to enhance systems’ capabilities over time. PSP is currently using this approach to acquire CAT. TSA planned to initiate new acquisition programs starting in fiscal year 2018 that will replace PSP, but this effort may be at risk because of understaffing. In August 2017, TSA reported that its checkpoint screening division—whose staff is concurrently responsible for PSP and its follow-on programs—continued to have staffing vacancies, including project managers, analysts, and a deputy program manager. TSA is mitigating these gaps with existing staff and, according to TSA officials, the staffing challenges may decrease because the new programs may be delayed in response to funding cuts. TSA officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. TECHNOLOGY INFRASTRUCTURE MODERNIZATION (TIM) TRANSPORTATION SECURITY ADMINISTRATION (TSA) The TIM program was initiated to address shortfalls in TSA’s threat assessment screening and vetting functions by providing a modern and centralized end-to-end credentialing system. The TIM system will manage credential applications and the review process for millions of transportation workers and travelers across three segment populations: maritime, surface, and aviation. It will support large programs, such as TSA Precheck and the Transportation Worker Identification Credential. Operational testing identified limitations with the system; cybersecurity has not been assessed. Staffing gaps in key areas, such as systems engineering and testing, are a significant program risk. GAO last reported on this program in October and April 2017 (GAO-18-46, GAO-17- 346SP). The TIM program is on track to meet the cost and schedule goals in its current acquisition program baseline (APB). In September 2016, the Department of Homeland Security’s (DHS) Under Secretary for Management approved the TIM program’s revised APB—which reflected a new technical approach to deploy capabilities using an agile development methodology—and subsequently removed the program from breach status, authorizing TSA to resume new development after a nearly 22-month pause. DHS leadership paused new development in January 2015 after the program breached its initial APB goals for various reasons, including technical challenges, insufficient contractor performance, and the addition of new requirements after DHS leadership had approved the program’s initial acquisition strategy. The program now plans to achieve full operational capability (FOC) in March 2022 and its life-cycle cost estimate (LCCE) increased to account for this 6-year schedule slip and integration with the Transportation Vetting System, among other things. Since the program’s re-baseline, it has been developing and deploying capabilities in 2-month incremental agile releases, such as functionality to transition TSA Precheck program to the TIM system. The program updated its LCCE in November 2017 to inform a program review with DHS leadership, which is within its current APB cost thresholds. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained operations and maintenance (O&M) funding for individual programs. TSA officials anticipate receiving approximately $318 million in O&M funding over this 5-year period, which includes nearly $118 million in fees from vetting programs. TSA officials plan to realign $57 million to cover the projected acquisition shortfall, and said any additional surplus funding available in fiscal year 2022 would be used to implement new system requirements identified by the program’s customers. In November 2017, TSA officials identified several program and technical risks that could affect the program’s cost, schedule, and performance. These risks include an increase in new requirements and increased risk of system vulnerabilities and cyberattacks if the program does not identify a provider to perform software updates on open source code. TSA officials are working to mitigate these risks. Transportation Security Administration (TSA) TECHNOLOGY INFRASTRUCTURE MODERNIZATION (TIM) Under the program’s new technical approach, TSA plans to replace the TIM system’s existing commercial-off-the-shelf applications with open source applications—software that can be accessed, used, modified, and shared by anyone—and move to a new virtual environment. The program’s new agile development methodology develops, tests, and deploys capabilities using an iterative, rather than a sequential approach. Consistent with this strategy, TSA awarded task orders in 2016 and 2017 totaling $34.5 million to the program’s existing contractor for agile design and development services, and plans to competitively award a new contract by May 2018. In October 2017, GAO found that TSA had not fully implemented several leading practices to ensure successful agile adoption. GAO also found that TSA and DHS needed to conduct more effective oversight of the TIM program to reduce the risk of repeating past mistakes. DHS concurred with all 14 recommendations made by GAO to improve program execution and oversight, and identified actions DHS and TSA can take to address them. TSA reported that staffing challenges are a significant risk to the program’s success and identified gaps in key areas—such as systems engineering, testing, and agile development. Program officials told GAO these positions cannot be filled because of a hiring freeze within TSA, which the component has imposed to assess their current workforce and restructure, if necessary. Program officials told GAO they requested waivers from the hiring freeze and, as of January 2018, they had received approval to hire 4 additional staff. TSA officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. FAST RESPONSE CUTTER (FRC) UNITED STATES COAST GUARD (USCG) The USCG uses the FRC to conduct search and rescue, migrant and drug interdiction, and other law enforcement missions. The FRC carries one cutter boat on board and is able to conduct operations in moderate sea conditions. The FRC replaces the USCG’s Island Class patrol boat and provides improved fuel capacity, surveillance, and communications interoperability with other Department of Homeland Security (DHS) and Department of Defense assets. FRC found operationally effective and suitable, and all key performance parameters validated. Main diesel engine issues persist, which may require further retrofits. GAO last reported on this program in March and April 2017 (GAO-17-218, GAO-17- 346SP). According to USCG officials, the FRC program is on track to meet its current cost and schedule goals. The USCG plans to acquire 58 FRCs and, as of September 2017, 25 had been delivered and 19 were on contract. To inform the budget process, the program updated its life-cycle cost estimate in June 2017, which is within its current acquisition program baseline (APB) cost thresholds. Previously, the program’s initial operational capability (IOC) date slipped after a bid protest related to the program’s initial contract award—now known as phase 1—and the need for structural modifications. USCG officials attributed the 5-year slip in the program’s full operational capability (FOC) date to a decrease in annual procurement quantities under the phase 1 contract. Specifically, in fiscal years 2010 and 2011, the quantities decreased from 6 FRCs per year to 4. In May 2014, the USCG determined that it would procure only 32 of the 58 FRCs through this contract and initiated efforts to conduct a full and open competition for the remaining 26 vessels—known as phase 2. In May 2016, the USCG awarded the phase 2 contract for the remaining 26 FRCs, which has a potential value of $1.42 billion. Under the phase 2 contract, the USCG can procure 4 to 6 FRCs per option period. The USCG ordered 6 FRCs at the time of the phase 2 award and, in June 2017, exercised an option for an additional 6 FRCs. The USCG has established that the annual procurement quantity will be dictated by funding levels, and funding shortfalls could cause further schedule delays. The affordability gap from fiscal years 2018 to 2022 may be overstated because—as we found in April 2015—DHS’s funding plan to Congress does not contain operations and maintenance (O&M) funding for USCG programs. USCG officials anticipate receiving $1.6 billion in O&M funding over this 5-year period. USCG officials stated that they expect to exercise an option for 4 FRCs in fiscal year 2018 and that the USCG plans to prioritize acquisition funding in fiscal years 2019 and 2020 to procure the final 10 hulls and complete procurement of all 58 FRCs. United States Coast Guard (USCG) FAST RESPONSE CUTTER (FRC) The USCG continues to work with the contractor—Bollinger Shipyards, LLC—to address issues covered by the warranty and acceptance clauses for each ship. For example, 18 engines—9 operational engines and 9 spare engines—have been replaced under the program’s warranty. According to USCG documentation, 65 percent of the current issues with the engines have been resolved through retrofits; however, additional problems with the engines have been identified since our April 2017 review. For example, issues with water pump shafts are currently being examined through a root cause analysis and will be redesigned and are scheduled to undergo retrofits starting in December 2018. We previously found that the FRC’s warranty resulted in improved cost and quality by requiring the shipbuilder to pay for the repair of defects. As of September 2017, USCG officials said the replacements and retrofits completed under the program’s warranty allowed the USCG to avoid an estimated $104 million in potential unplanned costs—of which $63 million is related to the engines. The FRC program does not have any critical staffing vacancies, but the USCG identified insufficient staffing for shore-side support groups as a potential risk that could affect the asset’s operations. These groups provide maintenance to the FRCs while they are in port. In order to mitigate this staffing issue, the USCG is using commercial contracts for maintenance to supplement the capacity of the USCG’s maintenance staff. USCG officials stated that the FRC program is fully funded, executable, and on track to reach FOC by March of 2027. They added that FRCs were recently delivered to locations in Mississippi, Alaska, and Hawaii. USCG officials stated that FRCs are integral to USCG operations, such as providing critical support during the recent hurricane season, and that the program office continues to work with the contractor and stakeholders to quickly and properly address issues with FRCs as they are identified. USCG officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. H-65 CONVERSION/SUSTAINMENT PROGRAM (H-65) UNITED STATES COAST GUARD (USCG) The H-65 aircraft is a short-range helicopter that the USCG uses to fulfill its missions, including search and rescue, ports and waterways security, marine safety, and defense readiness. The H-65 acquisition program increased the fleet’s size by 7 aircraft, added armament capabilities, upgraded navigation systems, and replaced each of the helicopters’ engines. The program is currently focused on upgrades to radar sensors, the automatic flight control system (AFCS), and avionics. Operational assessment of avionics upgrade planned to start in February 2018. Program fully staffed, but schedule slips raise risks with future staffing requirements. GAO last reported on this program in April 2017 (GAO-17-346SP). As of November 2017, the program remains in breach of its current acquisition program baseline (APB). In November 2016, the USCG notified Department of Homeland Security (DHS) leadership that it would not complete all activities required—including developmental testing and an operational assessment—to achieve acquisition decision event (ADE) 2C for low-rate initial production of the avionics and AFCS upgrades by its current APB threshold date of March 2017. USCG officials primarily attributed these delays to an underestimation of the technical effort necessary to meet the requirements and have subsequently worked with the contractor to continue development of avionic upgrades. In January 2017, DHS leadership directed the program to update its APB, life-cycle cost estimate (LCCE) and test and evaluation master plan by May 2017. However, the USCG did not meet this deadline, in part, because it decided to add a service life extension program (SLEP) to the H-65 program. The SLEP is expected to extend the current 20,000 flight hour service life of each aircraft by another 10,000 flight hours by replacing obsolete aircraft components. USCG officials stated that this will allow the USCG to delay purchasing new aircraft to prioritize funding for the Offshore Patrol Cutter. USCG officials plan to obtain approval for the SLEP when the program submits its revised APB for DHS approval, which is expected by March 2018. The program is revising its LCCE, but provided an update in June 2017 to inform the budget process. This update exceeds its current APB thresholds because it includes an initial estimate for the SLEP. The USCG estimates that the SLEP will cost $54 million for the entire fleet. USCG officials attributed the increase in operations and maintenance (O&M) costs to the additional extension of the aircraft’s operational life. The program’s O&M costs previously increased due to the USCG’s decision to extend the aircraft’s operational life from 2030 to 2039. The affordability gap from fiscal years 2018 to 2022 may be overstated because— as we found in April 2015—DHS’s funding plan to Congress does not contain O&M funding for USCG programs. USCG officials anticipate receiving $1.6 billion in O&M funding over this 5-year period. United States Coast Guard (USCG) H-65 CONVERSION/SUSTAINMENT PROGRAM (H-65) The USCG awarded new contracts to Rockwell Collins—the original equipment manufacturer of the legacy AFCS and avionics—to address the challenges encountered with development of the new upgrades. Specifically, the program awarded new contracts to support continued development of the AFCS and avionics upgrades in July 2016 and March 2017, respectively. As of September 2017, the combined value of both contracts totaled more than $15 million. The USCG cancelled development of a dedicated surface search radar capability for the H-65 in 2014, but USCG officials said a commercial off-the-shelf weather radar with surface search capability will be installed as part of the avionics upgrade. USCG officials said there is some risk involved with extending the aircrafts’ service life beyond 20,000 flight hours since it has never been done by other agencies that operate the H-65. However, USCG officials stated that the aircraft manufacturer, Airbus, assisted the USCG’s chief aeronautical engineer in identifying specific parts needing replacement and is providing support. In July 2017, the USCG reported that the program was fully staffed, but that the schedule slips have introduced potential risks with future staffing requirements. The program is mitigating these risks by extending some military personnel and ensuring rotating personnel are replaced by new staff with the expertise needed to complete the program’s planned activities, such as testing. USCG officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. UNITED STATES COAST GUARD (USCG) The program is intended to assist the USCG in maintaining the capability to access the Arctic and Antarctic polar regions. The USCG requires its icebreaking fleet to conduct multiple missions, including defense readiness; marine environmental protection; ports, waterway, and coastal security; and search and rescue. The USCG plans to acquire three heavy icebreakers to recapitalize the only existing operational heavy icebreaker, which is nearing the end of its service life. Program initiated model testing of hull and propulsion systems, which will inform design decisions. Program office integrates USCG and Navy personnel, but funding responsibilities may cause challenges. GAO last reported on this program in September 2017 (GAO-17-698R). In June 2014, Department of Homeland Security (DHS) leadership granted the program acquisition decision event (ADE) 1 approval. The Acting Under Secretary for Management also acknowledged the USCG’s need to accelerate the acquisition process to mitigate gaps in the heavy icebreaking capability because the service life of the USCG’s only heavy polar icebreaker, which had already been extended, could end as early as 2020. In January 2018, DHS leadership approved the program’s initial acquisition program baseline (APB) establishing cost, schedule, and performance goals. The USCG planned to achieve a combined ADE 2A and 2B by December 2017, which would authorize the initiation of development efforts. According to DHS officials, this milestone was delayed to February 2018 to allow for the completion of required acquisition documents to inform the decision, such as the program’s life-cycle cost estimate and APB. The USCG is partnering with the Navy to leverage shipbuilding expertise and engaging early with potential shipbuilders through industry studies to mitigate some risks associated with the program’s accelerated acquisition schedule. However, GAO previously found that the program faces challenges in implementing the accelerated schedule. For example, the first icebreaker—which is preliminarily estimated to cost about $750 million to design and construct—would need to be fully funded in fiscal year 2019 at the same time the USCG is expecting to prioritize funding for the Offshore Patrol Cutter. In fiscal year 2017, the Consolidated Appropriations Act or associated explanatory materials, reflected funding for the program, including $150 million for advance procurement of heavy polar icebreakers and $25 million to the USCG for programmatic costs, respectively. USCG officials stated that the Navy funding could cover most of the design costs but would not cover long lead items or construction costs for any of the ships. They further stated that uncertainties with the amount and source of future appropriations have made planning the icebreaker acquisition challenging. United States Coast Guard (USCG) DHS leadership approved four key performance parameters (KPP) related to the ship’s ability to independently break through ice, the ship’s operating duration, and communications. In May 2017, the USCG began model testing of potential hull designs and propulsion configurations. USCG officials explained that the hulls of icebreakers are unique from other ships because they must balance a hull design optimized for icebreaking, which are generally broad and blunt, against a hull design optimized for seakeeping, which are generally narrow and streamlined. USCG officials noted that the power demands and propulsion system for the ship are dependent on the hull design. USCG officials stated that maneuverability was identified as a challenge during model testing and explained that azimuthing propulsors—propellers that sit below the ship and can rotate 360 degrees—offered better maneuverability than traditional propulsion systems. USCG officials said these propulsors are widely used on commercial ships, but may need modification to meet the USCG’s requirements. USCG officials anticipate results from the model testing to be completed by March 2018 and plan to use these results to inform the final specifications for the ships. The USCG established an integrated heavy polar icebreaker program office with the Navy and in 2017, DHS, the USCG, and Navy entered into several agreements that outline oversight roles, among other things. For example, these agreements state that the program will follow DHS acquisition policies with DHS leadership serving as the acquisition decision authority for program milestones. However, the Navy will review and approve acquisition documents before the program seeks DHS approval. These agreements also state that the program’s contracting actions could be funded by either USCG or Navy appropriations, and the source of the appropriations will award the contract. The program plans to competitively award a contract, which would include options for the detail design and construction for all three ships to a single shipbuilder by June 2019. Program officials stated they plan to award the contract under full and open competition to obtain competitive prices and include the construction of the three ships as options to accommodate the program’s funding uncertainties. In February 2017, the USCG awarded contracts to five shipbuilders—valued at approximately $4 million each—for design studies which will inform program decisions. Program officials stated that under these design studies contracts, the shipbuilders developed several potential ship designs and preliminary costs, with a focus on alternative propulsion options and hull designs. In August 2017, USCG officials told GAO that the program’s staffing gap was not negatively impacting program efforts. USCG officials stated that the program office had completed requirements for ADE 2A and 2B, and is on track to release the request for proposals for the detail design and construction contract by March 2018. These officials added that, during 2017, the program office refined the program’s requirements, completed ice and open water model testing, and partnered with five industry teams to evaluate multiple design solutions. USCG officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. LONG RANGE SURVEILLANCE AIRCRAFT (HC-130H/J) UNITED STATES COAST GUARD (USCG) The USCG uses HC-130H and HC-130J aircraft to conduct search and rescue missions, transport cargo and personnel, support law enforcement, and execute other operations. Both aircraft are quad-engine propeller-driven platforms. The HC-130J is a modernized version of the HC-130H, which has advanced engines, propellers, and equipment that provide enhanced speed, altitude, range, and surveillance capabilities. Performance testing of new mission system processor complete. Transfer of HC-130H aircraft to other agencies ongoing. GAO last reported on this program in April 2017 (GAO-17-346SP). During 2017, the USCG continued a nearly 3-year effort to re-baseline the program— which includes revisions to the program’s life-cycle cost estimate (LCCE) and acquisition program baseline (APB)—to account for significant changes. Specifically, the USCG decided to pursue an all HC-130J fleet and, in fiscal year 2014, Congress directed the transfer of 7 HC-130H aircraft to the U.S. Air Force. The USCG was in the process of upgrading these aircraft, but cancelled further HC-130H upgrades. In September 2017, Department of Homeland Security (DHS) leadership directed the USCG to submit the revised APB by January 2018. According to USCG officials, the re-baseline has been delayed, in part, because Congress also directed the USCG to conduct a multi-phased analysis of its mission needs. In November 2016, the USCG submitted the results of its analysis for fixed- wing aircraft, which confirmed the planned total quantity of 22 HC-130J aircraft and an annual flight-hour goal of 800 hours per aircraft. USCG officials said the results of the analysis will be reflected in the program’s revised LCCE and subsequent APB, but noted that challenges with the vendor hired to complete the LCCE revision have also contributed to delays. The program submitted cost information in June 2017 to inform the budget process, but it reflected no updates from the program’s November 2011 LCCE. USCG officials previously attributed the acquisition cost growth and schedule slip from the program’s initial APB to the increase in HC-130J quantities from 6 to 22. However, when the revised LCCE is complete, estimated costs may decrease since the HC-130J aircraft are less expensive to maintain. As of December 2017, USCG officials stated they had received 11 HC-130J aircraft and had awarded contracts for 3 more—some of which were not requested. USCG officials previously stated that the program needs to acquire 1-2 HC-130J aircraft per year to meet its full operational capability (FOC) date. However, it is unclear how the USCG will meet its FOC date because it only requested funding for 1 aircraft over the next 5 years. The affordability gap from fiscal years 2018 to 2022 may be overstated because—as we found in April 2015—DHS’s funding plan to Congress does not contain operations and maintenance (O&M) funding for USCG programs. USCG officials anticipate receiving approximately $1.4 billion in O&M funding over this 5- year period. United States Coast Guard (USCG) LONG RANGE SURVEILLANCE AIRCRAFT (HC-130H/J) In December 2013, Congress directed the transfer of 7 HC-130H aircraft to the U.S. Air Force for modifications—which consists of upgrades and installing a fire retardant delivery system—and subsequent transfer to the U.S. Forest Service. This direction factored into the USCG’s decision to pursue an all HC-130J fleet. As of December 2017, the Forest Service had not yet received any modified aircraft primarily because of issues with contractors. According to USCG officials, the original contract the Air Force awarded to install the fire retardant delivery system in May 2016 was terminated 7 months later due to an unqualified vendor and a new contract has not yet been awarded. In the meantime, the Forest Service is using 2 of the 7 HC-130Hs. USCG officials said these aircraft are not modified, but outfitted with a less effective firefighting device. As of November 2017, the USCG plans to operate 14 of its HC-130H aircraft until the end of their service lives or until they can be replaced with new HC-130J aircraft. However, as previously discussed, the USCG has not requested funding for the additional HC-130J aircraft to support this plan. In October 2017, USCG officials reported that they were in the process of hiring staff to address the program’s staffing gap. USCG officials provided technical comments on a draft of this assessment, which GAO incorporated, as appropriate. MEDIUM RANGE SURVEILLANCE AIRCRAFT (HC-144A/ C-27J) UNITED STATES COAST GUARD (USCG) The USCG uses HC-144A and C-27J aircraft to conduct all types of missions, including search and rescue and disaster response. All 32 aircraft—18 HC-144A aircraft and 14 C-27J aircraft—are twin-engine propeller driven platforms. The interior of both aircraft are able to be re-configured to accommodate cargo, personnel or medical transports. Developmental testing of new mission system processor is ongoing. Program continues to face challenges related to purchasing spare parts and accessing technical data. GAO last reported on this program in April 2017 and March 2015 (GAO-17-346SP, GAO-15-325). USCG officials said the program is on track to meet the cost and schedule goals in its current acquisition program baseline (APB), which Department of Homeland Security (DHS) leadership approved in August 2016 to reflect the restructuring of the HC-144A acquisition program. The USCG initially planned to procure a total of 36 HC-144A aircraft, but reduced that number to the 18 it had already procured after Congress directed the transfer of 14 C-27J aircraft from the U.S. Air Force to the USCG in fiscal year 2014. The program’s APB divides the program into two phases: phase 1 includes acceptance of the 18 HC-144A aircraft and upgrades to the aircraft’s mission and flight management systems, and phase 2 includes acceptance of and modifications to the C-27J aircraft to meet the USCG’s mission needs. In October 2017, USCG officials told GAO that the program had initiated phase 1 efforts to upgrade the first HC-144A aircraft. The USCG plans to complete upgrades on all HC-144As by the end of fiscal year 2021. For phase 2, the USCG has accepted all 14 C-27Js from the U.S. Air Force and plans to complete the modification of all C-27Js by March 2025 to achieve full operational capability (FOC). To inform the budget process, the program updated its life-cycle cost estimate (LCCE) in June 2017, which is within its current APB cost thresholds. This estimate includes C-27J modification costs, such as installation of a new sensor package and new mission system processor. The program’s LCCE for the 36 HC-144A aircraft previously increased to $28.7 billion in 2012 when the USCG accounted for 5 years of additional costs, among other things. The current LCCE represents a considerable decrease, but also reflects a reduction in the number of aircraft and planned flight hours. The affordability gap from fiscal years 2018 to 2022 may be overstated because—as we found in April 2015—DHS’s funding plan to Congress does not contain operations and maintenance (O&M) funding for USCG programs. USCG officials anticipate receiving nearly $1.7 billion in total funding over this 5-year period to cover nearly $1.8 billion in total costs. United States Coast Guard (USCG) MEDIUM RANGE SURVEILLANCE AIRCRAFT (HC-144A/C-27J) The USCG still faces challenges in transitioning the C-27J into the USCG fleet. In March 2015, GAO found that the successful and cost-effective fielding of the C-27J aircraft is contingent on the USCG’s ability to address risk areas including, purchasing spare parts and accessing technical data, among other issues. According to USCG officials, the program continues to face challenges purchasing spare parts and accessing technical data. The program is reliant on the aircraft original equipment manufacturer for about 35 percent of spare C-27J parts. For other parts, USCG officials said that the USCG continues to look for ways to provide the same or similar parts for the aircraft at a faster rate and the USCG plans to award contracts to two additional manufacturers in calendar year 2018. USCG officials stated that retrieving technical data for the C-27J aircraft remains a challenge, but the USCG is working with the Department of Defense to obtain rights to data currently owned by the original equipment manufacturer. Once the USCG receives appropriate rights to C-27J technical data, the USCG officials said they can begin modification of the aircraft. The USCG also plans to purchase the same surface search radar used on the HC-144A or the HC-130J for the C-27J, which will give the USCG some commonality in maintenance, logistics, and training for this aspect of the aircraft. In October 2017, USCG officials told GAO that the program’s staffing is adequate and the gap has not negatively affected the program. USCG officials stated that the program remains on track to meet the cost, schedule, and performance goals outlined in its current APB and that they monitor APB key parameters in accordance with DHS guidance. These officials added that market research continues to increase supply chain sources and to identify products for new mission systems. USCG officials also provided technical comments, which GAO incorporated as appropriate. NATIONAL SECURITY CUTTER (NSC) UNITED STATES COAST GUARD (USCG) The USCG uses the NSC to conduct search and rescue, migrant and drug interdiction, environmental protection, and other missions. The NSC replaces and provides improved capabilities over the USCG’s High Endurance Cutters. The NSC carries helicopters and cutter boats, provides an extended on-scene presence at forward deployed locations, and operates worldwide. Follow-on operational testing began in October 2017, but cybersecurity testing delayed. The USCG is conducting a study to determine root cause of propulsion system issues. GAO last reported on this program in March and April 2017 (GAO-17-218, GAO-17- 346SP). In November 2017, Department of Homeland Security (DHS) leadership approved a revised acquisition program baseline (APB), which accounted for the addition of a ninth NSC to the program of record. The USCG originally planned to acquire only eight NSCs; however, in the Consolidated Appropriations Act of 2016, Congress directed that not less than $640 million be immediately available and allotted to contract for the production of a ninth NSC. In December 2016, the USCG awarded a contract to produce the ninth NSC and, as of November 2017, six NSCs had been delivered and three were under construction. The USCG anticipates delivery of the ninth NSC in September 2020, which coincides with the program’s prior APB threshold date for full operational capability (FOC). However, the revised APB extends this date by 1 year to account for any risks in delivering the additional ship. The program’s FOC date previously slipped 4 years, which USCG officials attributed to funding shortfalls, among other things. The ninth NSC contributed to a $453 million and $123 million increase in the program’s APB cost thresholds for acquisition and operations and maintenance (O&M), respectively. However, the program’s revised life-cycle cost estimate (LCCE) is still lower than its initial estimate for eight ships, which USCG officials attribute to more accurate estimates. The revised LCCE also included costs for several design changes the USCG has had to implement on equipment with known issues. As of September 2017, 12 equipment systems required design changes, which totaled an estimated cost of over $260 million. This work includes structural enhancement work on the first two NSCs and the replacement of the gantry crane, which aids in the deployment of cutter boats. The affordability gap from fiscal years 2018 to 2022 may be overstated because— as we found in April 2015—DHS’s funding plan to Congress does not contain O&M funding for USCG programs. USCG officials anticipate receiving approximately $2.1 billion in O&M funding over this 5-year period to cover the NSC’s estimated $1.8 billion in O&M costs, but stated it will refine its annual budget request based on the program’s needs each year. The USCG also identified carryover funding to cover the projected acquisition funding shortfall in fiscal year 2018. United States Coast Guard (USCG) NATIONAL SECURITY CUTTER (NSC) The NSC program does not have any critical staffing vacancies. However, in July 2017, the program reported that the greatest staffing challenge is a potential extension to the program’s end date if the USCG acquires more than 9 NSCs. If this occurs, the program office must reassess future staffing requirements to ensure adequate program oversight continues until the last NSC completes post-delivery activities. In addition, the USCG has made changes to its staffing model for operating the NSCs. The USCG initially planned to implement a crew rotational concept in which crews would rotate while NSCs were underway to achieve a goal of 230 days away from the cutter’s homeport. In February 2018, USCG officials told GAO they abandoned the crew rotational concept because the concept did not provide the USCG with the expected return on investment. Instead, USCG officials said a new plan has been implemented that does not rotate crew and is anticipated to increase the days away from home port from the current capability of 185 days to 200 days. USCG officials stated that NSCs had a record year of narcotics seizures in 2017. In addition to the test activities identified in this assessment, USCG officials stated that the first follow-on OT&E event was completed in December 2017 and the first cybersecurity test event is scheduled for February 2018. They also noted that the shipbuilder continues to show improving cost performance and is completing construction within budget. USCG officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. OFFSHORE PATROL CUTTER (OPC) UNITED STATES COAST GUARD (USCG) The USCG plans to use the OPC to conduct patrols for homeland security, law enforcement, and search and rescue operations. The OPC is being designed for long-distance transit, extended on-scene presence, and operations with deployable aircraft and small boats. It is intended to replace the USCG’s aging Medium Endurance Cutters (MEC) and bridge the operational capabilities provided by the Fast Response Cutters and National Security Cutters (NSC). Program plans to refine the ship’s design, as needed, based on early operational assessment results. Program’s acquisition strategy incorporated some best practices. GAO last reported on this program in April and June 2017 (GAO-17-346SP, GAO-17-654T). According to USCG officials, the OPC program is on track to meet its cost and schedule goals. In September 2014, Department of Homeland Security (DHS) leadership approved the program’s current acquisition program baseline (APB), which accounts for schedule slips resulting from delays in awarding the program’s initial contracts and a subsequent bid protest. The USCG expects to start construction of the first OPC in fiscal year 2019 and procure a total of 25 ships. The USCG plans to initially fund one OPC per year and eventually two OPCs per year until all 25 OPCs are delivered. USCG officials have stated that additional OPC delays will decrease the USCG’s operational capacity because the MECs will likely require increased downtime for maintenance and other issues, reducing their availability. In January 2016, DHS leadership directed the USCG to revise the OPC life-cycle cost estimate (LCCE) and submit it for approval within 6 months of awarding the detailed design and construction contract for the ships—which the USCG subsequently awarded in September 2016. In June 2017, the program submitted an updated LCCE to inform the budget process that—while not approved by DHS leadership—accounts for the contract award and the program’s schedule slips. As of December 2017, the program’s revised LCCE still had not been approved. It is unclear whether it will address other issues, such as an increase in the estimated weight of each ship. The OPC’s initial LCCE was based in large part on the estimated weight of each ship. However, in November 2017, USCG officials said the ship is expected to weigh up to 35 percent more than originally estimated. Nevertheless, USCG officials expect to procure all 25 OPCs for the program’s APB objective cost of $10.5 billion because the contractor identified cost efficiencies to compensate for the increased weight. GAO previously raised questions about the OPC’s affordability and its effect on other USCG acquisition programs, such as the Heavy Polar Icebreaker. Specifically, GAO noted that the OPC procurement will consume about two-thirds of the USCG’s planned acquisition budget between fiscal years 2018 and 2032 based on recent funding history. The program’s affordability gap from fiscal years 2020 to 2022 may be overstated because—as we found in April 2015—DHS’s funding plan to Congress does not report operations and maintenance (O&M) funding for USCG programs. USCG officials anticipate receiving $103 million in O&M funding over this 5-year period. United States Coast Guard (USCG) OFFSHORE PATROL CUTTER (OPC) The USCG is in the process of completing the design of the OPC before starting construction, which is in-line with GAO shipbuilding best practices. In addition, USCG officials stated that the program is using state-of-the-market technology that has been proven on other ships as opposed to state-of-the-art technology, which lowers the risk of the program. The USCG used a two-phased down-select strategy to select a contractor to deliver the OPC. For phase 1, the USCG conducted a full and open competition and selected three contractors to perform preliminary design work. For phase 2, the USCG selected one of the phase 1 contractors—Eastern Shipbuilding—to develop a detailed design of the OPC and construct no more than the first 11 ships. The contract—worth approximately $110 million—includes separate options for each ship. The options for ships 10 and 11 were unpriced and included in the solicitation as an incentive to convert the contract type from fixed price incentive to firm fixed price. These options will be included in a repricing proposal submitted by the contractor for ships 6-9 after delivery of the first ship. USCG officials have stated the USCG will decide whether to exercise the option for ships 10 and 11 based on the contractor’s re-pricing proposal for ships 6-9. The USCG plans to re-compete the contract for the remaining 14-16 ships. The OPC program continued to increase its required staffing level and the USCG reported that adjustments to staffing will continue as the program matures. The program faces shortages including engineers, a logistics manager, and a technical director, but USCG officials said they are hiring staff to address these gaps. USCG officials stated that the OPC program is fully funded, executable, and on track to award construction for the first OPC in September 2018. These officials said design efforts are on track and the contractor is meeting the milestones to deliver the first OPC in 2021. USCG officials noted that they are continuing to increase staff at the contractor’s facility to prepare for the start of construction for the first OPC. USCG officials also provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. UNITED STATES CITIZENSHIP AND IMMIGRATION SERVICES (USCIS) The Transformation program was established in 2006 to transition USCIS from a fragmented, paper-based filing environment to a consolidated, paperless environment for processing immigration and citizenship applications. The program developed a new system architecture and delivers capability through releases that correspond to new product lines within four lines of business: Citizenship, Immigrant, Non-Immigrant, and Humanitarian. Revision of key performance parameters and test and evaluation master plan in progress. Program is reorganizing to leverage expertise within USCIS and revise its approach. GAO last reported on this program in April 2017 and July 2016 (GAO-17-346SP, GAO-16- 467). The program remains in breach of its current acquisition program baseline (APB). In September 2016, the Transformation program experienced a schedule breach when it failed to complete deployment of all the product lines associated with the Citizenship line of business. The deployment was delayed because of challenges processing new product lines on the new system architecture and other technical issues with the case management system. Prior to the breach, the program deployed six product lines, which supported approximately 24 percent of the total workload processed by USCIS in fiscal year 2016. Department of Homeland Security (DHS) leadership previously re- baselined the program in April 2015 after USCIS determined that it could not use any of the architecture delivered under its initial strategy, despite having invested more than $475 million in its development. In December 2016, DHS leadership directed USCIS to stop planning and development for new product lines, develop a breach remediation plan, and update its acquisition documentation. In February 2017, DHS leadership approved the program’s remediation plan and the program has since made progress in implementing this plan. However, DHS leadership elected to continue with the program’s pause in new development following program reviews in March 2017, July 2017, and October 2017. USCIS officials said they are revising the program’s acquisition documents—including its APB and life-cycle cost estimate (LCCE)—and plan to re-baseline by March 2018. The program updated the total costs in its LCCE to inform the budget process, but these costs do not reflect the program’s re-baselining plans. As a result, the status of the program against its cost and schedule goals is unclear. However, the program is more than 3 years past its original full operational capability (FOC) date. The affordability gap from fiscal years 2018 to 2022 may be overstated because DHS’s funding plan to Congress no longer contained operations and maintenance funding for individual programs. USCIS uses revenue from premium processing fees to fund the Transformation program and routinely collects more fees than the program’s estimated costs. USCIS officials told GAO that the program office underwent a reorganization in January 2017 to help address the program’s recent challenges. This effort included dismantling the program office and repositioning Transformation under the USCIS Office of Information Technology so the program could leverage expertise in areas such as engineering within USCIS. USCIS officials reported that the program no longer plans to deliver capability by product lines because this strategy focused too narrowly on the automation of forms associated with the lines of business. Going forward, USCIS officials said the program plans to develop capabilities that will address broader objectives, such as reducing the time it takes to process applications and decisions. The program previously made significant changes after it experienced a 5-month delay with its first release, which was deployed in May 2012. DHS attributed this delay to weak contractor performance and pursuing an unnecessarily complex system, among other things. To address these issues, the Office of Management and Budget, DHS, and USCIS determined the program should implement a new acquisition strategy, which allowed for an agile software development methodology and increased competition for development work. This strategy was reflected in the program’s April 2015 re-baseline. USCIS officials told GAO that they plan to address the Transformation program’s staffing gap now that the reorganization is complete. USCIS officials provided technical comments on a draft of this assessment, which GAO incorporated as appropriate. To help determine the extent to which the Department of Homeland Security (DHS) has taken actions to enhance its policies and processes to better reflect key portfolio management practices, we assessed the department’s requirements, acquisition management, and resource allocation policies using key practices we established in September 2012. These key practices are based on our past work, in which we examined the practices that private sector entities use to achieve a balanced mix of new projects and found that successful commercial companies use a disciplined and integrated approach to prioritize needs and allocate resources. As a result, these organizations can avoid pursuing more projects than their resources can support and better optimize the return on their investments. This approach, known as portfolio management, requires companies to view each of their investments as contributing to a collective whole, rather than as independent and unrelated. The objectives of this audit were designed to provide congressional committees insight into the Department of Homeland Security’s (DHS) major acquisition programs. We assessed the extent to which (1) DHS’s major acquisition programs are on track to meet their schedule and cost goals and (2) DHS has taken actions to enhance its policies and processes to better reflect key portfolio management practices. To answer these questions, we reviewed 28 of DHS’s 79 major acquisition programs. We reviewed all 16 of DHS’s Level 1 acquisition programs— those with life-cycle cost estimates (LCCE) of $1 billion or more—that had at least one project, increment, or segment in the Obtain phase—the stage in the acquisition life cycle when programs develop, test, and evaluate systems—at the initiation of our audit. Additionally, we reviewed 12 other major acquisition programs—including 8 Level 1 programs that either had not yet entered or were beyond the Obtain phase, and 4 Level 2 programs that have LCCEs between $300 million and less than $1 billion—that we identified were at risk of not meeting their cost estimates, schedules, or capability requirements based on our past work and discussions with DHS officials. Specifically, we met with representatives from DHS’s Office of Program Accountability and Risk Management (PARM)—DHS’s main body for acquisition oversight—as a part of our scoping effort to determine which programs (if any) were facing difficulties in meeting their cost estimates, schedules, or capability requirements. The 28 selected programs were sponsored by eight different components, and they are identified in table 7, along with our rationale for selecting them. To determine the extent to which DHS’s major acquisition programs are on track to meet their schedule and cost goals, we collected key acquisition documentation for each of the 28 programs, such as all LCCEs and acquisition program baselines (APB) approved at the department level since DHS’s current acquisition management policy went into effect in November 2008. DHS policy establishes that all major acquisition programs should have a department-approved APB, which establishes a program’s critical cost, schedule, and performance parameters, before they initiate efforts to obtain new capabilities. Twenty four of the 28 programs had one or more department-approved LCCEs and APBs between November 2008 and December 31, 2017. We used these APBs to establish the initial and current cost and schedule goals for the programs. We then developed a data collection instrument to help validate the information from the APBs and collect similar information from programs without department-approved APBs. Specifically, for each program, we pre-populated a data collection instrument to the extent possible with the schedule and cost information we had collected from the APBs and our 2017 assessment (if applicable) to identify schedule and cost goal changes, if any, since (a) the program’s initial baseline was approved and (b) January 2017—the data cut-off date of the report we issued in April 2017. We shared our data collection instruments with officials from the program offices to confirm or correct our initial analysis and to collect additional information to enhance the timeliness and comprehensiveness of our data sets. We then met with program officials to identify causes and effects associated with any identified schedule and cost goal changes. Subsequently, we drafted preliminary assessments for each of the 28 programs, shared them with program and component officials, and gave these officials an opportunity to submit comments to help us correct any inaccuracies, which we accounted for as appropriate (such as when new information was available). Additionally, in July 2017, we collected copies of the detailed data on affordability that programs submitted to inform the fiscal year 2019 resource allocation process. We also collected copies of any annual LCCE updates programs submitted in fiscal year 2017. For each of the 24 programs with a department-approved APB, we compared (a) the most recent cost data we collected (i.e., a department-approved LCCE, the detailed LCCE information submitted during the resource allocation process, a fiscal year 2017 annual LCCE update, or an update provided by the program office) to (b) DHS’s funding plan presented in the Future Years Homeland Security Program (FYHSP) report to Congress for fiscal years 2018–2022, which presents 5-year funding plans for DHS’s major acquisition programs, to assess the extent to which a program was projected to have an acquisition funding gap in fiscal year 2018. Through this process, we determined that our data elements were sufficiently reliable for the purpose of this engagement. The FYHSP reports information by the department’s new common appropriation structure, which created standard appropriation fund types including (1) procurement, construction, and improvements and (2) operations and support. We refer to these types of funding as (1) acquisition and (2) operations and maintenance throughout this report. which are listed in appendix II—and identified any significant shortfalls. Specifically, we assessed the joint requirements directives and instruction manual; DHS’s Acquisition Management Directive 102-01, Acquisition Management Instruction 102-01-001, and other related guidance; and DHS’s resource allocation directive, instruction, and handbook. First, we assessed each group of policies against the key practices using the following ratings: Met—the documents fully reflected the key practice. Partially met—the documents reflected some, but not all parts of the key practice. Not met—the documents did not reflect the key practice. We shared our preliminary analysis for each group of policies with the DHS officials responsible for implementing them—specifically, the Joint Requirements Council (JRC), PARM, and the Office of Program Analysis and Evaluation (PA&E)—to discuss our findings, identify relevant sections of the documents we had not yet accounted for, and solicit their thoughts on those key practices that were not reflected in the policies. Second, we used the scores for each group of policies to develop a department-wide rating for each key practice. When applicable, we weighted the department-wide rating based on the intent of the key practice. For example, the department-wide rating for the key practice related to resource allocation across the portfolio was based more heavily on the rating for the resource allocation policies, rather than the ratings for the requirements or acquisition management policies. Third, we rolled-up the ratings for all the key practices in a particular area—as identified in appendix II—to establish a department-wide overall rating for each key practice area. We concluded that a key practice area was met if all ratings for the individual key practices in that area were met; partially met if the ratings for the individual key practices in that area were all partially met or a mix of met and not met; or not met if the ratings for the individual key practices in that area were all not met. In addition, we reviewed documentation that resulted from DHS’s requirements, acquisition management, and resource allocation processes since January 2016 to get a sense of how the department has implemented its current policies. For example, we reviewed JRC- validated requirements documents; acquisition decision memorandums; Acquisition Program Health Assessment reports; and documentation related to the development of DHS’s fiscal year 2018 budget request and the fiscal year 2018–2022 FYHSP report, including resource allocation guidance, presentations to DHS leadership, and preliminary decisions. We also interviewed officials from the JRC, PARM, PA&E, and the Deputy’s Management Action Group to identify any current and planned initiatives to improve management of the department’s portfolio of major acquisition programs. We then compared our assessment of DHS’s current policies, practices, and planned initiatives to our previous findings and the Standards for Internal Control in the Federal Government. We conducted this performance audit from March 2017 through May 2018 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. In addition to the contact listed above, Rick Cederholm (Assistant Director), Aryn Ehlow (Analyst-in-Charge), Pete Anderson, Lorraine Ettaro, Helena Johnson, TyAnn Lee, Alexis Olson, Sylvia Schatz, Roxanna Sun, and Lindsay Taylor made key contributions to this report. Other contributors included Mathew Bader, Carissa Bryant, Andrew Burton, Erin Butkowski, Lisa Canini, Jenny Chow, John Crawford, Lindsey Cross, Laurier R. Fish, Betsy Gregory-Hosler, Claire Li, Sarah Martin, Marycella Mierez, Erin O’Brien, Katherine Pfeiffer, John Rastler, Ashley Rawson, Andrew Redd, Jill Schofield, Charlie Shivers III, and Jeanne Sung. DHS Program Costs: Reporting Program-Level Operations and Support Costs to Congress Would Improve Oversight. GAO-18-344. Washington, D.C.: April 25, 2018. Homeland Security Acquisitions: Identifying All Non-Major Acquisitions Would Advance Ongoing Efforts to Improve Management. GAO-17-396. Washington, D.C.: April 13, 2017. Homeland Security Acquisitions: Earlier Requirements Definition and Clear Documentation of Key Decisions Could Facilitate Ongoing Progress. GAO-17-346SP. Washington, D.C.: April 6, 2017. Coast Guard Cutters: Depot Maintenance Is Affecting Operational Availability and Cost Estimates Should Reflect Actual Expenditures. GAO-17-218. Washington, D.C.: March 2, 2017. Homeland Security Acquisitions: Joint Requirements Council’s Initial Approach Is Generally Sound and It Is Developing a Process to Inform Investment Priorities. GAO-17-171. Washington, D.C.: October 24, 2016. Homeland Security Acquisitions: DHS Has Strengthened Management, but Execution and Affordability Concerns Endure. GAO-16-338SP. Washington, D.C.: March 31, 2016. National Security Cutter: Enhanced Oversight Needed to Ensure Problems Discovered during Testing and Operations Are Addressed. GAO-16-148. Washington, D.C.: January 12, 2016. TSA Acquisitions: Further Actions Needed to Improve Efficiency of Screening Technology Test and Evaluation. GAO-16-117. Washington, D.C.: December 17, 2015. Homeland Security Acquisitions: Major Program Assessments Reveal Actions Needed to Improve Accountability. GAO-15-171SP. Washington, D.C.: April 22, 2015. Coast Guard Aircraft: Transfer of Fixed-Wing C-27J Aircraft Is Complex and Further Fleet Purchases Should Coincide with Study Results. GAO-15-325. Washington, D.C.: March 26, 2015. Homeland Security Acquisitions: DHS Should Better Define Oversight Roles and Improve Program Reporting to Congress. GAO-15-292. Washington, D.C.: March 12, 2015. Coast Guard Acquisitions: Better Information on Performance and Funding Needed to Address Shortfalls. GAO-14-450. Washington, D.C.: June 5, 2014. Homeland Security Acquisitions: DHS Could Better Manage Its Portfolio to Address Funding Gaps and Improve Communications with Congress. GAO-14-332. Washington, D.C.: April 17, 2014. Homeland Security: DHS Requires More Disciplined Investment Management to Help Meet Mission Needs. GAO-12-833. Washington, D.C.: September 18, 2012. Department of Homeland Security: Assessments of Selected Complex Acquisitions. GAO-10-588SP. Washington, D.C.: June 30, 2010. Department of Homeland Security: Billions Invested in Major Programs Lack Appropriate Oversight. GAO-09-29. Washington, D.C.: November 18, 2008.
We testified before the Senate Committee on Armed Services in September 2017 after four significant mishaps at sea resulted in the loss of 17 sailors’ lives and serious damage to Navy ships. We reported on some of the Navy’s challenges, including the degraded condition and expired training certifications of ships homeported overseas, reductions to ship crews that contributed to sailor overwork and safety risks, and an inability to complete maintenance on time. Since that time, the Navy has completed two internal reviews to address these and other challenges, identifying 111 recommendations to improve surface fleet readiness. The Navy formed an executive group to guide and closely track the implementation of recommendations, and its reform efforts are ongoing. As of November 2018, the Navy reported that it had implemented 78 (i.e., 70 percent) of these recommendations. Navy officials recognize that full implementation will take significant time and management attention to address the fundamental readiness challenges identified. In figure 1, we show photographs of two of the four Navy ships involved in significant mishaps that occurred in 2017. Both the USS Fitzgerald and the USS John S. McCain were involved in collisions that resulted in sailor fatalities. DOD has reported that more than a decade of conflict, budget uncertainty, and reductions in force structure have degraded its readiness; in response, the department has made rebuilding readiness a priority. The 2018 National Defense Strategy emphasizes that restoring and retaining readiness across the entire spectrum of conflict is critical to success in the emerging security environment. Nevertheless, DOD reported that readiness of the total military force remains low and has remained so since 2013. Our work has shown that the Navy has experienced increasing maintenance challenges as a high pace of operations has continued and maintenance has been deferred. Maintenance and personnel challenges also hinder readiness recovery of Navy aircraft. For the Marine Corps, our work has shown that ground force readiness has improved and remained stable in recent years, but acute readiness problems remain in aviation units. Over the past year, DOD has made department-wide progress in developing a plan to rebuild the readiness of the military force, with the military services providing regular input on the status of their readiness recovery efforts. In August 2018, we reported that the Office of the Secretary of Defense has developed a Readiness Recovery Framework that the department is using to guide the services’ efforts and plans to use to regularly assess, validate, and monitor readiness recovery. The Office of the Secretary of Defense and the services have recently revised readiness goals and accompanying recovery strategies, metrics, and milestones to align with the 2018 National Defense Strategy and Defense Planning Guidance. We have ongoing work assessing DOD’s progress in achieveing its overall readiness goals. DOD’s readiness rebuilding efforts are occurring in a challenging context that requires the department to make difficult decisions regarding how best to address continuing operational demands while preparing for future challenges. Our work has shown that an important aspect of this, across all of the services, is determining an appropriate balance between maintaining and upgrading legacy weapon systems currently in operational use and procuring new ones to overcome rapidly advancing future threats. Based on updated information we received in November 2018, the Navy has taken steps to provide dedicated training time so its surface forces may meet existing Navy training standards and their training is certified when they deploy. However, the Navy continues to struggle with rebuilding the readiness of the existing fleet due to enduring maintenance and manning challenges. As the Navy seeks to expand its fleet by 25 percent, these challenges will likely be further exacerbated and the Navy will likely face additional affordability challenges. After the collisions in 2017, the Navy focused on training surface ship crews to its existing standards. We testified in September 2017 that there were no dedicated training periods built into the operational schedules of the cruisers and destroyers based in Japan and 37 percent of training certifications for these surface ship crews had lapsed as of June 2017. Since that time, the Navy has worked to ensure surface ships are certified before they are deployed. For example, the Navy has established controls to limit waivers that allowed training lapses to worsen, now requiring multiple high-level approvals for ships to operate uncertified. Based on our analysis of updated data, the Navy has improved markedly in the percentage of cruisers and destroyers with lapsed certifications in Japan, from 41 percent of certifications expired in September 2017 to 9 percent as of November 2018, with less than 3 percent of certifications expired on ships in operational status. While the Navy has demonstrated its commitment to ensuring that crews are certified prior to deploying, training for amphibious operations and higher-level collective training may not be fully implemented for several years. In September 2017, we reported that some Marine Corps units were limited in their ability to complete training to conduct an amphibious operation—a military operation that is launched from the sea to introduce a landing force ashore—by several factors, including a decline in the number of amphibious ships from 62 in 1990 to 32 as of November 2018, access to range space, and a high pace of deployments, among others. We recommended that the Navy and the Marine Corps develop an approach to mitigate their amphibious operations training shortfalls as the services await the arrival of additional amphibious ships into the fleet. Marine Corps officials told us that the Marine Corps and the Navy are working together to maximize amphibious training opportunities. Additionally, the Navy has plans to phase in high-level collective training into the operational schedules of its ships homeported in Japan over the next several years. Previously, advanced and integrated training involving multiple ships was conducted ad hoc if at all for ships homeported in Japan. Such collective training is important because the 2018 National Defense Strategy states that the department’s principal priority is to prepare for threats from strategic competitors due to the magnitude of the threat they pose. However, in November 2018, officials from Fleet Forces Command told us that fully implementing its training approach to prepare for advanced adversaries would not be fully implemented across the fleet for several years. We have reported that the Navy faces persistent challenges in completing maintenance on time and providing sufficient manning to its ships. Unless these challenges are addressed, the Navy will be hampered in its ability to rebuild readiness and prepare for the future. Our work has found that the Navy has been unable to complete ship and submarine maintenance on time, resulting in continuing schedule delays that reduce time for training and operations and create costly inefficiencies in a resource constrained environment. The Navy’s readiness recovery is premised on the rigorous adherence to deployment, training, and maintenance schedules. However, we reported in May 2016 on the difficulty that both the public and private shipyards were having in completing maintenance on time. We reported that, from 2011 through 2014, about 28 percent of scheduled maintenance for surface combatants was completed on time and 11 percent was completed on time for aircraft carriers. We updated these data as of November 2018 to include maintenance periods completed through the end of fiscal year 2018 and found that the Navy continues to struggle to complete maintenance on time. For fiscal years 2012-2018, our analysis for key portions of the Navy fleet shows that 30 percent of Navy maintenance was completed on time, leading to more than 27,000 days in which ships were delayed and unavailable for training and operations as shown in figure 2 below. In addition to affecting training and operations, maintenance delays are costly. In November 2018, we examined attack submarine maintenance delays and reported that the Navy was incurring significant operating and support costs to crew, maintain, and support attack submarines that are delayed getting into and out of shipyard maintenance periods. We estimated that over the past 10 years the Navy has spent $1.5 billion in fiscal year 2018 constant dollars to support attack submarines that provide no operational capability—those sitting idle no longer certified to conduct normal operations—while waiting to enter the shipyards, and those delayed in completing their maintenance at the shipyards (see figure 3). We recommended that the Navy analyze how it allocates its maintenance workload across public and private shipyards. DOD concurred with our recommendation, stating that it has taken the first steps to take a more holistic view of submarine maintenance requirements and impacts across both the public and private shipyards. In an update provided in November 2018, the Navy told us that they are developing a contracting strategy to conduct two additional depot maintenance periods at private shipyards in the future. Our prior work has shown that three primary factors at the naval shipyards contribute to maintenance delays: Poor conditions and aging equipment limit the ability of the shipyards to meet current and future demands. We reported in September 2017 that facility and equipment limitations at the shipyards contributed to maintenance delays for the aircraft carriers and submarines, hindering the shipyards’ ability to support the Navy. Specifically, we found that the shipyards would be unable to support an estimated one-third of maintenance periods planned over the next 23 years. We recommended that the Navy take steps to improve its management of shipyard investments; the Navy concurred with this recommendation and we are encouraged by its response. For example, the Navy has developed a plan for the optimal placement of facilities and major equipment at each public shipyard, which the Navy estimates can ultimately increase its maintenance efficiency by reducing personnel and materiel travel by an average of 65 percent. This equates to recovering about 328,000 man days per year—an amount roughly equal to that of an aircraft carrier maintenance period. However, the Navy’s preliminary estimate —that this effort will require an estimated $21 billion and 20 years to address—is well beyond historical funding levels, and does not include some potentially significant costs (e.g., for utilities, roads, or environmental remediation). Shipyard workforce gaps and inexperience are limiting factors. The Navy has reported a variety of workforce challenges at the Navy’s four public shipyards such as hiring personnel in a timely manner and providing personnel with the training necessary to gain proficiency in critical skills. The Navy has noted that some occupations require years of training before workers become proficient. According to Navy officials, a large portion of its workforce is inexperienced. For example, 45 percent of the Puget Sound and 30 percent of the Portsmouth Naval Shipyards’ skilled workforce have fewer than 5 years of experience. According to DOD officials, workforce shortages and inexperience contribute to maintenance delays. For example, at Pearl Harbor Naval Shipyard, two submarines were delayed approximately 20 months, in part because of shortages in ship fitters and welders, among other skilled personnel. Most of DOD’s depots, which include the naval shipyards, have taken actions to maintain critical skills through retention incentives, bonuses, and awards. We plan to issue a report examining DOD’s depot skill gaps, including those at the naval shipyards, later this month. Depot supply support may not be cost-effective. In June 2016, we reported that the naval shipyards and other depots had not implemented actions that would likely improve the cost-effectiveness of their supply operations. Specifically, the Navy had not transferred certain functions to the Defense Logistics Agency (DLA) at the shipyards in the same manner as the Navy and Air Force did for their aviation depots. The Navy and Air Force aviation depots that transferred these functions to DLA had reaped a number of efficiencies in their supply operations, including a 10-percent reduction in backorders over a 5-year period. We recommended that the Navy analyze whether such a transfer of functions is warranted at the shipyards and the Navy concurred with the recommendation. However, as of October 2018, the Navy had not conducted a comprehensive analysis of transferring these functions and had provided no plans to do so. In May 2017, we reported that the Navy’s process for determining manpower requirements—the number and skill mix of sailors needed on the Navy’s ships—did not fully account for all ship workload. The Navy was using outdated standards to calculate the size of ship crews that may have been leading to overburdened crews working long hours. We recommended steps to help ensure the Navy’s manpower requirements meet the needs of the existing and future surface fleet, and the Navy has been studying ship workload and revising its guidance. As of November 2018, the Navy was continuing to analyze the manpower requirements of its ship classes to better size and compose ship crews, and the Navy was also working to improve shipboard manning. However, these efforts are not yet complete and it is too early to assess their effectiveness. Until manpower requirements are reassessed across the fleet, the Navy risks that ship crews will continue to be undersized and sailors will be overworked with potential negative effects on readiness and safety. Additionally, the Navy provided information in November 2018 that showed that it is taking steps to ensure that ships have a minimum percentage of crew assigned and with the appropriate skills. The Navy has prioritized manning its surface ships homeported overseas. The Navy established a minimum threshold of filling at least 95 percent of authorized billets in its ship crews with sailors (referred to as fill), with a minimum goal of 92 percent of those sailors having the right qualifications for the billet (known as fit). According to Navy officials, the Navy is for the most part meeting its fill goals Navy-wide, but has not consistently met its fit goals. However, during group discussions in November 2018 with ship crews and interviews with Navy officials in Japan, we learned that the Navy’s methods for tracking fit and fill do not account for sailor experience and may be inaccurately capturing the actual presence of sailors onboard and available for duty on its ships. Moreover, sailors consistently told us that ship workload has not decreased, and it is still extremely challenging to complete all required workload while getting enough sleep. Navy officials told us that manning challenges will continue through at least fiscal year 2021 as the Navy increases its end strength and trains its new sailors to gain the proper mix of skills to operate and maintain the fleet. To meet continued operational demands, the Navy is planning for the most significant fleet size increase in over 30 years. According to the Navy’s fiscal year 2019 shipbuilding plan, the Navy plans to build and maintain a fleet of 355 battle force ships—an increase of about 25 percent above the Navy’s current force of 287 ships. To reach its goal, the Navy plans to buy 301 ships through 2048 and extend the service life of its 66 Arleigh Burke class destroyers and up to 7 attack submarines. Together, the fiscal year 2019 shipbuilding plan and the service life extensions would allow the Navy to reach a 355-ship fleet by the 2030s. Congressional Budget Office reporting and our past work have shown that the Navy has consistently and significantly underestimated the cost and timeframes for delivering new ships to the fleet. For example, the Navy estimates that buying the new ships specified in the fiscal year 2019 plan would cost $631 billion over 30 years while the Congressional Budget Office has estimated that those new ships would cost $801 billion—a difference of 27 percent. We also reported in June 2018 that acquisition outcomes for ship classes built during the last 10 years have often not achieved cost, schedule, quality, or performance goals that were established. Furthermore, we have reported that: all 8 of the lead ships delivered over the past decade that we reviewed were provided to the fleet behind schedule, and more than half of those ships were delayed by more than 2 years, and six ships of different classes valued at $6.3 billion were delivered to the Navy with varying degrees of incomplete work and quality problems. As a result of past cost and schedule problems, our work has shown that the Navy has a less-capable and smaller fleet today than it planned over 10 years ago. The Navy has also received $24 billion more in funding than it originally planned in its 2007 long-range shipbuilding plan but has 50 fewer ships in its inventory today, as compared with the goals it first established. Therefore, we have reported that as the Navy moves forward in implementing its shipbuilding plan it will be paramount for the Navy to learn from and apply lessons learned from the past. In addition to the cost of buying the ships and submarines to expand fleet size, the Navy will likely face affordability challenges with regard to the manning of an expanded fleet with the right number of sailors with the right mix of skills. In May 2017, we reported that the personnel costs for surface ship classes in fiscal years 2000-2015 were the largest share of total operating and support costs and that careful planning will be needed as new ships are brought into the fleet. We also reported that crew sizes on recently inducted ship classes grew from original projections as the Navy gained experience operating them. For example, the total crew size of Littoral Combat Ships has grown from 75 in 2003 to 98 personnel in 2016, a 31-percent increase. Navy officials told us that they plan to better articulate the personnel and resources needed for a larger fleet after fully accounting for workload and right-sizing ship crews. The Navy’s end strength has since increased by over 11,000 personnel from fiscal year 2017 levels, which should help alleviate manning challenges as the fleet grows. In November 2018, officials from Fleet Forces Command provided us with projections of its manning shortfalls continuing through at least fiscal year 2021 and steps it was planning to take to mitigate them. Our work has shown that Navy and Marine Corps aircraft availability has been limited by aging aircraft, delayed maintenance, and insufficient supply support. Pilot and maintenance personnel shortfalls further limit readiness recovery across legacy air platforms. The growing F-35 program, which is meant to replace many aging aircraft, has presented additional operational and sustainment challenges, which will likely persist into the future if not corrected. DOD, the Navy, and the Marine Corps have emphasized mission capability of critical aviation platforms— including the Navy and Marine Corps F/A-18s and F-35s—and are taking steps to improve availability, but these efforts will take time to realize results. Navy and Marine Corps aircraft availability has been limited by challenges associated with aging aircraft fleets, depot maintenance, and supply support challenges that limit the services’ ability to keep aviation units ready. The Navy and Marine Corps spend billions of dollars each year on sustainment, such as for spare parts and depot maintenance, to meet aircraft availability goals. However, aircraft availability rates have generally declined since fiscal year 2011. While specific aircraft availability data are considered sensitive by the Navy and the Marine Corps, and cannot be discussed in detail, we found in September 2018 that the Navy and the Marine Corps generally did not meet aircraft availability goals in fiscal years 2011-2016 for the seven aircraft we reviewed. In updating data in November 2018, we found that none of the aircraft met aircraft availability goals for fiscal years 2017 and 2018. According to the Navy, the pace of operations has increased wear and tear on its aircraft and decreased the time available for maintenance and modernization—a necessity for an aging fleet. For example, the average age of a legacy F/A-18A-D Hornet is 26 years, of an AV-8B Harrier is 21 years, and of the C-2A Greyhound is 29 years. Both services expect these aircraft will continue to be used for the foreseeable future and in some cases into the 2030s. The Navy and the Marine Corps face delays in the arrival of the F-35 to replace their legacy F/A-18A-D Hornets and AV-8B Harriers. To compensate for the delay, the Navy and the Marine Corps are planning to procure additional aircraft, such as the F/A-18E-F Super Hornet, and extend the service life and upgrade the capabilities of their legacy aircraft. However, these efforts and the sustainment of the Navy and Marine Corps legacy aircraft fleet face key challenges as shown in figure 4. Specifically, our prior work has shown that the Navy and the Marine Corps are confronted with two sets of challenges in sustaining their aircraft: Depot maintenance complexities for aging aircraft and spare parts availability. Depot maintenance on aging weapon systems, including Navy and Marine Corps aircraft, becomes less predictable as structural fatigue occurs and parts that were not expected to be replaced begin to wear out. While the Navy and the Marine Corps reported that sustainment funding accounts, such as those for depot maintenance and spare parts, have been funded at increased levels in fiscal years 2017 and 2018, efforts to improve spare parts availability take time to produce results due to long lead times for acquiring some items. In addition, Navy and Marine Corps aircraft face challenges associated with diminishing manufacturing sources and parts obsolescence. DOD has a program intended to manage these risks, but we reported in September 2017 that its implementation varied across DOD weapon system program offices. We made recommendations to improve the program’s management; DOD concurred and has initiated improvement efforts. Maintenance personnel inexperience and retention. The Navy has had difficulty attracting and retaining skilled maintainers, such as sheet metal workers and machinists at its aviation depots (i.e., Fleet Readiness Centers), which directly affects its ability to complete planned maintenance. Some of the depots experienced challenges attracting and retaining skilled personnel due to competition with nearby contractors that are able to offer higher pay, according to Navy depot officials. Similar to the shipyards, the aviation depots also lack experienced personnel, affecting the efficiency and quality of maintenance. For example, 41 percent of the skilled workers at Fleet Readiness Center Southwest have 2 years or fewer of experience. Workforce inexperience and attrition of skilled personnel were some of the reasons cited for machining defects detected in the landing gear for F/A-18, E-2, and C-2A aircraft by a recent Navy report. All of the depots have undertaken retention efforts such as incentives, bonuses, and awards to address these issues. Until the Navy and Marine Corps address maintenance and supply challenges it will be difficult to meet Secretary of Defense-established mission capability goals. Specifically, in September 2018, the Secretary of Defense issued a memorandum emphasizing that a key component of implementing the 2018 National Defense Strategy is ensuring critical aviation platforms meet their mission capability targets by the end of fiscal year 2019. The memorandum established a goal of achieving a minimum of 80-percent mission capable rates for various aircraft, including for the Navy’s and Marine Corps’ F/A-18 inventories, by the end of fiscal year 2019 while also reducing operating and maintenance costs. To accomplish this, the Navy and the Marine Corps developed the Return to Readiness strategy in November 2018 that includes a broad array of actions to improve the availability of spare parts and evaluate the application of best commercial practices to naval aviation sustainment, among other actions. Office of the Secretary of Defense and Navy program officials told us, and based on our prior work we agree, that this goal will be challenging to achieve by the end of fiscal year 2019. We reported in April 2018 that fighter pilot shortages in the Navy and the Marine Corps have been worsening in recent years and shortfalls are projected to remain through at least fiscal year 2023. Our analysis of Navy and Marine Corps data showed that the Navy’s shortage of first operational tour fighter pilots more than doubled from 12 percent in fiscal year 2013 to 26 percent in fiscal year 2017. Similarly, the Marine Corps’ overall shortage of fighter pilots quadrupled from 6 percent in fiscal year 2006 to 24 percent in fiscal year 2017. Also, as we reported in April 2018, service officials attributed the pilot shortages to reduced training opportunities and increased attrition due to career dissatisfaction, among other factors. Officials from both services stated at the time that they have ensured that deploying squadrons have been fully staffed with fighter pilots by using various approaches including using senior pilots to staff junior positions and having pilots deploy more frequently and for longer periods. However, we reported that squadron leaders and fighter pilots said that these approaches had a negative impact on the fighter pilot training and retention and ultimately may be exacerbating the situation. Further compounding their pilot shortages, we also found that the services have not recently reevaluated squadron requirements to reflect an increased fighter pilot workload. As a result, the reported shortage actually could be greater. The services were taking actions, including increasing retention incentives for fighter pilots. To help determine the magnitude of the shortages and help target strategies to better meet their personnel needs, we recommended, and the Navy and Marine Corps agreed, to reevaluate fighter pilot squadron requirements. Sustainment challenges are not just an issue for older aircraft, but represent an enduring challenge for the F-35 Lightning II aircraft—a key component to the future of tactical aviation for the Navy and Marine Corps. The Navy and Marine Corps are both flying F-35s now as the program ramps up development, and they plan to procure nearly 700 aircraft over the coming decades. The sustainment costs of the F-35 fleet are projected to exceed $1 trillion over its 60-year life cycle. In October 2017, we reported that: F-35B aircraft (including Marine Corps aircraft) were available (i.e., the aircraft were safe to fly, available for use, and able to perform at least one tasked mission) about 52 percent of the time from March 2017 through June 2017, which fell short of the 65-percent goal established by the Marine Corps for non-deployed units and F-35B aircraft (including Marine Corps aircraft) were fully mission capable (i.e., the aircraft were capable of accomplishing all tasked missions) about 15 percent of the time from March 2017 through June 2017, which fell short of the 60-percent goal established by the Marine Corps for non-deployed units. We also reported on numerous sustainment challenges leading to less than desirable outcomes for F-35 warfighter readiness. For example, F-35 aircraft were unable to fly 22 percent of the time because of parts shortages from January 2017 through August 7, 2017. Additionally, DOD’s capabilities to repair F-35 parts at military depots were 6 years behind schedule, which resulted in average part repair times that are twice that of the program’s objective. As DOD gains experience with the F-35, our work has shown that the department has encountered additional challenges. In 2017, the Marine Corps became the first military service to station F-35 aircraft overseas, transferring aircraft to Iwakuni, Japan. While in the Pacific, DOD expects to disperse its F-35s into smaller detachments to outmaneuver the enemy and counter regional threats. However, in April 2018, we reported that this approach posed logistics and supply challenges. In June 2018, we reported that the F-35 program had not improved its reliability and maintainability over the past year and continued to fall short on half of its performance targets. Furthermore, we found that the program may not meet its required targets before each variant of the F-35 is expected to demonstrate maturity—the point at which the aircraft has flown enough hours to predictably determine reliability and maintainability over its lifespan. This means that the Navy and the Marine Corps may have to decide whether they are willing to accept less reliable and maintainable aircraft than originally planned. Among other outcomes, this could result in higher maintenance costs and lower aircraft availability than anticipated which also could pose readiness challenges in the future. As we reported in October 2017, the poor reliability of certain parts is already contributing to shortages of F-35 spare parts. Challenges posed by the F-35 program are largely the result of sustainment plans that do not fully include or consider key requirements. Our work has shown that planning for sustainment and aligning its funding are critical if DOD wants to meet its aircraft availability goals and effectively deploy to support operations. To address the challenges associated with F-35 sustainment and operational deployment, we recommended that DOD revise its sustainment plans, align associated funding, and mitigate the risks associated with key supply chain-related challenges for deployed F-35s in the Pacific, among others. DOD concurred with these recommendations and stated that it is taking steps to address them. Furthermore, as previously discussed, the Secretary of Defense has established an 80-percent mission capability goal for critical aviation assets, including the F-35. Due to current low availability and numerous sustainment issues, the F-35 fleet will be challenged in meeting the goal. In sum, the Navy’s and Marine Corps’ significant readiness challenges have developed over more than a decade of conflict, budget uncertainty, and reductions in force structure. Both services have made encouraging progress identifying the causes of their readiness decline and have begun efforts to arrest and reverse it; however, our prior work shows that fully addressing the persistent readiness challenges will require years of sustained management attention. Our work cited today contains 25 specific recommendations to the Navy and the Marine Corps and an additional 20 recommendations to various other DOD components to assist these services in rebuilding the readiness of their forces and in modernizing for the future. Attention to these recommendations can assist the Navy and the Marine Corps as they seek to rebuild the readiness of their forces. Chairmen Wicker and Sullivan, Ranking Members Hirono and Kaine, and Members of the Subcommittees, this concludes my prepared statement. I would be pleased to respond to any questions you may have at this time. If you or your staff have questions about this testimony, please contact John H. Pendleton, Director, Defense Capabilities and Management at (202) 512-3489 or pendletonj@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this statement. GAO staff who made key contributions to this testimony are Suzanne Wren, Assistant Director; Clarine Allen; Steven Banovac; John Bumgarner; Chris Cronin; Benjamin Emmel; Cynthia Grant; Mae Jones; Amie Lesser; Tobin McMurdie; Shahrzad Nikoo; Carol Petersen; Cody Raysinger; Michael Silver; John E. “Jet” Trubey; and Chris Watson. Over the past 4 years, we have issued a number of reports related to Navy and Marine Corps readiness and we used them to develop this statement. Table 1 summarizes the recommendations in these reports. The Department of Defense (DOD) concurred with most of the 45 recommendations and has many actions underway. However, DOD has not fully implemented any of the recommendations to date. For each of the reports, the specific recommendations and any progress made in implementing them are summarized in tables 2 through 16. Report numbers with a C or RC suffix are classified. Report numbers with a SU suffix are sensitive but unclassified. Classified and sensitive but unclassified reports are available to personnel with the proper clearances and need to know, upon request. Navy Readiness: Actions Needed to Address Costly Maintenance Delays Facing the Attack Submarine Fleet. GAO-19-229. Washington, D.C.: November 19, 2018. Air Force Readiness: Actions Needed to Rebuild Readiness and Prepare for the Future. GAO-19-120T. Washington, D.C.: October 10, 2018. Weapon System Sustainment: Selected Air Force and Navy Aircraft Generally Have Not Met Availability Goals, and DOD and Navy Guidance Need to Be Clarified. GAO-18-678. Washington, D.C.: September 10, 2018. Weapon System Sustainment: Selected Air Force and Navy Aircraft Generally Have Not Met Availability Goals, and DOD and Navy Guidance Need Clarification. GAO-18-146SU. Washington, D.C.: April 25, 2018. Military Readiness: Update on DOD’s Progress in Developing a Readiness Rebuilding Plan. GAO-18-441RC. Washington, D.C.: August 10, 2018. (SECRET) Military Personnel: Collecting Additional Data Could Enhance Pilot Retention Efforts. GAO-18-439. Washington, D.C.: June 21, 2018. F-35 Joint Strike Fighter: Development Is Nearly Complete, but Deficiencies Found in Testing Need to Be Resolved. GAO-18-321. Washington, D.C.: June 5, 2018. Warfighter Support: DOD Needs to Share F-35 Operational Lessons Across the Military Services. GAO-18-464R. Washington, D.C.: April 25, 2018. Military Readiness: Clear Policy and Reliable Data Would Help DOD Better Manage Service Members’ Time Away from Home. GAO-18-253. Washington, D.C.: April 25, 2018. Military Personnel: DOD Needs to Reevaluate Fighter Pilot Workforce Requirements. GAO-18-113. Washington, D.C.: April 11, 2018. Military Aircraft: F-35 Brings Increased Capabilities, but the Marine Corps Needs to Assess Challenges Associated with Operating in the Pacific. GAO-18-79C. Washington, D.C.: March 28, 2018. (SECRET) Navy and Marine Corps Training: Further Planning Needed for Amphibious Operations Training. GAO-18-212T. Washington, DC.: December 1, 2017. F-35 Aircraft Sustainment: DOD Needs to Address Challenges Affecting Readiness and Cost Transparency. GAO-18-75. Washington, D.C.: October 26, 2017. Defense Supply Chain: DOD Needs Complete Information on Single Sources of Supply to Proactively Manage the Risks. GAO-17-768. Washington, D.C.: September 28, 2017. Navy and Marine Corps Training: Further Planning Needed for Amphibious Operations Training. GAO-17-789. Washington, D.C.: September 26, 2017. Navy Readiness: Actions Needed to Address Persistent Maintenance, Training, and Other Challenges Facing the Fleet. GAO-17-809T. Washington, D.C.: September 19, 2017. Naval Shipyards: Actions Needed to Improve Poor Conditions That Affect Operation. GAO-17-548. Washington, D.C.: September 12, 2017. Navy Readiness: Actions Needed to Address Persistent Maintenance, Training, and Other Challenges Facing the Fleet. GAO-17-798T. Washington, D.C.: September 7, 2017. Navy Readiness: Actions Needed to Maintain Viable Surge Sealift and Combat Logistics Fleets GAO-17-503. Washington, D.C.: August 22, 2017 (reissued on Oct 31, 2017). Department of Defense: Actions Needed to Address Five Key Mission Challenges. GAO-17-369. Washington, D.C.: June 13, 2017. Military Readiness: Coastal Riverine Force Challenges. GAO-17-462C. Washington, D.C.: June 13, 2017. (SECRET) Navy Shipbuilding: Policy Changes Needed to Improve the Post-Delivery Process and Ship Quality. GAO-17-418. Washington, D.C.: July 13, 2017 Offshore Petroleum Discharge System: The Navy Has Not Mitigated Risk Associated with System Limitations. GAO-17-531C. Washington, D.C.: June 22, 2017. (SECRET) Navy Force Structure: Actions Needed to Ensure Proper Size and Composition of Ship Crews. GAO-17-413. Washington, D.C.: May 18, 2017. Military Readiness: DOD’s Readiness Rebuilding Efforts May Be at Risk without a Comprehensive Plan. GAO-16-841. Washington, D.C.: September 7, 2016. Military Readiness: DOD’s Readiness Rebuilding Efforts May Be at Risk without a Comprehensive Plan. GAO-16-534C. Washington, D.C.: June 30, 2016. (SECRET) Defense Inventory: Further Analysis and Enhanced Metrics Could Improve Service Supply and Depot Operations. GAO-16-450. Washington, D.C.: June 9, 2016. Navy and Marine Corps: Services Face Challenges to Rebuilding Readiness. GAO-16-481RC. Washington, D.C.: May 25, 2016. (SECRET//NOFORN) Military Readiness: Progress and Challenges in Implementing the Navy’s Optimized Fleet Response Plan. GAO-16-466R. Washington, D.C.: May 2, 2016. F-35 Sustainment: DOD Needs a Plan to Address Risks Related to Its Central Logistics System. GAO-16-439. Washington, D.C.: April 14, 2016. Navy Force Structure: Sustainable Plan and Comprehensive Assessment Needed to Mitigate Long-Term Risks to Ships Assigned to Overseas Homeports. GAO-15-329. Washington, D.C.: May 29, 2015. This is a work of the U.S. government and is not subject to copyright protection in the United States. The published product may be reproduced and distributed in its entirety without further permission from GAO. However, because this work may contain copyrighted images or other material, permission from the copyright holder may be necessary if you wish to reproduce this material separately.
The Federal Housing Administration (FHA) is an agency of the Department of Housing and Urban Development (HUD) that insures private mortgage lenders against the possibility of borrowers defaulting on certain mortgage loans. If a mortgage borrower defaults on a mortgage—that is, does not repay the mortgage as promised—and the home goes to foreclosure, FHA is to pay the lender the remaining amount that the borrower owes. FHA insurance protects the lender, rather than the borrower, in the event of borrower default; a borrower who defaults on an FHA-insured mortgage will still experience the consequences of foreclosure. To be eligible for FHA insurance, the mortgage must be originated by a lender that has been approved by FHA, and the mortgage and the borrower must meet certain criteria. FHA is one of three government agencies that provide insurance or guarantees on certain home mortgages made by private lenders, along with the Department of Veterans Affairs (VA) and the United States Department of Agriculture (USDA). Of these federal mortgage insurance programs, FHA is the most broadly targeted. Unlike VA- and USDA-insured mortgages, the availability of FHA-insured mortgages is not limited by factors such as veteran status, income, or whether the property is located in a rural area. However, the availability or attractiveness of FHA-insured mortgages may be limited by other factors, such as the maximum mortgage amount that FHA will insure, the fees that it charges for insurance, and its eligibility standards. This report provides background on FHA's history and market role and an overview of the basic eligibility and underwriting criteria for FHA-insured home loans. It also provides data on the number and dollar volume of mortgages that FHA insures, along with data on FHA's market share in recent years. It does not go into detail on the financial status of the FHA mortgage insurance fund. For information on FHA's financial position, see CRS Report R42875, FHA Single-Family Mortgage Insurance: Financial Status of the Mutual Mortgage Insurance Fund (MMI Fund) . The Federal Housing Administration was created by the National Housing Act of 1934, during the Great Depression, to encourage lending for housing and to stimulate the construction industry. Prior to the creation of FHA, few mortgages exceeded 50% of the property's value and most mortgages were written for terms of five years or less. Furthermore, mortgages were typically not structured to be fully repaid by the end of the loan term; rather, at the end of the five-year term, the remaining loan balance had to be paid in a lump sum or the mortgage had to be renegotiated. During the Great Depression, lenders were unable or unwilling to refinance many of the loans that became due. Thus, many borrowers lost their homes through foreclosure, and lenders lost money because property values were falling. Lenders became wary of the mortgage market. FHA institutionalized a new idea: 20-year mortgages on which the loan would be completely repaid at the end of the loan term. If borrowers defaulted, FHA insured that the lender would be fully repaid. By standardizing mortgage instruments and setting certain standards for mortgages, the creation of FHA was meant to instill confidence in the mortgage market and, in turn, help to stimulate investment in housing and the overall economy. Eventually, lenders began to make long-term mortgages without FHA insurance if borrowers made significant down payments. Over time, 15- and 30-year mortgages have become standard mortgage products. When the Department of Housing and Urban Development (HUD) was created in 1965, FHA became part of HUD. Today, FHA is intended to facilitate access to affordable mortgages for some households who otherwise might not be well-served by the private market. Furthermore, it facilitates access to mortgages during economic or mortgage market downturns by continuing to insure mortgages when the availability of mortgage credit has otherwise tightened. For this reason, it is said to play a "countercyclical" role in the mortgage market—that is, it tends to insure more mortgages when the mortgage market or overall economy is weak, and fewer mortgages when the economy is strong and other types of mortgages are more readily available. Some prospective homebuyers may have the income to sustain monthly mortgage payments but lack the funds to make a large down payment or otherwise have difficulty obtaining a mortgage. Borrowers with small down payments, weaker credit histories, or other characteristics that increase their credit risk might find it difficult to obtain a mortgage at an affordable interest rate or to qualify for a mortgage at all. This has raised a policy concern that some borrowers with the income to repay a mortgage might be unable to obtain affordable mortgages. FHA mortgage insurance is intended to make lenders more willing to offer affordable mortgages to these borrowers by insuring the lender against the possibility of borrower default. FHA-insured loans have lower down payment requirements than most conventional mortgages. (Conventional mortgages are mortgages that are not insured by FHA or guaranteed by another government agency, such as VA or USDA. ) Because saving for a down payment is often the biggest barrier to homeownership for first-time homebuyers and lower- or moderate-income homebuyers, the smaller down payment requirement for FHA-insured loans may allow some households to obtain a mortgage earlier than they otherwise could. (Borrowers with down payments of less than 20% could also obtain non-FHA mortgages with private mortgage insurance. See the nearby text box on "FHA and Private Mortgage Insurance.") FHA-insured mortgages also have less stringent requirements related to credit history than many conventional loans. This might make FHA-insured mortgages attractive to borrowers without traditional credit histories or with weaker credit histories, who would either find it difficult to take out a mortgage absent FHA insurance or may find it more expensive to do so. FHA-insured mortgages play a particularly large role for first-time homebuyers, low- and moderate-income households, and minorities. For example, 83% of FHA-insured mortgages made to purchase a home (rather than to refinance an existing mortgage) in FY2018 were obtained by first-time homebuyers. Over one-third of all FHA loans (both purchase and refinance loans) were obtained by minority households, and FHA-insured mortgages accounted for about 57% of all forward mortgages made to low- or moderate-income borrowers during the year. Since FHA-insured mortgages are often obtained by borrowers who cannot make large down payments or those with weaker credit histories, some have questioned whether FHA-insured mortgages are similar to subprime mortgages. Like subprime mortgages, FHA-insured mortgages are often obtained by borrowers with lower credit scores, though some borrowers with higher credit scores also obtain FHA-insured mortgages. However, FHA-insured mortgages are prohibited from carrying the full range of features that many subprime mortgages could carry. For example, FHA-insured loans must be fully documented, and they cannot include features such as negative amortization. (FHA mortgages can include adjustable interest rates.) Some of these types of features appear to have contributed to high default and foreclosure rates on subprime mortgages. Nevertheless, some have suggested that FHA-insured mortgages are too risky, and that they can harm borrowers by providing mortgages that often have a higher likelihood of default than other mortgages due to combinations of risk factors such as low down payments and lower credit scores. Traditionally, FHA plays a countercyclical role in the mortgage market, meaning that it tends to insure more mortgages when mortgage credit markets are tight and fewer mortgages when mortgage credit is more widely available. A major reason for this is that FHA continues to insure mortgages that meet its standards even during market downturns or in regions experiencing economic turmoil. When the economy is weak and lenders and private mortgage insurers tighten credit standards and reduce lending activity, FHA-insured mortgages may be the only mortgages available to some borrowers, or may have more favorable terms than mortgages that lenders are willing to make without FHA insurance. When the economy is strong and mortgage credit is more widely available, many borrowers may find it easier to qualify for affordable conventional mortgages. This section briefly describes some of the major features of FHA-insured mortgages for purchasing or refinancing a single-family home. Single-family homes are defined as properties with one to four separate dwelling units. FHA-insured loans are available to borrowers who intend to be owner-occupants and who can demonstrate the ability to repay the loan according to the terms of the contract. FHA-insured loans must be underwritten in accordance with accepted practices of prudent lending institutions and FHA requirements. Lenders must examine factors such as the applicant's credit, financial status, monthly shelter expenses, funds required for closing expenses, effective monthly income, and debts and obligations. In general, individuals who have previously been subject to a mortgage foreclosure are not eligible for FHA-insured loans for at least three years after the foreclosure. As a general rule, the applicant's prospective mortgage payment should not exceed 31% of gross effective monthly income. The applicant's total obligations, including the proposed housing expenses, should not exceed 43% of gross effective monthly income. If these ratios are not met, the borrower may be able to present the presence of certain compensating factors, such as cash reserves, in order to qualify for an FHA-insured loan. Since October 4, 2010, FHA has required a minimum credit score of 500, and has required higher down payments from borrowers with credit scores below 580 than from borrowers with credit scores above that threshold. See the " Down Payment " section for more information on down payment requirements for FHA-insured loans. In general, borrowers must intend to occupy the property as a principal residence. FHA-insured loans may be used to purchase one-family detached homes, townhomes, rowhouses, two- to four-unit buildings, manufactured homes and lots, and condominiums in developments approved by FHA. FHA-insured loans may also be obtained to build a home; to repair, alter, or improve a home; to refinance an existing home loan; to simultaneously purchase and improve a home; or to make certain energy efficiency or weatherization improvements in conjunction with a home purchase or mortgage refinance. FHA-insured mortgages may be obtained with loan terms of up to 30 years. The interest rate on an FHA-insured loan is negotiated between the borrower and lender. The borrower has the option of selecting a loan with an interest rate that is fixed for the life of the loan or one on which the rate may be adjusted annually. FHA requires a lower down payment than many other types of mortgages. Under changes made by the Housing and Economic Recovery Act of 2008 (HERA, P.L. 110-289 ), borrowers are required to contribute at least 3.5% in cash or its equivalent to the cost of acquiring a property with an FHA-insured mortgage. (Prior law had required borrowers to contribute at least 3% in cash or its equivalent.) Prohibited sources of the required funds include the home seller, any entity that financially benefits from the transaction, and any third party that is directly or indirectly reimbursed by the seller or by anyone that would financially benefit from the transaction. HUD has interpreted the 3.5% cash contribution as a down payment requirement and has specified that contributions toward closing costs cannot be counted toward it. Since October 4, 2010, FHA has required a 10% down payment from borrowers with credit scores between 500 and 579, while borrowers with credit scores of 580 or above are still required to make a down payment of at least 3.5%. FHA no longer insures loans made to borrowers with credit scores below 500. There is no income limit for borrowers seeking FHA-insured loans. However, FHA-insured mortgages cannot exceed a maximum mortgage amount set by law. The maximum mortgage amounts allowed for FHA-insured loans vary by area, based on a percentage of area median home prices. Different limits are in effect for one-unit, two-unit, three-unit, and four-unit properties. The limits are subject to a statutory floor and ceiling; that is, the maximum mortgage amount that FHA will insure in a given area cannot be lower than the floor, nor can it be higher than the ceiling. In 2008, Congress temporarily increased the maximum mortgage amounts in response to turmoil in the housing and mortgage markets, with the intention of allowing more households to qualify for FHA-insured mortgages during a period of tighter credit availability. New permanent maximum mortgage amounts were later established by the Housing and Economic Recovery Act of 2008. The maximum mortgage amounts established by HERA were higher than the previous permanent limits, but in many cases lower than the temporarily increased limits. However, the higher temporary limits were extended for several years, until they expired at the end of calendar year 2013. Since January 1, 2014, the maximum mortgage amounts have been set at the permanent HERA levels. For a one-unit home, HERA established the maximum mortgage amounts at 115% of area median home prices, with a floor set at 65% of the Freddie Mac conforming loan limit and a ceiling set at 150% of the Freddie Mac conforming loan limit. For calendar year 2019, the floor is $314,827 and the ceiling is $726,525. (That is, FHA will insure mortgages with principal balances up to $314,827 in all areas of the country. In higher-cost areas, it will insure mortgages with principal balances up to 115% of the area median home price, up to a cap of $726,525 in the highest-cost areas.) These maximum mortgage amounts, and the maximum mortgage amounts for 2-4 unit homes, are shown in Table 1 . Borrowers of FHA-insured loans pay an up-front mortgage insurance premium (MIP) and annual mortgage insurance premiums in exchange for FHA insurance. These premiums are set as a percentage of the loan amount. The maximum amounts that FHA is allowed to charge for the annual and the upfront premiums are set in statute. However, since these are maximum amounts, HUD has the discretion to set the premiums at lower levels. The maximum up-front premium that FHA may charge is 3% of the mortgage amount, or 2.75% of the mortgage amount for a first-time homebuyer who has received homeownership counseling. Currently, FHA is charging the same up-front premiums to first-time homebuyers who receive homeownership counseling and all other borrowers. Since April 9, 2012, HUD has set the up-front premium at 1.75% of the loan amount, whether or not the borrower is a first-time homebuyer who received homeownership counseling. This premium applies to most single-family mortgages. The amount of the maximum annual premium varies based on the loan's initial loan-to-value ratio. For most loans, (1) if the loan-to-value ratio is above 95%, the maximum annual premium is 1.55% of the loan balance, and (2) if the loan-to-value ratio is 95% or below, the maximum annual premium is 1.5% of the loan balance. FHA increased the actual annual premiums that it charges several times in recent years in order to bring more money into the FHA insurance fund and ensure that it has sufficient funds to pay for defaulted loans. However, in January 2015, FHA announced a decrease in the annual premium for most single-family loans. For most FHA case numbers assigned on or after January 26, 2015, the annual premiums are 0.85% of the outstanding loan balance if the initial loan-to-value ratio is above 95% and 0.80% of the outstanding loan balance if the initial loan-to-value ratio is 95% or below. This is a decrease from 1.35% and 1.30%, respectively, which is what FHA had been charging from April 1, 2013, until January 26, 2015. These premiums apply to most single-family mortgages; FHA charges different annual premiums in certain circumstances, including for loans with shorter loan terms or higher principal balances. Table 2 shows the up-front and annual mortgage insurance premiums that have been in effect for most loans since January 26, 2015. In the past, if borrowers prepaid their loans, they may have been due refunds of part of the up-front insurance premium that was not "earned" by FHA. The refund amount depended on when the mortgage closed and declined as the loan matured. The Consolidated Appropriations Act 2005 ( P.L. 108-447 ) amended the National Housing Act to provide that, for mortgages insured on or after December 8, 2004, borrowers are not eligible for refunds of up-front mortgage insurance premiums except when borrowers are refinancing existing FHA-insured loans with new FHA-insured loans. After three years, the entire up-front insurance premium paid by borrowers who refinance existing FHA-insured loans with new FHA-insured loans is considered "earned" by FHA, and these borrowers are not eligible for any refunds. The annual mortgage insurance premiums are not refundable. However, beginning with loans closed on or after January 1, 2001, FHA had followed a policy of automatically cancelling the annual mortgage insurance premium when, based on the initial amortization schedule, the loan balance reached 78% of the initial property value. However, for loans with FHA case numbers assigned on or after June 3, 2013, FHA will continue to charge the annual mortgage insurance premium for the life of the loan for most mortgages. This change responded to concerns about the financial status of the FHA insurance fund. FHA has stated that, since it continues to insure the entire remaining mortgage amount for the life of the loan, and since premiums were cancelled on the basis of the loan amortizing to a percentage of the initial property value rather than the current value of the home, FHA has at times had to pay insurance claims on defaulted mortgages where the borrowers were no longer paying annual mortgage insurance premiums. An FHA-insured mortgage is considered delinquent any time a payment is due and not paid. Once the borrower is 30 days late in making a payment, the mortgage is considered to be in default. In general, mortgage servicers may initiate foreclosure on an FHA-insured loan when three monthly installments are due and unpaid, and they must initiate foreclosure when six monthly installments are due and unpaid, except when prohibited by law. A program of loss mitigation strategies was authorized by Congress in 1996 to minimize the number of FHA loans entering foreclosure, and has since been revised and expanded to include additional loss mitigation options. Prior to initiating foreclosure, mortgage servicers must attempt to make contact with borrowers and evaluate whether they qualify for any of these loss mitigation options. The options must be considered in a specific order, and specific eligibility criteria apply to each option. Some loss mitigation options, referred to as home retention options, are intended to help borrowers remain in their homes. Other loss mitigation options, referred to as home disposition options, will result in the borrower losing his or her home, but avoiding some of the costs of foreclosure. The loss mitigation options that servicers are instructed to pursue on FHA-insured loans are summarized in Table 3 . Additional loss mitigation options are available for certain populations of borrowers. For example, defaulted borrowers in military service may be eligible to suspend the principal portion of monthly payments and pay only interest for the period of military service, plus three months. On resumption of payment, loan payments are adjusted so that the loan will be paid in full according to the original amortization. Certain loss mitigation options are also available in areas affected by presidentially declared major disasters. FHA's single-family mortgage insurance program is funded through FHA's Mutual Mortgage Insurance Fund (MMI Fund). Cash flows into the MMI Fund primarily from insurance premiums and proceeds from the sale of foreclosed homes. Cash flows out of the MMI Fund primarily to pay claims to lenders for mortgages that have defaulted. This section provides a brief overview of (1) how the FHA-insured mortgages insured under the MMI Fund are accounted for in the federal budget and (2) the MMI Fund's compliance with a statutory capital ratio requirement. For more detailed information on the financial status of the MMI Fund, see CRS Report R42875, FHA Single-Family Mortgage Insurance: Financial Status of the Mutual Mortgage Insurance Fund (MMI Fund) . The Federal Credit Reform Act of 1990 (FCRA) specifies the way in which the costs of federal loan guarantees, including FHA-insured loans, are recorded in the federal budget. The FCRA requires that the estimated lifetime cost of guaranteed loans (in net present value terms) be recorded in the federal budget in the year that the loans are insured. When the present value of the lifetime cash flows associated with the guaranteed loans is expected to result in more money coming into the account than flowing out of it, the program is said to generate negative credit subsidy. When the present value of the lifetime cash flows associated with the guaranteed loans is expected to result in less money coming into the account than flowing out of it, the program is said to generate positive credit subsidy. Programs that generate negative credit subsidy result in offsetting receipts for the federal government, while programs that generate positive credit subsidy require an appropriation to cover the cost of new loan guarantees. The MMI Fund has historically been estimated to generate negative credit subsidy in the year that the loans are insured and therefore has not required appropriations to cover the expected costs of loans to be insured. The MMI Fund does receive appropriations to cover salaries and administrative contract expenses. The amount of money that loans insured in a given year actually earn for or cost the government over the course of their lifetime is likely to be different from the original credit subsidy estimates. Therefore, each year as part of the annual budget process, each prior year's credit subsidy rates are re-estimated based on the actual performance of the loans and other factors, such as updated economic projections. These re-estimates affect the way in which funds are held in the MMI Fund's two primary accounts: the Financing Account and the Capital Reserve Account. The Financing Account holds funds to cover  expected  future costs of FHA-insured loans. The Capital Reserve Account holds additional funds to cover any additional unexpected future costs. Funds are transferred between the two accounts each year on the basis of the re-estimated credit subsidy rates to ensure that enough is held in the Financing Account to cover updated projections of expected costs of insured loans.  If FHA ever needs to transfer more funds to the Financing Account than it has in the Capital Reserve Account, it can receive funds from Treasury to make this transfer under existing authority and without any additional congressional action. This occurred for the first time at the end of FY2013, when FHA received $1.7 billion from Treasury to make a required transfer of funds between the accounts. The funds that FHA received from Treasury did not need to be spent immediately, but were to be held in the Financing Account and used to pay insurance claims, if necessary, only after the remaining funds in the Financing Account were spent. The MMI Fund has not needed any additional funds from Treasury to make required transfers of funds between the two accounts since that time. The MMI Fund is also required by statute to maintain a capital ratio of at least 2%, which is intended to ensure that the fund is able to withstand some increases in the costs of loans guaranteed under the insurance fund. The capital ratio measures the amount of funds that the MMI Fund currently has on hand, plus the net present value of the expected future cash flows associated with the mortgages that FHA currently insures (e.g., the amounts it expects to earn through premiums and lose through claims paid). It then expresses this amount as a percentage of the total dollar volume of mortgages that FHA currently insures. In other words, the capital ratio is a measure of the amount of funds that would remain in the MMI Fund after all expected future cash flows on the loans that it currently insures have been realized, assuming that FHA did not insure any more loans going forward. Beginning in FY2009, and for several years thereafter, the capital ratio was estimated to be below this mandated 2% level. The capital ratio again exceeded the 2% threshold in FY2015, when it was estimated to be 2.07%. This represented an improvement from an estimated capital ratio of 0.41% at the end of FY2014, and from negative estimated capital ratios at the ends of FY2013 and FY2012. The capital ratio has remained above 2% since that time, and was estimated to be 2.76% in FY2018. A low or negative capital ratio does not in itself trigger any special assistance from Treasury, but it raises concerns that FHA could need assistance in order to continue to hold enough funds in the Financing Account to cover expected future losses. In the years since the housing market turmoil that began around 2007, FHA has taken a number of steps designed to strengthen the insurance fund. These steps have included increasing the mortgage insurance premiums charged to borrowers; strengthening underwriting requirements, such as by instituting higher down payment requirements for borrowers with the lowest credit scores; and increasing oversight of FHA-approved lenders. The number of new mortgages insured by FHA in a given year depends on a variety of factors. In general, the number of new mortgages insured by FHA increased during the housing market turmoil (and resulting contraction of mortgage credit) that began around 2007, reaching a peak of 1.8 million mortgages in FY2009 before beginning to decrease somewhat. FY2014 was the only year since FY2007 that FHA insured fewer than 1 million new mortgages. As shown in Table 4 , FHA insured just over 1 million new single-family purchase and refinance mortgages in FY2018. Together, these mortgages had an initial loan balance of $209 billion. About 77% (776,284) of the mortgages were for home purchases, while about 23% (238,325) were for refinancing an existing mortgage. The overall number of mortgages insured by FHA in FY2018 represented a decrease from FY2017, when it insured 1.25 million mortgages. Many FHA-insured mortgages are obtained by first-time homebuyers, lower-and moderate-income homebuyers, and minority homebuyers. Of the home purchase mortgages insured by FHA in FY2018, about 83% were made to first-time homebuyers. Over a third of all mortgages (both for home purchases and refinances) insured by FHA in FY2018 were made to minority borrowers. As shown in Table 5 , at the end of FY2018 FHA was insuring a total of over 8 million single-family loans that together had an outstanding balance of nearly $1.2 trillion. Since it was first established in 1934, FHA has insured a total of over 47.5 million home loans. FHA's share of the mortgage market is the amount of mortgages that are insured by FHA compared to the total amount of mortgages originated or outstanding in a given time period. FHA's market share can be measured in a number of different ways. Therefore, when evaluating FHA's market share, it is important to recognize which of several different figures is being reported. First, FHA's share of the mortgage market can be computed as the number of FHA-insured mortgages divided by the total number of mortgages, or as the dollar volume of FHA-insured mortgages divided by the total dollar volume of mortgages. Furthermore, FHA's market share is sometimes reported as a share of all mortgages , and sometimes only as a share of home purchase mortgages (as opposed to both mortgages made to purchase a home and mortgages made to refinance an existing mortgage). A market share figure can be reported as a share of all mortgages originated within a specific time period , such as a given year, or as a share of all mortgages outstanding at a point in time , regardless of when they were originated. Finally, FHA's market share is sometimes also reported as a share of the total number of mortgages that have some kind of mortgage insurance (including mortgages with private mortgage insurance and mortgages insured by another government agency) rather than as a share of all mortgages regardless of whether or not they have mortgage insurance. FHA's market share tends to fluctuate in response to economic conditions and other factors. Between calendar years 1996 and 2002, FHA's market share averaged about 14% of the home purchase mortgage market and about 11% of the overall mortgage market (both home purchase mortgages and refinance mortgages), as measured by number of mortgages. However, by 2005 FHA's market share had fallen to less than 5% of home-purchase mortgages and about 3% of the overall mortgage market. Subsequently, as economic conditions worsened and mortgage credit tightened in response to housing market turmoil that began around 2007, FHA's market share rose sharply, peaking at over 30% of home-purchase mortgages in 2009 and 2010, and over 20% of all mortgages (including both home purchases and refinances) in 2009. In 2017, FHA insured 19.5% of new home purchase mortgages and about 16.7% of new mortgages overall, a small decrease compared to its market share in 2016. Figure 1 shows FHA's market share as a percentage of the total number of new mortgages originated for each calendar year between 1996 and 2017. As described, FHA's market share can be measured in a number of different ways. The figure shows FHA's share of (1) all newly originated mortgages, (2) just newly originated purchase mortgages, and (3) just newly originated refinance mortgages. FHA's share of home purchase mortgages tends to be the highest, largely because borrowers who refinance are more likely to have built up a greater amount of equity in their homes and, therefore, might be more likely to obtain conventional mortgages. For the number of mortgages insured by FHA in each year calendar since 1996, see the Appendix . The increase in FHA's market share after 2007 was due to a variety of factors related to the housing market turmoil and broader economic instability that was taking place at the time. Housing and economic conditions led many banks to limit their lending activities, including lending for mortgages. Similarly, private mortgage insurance companies, facing steep losses from past mortgages, began tightening the underwriting criteria for mortgages that they would insure. Furthermore, in 2008 Congress increased the maximum mortgage amounts that FHA can insure, which may have made FHA-insured mortgages a more viable option for some borrowers in certain areas. More recently, FHA's market share has decreased somewhat from its peak during the housing market turmoil, although it generally remains somewhat higher than it was in the late 1990s and early 2000s. A number of factors may have contributed to this decrease, including lower loan limits in some high-cost areas, higher mortgage insurance premiums, and greater availability of non-FHA-insured mortgages. While not the focus of this report, the appropriate market share for FHA has been a subject of ongoing debate among policymakers. It is likely to continue to be a topic of debate, both in the context of policies specifically related to FHA as well as part of broader debate about the future of the U.S. housing finance system. Table A-1 provides data on the number of mortgages insured by FHA in each calendar year since 1996, along with FHA's overall market share in each calendar year.
This report provides background information and potential oversight issues for Congress on the Gerald R. Ford (CVN-78) class aircraft carrier program. The Navy's proposed FY2019 budget requests a total of $2,347 million (i.e., about $2.3 billion) in procurement funding for the CVN-78 program. Congress's decisions on the CVN-78 program could substantially affect Navy capabilities and funding requirements and the shipbuilding industrial base. The Navy's FY2020 budget submission also proposed to not fund the mid-life nuclear refueling overhaul (called a Refueling Complex Overhaul, or RCOH) for the aircraft carrier CVN-75 ( Harry S. Truman ), and to instead retire the ship around FY2024 and also deactivate one of the Navy's carrier air wings at about the same time. On April 30, 2019, however, the Administration announced that it was effectively withdrawing this proposal from the Navy's FY2020 budget submission. The Administration now supports funding the CVN-75 RCOH and keeping CVN-75 (and by implication its associated air wing) in service past FY2024. For additional discussion of this withdrawn budget proposal, see Appendix A . For an overview of the strategic and budgetary context in which the CVN-78 class program and other Navy shipbuilding programs may be considered, see CRS Report RL32665, Navy Force Structure and Shipbuilding Plans: Background and Issues for Congress , by Ronald O'Rourke. The Navy's current aircraft carrier force consists of 11 nuclear-powered ships, including 10 Nimitz-class ships (CVNs 68 through 77) that entered service between 1975 and 2009, and one Gerald R. Ford (CVN-78) class ship that was commissioned into service on July 22, 2017. 10 U.S.C. 8062(b) requires the Navy to maintain a force of not less than 11 operational aircraft carriers. The requirement for the Navy to maintain not less than a certain number of operational aircraft carriers was established by Section 126 of the FY2006 National Defense Authorization Act ( H.R. 1815 / P.L. 109-163 of January 6, 2006), which set the number at 12 carriers. The requirement was changed from 12 carriers to 11 carriers by Section 1011(a) of the FY2007 John Warner National Defense Authorization Act ( H.R. 5122 / P.L. 109-364 of October 17, 2006). 10 U.S.C. 8062(e), which was added by Section 1042 of the FY2017 National Defense Authorization Act ( S. 2943 / P.L. 114-328 of December 23, 2016), requires the Navy to maintain a minimum of nine carrier air wings. In December 2016, the Navy released a force-level goal for achieving and maintaining a fleet of 355 ships, including 12 aircraft carriers —one more than the minimum of 11 carriers required by 10 U.S.C. 8062(b). This was the first Navy force-level goal to call for 12 (rather than 11) carriers since a 2002-2004 Navy force-level goal for a fleet of 375 ships. Given the time needed to build a carrier and the projected retirement dates of existing carriers, increasing the carrier force from 11 ships to 12 ships on a sustained basis would take a number of years: Procuring carriers on 3-year centers—that is, procuring one carrier every three years—would achieve a 12-carrier force on a sustained basis by about 2030, unless the service lives of one or more existing carriers were substantially extended. Procuring carriers on 3.5-year centers (i.e., a combination of 3- and 4-year centers) would achieve a 12-carrier force on a sustained basis no earlier than about 2034, unless the service lives of one or more existing carriers were substantially extended. Procuring carriers on 4-year centers would achieve a 12-carrier force on a sustained basis by about 2063—almost 30 years later than under 3.5-year centers—unless the service lives of one or more existing carriers were substantially extended. Under the Navy's FY2020 30-year shipbuilding plan, as under the Navy's FY2019 30-year shipbuilding plan, carrier procurement would shift from 5-year centers to 4-year centers after the procurement of CVN-82 in FY2028, and a 12-carrier force would be achieved on a sustained basis in the 2060s. The projected size of the carrier force in the Navy's FY2020 30-year (FY2020-FY2049) shipbuilding plan reflected the Navy's now-withdrawn FY2020 budget proposal to not fund the RCOH for the aircraft carrier CVN-75 ( Harry S. Truman ), and to instead retire the ship around FY2024. With the withdrawal of this budget proposal, the projected size of the carrier force is now, for the period FY2022-FY2047, one ship higher than what is shown in the Navy's FY2020 budget submission. The newly adjusted force-level projection, reflecting the withdrawal of the proposal to retire CVN-75 around FY2024, is as follows: The force is projected to include 11 ships in FY2020-FY2021, 12 ships in FY2022-FY2024, 11 ships in FY2025-FY2026, 10 ships in FY2027, 11 ships in FY2028-FY2039, 10 ships in FY2040, 11 ships in FY2041, 10 ships in FY2042-FY2044, 11 ships in FY2045, 10 ships in FY2046-FY2047, 9 ships in FY2048, and 10 ships in FY2049. Under incremental funding, some of the funding needed to fully fund a ship is provided in one or more years after the year in which the ship is procured. In recent years, Congress has authorized DOD to use incremental funding for procuring certain Navy ships, most notably aircraft carriers: Section 121 of the FY2007 John Warner National Defense Authorization Act ( H.R. 5122 / P.L. 109-364 of October 17, 2006) granted the Navy the authority to use four-year incremental funding for CVNs 78, 79, and 80. Under this authority, the Navy could fully fund each of these ships over a four-year period that includes the ship's year of procurement and three subsequent years. Section 124 of the FY2012 National Defense Authorization Act ( H.R. 1540 / P.L. 112-81 of December 31, 2011) amended Section 121 of P.L. 109-364 to grant the Navy the authority to use five-year incremental funding for CVNs 78, 79, and 80. Since CVN-78 was fully funded in FY2008-FY2011, the provision in practice applied to CVNs 79 and 80. Section 121 of the FY2013 National Defense Authorization Act ( H.R. 4310 / P.L. 112-239 of January 2, 2013) amended Section 121 of P.L. 109-364 to grant the Navy the authority to use six-year incremental funding for CVNs 78, 79, and 80. Since CVN-78 was fully funded in FY2008-FY2011, the provision in practice applies to CVNs 79 and 80. Section 121(c) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 ( H.R. 5515 / P.L. 115-232 of August 13, 2018) authorized incremental funding to be used for making payments under the two-ship block buy contract for the construction of CVN-80 and CVN-81. This provision does not limit the total number of years across which incremental funding may be used to procure either ship. All U.S. aircraft carriers procured since FY1958 have been built by Huntington Ingalls Industries/Newport News Shipbuilding (HII/NNS), of Newport News, VA. HII/NNS is the only U.S. shipyard that can build large-deck, nuclear-powered aircraft carriers. The aircraft carrier construction industrial base also includes roughly 2,000 supplier firms in 46 states. The Gerald R. Ford (CVN-78) class carrier design ( Figure 1 ) is the successor to the Nimitz -class carrier design. The Ford -class design uses the basic Nimitz -class hull form but incorporates several improvements, including features permitting the ship to generate more aircraft sorties per day, more electrical power for supporting ship systems, and features permitting the ship to be operated by several hundred fewer sailors than a Nimitz -class ship, reducing 50-year life-cycle operating and support (O&S) costs for each ship by about $4 billion compared to the Nimitz -class design, the Navy estimates. Navy plans call for procuring at least four Ford-class carriers—CVN-78, CVN-79, CVN-80, and CVN-81. CVN-78, which was named Gerald R. Ford in 2007, was procured in FY2008. The Navy's proposed FY2020 budget estimates the ship's procurement cost at $13,084.0 million (i.e., about $13.1 billion) in then-year dollars. The ship received advance procurement (AP) funding in FY2001-FY2007 and was fully funded in FY2008-FY2011 using congressionally authorized four-year incremental funding. To help cover cost growth on the ship, the ship received an additional $1,394.9 million in FY2014-FY2016 and FY2018 cost-to-complete procurement funding. (This $1,394.9 million is included in the above-mentioned estimated procurement cost of $13,084.0 million.) The ship was delivered to the Navy on May 31, 2017, and was commissioned into service on July 22, 2017. The Navy is currently working to complete construction, testing, and certification of the ship's 11 weapons elevators. CVN-79, which was named John F. Kennedy on May 29, 2011, was procured in FY2013. The Navy's proposed FY2020 budget estimates the ship's procurement cost at $11,327.4 million (i.e., about $11.3 billion) in then-year dollars. The ship received AP funding in FY2007-FY2012, and was fully funded in FY2013-FY2018 using congressionally authorized six-year incremental funding. The ship is being built with an improved shipyard fabrication and assembly process that incorporates lessons learned from the construction of CVN-78. A key aim of this improved process is to substantially reduce the real (i.e., inflation-adjusted) construction cost of CVN-79 compared to that of CVN-78. CVN-79 is scheduled for delivery to the Navy in September 2024. CVN-80 ( Enterprise ) and CVN-81 (not yet named) are being procured under a two-ship block buy contract that was authorized by Section 121(a)(2) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 ( H.R. 5515 / P.L. 115-232 of August 13, 2018). The provision permitted the Navy to add CVN-81 to the existing contract for building CVN-80 after the Department of Defense (DOD) made certain certifications to Congress. DOD made the certifications on December 31, 2018, and the Navy announced the award of the contract on January 31, 2019. Compared to the estimated procurement costs for CVN-80 and CVN-81 in the Navy's FY2019 budget submission, the Navy estimates under its FY2020 budget submission that the two-ship block buy contract will reduce the cost of CVN-80 by $246.6 million and the cost of CVN-81 by $2,637.3 million, for a combined reduction of $2,883.9 million (i.e., about $2.9 billion). (DOD characterizes the combined reduction as "nearly $3 billion." ) Using higher estimated baseline costs for CVN-80 and CVN-81 taken from a December 2017 Navy business case analysis, the Navy estimates under its FY2020 budget submission that the two-ship contract will reduce the cost of CVN-80 by $770.9 million and the cost of CVN-81 by $3,086.3 million, for a combined reduction of $3,857.2 million (i.e., about $3.9 billion). (DOD characterizes the combined reduction as $4 billion.) These figures are all expressed in then-year dollars, meaning dollars that are not adjusted for inflation. Regarding the difference between a savings of about $2.9 billion from the figures in the Navy's FY2019 budget submission and a savings of about $3.9 billion from the December 2017 Navy business case analysis, a February 5, 2019, press report quoted a Navy spokesman as stating that the Navy's FY2019 budget submission "already accounted for at least $1B [$1 billion] of potential savings, a two-CVN buy would save an additional $3B [$3 billion]." This suggests that the Navy, in preparing its FY2019 budget submission, may have anticipated that it would receive from Congress authority for implementing some kind of combined purchase (such as, perhaps, a combined purchase of materials) for CVN-80 and CVN-81. For additional background information on the two-ship block buy contract, see Appendix B . CVN-80, which was named Enterprise on December 1, 2012, was procured in FY2018. The Navy's proposed FY2020 budget estimates the ship's procurement cost at $12,335.1 million (i.e., about $12.3 billion) in then-year dollars. The ship received AP funding in FY2016 and FY2017, and the Navy plans to fully fund the ship in FY2018-FY2025 using incremental funding authorized by Section 121(c) of P.L. 115-232 . The Navy's proposed FY2020 budget requests $1,062.0 million in procurement funding for the ship. The ship is scheduled for delivery to the Navy in March 2028. Prior to the awarding of the two-ship block buy contract, CVN-81, which has not yet been named, was scheduled to be procured in FY2023. Following the awarding of the two-ship block buy contract, the Navy has chosen to show CVN-81 in its FY2020 budget submission as a ship to be procured in FY2020 (as opposed to a ship that was procured in FY2019). The Navy's FY2020 budget submission estimates the ship's procurement cost at $12,450.7 million (i.e., about $12.5 billion) in then-year dollars. The Navy plans to fully fund the ship beginning in FY2019 and extending beyond FY2026 using incremental funding authorized by Section 121(c) of P.L. 115-232 . The Navy's proposed FY2020 budget requests $1,285.0 million in procurement funding for the ship. The ship is scheduled for delivery to the Navy in February 2032. Table 1 shows procurement funding for CVNs 78, 79, 80, and 81 through FY2026+ (meaning FY2026 and some number of years after FY2026). Congress has established procurement cost caps for CVN-78 class aircraft carriers: Section 122 of the FY2007 John Warner National Defense Authorization Act ( H.R. 5122 / P.L. 109-364 of October 17, 2006) established a procurement cost cap for CVN-78 of $10.5 billion, plus adjustments for inflation and other factors, and a procurement cost cap for subsequent Ford-class carriers of $8.1 billion each, plus adjustments for inflation and other factors. The conference report ( H.Rept. 109-702 of September 29, 2006) on P.L. 109-364 discusses Section 122 on pages 551-552. Section 121 of the FY2014 National Defense Authorization Act ( H.R. 3304 / P.L. 113-66 of December 26, 2013) amended the procurement cost cap for the CVN-78 program to provide a revised cap of $12,887.0 million for CVN-78 and a revised cap of $11,498.0 million for each follow-on ship in the program, plus adjustments for inflation and other factors (including an additional factor not included in original cost cap). Section 122 of the FY2016 National Defense Authorization Act ( S. 1356 / P.L. 114-92 of November 25, 2015) further amended the cost cap for the CVN-78 program to provide a revised cap of $11,398.0 million for each follow-on ship in the program, plus adjustment for inflation and other factors, and with a new provision stating that, if during construction of CVN-79, the Chief of Naval Operations determines that measures required to complete the ship within the revised cost cap shall result in an unacceptable reduction to the ship's operational capability, the Secretary of the Navy may increase the CVN-79 cost cap by up to $100 million (i.e., to $11.498 billion). If such an action is taken, the Navy is to adhere to the notification requirements specified in the cost cap legislation. Section 121(a) of the FY2018 National Defense Authorization Act ( H.R. 2810 / P.L. 115-91 of December 12, 2017) further amended the cost cap for the CVN-78 program to provide a revised cap of $12,568.0 million for CVN-80 and subsequent ships in the program, plus adjustment for inflation and other factors. (The cap for CVN-79 was kept at $11,398.0 million, plus adjustment for inflation and other factors.) The provision also amended the basis for adjusting the caps for inflation, and excluded certain costs from being counted against the caps. In an August 2, 2017, letter to the congressional defense committees, then-Acting Secretary of the Navy Sean Stackley notified the committees that under subsection (b)(7) of Section 122 of P.L. 114-92 as amended by Section 121 of P.L. 113-66 —a subsection allowing increases to the cost cap for CVN-78 for "the amounts of increases or decreases in costs of that ship that are attributable solely to an urgent and unforeseen requirement identified as a result of the shipboard test program"—he had increased the cost cap for CVN-78 by $20 million, to $12,907.0 million. In a May 8, 2018, letter to the congressional defense committees, Secretary of the Navy Richard Spencer notified the committees that under subsections (b)(6) and (b)(7) of Section 122 of P.L. 114-92 as amended by Section 121 of P.L. 113-66 —subsections allowing increases to the cost cap for CVN-78 for "the amounts of increases or decreases to cost required to correct deficiencies that may affect the safety of the ship and personnel or otherwise preclude the ship from safe operation and crew certification" and for "the amounts of increases or decreases in costs of CVN 78 that are attributable solely to an urgent and unforeseen requirement identified as a result of the shipboard test program," respectively—he had increased the cost cap for CVN-78 by $120 million, to $13,027 million. Table 2 shows changes in the estimated procurement costs of CVNs 78, 79, 80, and 81 since the budget submission for FY2008—the year of procurement for CVN-78. The Navy's FY2020 budget submission proposed to not fund the mid-life nuclear refueling overhaul (called a Refueling Complex Overhaul, or RCOH) for the aircraft carrier CVN-75 ( Harry S. Truman ), and to instead retire the ship around FY2024 and also deactivate one of the Navy's carrier air wings at about the same time. On April 30, 2019, however, the Administration announced that it was effectively withdrawing this proposal from the Navy's FY2020 budget submission. The Administration now supports funding the CVN-75 RCOH and keeping CVN-75 (and by implication its associated air wing) in service past FY2024. For additional discussion of this withdrawn budget proposal, see Appendix A . One issue for Congress concerns DOD's decision to show CVN-81 in its FY2020 budget submission as a ship to be procured in FY2020, instead of a ship that was procured in FY2019. Grounds for showing CVN-81 as a ship that was procured in FY2019 would include the following: Within Section 121 of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 ( H.R. 5515 / P.L. 115-232 of August 13, 2018)—the provision that authorized the two-ship block buy contract for CVN-80 and CVN-81—subsection (a)(1) specifically authorizes a contract for the procurement of CVN-81 "beginning with the fiscal year 2019 program year." The header for subsection (a)(1) is "Procurement Authorized." Consistent with Section 121(a)(1), the funding table for the Navy's shipbuilding account in the conference report ( H.Rept. 115-874 of July 25, 2018) on H.R. 5515 shows a quantity of "1" in line 002 of the FY2019 SCN (Shipbuilding and Conversion, Navy) appropriation account. Line 002 is the line item for procurement (not advance procurement [AP]) funding for the CVN-78 program. A notation in the table for line 002 states that the procurement funding authorized for this line item is for "Authorize CVN81—One ship." The funding table does not authorize any funding for line 003 of the FY2019 SCN account—the line item for AP funding for the CVN-78 program. (AP funding is funding for the procurement of a ship to be procured in a future fiscal year.) Consistent with the two above points, the paragraph in the FY2019 DOD appropriations act (Division A of H.R. 6157 / P.L. 115-245 of September 28, 2018) that makes appropriations for the SCN account makes procurement (not AP) appropriations for the CVN-78 program. This paragraph also states that "the funds made available by this Act for the Carrier Replacement Program (CVN-80) may be available to modify or enter into a new contract for the procurement of a Ford-class aircraft carrier designated CVN–81 pursuant to section 121 of the John S. McCain National Defense Authorization Act for Fiscal Year 2019." Consistent with this bill language, the funding table for the SCN account in the joint explanatory statement for H.R. 6157 shows that this funding was provided for line 2 of the FY2019 SCN account (CVN-78 program procurement funding), not line 3 of the FY2019 SCN account (CVN-78 program AP funding). Consistent with all of the above points (and as reflected in Table 1 of this CRS report), the Navy's FY2020 budget submission shows the $618 million in FY2019 funding for CVN-81 as full funding (meaning funding for a procured ship), rather than AP funding (meaning funding for a ship to be procured in a future fiscal year). DOD's decision to show CVN-81 in its FY2020 budget submission as a ship to be procured in FY2020, instead of a ship that was procured in FY2019, affects the comparison of numbers of ships procured in FY2019 and FY2020. If DOD had decided to show CVN-81 in its FY2020 budget submission as a ship that was procured in FY2019, then the total number of ships procured in FY2019 would be 14, and the total number requested for FY2020 would be 11—3 ships, or 21%, fewer than the FY2019 total of 14. Showing CVN-81 in the FY2020 budget submission as an FY2020 ship changes the FY2019 and FY2020 totals to 13 ships and 12 ships, respectively, making number FY2020 closer to the FY2019 number. DOD's decision to show CVN-81 in its FY2020 budget submission as a ship to be procured in FY2020, instead of a ship that was procured in FY2019, also affects the aircraft carrier procurement profile shown in the Navy's FY2020 30-year (FY2020-FY2049) 30-year shipbuilding plan. If DOD had decided to show CVN-81 in its FY2020 budget submission as a ship that was procured in FY2019, the ship-procurement table in the 30-year plan would show the procurement of no carriers for the first eight years (FY2020-FY2027) of the 30-year period. Showing CVN-81 in the FY2020 budget submission as an FY2020 ship changes the presentation to show the procurement of an aircraft carrier in the first year of the 30-year period. Potential oversight questions for Congress include the following: Compliance with c ongressional intent . Is DOD's decision to show CVN-81 as a ship to be procured in FY2020, rather than as a ship that was procured in FY2019, consistent with congressional intent as shown in bill and report language for P.L. 115-232 and P.L. 115-245 ? Can DOD's decision be viewed as a challenge to Congress's Article 1 power to authorize and appropriate funds for the construction of Navy ships? If DOD's decision regarding the year of procurement for CVN-81 is accepted, would this set a precedent for the executive branch regarding its future compliance with Congressional decisions for authorizing and funding of other federal programs? Executability of FY2019 procurement funds for CVN-81. FY2019 SCN-account funding for the CVN-78 program was appropriated by Congress, and shows in the Navy's FY2020 budget-justification books, as procurement funding (meaning funding for one or more procured ships) rather than AP funding (meaning funding for one or more ships to be procured in a future fiscal year). If CVN-81 is accepted as a ship to be procured in FY2020, what implications, if any, might that have for the executability of the $618 million in FY2019 procurement (as opposed to AP) funds for CVN-81 shown in the Navy's FY2020 budget submission (as reflected in Table 1 of this CRS report)? Executability of CVN-81 during portion of FY2020 under a CR. Navy officials have testified that if the Navy operates under a continuing resolution (CR) for some part of FY2020, then absent a special legislative provision in the CR known as an anomaly, the Navy during that period likely would not be able to proceed with CVN-81, because CRs typically prevent year-to-year quantity increases in procurement programs, and treating CVN-81 as a ship to be procured in FY2020 would mean that the CVN-78 program would have a year-to-year quantity increase of zero ships in FY2019 followed by one ship in FY2020. If work on CVN-81 were to not proceed for some part of FY2020 because the Navy during that period were to operate under a CR, what impact would that have on the implementation and status of the two-ship contract for building CVN-80 and CVN-81? FY2019 and FY2020 numbers of ships procured and 30-year shipbuilding plan. What effect, if any, did considerations regarding the comparison of numbers of ships procured in FY2019 and FY2020 and the aircraft carrier procurement profile during the initial years of the 30-year shipbuilding plan have on DOD's decision to show CVN-81 in its FY2020 budget submission as a ship to be procured in FY2020, instead of a ship that was procured in FY2019? Treatment in FY2020 legislation. Since P.L. 115-232 shows CVN-81 as authorized in FY2019, how should the House and Senate Armed Services committees act on the request in the Navy's FY2020 budget submission to authorize an aircraft carrier in FY2020? If the FY2020 national defense authorization act authorizes the procurement of an aircraft carrier in FY2020, and the authorization for the procurement of an aircraft carrier in FY2019 were not rescinded, would that create confusion as to whether the ship being authorized in FY2020 was CVN-81 or CVN-82, the latter being a ship currently planned for procurement in FY2028? If the FY2019 authorization for CVN-81 were rescinded, what implications, if any, would that have for the implementation of Section 121 of P.L. 115-232 , including the award of the two-carrier contract on January 31, 2019 (i.e., during FY2019)? Another issue for Congress concerns the Navy's decision, as part of its FY2020 budget submission, to not accelerate the scheduled procurement of CVN-82 from FY2028 to an earlier fiscal year. The Navy's FY2020 budget submission shows that, as a result of the two-carrier contract, the scheduled delivery date for CVN-81 has been accelerated by seven months, to February 2032, compared to September 2032 in the Navy's FY2019 budget submission. The scheduled year of procurement for CVN-82 has not been changed—in the Navy's FY2020 budget submission, it shows as a ship to be procured in FY2028, as it did in the Navy's FY2019 budget submission. The accelerated delivery date for CVN-81, combined with the unchanged year of procurement for CVN-82, suggests that the interval between the construction of CVN-81 and construction of CVN-82 has been increased by something like seven months. Other things held equal, this increased interval could result in increased loss of learning in shifting from construction of CVN-81 to construction of CVN-82, and possibly in reduced spreading of shipyard fixed overhead costs during the construction of CVN-82. Both of these effects could increase the procurement cost of CVN-82. Potential oversight questions for Congress include the following: What impact, if any, will the accelerated delivery of CVN-81 under the two-carrier contract, combined with the unchanged year of procurement for CVN-82, have on the procurement cost of CVN-82? How might the procurement cost of CVN-82 change in real (i.e., inflation-adjusted) terms if its year of procurement were accelerated to an earlier year, such as FY2027? Another issue for Congress is whether to approve, reject, or modify the Navy's FY2020 procurement funding requests for CVN-78 program. In assessing this question, Congress could consider various factors, including whether the Navy has properly scheduled and accurately priced the work it is proposing to do on the CVN-78 program in FY2020, particularly in the context of implementing the two-carrier contract for CVN-80 and CVN-81. Another issue for Congress concerns the date for achieving the Navy's 12-ship force-level goal for aircraft carriers. As noted earlier, under the Navy's FY2020 30-year shipbuilding plan, carrier procurement would shift from 5-year centers to 4-year centers after the procurement of CVN-82 in FY2028, and a 12-carrier force would be achieved on a sustained basis in the 2060s. As also noted earlier, shifting carrier procurement to 3- or 3.5-year centers could achieve a 12-carrier fleet as soon as the 2030s, unless the service lives of one or more existing carriers were substantially extended. Other things held equal, procuring carriers on 3- or 3.5-year centers rather than 4-year centers would increase Navy funding requirements during the period of the 30-year shipbuilding plan for procuring aircraft carriers and for operating and supporting a 12-carrier force rather than a force of 11 or fewer carriers. For the past several years, cost growth in the CVN-78 program, Navy efforts to stem that growth, and Navy efforts to manage costs so as to stay within the program's cost caps have been continuing oversight issues for Congress on the CVN-78 program. As shown in Table 2 , the estimated procurement costs of CVN-78, CVN-79, and CVN-80 have grown 24.7%, 23.2%, and 15.1%, respectively, since the submission of the FY2008 budget. Cost growth on CVN-78 required the Navy to program $1,394.9 million in cost-to-complete procurement funding for the ship in FY2014-FY2016 and FY2018 (see Table 1 ). As also shown in Table 2 , however, cost growth on CVN-78, CVN-79, and CVN-80 more or less stopped in FY2013 and FY2014: while the estimated cost of CVN-78 grew considerably between the FY2008 budget (the budget in which CVN-78 was procured) and the FY2014 budget, since the FY2014 budget, it has grown by only a small amount (about 2%); while the estimated cost of CVN-79 grew considerably between the FY2008 budget and the FY2013 budget (in part because the procurement date for the ship was deferred by one year in the FY2010 budget), since the FY2013 budget it has declined by a small amount (less than 1%); and while the estimated cost of CVN-80 grew considerably between the FY2008 budget and the FY2013 budget (in part because the procurement date for the ship was deferred by two years in the FY2010 budget), since the FY2013 budget it has declined by about 11%. Section 128 of the FY2016 National Defense Authorization Act ( S. 1356 / P.L. 114-92 of November 25, 2015) states the following: SEC. 128. Limitation on availability of funds for U.S.S. John F. Kennedy (CVN–79). (a) Limitation.—Of the funds authorized to be appropriated by this Act or otherwise made available for fiscal year 2016 for procurement for the U.S.S. John F. Kennedy (CVN–79), $100,000,000 may not be obligated or expended until the date on which the Secretary of the Navy submits to the congressional defense committees the certification under subsection (b)(1) or the notification under paragraph (2) of such subsection, as the case may be, and the reports under subsections (c) and (d).... (c) Report on costs relating to CVN–79 and CVN–80.— (1) IN GENERAL.—Not later than 90 days after the date of the enactment of this Act, the Secretary of the Navy shall submit to the congressional defense committees a report that evaluates cost issues related to the U.S.S. John F. Kennedy (CVN–79) and the U.S.S. Enterprise (CVN–80). (2) ELEMENTS.—The report under paragraph (1) shall include the following: (A) Options to achieve ship end cost of no more than $10,000,000,000. (B) Options to freeze the design of CVN–79 for CVN–80, with exceptions only for changes due to full ship shock trials or other significant test and evaluation results. (C) Options to reduce the plans cost for CVN–80 to less than 50 percent of the CVN–79 plans cost. (D) Options to transition all non-nuclear Government-furnished equipment, including launch and arresting equipment, to contractor-furnished equipment. (E) Options to build the ships at the most economic pace, such as four years between ships. (F) A business case analysis for the Enterprise Air Search Radar modification to CVN–79 and CVN–80. (G) A business case analysis for the two-phase CVN–79 delivery proposal and impact on fleet deployments. Section 126 of the FY2017 National Defense Authorization Act ( S. 2943 / P.L. 114-328 of December 23, 2016) states the following: SEC. 126. Limitation on availability of funds for procurement of U.S.S. Enterprise (CVN–80). (a) Limitation.—Of the funds authorized to be appropriated by this Act or otherwise made available for fiscal year 2017 for advance procurement or procurement for the U.S.S. Enterprise (CVN–80), not more than 25 percent may be obligated or expended until the date on which the Secretary of the Navy and the Chief of Naval Operations jointly submit to the congressional defense committees the report under subsection (b). (b) Initial report on CVN–79 and CVN–80.—Not later than December 1, 2016, the Secretary of the Navy and the Chief of Naval Operations shall jointly submit to the congressional defense committees a report that includes a description of actions that may be carried out (including de-scoping requirements, if necessary) to achieve a ship end cost of— (1) not more than $12,000,000,000 for the CVN–80; and (2) not more than $11,000,000,000 for the U.S.S. John F. Kennedy (CVN–79). (c) Annual report on CVN–79 and CVN–80.— (1) IN GENERAL.—Together with the budget of the President for each fiscal year through fiscal year 2021 (as submitted to Congress under section 1105(a) of title 31, United States Code) the Secretary of the Navy and the Chief of Naval Operations shall submit a report on the efforts of the Navy to achieve the ship end costs described in subsection (b) for the CVN–79 and CVN–80. (2) ELEMENTS.—The report under paragraph (1) shall include, with respect to the procurement of the CVN–79 and the CVN–80, the following: (A) A description of the progress made toward achieving the ship end costs described in subsection (b), including realized cost savings. (B) A description of low value-added or unnecessary elements of program cost that have been reduced or eliminated. (C) Cost savings estimates for current and planned initiatives. (D) A schedule that includes— (i) a plan for spending with phasing of key obligations and outlays; (ii) decision points describing when savings may be realized; and (iii) key events that must occur to execute initiatives and achieve savings. (E) Instances of lower Government estimates used in contract negotiations. (F) A description of risks that may result from achieving the procurement end costs specified in subsection (b). (G) A description of incentives or rewards provided or planned to be provided to prime contractors for meeting the procurement end costs specified in subsection (b). Section 121(b) of the FY2018 National Defense Authorization Act ( H.R. 2810 / P.L. 115-91 of December 12, 2017) states the following: SEC. 121. Aircraft carriers. ... (b) Waiver on limitation of availability of funds for CVN–79.—The Secretary of Defense may waive subsections (a) and (b) of section 128 of the National Defense Authorization Act for Fiscal Year 2016 (Public Law 114–92; 129 Stat. 751) after a period of 60 days has elapsed following the date on which the Secretary submits to the congressional defense committees a written notification of the intent of the Secretary to issue such a waiver. The Secretary shall include in any such notification the following: (1) The rationale of the Secretary for issuing the waiver. (2) The revised test and evaluation master plan that describes when full ship shock trials will be held on Ford-class aircraft carriers. (3) A certification that the Secretary has analyzed and accepted the operational risk of the U.S.S. Gerald R. Ford deploying without having conducted full ship shock trials, and that the Secretary has not delegated the decision to issue such waiver. Sources of risk of cost growth on CVN-78 included, among other things, certain new systems to be installed on CVN-78 whose development, if delayed, could delay the completion of the ship. These systems included a new type of aircraft catapult called the Electromagnetic Launch System (EMALS), a new aircraft arresting system called the Advanced Arresting Gear (AAG), and the ship's primary radar, called the Dual Band Radar (DBR). Congress has followed these and other sources of risk of cost growth for years. In July 2016, the DOD Inspector General issued a report critical of the Navy's management of the AAG development effort. In January 2017, it was reported that after conducting a review of potential alternative systems, the Navy had decided to continue stay with its plan to install EMALs and AAG on the first three Ford-class carriers. Section 125 of the FY2017 National Defense Authorization Act ( S. 2943 / P.L. 114-328 of December 23, 2016) limited the availability of funds for the AAG program until certain conditions are met. Navy officials have stated that they are working to control the cost of CVN-79 by equipping the ship with a less expensive primary radar, by turning down opportunities to add features to the ship that would have made the ship more capable than CVN-78 but would also have increased CVN-79's cost, and by using a build strategy for the ship that incorporates improvements over the build strategy that was used for CVN-78. These build-strategy improvements, Navy officials have said, include the following items, among others: achieving a higher percentage of outfitting of ship modules before modules are stacked together to form the ship; achieving "learning inside the ship," which means producing similar-looking ship modules in an assembly line-like series, so as to achieve improved production learning curve benefits in the production of these modules; and more economical ordering of parts and materials including greater use of batch ordering of parts and materials, as opposed to ordering parts and materials on an individual basis as each is needed. For additional background information on cost growth in the CVN-78 program, Navy efforts to stem that growth, and Navy efforts to manage costs so as to stay within the program's cost caps, see Appendix C and Appendix D . Another oversight issue for Congress concerns Navy efforts to complete the construction, testing, and certification of the weapons elevators on CVN-78. (The ship's weapons elevators transport missiles and bombs from the ship's weapon magazines to the ship's flight deck, so that they can be loaded onto aircraft that are getting ready to take off from the ship.) A November 2, 2018, press report states the following: The $13 billion Gerald R. Ford aircraft carrier, the U.S. Navy's costliest warship, was delivered last year without elevators needed to lift bombs from below deck magazines for loading on fighter jets. Previously undisclosed problems with the 11 elevators for the ship built by Huntington Ingalls Industries Inc. add to long-standing reliability and technical problems with two other core systems—the electromagnetic system to launch planes and the arresting gear to catch them when they land. The Advanced Weapons Elevators, which are moved by magnets rather than cables, were supposed to be installed by the vessel's original delivery date in May 2017. Instead, final installation was delayed by problems including four instances of unsafe "uncommanded movements" since 2015, according to the Navy. While progress was being made on the carrier's other flawed systems, the elevator is "our Achilles heel," Navy Secretary Richard Spencer told reporters in August without providing details.... The Navy says that the first carrier will be fully combat-capable, including the elevators, by July—the end of its current 12-month pier-side shakedown period in Virginia. Navy weapons buyer James Geurts cited what he called "considerable progress" on the Ford, including on the elevators, in a July 6 memo to Pentagon acquisition head Ellen Lord. The Navy in May requested permission from Congress in May to increase the Ford's cost cap by $120 million, partly to fix elevator issues "to preclude any effect on the safety of the ship and personnel." The safety issues related to the uncommanded movements, the Navy said in an email.... Beci Brenton, a spokeswoman for Newport News, Virginia-based Huntington Ingalls, said "all the elevators are installed." She said the weapons elevator is among "the most advanced technologies being incorporated into" the carrier and "its completion has been delayed due to a number of first-in-class issues," Brenton said. "We are committed to working through the remaining technical challenges," she said. William Couch, a spokesman for the Naval Sea Systems Command, said the elevators are "in varying levels of construction and testing." Six are far enough along to be operated by the shipbuilder, and testing has started on two of those, he said. All 11 "should have been completed and delivered with the ship delivery," according to Couch. He said the contractor has corrected "all issues," including the "four uncommanded movements over the last three years that were discovered during the building, operational grooming, or testing phases."... A November 2010 program on PBS's "Nova" science series extolled the "Elevator of Tomorrow" being developed by Federal Equipment Co., a Cincinnati-based subcontractor to Huntington Ingalls. Doug Ridenour, president of Federal Equipment Co., said the elevator's key technologies "have been consistently demonstrated for years" in a test unit in the company's plant and any programming or software-related issues have been fixed. But "shipboard integration involves many other technology insertions not controlled by" his company, he said. At a November 27, 2018, hearing on Navy shipbuilding programs before the Seapower subcommittee of the Senate Armed Services Committee, the following exchange occurred: SENATOR TIM KAINE (continuing): There have been challenges with the advanced weapons elevators on the CVN, some of the technical difficult[ies] seem similar to those that were experienced earlier on both the [aircraft] launch and arresting systems. I think that the Navy put together independent review teams to tackle those issues and provide solutions. Are we at a point where that may be needed on the weapons elevators or are we in a position where we think the progress on the weapons elevators is satisfactory? JAMES F. GEURTS, ASSISTANT SECRETARY OF THE NAVY FOR RESEARCH, DEVELOPMENT AND ACQUISITION: Yes, sir. So there are 11 weapons elevators [and] each one of them we have to produce, test and then certify. The first two of those have been produced, the first one's been through test and certification. The second one is about 94 percent through test. We are making progress to get through all of the elevators during this availability. I am likely to do an independent review team not on the immediate construction for CVN-78 but looking at the longer-term sustainability, resilience, reliability to make sure we are in a position to support those elevators for the long term, that we've got all of the training and all of the reliability built into those. We've done so many independent reviews for the [CVN-]78 elevator design as they are so we won't do one on the current efforts on [CVN-]78. We've got a dedicated team working our way through those issues. KAINE: And is your timing on that testing and certification on [CVN-]78—you have this 12-month period where you are testing—[do] you think you will get through the testing and certification of all of the 11 elevators in that year one? GEURTS: My current assessment is we will get through all of the production and much of the testing. We may have some of the certification issues to go. I am watching it very closely and we will keep you and your staff informed on progress there. A December 5, 2018, press report stated the following: The Navy plans to complete installation and testing of the 11 elevators before the Ford completes its post-delivery shakedown phase in July, Captain Danny Hernandez, a Navy spokesman, said in an email. Six will also be certified for use by then, but five won't be completed until after July, he said. "A dedicated team is engaged on these efforts and will accelerate this certification work and schedule where feasible," he said. Huntington spokeswoman Beci Brenton said via email that company officials had a "very productive meeting" with Inhofe that included both the elevators and benefits of a two-carrier contract. The elevator's completion "has been delayed due to a number of first-in-class issues associated with the first-time installation, integration and test of this new technology," she said. "However, we are making substantial substantial progress in resolving the remaining technical challenges." A January 6, 2019, press report stated the following: The Navy Secretary has committed that the service and its industry partners will have working weapons elevators on aircraft carrier USS Gerald R. Ford (CVN-78) by the end of the summer—and the secretary's job is now on the line over that issue. The Navy accepted delivery of the first-in-class carrier and commissioned it into the fleet without any functioning weapons elevators. The carrier is now in its post-shakedown availability at builder Newport News Shipbuilding, after spending a year at sea running the ship to discover any potential flaws. Though the Navy already said the elevators would be addressed during this PSA period, the stakes are now higher: Navy Secretary Richard V. Spencer told President Donald Trump that the elevators would be installed and working by the time the carrier returns to sea, or else the president can use his famous "you're fired" line on the service secretary. Spencer said this morning at an event hosted by the Center for a New American Security that he spoke to Trump at length last month at the Army-Navy football game in Philadelphia. "I asked him to stick his hand out; he stuck his hand out. I said, let's do this like corporate America. I shook his hand and said, the elevators will be ready to go when she pulls out or you can fire me," Spencer said, adding that someone had to take accountability over the ongoing elevator challenges. "We're going to get it done. I know I'm going to get it done. I haven't been fired yet by anyone; being fired by the president really isn't on the top of my list."... The elevator issue has plagued the carrier for years, even if it garnered less attention than other high-profile new technologies on the carrier, such as the new Electromagnetic Aircraft Launch System (EMALS) and the Advanced Arresting Gear, both of which had their own fair share of technical problems. In 2016, the late Sen. John McCain (R-Ariz.), who then chaired the Senate Armed Services Committee, railed against the Ford-class program, noting that Ford was already overdue to be delivered to the Navy and still was facing ongoing technical difficulties. "The Navy's announcement of another two-month delay in the delivery of CVN-78 further demonstrates that key systems still have not demonstrated expected performance. The advanced arresting gear (AAG) cannot recover airplanes. Advanced weapons elevators cannot lift munitions. The dual-band radar cannot integrate two radar bands. Even if everything goes according to the Navy's plan, CVN-78 will be delivered with multiple systems unproven," McCain said in a July 2016 hearing. A month later the Pentagon announced a 60-day review of the Ford program, with a specific focus on five technology areas, including the elevators. Ford ultimately delivered to the Navy in June 2017 and commissioned a month later, still without working weapons elevators. In July 2018, when Ford entered PSA, the Navy said the maintenance availability had been extended from a planned eight months to a full year, to accommodate both the typical work that arises in PSA but also deferred work such as the construction and installation of weapons elevators and an upgrade to the AAG, whose technical challenges greatly contributed to the delayed delivery and commissioning of the ship. A January 16, 2019, press report stated the following: The Navy's newest aircraft carrier, USS Gerald R. Ford (CVN 78), closed out 2018 on a high note with the acceptance of the ship's first advanced weapons elevator (AWE), setting the tone for more positive developments in the year ahead. AWE Upper Stage #1 was turned over to the ship on Dec. 21, following testing and certification by engineers at Huntington Ingalls Industries-Newport News Shipbuilding, where the ship is currently working through its post-shakedown availability (PSA). The acceptance marks a major milestone for the ship and the Ford-class of aircraft carriers to follow.... Though the first elevator has been accepted, work still remains on the remaining 10. Currently, all shipboard installation and testing activities of the AWEs are due to be completed prior to the end of Ford's PSA, scheduled for July. However, some remaining certification documentation will be performed for five of the 11 elevators after PSA completion. A March 6, 2019, press report stated the following: Nearly one month following the acceptance of its first advanced weapons elevator (AWE), the Navy's newest aircraft carrier, USS Gerald R. Ford (CVN 78), has accepted its second. AWE Upper Stage #3 was turned over to the ship February 14, following testing and certification by engineers at Huntington Ingalls Industries-Newport News Shipbuilding (NNS), where the ship is currently working through its post-shakedown availability (PSA). According to Ford's Weapons Officer, Cmdr. Joe Thompson, acceptance of the second AWE offers an opportunity for Ford Sailors to become acquainted with the equipment during the PSA. "This gives us more time to learn and become subject matter experts," explained Thompson. "All of us are learning on brand new systems and brand new concepts. This acceptance gives us the opportunity to have that 'run time' on the physical aspects of the elevator, but also in evaluating the technical manuals, and learning the maintenance required to keep them operational." With two elevators in hand, Thompson explained that Sailors training on these new systems will be able to apply the lessons learned from the first elevator, Upper Stage #1, and apply them to Upper Stage #3, thereby streamlining the learning process and lessening the learning curve. "This is going to allow us to progress faster," he explained. "As we get smarter on one, we move on to the next and apply the lessons learned not only with regard to elevator operation, but also in the testing and certification, and maintenance processes."… Acceptance of the elevator was accelerated due to a merging of the test programs between NNS and the Naval Surface Warfare Center (NSWC), which removed redundant steps and moved certification up by 10 days. The team has identified other areas where redundancy can be removed to make the acceptance timelines more efficient. Another oversight issue for Congress concerns CVN-78 program issues raised in a December 2018 report from DOD's Director, Operational Test and Evaluation (DOT&E)—DOT&E's annual report for FY2018. Regarding the CVN-78 program, the report stated the following in part: Assessment • The delays in the ship development and initial trials pushed both phases of initial operational testing until FY21 and FY22. The delay in the ship's delivery and development added approximately 2 years to the timeline. As noted in previous annual reports, the CVN 78 test schedule has been aggressive, and the development of EMALS [Electromagnetic Aircraft Launch System], AAG [Advanced Arresting gear], AWE [Advanced Weapons Elevator], DBR [Dual Band Radar], and the Integrated Warfare System delayed the ship's first deployment to FY22. Reliability • Four of CVN 78's new systems stand out as being critical to flight operations: EMALS, AAG, DBR, and AWEs. Overall, the poor reliability demonstrated by AAG and EMALS and the uncertain reliability of DBR and AWEs could delay CVN 78 IOT&E [Initial Operational Test and Evaluation]. The Navy continues to test all four of these systems in their shipboard configurations aboard CVN 78. Reliability estimates derived from test data for EMALS and AAG are discussed in following subsections. For DBR and AWE, only engineering reliability estimates have been provided. EMALS • Testing to date involved 747 shipboard launches and demonstrated EMALS capability to launch aircraft planned for the CVN 78 Air Wing. • Through the first 747 shipboard launches, EMALS suffered 10 critical failures. This is well below the requirement of 4,166 Mean Cycles Between Critical Failures, where a cycle represents the launch of one aircraft. • The reliability concerns are exacerbated by the fact that the crew cannot readily electrically isolate EMALS components during flight operations due to the shared nature of the Energy Storage Groups and Power Conversion Subsystem inverters onboard CVN 78. The process for electrically isolating equipment is time-consuming; spinning down the EMALS motor/generators takes 1.5 hours by itself. The inability to readily electrically isolate equipment precludes EMALS maintenance during flight operations. AAG • Testing to date included 763 attempted shipboard landings and demonstrated AAG capability to recover aircraft planned for the CVN 78 air wing. • The Program Office redesigned major components that did not meet system specifications during land-based testing. Through the first 763 attempted shipboard landings, AAG suffered 10 operational mission failures (which includes one failure of the barricade system). This reliability estimate falls well below the re-baselined reliability growth curve and well below the requirement of 16,500 Mean Cycles Between Operational Mission Failures, where a cycle represents the recovery of one aircraft. • The reliability concerns are magnified by the current AAG design that does not allow electrical isolation of the Power Conditioning Subsystem equipment from high power buses, limiting corrective maintenance on below-deck equipment during flight operations. Combat System • Results of SBDT [sea-based developmental testing] events indicate good SSDS [ship self-defense system] performance in scheduling and launching simulated RAMs [Rolling Airframe Missiles] and ESSMs [Evolved Sea Sparrow Missiles], as well as scheduling DBR directives for ESSM acquisition and target illumination. Insufficient interoperability testing with a CEC [Cooperative Engagement Capability] network and Link 16 prevents an estimate of performance in this area. It is unknown if the integration problems between SSDS and Surface Electronic Warfare Improvement Program (SEWIP) Block 2 identified during engineering testing at Wallops Island have been resolved because SEWIP Block 2 was not installed on the ship during these SBDT events. • CVN 78's combat system testing on the SDTS [self-defense test ship] is at risk due to schedule constraints, lack of funding, and insufficient planned developmental testing. DBR • Throughout the five CVN 78 SBDTs, DBR was plagued by extraneous false and close-in dual tracks adversely affecting its performance. • Integration of the DBR electronic protection capabilities remains incomplete and unfunded. With modern threats, a lack of electronic protection places the ship in a high-risk scenario if deployed to combat. • The Navy analysis noted that DBR performance needs to be improved to support carrier air traffic control center certification. Sortie Generation Rate • CVN 78 is unlikely to achieve its SGR [sortie generation rate] requirement. The target threshold is based on unrealistic assumptions including fair weather and unlimited visibility, and that aircraft emergencies, failures of shipboard equipment, ship maneuvers, and manning shortfalls will not affect flight operations. During the 2013 operational assessment, DOT&E conducted an analysis of past aircraft carrier operations in major conflicts. The analysis concludes that the CVN 78 SGR requirement is well above historical levels. • DOT&E plans to assess CVN 78 performance during IOT&E by comparing it to the SGR requirement as well as to the demonstrated performance of the Nimitz-class carriers. • Poor reliability of key systems that support sortie generation on CVN 78 could cause a cascading series of delays during flight operations that would affect CVN 78's ability to generate sorties. The poor or unknown reliability of these critical subsystems represents the most risk to the successful completion of CVN 78 IOT&E. Manning • Based on current expected manning, the berthing capacity for officers and enlisted will be exceeded by approximately 100 personnel with some variability in the estimates. This also leaves no room for extra personnel during inspections, exercises, or routine face-to-face turnovers. • Planned ship manning requires filling 100 percent of the billets. This is not the Navy's standard practice on other ships, and the personnel and training systems may not be able to support 100 percent manning. Additionally, workload estimates for the many new technologies such as catapults, arresting gear, radar, and weapons and aircraft elevators are not yet well understood. Electromagnetic Compatibility • Developmental testing identified significant EMI [electromagnetic interference] and radiation hazard problems. The Navy continues to characterize and develop mitigation plans for the problems, but some operational limitations and restrictions are expected to persist into IOT&E and deployment. The Navy will need to develop capability assessments at differring levels of system utilization in order for commanders to make informed decisions on system employment. Live Fire Test & Evaluation • The vulnerability of CVN 78's many new critical systems to underwater threat-induced shock is unknown. The program plans to complete shock testing on EMALS, AAG, and the AWE components during CY19, but because of a scarcity of systems, shock testing of DBR components lags and will likely not be completed before the FSSTs [full ship shock trials]. • The Vulnerability Assessment Report provides an assessment of the ship's survivability to air-delivered threat engagements. The classified findings in the report identify the specific equipment that most frequently would lead to mission capability loss. In FY19, the Navy is scheduled to deliver additional report volumes that will assess vulnerability to underwater threats and compliance with Operational Requirements Document survivability criteria. Recommendations The Navy should: 1. Provide schedule, funding, and an execution strategy for assessing SGR. This strategy should specify which testing will be accomplished live, a process for accrediting the Seabasing/Seastrike Aviation Model for operational testing, and a method for comparing CVN 78 performance with that of the Nimitz class. 2. Continue to characterize the electromagnetic environment onboard CVN 78 and develop operating procedures to maximize system effectiveness and maintain safety. As applicable, the Navy should utilize the lessons learned from CVN 78 to inform design modifications for CVN 79 and future carriers. 3. Develop and implement DBR electronic protection to enhance ship survivability against modern threats. 4. Submit an updated TEMP. Another oversight issue for Congress concerns CVN-78 program issues raised in the 2019 edition of the Government Accountability Office's (GAO's) annual report surveying selected DOD weapon acquisition programs. Some of these issues raised by GAO overlap with issues discussed in previous sections of this CRS report. Regarding the CVN-78 program, the report stated the following: Technology Maturity, Design Stability, and Production Readiness The Navy accepted delivery of the lead ship, CVN 78, in May 2017 despite challenges related to immature technologies and struggles to demonstrate the reliability of mature systems. The Navy reports that 10 of the Ford Class's 12 critical technologies are fully mature—the advanced arresting gear (AAG) and one of the ship's missile systems are not yet mature. The advanced weapons elevators are among the systems deemed mature by the Navy; however, according to Navy officials, only 2 of the 11 elevators installed on the ship can bring munitions to the flight deck—a key element of operational flights. The shipbuilder is working to correct the system during its first post-delivery maintenance period, now scheduled to end in October 2019, and the Navy plans to create a land-based site to test the elevators, which will come at an additional cost. Shipboard testing is ongoing for several critical systems and could delay future operational testing. Those systems include the electromagnetic aircraft launch system (EMALS), AAG, and dual band radar (DBR). Although the Navy is testing EMALS and AAG on the ship with aircraft, the reliability of those systems remains a concern. If these systems cannot function safely, CVN 78 will not demonstrate it can rapidly deploy aircraft—a key requirement for these carriers. Recent shipboard testing revealed that the Navy is struggling to get DBR to operate as planned. Moreover, DBR poses a greater radiation hazard to personnel and systems on an aircraft carrier than the Navy anticipated, which could restrict certain types of flight operations. The remaining challenges the Navy faces in maturing CVN 78's critical technologies could lead to their redesign or replacement on later ships. This would include CVN 79, which is currently 55 percent complete, as well as the third and fourth ships, CVNs 80 and 81. CVN 79 repeats the CVN 78 design with some modifications and replaces DBR with the Enterprise Air Surveillance Radar (EASR), which is in development. The Navy does not identify this new system as a critical technology in the Ford Class program because it derives from the pre-existing Air and Missile Defense Radar (AMDR) program. However, EASR is a different size and performs a different mission than the AMDR systems, which are designed for destroyers. Therefore, EASR may still require design and development efforts to function on the carrier. The Navy plans to procure two EASR units for CVNs 79 and 80 and install the CVN 79 unit during that ship's second phase of delivery. CVNs 80 and 81 will repeat the design of CVN 79. Other Program Issues CVN 78's procurement costs increased by 23 percent over its initial cost cap and as a result of continuing technical deficiencies, the Navy may still require more funding to complete this ship. The Navy increased the current $12.9 billion cost cap for CVN 78 by $120 million in May 2018 to account for additional post-delivery work, but added work and cost changes may result in an additional cost increase. Costs for CVN 79 are also likely to increase as a result of optimistic cost and labor targets, putting the ship at risk of exceeding its $11.4 billion cost cap. The CVN 79 cost estimate assumes unprecedented construction efficiency—labor hours will be 18 percent lower than CVN 78. However, our analysis shows the shipbuilder is not meeting this goal and is unlikely to improve performance enough to meet cost and labor targets. Congress raised the cost cap for CVN 80 and later ships to $12.6 billion and approved the Navy's plans to buy two carriers—CVNs 80 and 81—at the same time, based on the shipbuilder's estimate that this strategy will save the Navy over $2 billion. However, it is unclear whether the Navy can meet this cost cap, even with the estimated savings from a two-ship buy, because it assumes further reductions in subsystem costs, construction change orders, and labor hours. The Navy projects a further reduction in labor hours compared to CVN 79—about 25 percent fewer labor hours than CVN 78—will contribute to cost savings for these ships. The program office indicated that it does not separately track or report information on software development to integrate the various subsystems of the ship. These subsystems include CVN 78's combat control systems, which rely on integrating systems through software intensive development. Program Office Comments We provided a draft of this assessment to the program office for review and comment. The program office provided technical comments, which we incorporated where appropriate. The program office stated that, in July 2018, CVN 78 entered a year-long maintenance period. It also said that, as of February 2019, two advanced weapons elevators are operating, and it continues to improve developmental system reliability. The program also stated that, with CVN 79 construction 55 percent complete, shipbuilder cost performance remains stable, but slightly below the level needed to achieve production labor hour reduction targets. The program stated that the shipbuilder continues to work through the effects of material shortfalls that disrupted performance. The program said that the Navy plans to deliver a complete, deployable ship as scheduled and within the cost cap to maintain an 11-carrier fleet. The program office also stated that the Navy awarded the CVN 80/81 procurement contract in January 2019 and expects to save $4 billion, compared to if it had purchased each ship individually. According to the program, the contract limits the Navy's liability and incentivizes the shipyard's best performance. Another oversight issue for Congress is whether the Navy should shift at some point from procuring large-deck, nuclear-powered carriers like the CVN-78 class to procuring smaller aircraft carriers. The issue has been studied periodically by the Navy and other observers over the years. To cite one example, the Navy studied the question in deciding on the aircraft carrier design that would follow the Nimitz (CVN-68) class. Advocates of smaller carriers argue that they are individually less expensive to procure, that the Navy might be able to employ competition between shipyards in their procurement (something that the Navy cannot do with large-deck, nuclear-powered carriers like the CVN-78 class, because only one U.S. shipyard, HII/NNS, can build aircraft carriers of that size), and that today's aircraft carriers concentrate much of the Navy's striking power into a relatively small number of expensive platforms that adversaries could focus on attacking in time of war. Supporters of large-deck, nuclear-powered carriers argue that smaller carriers, though individually less expensive to procure, are less cost-effective in terms of dollars spent per aircraft embarked or aircraft sorties that can be generated, that it might be possible to use competition in procuring certain materials and components for large-deck, nuclear-powered aircraft carriers, and that smaller carriers, though perhaps affordable in larger numbers, would be individually less survivable in time of war than large-deck, nuclear-powered carriers. At a March 18, 2015, hearing on Navy shipbuilding programs before the Seapower subcommittee of the Senate Armed Services Committee, the Navy testified that it had initiated a new study on the question. At the hearing, the following exchange occurred: SENATOR JOHN MCCAIN, CHAIRMAN, SENATE ARMED SERVICES COMMITTEE, ATTENDING EX OFFICIO: And you are looking at additional options to the large aircraft carrier as we know it. SEAN STACKLEY, ASSISTANT SECRETARY OF THE NAVY FOR RESEARCH, DEVELOPMENT,AND ACQUISITION: We've initiated a study and I think you've discussed this with the CNO [Chief of Naval Operations] and that's with the frontend of that study. Yes, sir. Later in the hearing, the following exchange occurred: SENATOR ROGER WICKER, CHAIRMAN, SEAPOWER SUBCOMMITTEE: Well, Senator McCain expressed concern about competition [in Navy shipbuilding programs]. And I think that was with, in regard to aircraft carriers. SEAN J. STACKLEY, ASSISTANT SECRETARY OF THE NAVY FOR RESEARCH, DEVELOPMENT,AND ACQUISITION: Yes, Sir. WICKER: Would you care to respond to that? STACKLEY: He made a generic comment that we need competition to help control cost in our programs and we are absolutely in agreement there. With specific regards to the aircraft carrier, we have been asked and we are following suit to conduct a study to look at alternatives to the Nimitz and Ford class size and type of aircraft carriers, to see if it make sense. We've done this in the past. We're not going to simply break out prior studies, dust them off and resubmit it. We're taking a hard look to see is there—is there a sweet spot, something different other than today's 100,000 ton carrier that would make sense to provide the power projection that we need, that we get today from our aircraft carriers, but at the same time put us in a more affordable position for providing that capability. WICKER: OK. But right now, he's—he's made a correct factual statement with regard to the lack of competition. STACKLEY: Yes, Sir. There is—yes, there is no other shipyard in the world that has the ability to construct a Ford or a Nimitz nuclear aircraft carrier other than what we have in Newport News and the capital investment to do that is prohibitive to set up a second source, so obviously we are—we are content, not with the lack of competition, but we are content with knowing that we're only going to have one builder for our aircraft carriers. On March 20, 2015, the Navy provided the following additional statement to the press: As indicated in testimony, the Navy has an ongoing study to explore the possible composition of our future large deck aviation ship force, including carriers. There is a historical precedent for these type[s] of exploratory studies as we look for efficiencies and ways to improve our war fighting capabilities. This study will reflect our continued commitment to reducing costs across all platforms by matching capabilities to projected threats and Also [sic] seeks to identify acquisition strategies that promote competition in naval ship construction. While I can't comment on an ongoing study, what I can tell you is that the results will be used to inform future shipbuilding budget submissions and efforts, beyond what is currently planned. Section 128 of the FY2016 National Defense Authorization Act ( S. 1356 / P.L. 114-92 of November 25, 2015) states the following: SEC. 128. Limitation on availability of funds for U.S.S. John F. Kennedy (CVN–79). (a) Limitation.—Of the funds authorized to be appropriated by this Act or otherwise made available for fiscal year 2016 for procurement for the U.S.S. John F. Kennedy (CVN–79), $100,000,000 may not be obligated or expended until the date on which the Secretary of the Navy submits to the congressional defense committees the certification under subsection (b)(1) or the notification under paragraph (2) of such subsection, as the case may be, and the reports under subsections (c) and (d).... (d) Report on future development.— (1) IN GENERAL.—Not later than April 1, 2016, the Secretary of the Navy shall submit to the congressional defense committees a report on potential requirements, capabilities, and alternatives for the future development of aircraft carriers that would replace or supplement the CVN–78 class aircraft carrier. (2) ELEMENTS.—The report under paragraph (1) shall include the following: (A) A description of fleet, sea-based tactical aviation capability requirements for a range of operational scenarios beginning in the 2025 timeframe. (B) A description of alternative aircraft carrier designs that meet the requirements described under subparagraph (A). (C) A description of nuclear and non-nuclear propulsion options. (D) A description of tonnage options ranging from less than 20,000 tons to greater than 100,000 tons. (E) Requirements for unmanned systems integration from inception. (F) Developmental, procurement, and lifecycle cost assessment of alternatives. (G) A notional acquisition strategy for the development and construction of alternatives. (H) A description of shipbuilding industrial base considerations and a plan to ensure opportunity for competition among alternatives. (I) A description of funding and timing considerations related to developing the Annual Long-Range Plan for Construction of Naval Vessels required under section 231 of title 10, United States Code. The report required by Section 128(d) of P.L. 114-92 , which was conducted for the Navy by the RAND Corporation, was delivered to the congressional defense committees in classified form in July 2016. An unclassified version of the report was then prepared and issued in 2017 as a publicly released RAND report. The executive summary of that report states the following (emphasis as in original): We analyzed the feasibility of adopting four aircraft carrier concept variants as follow-ons to the Ford-class carrier following USS Enterprise (CVN 80) or the as-yet-unnamed CVN 81. Among these options are two large-deck carrier platforms that would retain the capability to launch and recover fixed-wing aircraft using an on-deck catapult and arresting gear system and two smaller carrier platforms capable of supporting only short takeoff and vertical landing (STVOL) aircraft. Specifically, the four concept variants are as follows: • a follow-on variant continuing the current 100,000-ton Ford-class carrier but with two life-of-the-ship reactors and other equipment and system changes to reduce cost (we refer to this design concept as CVN 8X) • a 70,000-ton USS Forrestal–size carrier with an updated flight deck and hybrid nuclear-powered integrated propulsion plant with capability to embark the current large integrated air wing but with reduced sortie generation capability, survivability, and endurance compared with the Ford class (we refer to this design concept as CVN LX) • a 43,000-ton variant of the USS America–class, fossil fuel–powered and arranged to support only STOVL operations but at a higher tempo than the current LHA 6 (USS America) (we refer to this design concept as CV LX). This variant would incorporate the larger ship's beam excursion the Navy examined in the LHA 8–class flight 1 studies. • a 20,000-ton variant that will resemble escort carriers that some allied navies currently operate (we refer to this design concept as CV EX). Similar to the 43,000-ton variant, it will be conventionally powered and will operate STOVL aircraft.... Our analyses of the carrier variants illuminated capability shortfalls in some instances. Our overall findings are as follows: • The CVN 8X, the descoped Ford-class carrier, offers similar warfighting capability to that of the Ford-class carrier today. There might be opportunities to reduce costs by eliminating costly features that only marginally improve capability, but similar tradeoffs are likely to be made in the current program as well. • The CVN LX concept variant offers an integrated, current air wing with capabilities near current levels but with less organic mission endurance for weapons and aviation fuel. It will not generate the same SGR as the Ford-class carrier, but this is not a significant limitation for stressing warfighting scenarios. It will be less survivable in some environments and have less redundancy than the Ford program-of-record ship, and these factors might drive different operation concepts. Although we do not characterize the impact of decreased survivability, this is an important limitation that will have to be weighed against the potential cost savings. The major means of reducing cost is through engineering redundancy, speed, and air wing fuel capacity, and these could affect mobility and theater closure. • The concept variant CV LX, which is a version of the LHA 6 platforms, might be a low-risk, alternative pathway for the Navy to reduce carrier costs if such a variant were procured in greater numbers than the current carrier shipbuilding plan; our analysis suggests a two-to-one replacement. Over the long term, however, as the current carrier force is retired, the CV LX would not be a viable option for the eventual carrier force unless displaced capabilities were reassigned to new aircraft or platforms in the joint force, which would be costly. This platform would be feasible for a subset of carrier missions but, even for those missions, could require an increase in the number of platforms. This concept variant might, if procured in sufficient numbers, eventually enable the Navy to reduce the number of Ford-class carriers in the overall force structure, but more-extensive analysis of missions, operations, and basing of such a variant and the supported air combat element is required. • The smallest concept variants reviewed, the CV EX 20,000-ton sea-based platforms, do not provide either a significant capacity or an integrated air wing and, thus, force reliance on other legacy platforms or land-based assets to provide key elements of capability—in particular, AEW. As a result, this concept variant is not really a replacement for current aircraft carrier capability and would require other platforms, aircraft, weapons, and capabilities in the joint force. These platforms would be a viable pathway only in broad fleet architecture transformation providing a narrow mission set, perhaps regionally, and would require extensive analysis. Given that such a concept variant is not a viable replacement for an aircraft carrier, such analysis would be required to see whether any adjustment on the current aircraft carrier program would be feasible.... The overall results of our cost comparison are as follows: • The descoped Ford-class carrier, the CVN 8X, might generate fewer sorties than the current key performance parameter values for the Ford class and might have only incremental reduction in overall platform cost . The analysis examining cost reduction with transition to a life-of-the-ship reactor, such that being done on submarine programs, does not appear to be cost effective. Between the developmental costs and a reduced service life, there is little cost advantage in this variant. • The CVN LX concept would allow considerable savings across the ship's service life and appears to be a viable alternative to consider for further concept exploration . Construction costs would be lower; design changes and life-cycle costs would reflect the lessons already applied in the Ford class. The reliance on hybrid drive with fewer mechanical parts than legacy platforms is likely to further reduce maintenance cost. However, CVN LX would be a new design that would require a significant investment in nonrecurring engineering in the near term to allow timely delivery in the 2030s. • CV LX, although it requires a larger force structure to maintain air capabilities, might still reduce overall construction costs if large carrier numbers were reduced. But, as described in the report, reducing carrier numbers with the resulting loss of capability should not be pursued without extensive further analysis for all displaced missions in the joint force execution of warfighting scenarios and, potentially, regional basing and narrowly focused missions for these platforms. Any cost savings would likely be offset to an unknown degree by requirements for additional systems to mitigate loss of capability associated with this variant. • CV EX, the smallest variant, is not a practical variant at all without considerable revision of the Navy warfighting concept of operations. Although the same is to a degree true with CV LX, the impact of an even larger number of low-sortie ships with small and limited air wings is even more pronounced with this variant. CV EX has all of the shortfalls of CV LX and will pose even greater issues of mutual support and logistics sustainment.... Conclusions Our analysis points to potential options for replacing the Nimitz-class carrier as these ships reach expected service life that have lower procurement costs than the Ford-class carriers. However, most of these options come with reduced capability that might require changes in the concept of operations to deliver sea-based aircraft capability comparable to that of carriers in the fleet today. If a new platform is introduced in the mid-2030s, the Navy's force structure will still contain a large legacy force of Nimitz- and Ford-class carriers, at least until the mid-2050 time frame, which might lower the risks of introducing a new carrier for some period of time. But, ultimately, if a new carrier variant is selected, it will define the carrier force and constitute the supported capability available to the Navy. Capability shortfalls can be mitigated, to some degree, with changes in operational concepts or by adding additional platforms to the force structure—which introduces additional cost that might offset anticipated cost savings. In addition, if the Navy stops procuring large-deck nuclear carriers, the ability to reconstitute the industrial base at some time in the future comes with substantial risk. Although SGR [sortie generation rate] was a central variable in comparing the carrier variants, our analysis suggests that there is room to make trade-offs in aircraft sortie rate capacity between the Ford-class carrier and a lower-cost platform. However, it is important to consider that, whatever threats complicate carrier operations, they might even more significantly affect land-based tactical air operations. Carriers can move; have defensive support from escorts; can readily replenish; and might, in fact, be more survivable than their land-based counterparts. This is an important factor for Congress and the Department of Defense to consider before a trade-off is made to give up the supported air wing sortie generation capacity in the overall sea-based force. The question of whether to shift to smaller aircraft carriers was also addressed in three studies on future fleet architecture that were required by Section 1067 of the FY2016 National Defense Authorization Act ( S. 1356 / P.L. 114-92 of November 25, 2015). These three studies are discussed in more detail in another CRS report. A February 15, 2019, press report stated the following: Under Secretary of the Navy Thomas Modly said now that the Navy found a way to build two new Gerald R. Ford-class aircraft carriers while saving money it is starting to look at future carrier procurement, which might be very different.… Modly said Secretary of the Navy Richard Spencer sees $13 billion carriers as not sustainable going forward and the service will be looking at ways to further reduce costs or keep the carrier capabilities more affordable in future ship procurements. "There was general conclusion that those two for sure would be built" and once that was determined "that was going to happen," Modly said during the AFCEA West 2019 conference here [in San Diego].… After the CVN-80 and -81 [procurement] decision was made, "I think a lot of derivative decisions still need to be made. So the secretary [Spencer] would like to take a look at 'O.K. now that we made that decision, and that second one that comes will be in quite a few years from now, we need to start thinking now about what's the next one look like.'" Modly told reporters they are asking questions like "Is it going to be advanced as this one? Or is it going to be smaller or are we going to buy two smaller ones or maybe shift air power to other forms of delivery. And we don't know the answers of that but we're looking at this." An earlier oversight issue for Congress for the CVN-78 program was whether to conduct the shock trial for the CVN-78 class in the near term, on the lead ship in the class, or years later, on the second ship in the class. For background information on that issue, see Appendix E . Table 3 summarizes congressional action on the FY2020 procurement funding request for the CVN-78 program. As shown in Table 1 , of the $2,347.0 million requested for FY2020, $1,062 million is for CVN-80 and $1,285 million is for CVN-81. Appendix A. Withdrawn Proposal to Not Fund CVN-75 RCOH The Navy's FY2020 budget submission proposed to not fund the mid-life nuclear refueling overhaul (called a Refueling Complex Overhaul, or RCOH) for the aircraft carrier CVN-75 ( Harry S. Truman ), and to instead retire the ship around FY2024 and also deactivate one of the Navy's carrier air wings at about the same time. On April 30, 2019, however, the Administration announced that it was effectively withdrawing this proposal from the Navy's FY2020 budget submission. The Administration now supports funding the CVN-75 RCOH and keeping CVN-75 (and by implication its associated air wing) in service past FY2024. This appendix presents, for reference purposes, additional background information on this withdrawn budget proposal. Following the Administration's April 30 withdrawal of its proposal to not fund the CVN-75 RCOH, the Navy states that the CVN-75 RCOH can no longer begin in FY2024, as planned prior to the Navy's FY2020 budget submission, because the Navy spent the months prior to April 30 planning for the ship's deactivation rather than for giving it an RCOH. As a result, the Navy states, the CVN-75 will now begin a year later, in FY2025. As a consequence of this one-year shift in the schedule for the RCOH, the Navy states, the funding stream for the CVN-75 shown in Table A-1 will also now shift one year to the right, and the CVN-75 RCOH can be reinstated without any funding in FY2020, because FY2020 is now effectively the same as FY2019 in Table A-1 . Performing an RCOH on a carrier is needed for the carrier to be able to operate for the second half of its intended 50-year service life. Not performing an RCOH on CVN-75 would mean that, instead of remaining in service for the second half of its intended 50-year service life, the ship would be decommissioned, permanently removed from service, and eventually dismantled. (CVN-75 was commissioned into service on July 25, 1998, and will be 26 years old in 2024.) The Navy's FY2020 budget submission shows that, for the period FY2022-FY2047, this would have reduced the size of the carrier force by one ship compared to what it would otherwise be. More specifically, the Navy's FY2020 30-year (FY2020-FY2049) shipbuilding plan, reflecting the proposal to not fund the CVN-75 RCOH, projected that the carrier force would remain at 11 ships through FY2024, decline to 10 ships in FY2025, and remain at 10 ships for the remainder of the 30-year period, except for a few years (FY2027, FY2040, FY2042-FY2044, and FY2046-FY2048) when it would temporarily decline to 9 ships. Consequently, beginning in FY2025 and extending through the end of the 30-year period, the carrier force would not be in compliance with the requirement under 10 U.S.C. 8062(b) for the Navy to maintain a force of not less than 11 operational aircraft carriers. As an associated action, the Navy's FY2020 budget submission also proposed deactivating one of the Navy's carrier air wings around FY2024. This would reduce the number of carrier air wings from nine to eight, meaning that the Navy beginning around FY2024 would no longer be in compliance with the requirement under 10 U.S.C. 8062(e) to maintain a minimum of nine carrier air wings. Table A-1 shows funding for the CVN-75 RCOH in the Navy's FY2019 budget submission. As shown in the table, the estimated total cost of the CVN-75 RCOH in the FY2019 budget submission was $5,578 million (i.e., about $5.6 billion). The figure of about $5.6 billion shown in Table A-1 does not include the cost of the two nuclear fuel cores that would be installed as part of the RCOH. (CVN-75, like all Nimitz-class carriers, has two nuclear reactors, each of which would receive a new fuel core as part of an RCOH.) Fuel cores for aircraft carrier RCOHs are procured through the Other Procurement, Navy (OPN) appropriation account. The Navy states that it procured the cores for the CVN-75 RCOH—one of them in FY2008 and the other in FY2011—for a total cost of about $538 million. Adding this $538 million cost to the total cost shown in Table A-1 would increase the total estimated cost of the CVN-75 RCOH to about $6.1 billion. The fuel cores for the planned future RCOHs for CVN-76 and CVN-77 (the final two Nimitz-class carriers) have also been procured—the CVN-76 RCOH cores were funded in FY2012 and FY2013, and the CVN-77 RCOH cores were funded in FY2015 and FY2019. Thus, if CVN-75 were to not receive an RCOH, and if it were not possible or cost effective to rescind the funding for the core funded in FY2019, then two of the six Nimitz-class fuel cores that have been procured since FY2008 for anticipated use in RCOHs would not in the end be used in an RCOH and would in effect become surplus to the RCOH effort. The Navy indicated that if that were to occur, these two cores would be placed in storage for potential future use as emergency replacement cores for a Nimitz-class ship until all Nimitz-class ships complete their service lives. If CVN-75 were to not receive an RCOH and is instead be decommissioned, the savings from not funding the RCOH would be partially offset by the cost to deactivate and dismantle CVN-75. The Navy estimated the cost to deactivate and dismantle CVN-75 at about $1.5 billion. The initial increments of this approximate $1.5-billion cost would have occurred in FY2023 ($130.3 million) and FY2024 ($247.2 million). The estimated net savings from not funding the RCOH and instead deactivating and dismantling the ship would thus have been about $4.1 billion (i.e., about $5.6 billion less about $1.5 billion). The Navy stated that there would also be 20 to 25 years of additional annual savings of about $1 billion per year in the form of avoided annual operation and support (O&S) costs for CVN-75 and the deactivated carrier air wing. DOD officials reportedly wanted to redirect the estimated net RCOH-related savings of about $4.1 billion and the estimated recurring savings of about $1 billion per year to Navy investments for technologies that will add to future Navy capabilities. RCOHs are done primarily by Huntington Ingalls Industries/Newport News Shipbuilding (HII/NNS) in Newport News, VA, and form a significant part of HII/NNS's business base, along with construction of new nuclear-powered aircraft carriers and construction of new nuclear-powered submarines. RCOHs in recent years have been scheduled in a more-or-less heel-to-toe fashion at HII/NNS—when one RCOH is done, the next one is scheduled to begin soon thereafter. RCOHs are done in a particular dry dock at HII/NNS, so a carrier undergoing an RCOH in that dry dock must be ready to depart the dry dock before the following carrier can be moved into the dry dock for its RCOH. Until it was withdrawn, the proposal in the Navy's FY2020 budget submission to not fund CVN-75's RCOH and instead decommission the ship (and a carrier air wing) raised a number of potential oversight issues for Congress, including the following: Compliance with congressional direction. The central purposes of 10 U.S.C. 8062(b) and 8062(e) are to act as mandates to the executive branch to support a force of not less than 11 carriers and a minimum of 9 carrier air wings in executive branch planning. They represent directions from Congress for the Navy to provide the funding needed to maintain an 11-carrier, 9-carrier-air-wing force, regardless of limitations on the Navy's overall budget or other considerations. A proposed budget from the Navy that is inconsistent with these provisions might thus be viewed as a challenge to Congress's Article 1 power to set policy and to determine the composition of federal spending (i.e., Congress's constitutional power of the purse). If DOD were to treat the requirements in 10 U.S.C. 8062(b) and 8062(e) as optional matters rather than mandates, would this create a precedent for the executive branch to treat similar provisions in the U.S. Code as optional matters rather than mandates? For example, would it create a precedent for DOD, if it so desired, to begin treating as an optional matter the long-standing requirement in 10 U.S.C. 8063(a) that the Marine Corps "shall be so organized as to include not less than three combat divisions and three air wings, and such other land combat, aviation, and other services as may be organic therein?" If the executive branch were to begin treating statutory provisions like 10 U.S.C. 8062(b) and 8062(e) as optional matters rather than mandates, what implications might this have for policy and program execution, for Congress's power to legislatively establish policy and program goals, and for Congress's power of the purse? Alternative capabilities to be funded ; net impact on Navy capabilities . What were OSD's plans for redirecting the savings associated with deactivating CVN-75 and a carrier air wing around FY2024? What types of capabilities would have been created or maintained by these redirected funds? How would these capabilities compare in nature and timing to the capabilities that are to be provided by the continued operation of CVN-75 and the carrier air wing? Taking these factors into account, what would have been the net operational impact for the Navy of deactivating CVN-75 and a carrier air wing around FY2024 and redirecting the resulting savings toward these other investments? Requirement for 12-carrier force. The Navy's 2016 Force Structure Assessment (FSA) led to a Navy force-level requirement for a fleet of 355 ships that includes 12 aircraft carriers. OSD allowed the Navy to present that FSA to the Congress, and to program shipbuilding and other actions in support of achieving the 355-ship force-level goal. OSD did not publicly object to the FSA's 12-carrier requirement (or any other part of the 355-ship force-level goal). What was the analytical basis for an action that would reduce the size of the carrier from 11 to 10, instead of helping it to eventually increase from 11 to 12? Next Force Structure Assessment (FSA). The Navy states that it is currently conducting a new FSA as the successor to the 2016 FSA, and that this new FSA is to be completed by the end of 2019. This new FSA could change the 355-ship figure, the planned mix of ships, or both. Did the Navy's proposal to not fund the CVN-75 RCOH, and thereby reduce the carrier force from 11 ships to 10 ships, prejudge the outcome of the new FSA? Would the new FSA be tainted by the knowledge that the Navy had already proposed reducing the carrier force to 10 ships? How well could the analysts performing the new FSA have avoided being influenced by the Navy's proposed action? Was the Navy prepared to go ahead with the CVN-75 RCOH if the new FSA concludes that there is a requirement for 11 or more carriers? Likelihood of need for emergency replacement cores. How likely was it that the Nimitz-class program would need to use an emergency replacement set of fuel cores during the remainder of the Nimitz-class life cycle? What set of circumstances might lead to a need for an emergency replacement set of fuel cores? How often have such circumstances previously arisen for a nuclear-powered U.S. Navy ship whose fuel cores are intended to be sufficient for powering the ship for at least one-half of its expected service life? Given the assessed likelihood of the Nimitz-class program needing to use an emergency replacement set of fuel cores during the remainder of the Nimitz-class life cycle, what would have been the government's resulting return on investment of the several hundred million dollars used to procure the two fuel cores that would be placed in storage? Acting Secretary of Defense. The proposal to not fund the CVN-75 RCOH and to deactivate a carrier air wing represented a notable change from prior DOD force-structure planning and budgeting. Was it appropriate for such a change to be proposed by DOD during a time when DOD has an acting Secretary of Defense rather than a Secretary who was confirmed specifically for that position? Impact on industrial base and cost of other work. What would have been the impact on HII/NNS and the other parts of the aircraft carrier industrial base if CVN-75 were inactivated rather than given an RCOH? What impact, if any, would this have had on the cost of other work performed at HII/NNS and other parts of the aircraft carrier industrial base during these years, and on the eventual cost of the CVN-76 RCOH? For further reference, it can be noted that the Navy's FY2015 budget submission proposed not funding the RCOH for the aircraft carrier CVN-73 ( George Washington ). The proposal raised oversight issues for Congress broadly similar to those listed above. Congress, in acting on the Navy's proposed FY2015 budget, rejected the proposal to not fund CVN-73's RCOH. The RCOH was funded and is currently underway. Appendix B. Background Information on Two-Ship Block Buy for CVN-80 and CVN-81 This appendix presents additional background information on the two-ship block buy contract for CVN-80 and CVN-81. The option for procuring two CVN-78 class carriers under a two-ship block buy contract had been discussed in this CRS report since April 2012. In earlier years, the discussion focused on the option of using a block buy contract for procuring CVN-79 and CVN-80. In more recent years, interest among policymakers focused on the option of using a block buy contract for procuring CVN-80 and CVN-81. On March 19, 2018, the Navy released a request for proposal (RFP) to Huntington Ingalls Industries/Newport News Shipbuilding (HII/NNS) regarding a two-ship buy of some kind for CVN-80 and CVN-81. A March 20, 2018, Navy News Service report stated the following: The Navy released a CVN 80/81 two-ship buy Request for Proposal (RFP) to Huntington Ingalls Industries—Newport News Shipbuilding (HII-NNS) March 19 to further define the cost savings achievable with a two-ship buy. With lethality and affordability a top priority, the Navy has been working with HII-NNS over the last several months to estimate the total savings associated with procuring CVN 80 and CVN 81 as a two-ship buy. "In keeping with the National Defense Strategy, the Navy developed an acquisition strategy to combine the CVN 80 and CVN 81 procurements to better achieve the Department's objectives of building a more lethal force with greater performance and affordability," said James F. Geurts, Assistant Secretary of the Navy, Research Development and Acquisition. "This opportunity for a two-ship contract is dependent on significant savings that the shipbuilding industry and government must demonstrate. The Navy is requesting a proposal from HII-NNS in order to evaluate whether we can achieve significant savings." The two-ship buy is a contracting strategy the Navy has effectively used in the 1980s to procure Nimitz-class aircraft carriers and achieved significant acquisition cost savings compared to contracting for the ships individually. While the CVN 80/81 two-ship buy negotiations transpire, the Navy is pursuing contracting actions necessary to continue CVN 80 fabrication in fiscal year (FY) 2018 and preserve the current schedule. The Navy plans to award the CVN 80 construction contract in early FY 2019 as a two-ship buy pending Congressional approval and achieving significant savings. Section 121(a)(2) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 ( H.R. 5515 / P.L. 115-232 of August 13, 2018) permitted the Navy, after the Department of Defense (DOD) made certain certifications to Congress, to add CVN-81 to the existing contract for building CVN-80. DOD provided the required certification on December 31, 2018. On January 31, 2019, the Navy announced that it had awarded a two-ship fixed-price incentive (firm target) (FPIF) contract for CVN-80 and CVN-81 to HII/NNS. The two-ship contract for CVN-80 and CVN-81 can be viewed as a block buy contract because the two ships are being procured in different fiscal years (CVN-80 was procured in FY2018 and CVN-81 is shown in the Navy's FY2020 budget submission as a ship procured in FY2020). The Navy's previous two-ship aircraft carrier procurements occurred in FY1983 (for CVN-72 and CVN-73) and FY1988 (for CVN-74 and CVN-75). In each of those two earlier cases, however, the two ships were fully funded within a single fiscal year, making each of these cases a simple two-ship purchase (akin, for example, to procuring two Virginia-class attack submarines or two DDG-51 class destroyers in a given fiscal year) rather than a two-ship block buy (i.e., a contract spanning the procurement of end items procured across more than one fiscal year). Compared to DOD's estimate that the two-ship block buy contract for CVN-80 and CVN-81 would produce savings of $3.9 billion (as measured from estimated costs for the two ships in the December 2017 Navy business case analysis), DOD states that "the Department of Defense's Office of Cost Assessment and Program Evaluation (CAPE) developed an Independent Estimate of Savings for the two-ship procurement and forecast savings of $3.1 billion ([in] Then-Year [dollars]), or approximately 11 percent.... The primary differences between [the] CAPE and Navy estimates of savings are in Government Furnished Equipment and production change orders." Within the total estimated combined reduction in cost, HII/NNS reportedly expects to save up to $1.6 billion in contractor-furnished equipment. A November 2018 DOD report to Congress that was submitted as an attachment to DOD's December 31, 2018, certification stated the following regarding the sources of cost reduction for the two-ship contract: The CVN 80 and CVN 81 two-ship buy expands and improves upon the affordability initiatives identified in the Annual Report on Cost Reduction Efforts for JOHN F. KENNEDY (CVN 79) and ENTERPRISE (CVN 80) as required by section 126(c) of the National Defense Authorization Act for Fiscal Year 2017 ( P.L. 114-328 ). Production saving initiatives for single-ship buys included use of unit families in construction, pre-outfitting and complex assemblies which move work to a more efficient workspace environment, reduction in the number of superlifts, and facility investments which improve the shipbuilder trade effectiveness. A two-ship buy assumes four years between ship deliveries which allows more schedule overlap, and therefore more shop-level and assembly-level production efficiencies than two single-ship buys. Procuring two ships to a single technical baseline reduces the requirement for engineering labor hours when compared to single-ship estimates. The ability to rollover production support engineering and planning products maximizes savings while recognizing the minimum amount of engineering labor necessary to address obsolescence and regulatory changes on CVN 81. The two-ship agreement with the shipbuilder achieves a 55 percent reduction in construction support engineering hours on CVN 81 and greater than 18 percent reduction in production support and planning hours compared to single ship procurements. The two-ship procurement strategy allows for serial production opportunities that promote tangible learning and reduced shop and machine set-up times. It allows for efficient use of production facilities, re-use of production jigs and fixtures, and level loading of key trades. The continuity of work allows for reductions in supervision, services and support costs. The result of these efficiencies is a production man-hours step down that is equivalent to an 82 percent learning curve since CVN 79. Key to achieving these production efficiencies is Integrated Digital Shipbuilding (iDS). The Navy's Research, Development, Test, and Evaluation (RDT&E) and the shipbuilder's investment in iDS, totaling $631 million, will reduce the amount of production effort required to build FORD Class carriers. The two-ship buy will accelerate the benefits of this approach. The ability to immediately use the capability on CVN 81 would lead to a further reduction in touch labor and services in affected value streams. The two-ship agreement with the shipbuilder represents a production man-hours reduction of over seven percent based on iDS efficiencies. Contractual authority for two ships allows the shipbuilder to maximize economic order quantity material procurement. This allows more efficient ordering and scheduling of material deliveries and will promote efficiencies through earlier ordering, single negotiations, vendor quotes, and cross program purchase orders. These efficiencies are expected to reduce material costs by about six percent more when compared to single-ship estimates. Improved material management and flexibility will prevent costly production delays. Furthermore, this provides stability within the nuclear industrial base, de-risking the COLUMBIA and VIRGINIA Class programs. The two-ship buy would provide economic stability to approximately 130,000 workers across 46 States within the industrial base. Change order requirements are likewise reduced as Government Furnished Equipment (GFE) providers will employ planning and procurement strategies based on the common technical baseline that minimize configuration changes that must be incorporated on the follow ship. Change order budget allocations have been reduced over 25 percent based on two-ship strategies. In addition to the discrete savings achieved with the shipbuilder, the two-ship procurement authority provides our partner GFE providers a similar opportunity to negotiate economic order quantity savings and achieve cross program savings when compared to single-ship estimates. An April 16, 2018, press report stated the following: If the Navy decides to buy aircraft carriers CVN-80 and 81 together, Newport News Shipbuilding will be able to maintain a steady workload that supports between 23,000 and 25,000 workers at the Virginia yard for the next decade or so, the shipyard president told reporters last week. Part of the appeal of buying the two carriers together is that the Navy would also buy them a bit closer together: the ships would be centered about three-and-a-half or four years apart, instead of the five-year centers for recent carrier acquisition, Newport News Shipbuilding President Jennifer Boykin told reporters. Boykin said the closer ship construction centers would allow her to avoid a "labor valley" where the workforce levels would dip down after one ship and then have to come back up, which is disruptive for employees and costly for the company. If this two-carrier buy goes through, the company would avoid the labor valley altogether and ensure stability in its workforce, Boykin said in a company media briefing at the Navy League's Sea Air Space 2018 symposium. That workforce stability contributes to an expected $1.6 billion in savings on the two-carrier buy from Newport News Shipbuilding's portion of the work alone, not including government-furnished equipment.... Boykin said four main things contribute to the expected $1.6 billion in savings from the two-carrier buy. First, "if you don't have the workforce valley, there's a labor efficiency that represents savings." Second, "if you buy two at once, my engineering team doesn't have to produce two technical baselines, two sets of technical products; they only have to produce one, and the applicability is to both, so there's savings there. When we come through the planning, the build plan of how we plan to build the ship, the planning organization only has to put out one plan and the applicability is to both, so there's savings there." The third savings is a value of money over time issue, she said, and fourth is economic order quantity savings throughout the entire supply chain. Discussions of the option of using a block buy contract for procuring carriers have focused on using it to procure two carriers in part because carriers have been procured on five-year centers, meaning that two carriers could be included in a block-buy contract spanning six years—the same number of years originally planned for the two block buy contracts that were used to procure mnay of the Navy's Littoral Combat Ships. It can be noted, however, that there is no statutory limit on the number of years that a block buy contract can cover, and that the LCS block buy contracts were subsequently amended to cover LCSs procured in a seventh year. This, and the possibility of procuring carriers on 3- or 3.5-year centers, raises the possibility of using a block buy contract to procure three aircraft carriers: For example, if procurement of aircraft carriers were shifted to 3- or 3.5-year centers, a block buy contract for procuring CVN-80, CVN-81, and CVN-82 could span seven years (with the first ship procured in FY2018, and the third ship procured in FY2024) or eight years (with the first ship procured in FY2018 and the third ship procured in FY2025). The percentage cost reduction possible under a three-ship block buy contract could be greater than that possible under a two-ship block buy contract, but the offsetting issue of reducing congressional flexibility for changing aircraft carrier procurement plans in coming years in response to changing strategic or budgetary circumstances could also be greater. Appendix C. Cost Growth and Managing Costs Within Program Cost Caps This appendix presents additional background information on cost growth in the CVN-78 program, Navy efforts to stem that growth, and Navy efforts to manage costs so as to stay within the program's cost caps. October 2018 CBO Report An October 2018 CBO report on the potential cost of the Navy's 30-year shipbuilding plan states the following regarding the CVN-78 program: The Navy's current estimate of the total cost of the Gerald R. Ford , the lead ship of the CVN-78 class, is $13.0 billion in nominal dollars appropriated over the period from 2001 to 2018, an amount that is equal to the cost cap set in law. CBO used the Navy's inflation index for naval shipbuilding to convert that figure to $15.5 billion in 2018 dollars, or 23 percent more than the corresponding estimate when the ship was first authorized in 2008. Neither the Navy's nor CBO's estimate includes the $5 billion in research and development costs that apply to the entire class. Because construction of the lead ship is finished, CBO used the Navy's estimate for that ship to estimate the cost of successive ships in the class. But not all of the cost risk has been eliminated; in particular, the ship's power systems and advanced arresting gear (the system used to recover fixed-wing aircraft landing on the ship) are not yet working properly. It is not clear how much those problems will cost to fix, but current Navy estimates suggest that it will be several tens of millions of dollars or more. CBO does not have enough information to estimate those final repair costs. The next carrier after the CVN-78 will be the CVN-79, the John F. Kennedy . Funding for that ship began in 2007, the Congress officially authorized its construction in 2013, and the planned appropriations for it were completed in 2018. The shipbuilder expects to complete construction of the CVN-79 in 2024 and deploy it for the first time in 2026. The Navy estimates that the ship will cost $11.3 billion in nominal dollars (or $11.6 billion in 2018 dollars). The Navy's selected acquisition report on the CVN-79 states that "the Navy and shipbuilder have made fundamental changes in the manner in which the CVN 79 will be built to incorporate lessons learned from CVN 78 and eliminate the key contributors to cost performance challenges realized in the construction of CVN 78." Nevertheless, the Navy informed CBO that there is a greater than 60 percent chance that the ship's final cost will be more than the current estimate. Although CBO expects the Navy to achieve a considerable cost reduction in the CVN-79 compared with the CVN-78, as is typical with the second ship of a class, CBO's estimate is higher than the Navy's. Specifically, CBO estimates that the ship will cost $11.7 billion in nominal dollars (or $12.0 billion in 2018 dollars), about 4 percent more than the Navy's estimate. In 2018, the Congress authorized the third carrier of the class, the Enterprise (CVN-80). Appropriations for that ship began in 2016 and are expected to be complete by 2023. The Navy estimates that the ship will cost $12.6 billion in nominal dollars (or $11.5 billion in 2018 dollars). However, as with CVN-79, the Navy told CBO that there is a greater than 60 percent chance that the ship's final cost will be more than the current estimate. CBO estimates that the ship will cost $13.0 billion in nominal dollars (or $11.8 billion in 2018 dollars), about 3 percent more than the Navy's estimate. The Navy estimates an average cost of $12.4 billion (in 2018 dollars) for the 7 carriers (CVN-81 through CVN-87) in the 2019 shipbuilding plan. CBO's estimate is $12.8 billion per ship.... The gap between the estimates has narrowed since the 2017 plan: The Navy's has increased by $500 million per ship, and CBO's has dropped by $200 million per ship. It is not clear why the Navy's estimates increased, but CBO's estimates fell mainly because the agency projects somewhat less growth in real costs of the shipbuilding industry in future years. August 2018 Press Report An August 17, 2018, press report states the following: Huntington Ingalls Industries Inc., the sole U.S. builder of aircraft carriers, continues to fall short of the Navy's demand to cut labor expenses to stay within an $11.39 billion cost cap mandated by Congress on the second in a new class of warships. With about 47 percent of construction complete on the USS John F. Kennedy, Navy figures show the contractor isn't yet meeting the goal it negotiated with the service: reducing labor hours by 18 percent from the first carrier, the USS Gerald Ford.... It took about 49 million hours of labor to build the Ford, according to the U.S. Government Accountability Office. The Navy's goal for the Kennedy is to reduce that to about 40 million hours. Huntington Ingalls's performance "remains stable at approximately 16 percent" less, William Couch, spokesman for the Naval Sea Systems Command, said in an email. He said "key production milestones and the ship's preliminary acceptance date remain on track" and there are "ample opportunities" for improvement "with nearly four years until contract delivery and over 70 percent of assembly work" remaining on the vessel's superstructure. But the Pentagon's naval warfare division, which reports to Ellen Lord, the Defense Department's chief weapons buyer, is less sanguine. It said in a July assessment that Huntington Ingalls "is unlikely to fully recover the needed 18 percent" reduction.... On the effort to meet the 18 percent labor-hour reduction for the Kennedy, the Navy's program manager "assesses that although difficult, the shipbuilder can still attain" it, Couch said. Beci Brenton, a spokeswoman for Newport News, Virginia-based Huntington Ingalls, said "we are seeing the benefits associated with significant build strategy changes and incorporation of lessons learned" from the first vessel. Brenton said "the current production performance" is 16 percent less than the Ford's estimate at the time of contract award for the second vessel but the reduction is 17 percent when compared with the first vessel's current cost.... But Shelby Oakley, a director with the GAO who monitors Navy shipbuilding, said "with so much of the program underway, it is unlikely that the Navy will regain efficiency." In later phases of a shipbuilding contract, she said, "performance typically degrades, not improves." It's also "unclear how the lessons learned" from the first ship "could help regain efficiency when they are already baked in to the Navy's overly optimistic estimate for the program," she said. June 2018 Press Report A June 19, 2018, press report stated the following: Huntington Ingalls Industries Inc. is asking General Electric Co. to compensate it for damage caused by flawed workmanship during installation of propulsion system components on the U.S. Navy's $13 billion aircraft carrier Gerald R. Ford. The problem, which forced the most expensive U.S. warship back to port in January, has yet to be fully resolved although the carrier is once again at sea.... Huntington Ingalls, a shipbuilder based in Newport News, Virginia, "has notified the original manufacturer of the shipyard's intent to seek compensation," Naval Sea Systems Command spokesman William Couch said in an email. Beci Brenton, a spokeswoman for Huntington said, "We continue to work with appropriate stakeholders to support resolution of this situation." Perry Bradley, a spokesman for Boston-based GE, said "we're not going to comment on specifics other than to say" that "GE is working closely with" Huntington's Newport News Shipyard unit and "the U.S. Navy to resolve the issue."... The episode in January was the second failure in less than a year with a "main thrust bearing" that's part of the carrier's propulsion system. The first occurred in April 2017, during sea trials a month before the vessel's delivery. The ship has been sailing in a shakedown period to test systems and work out bugs. It's now scheduled to be ready for initial combat duty in 2022. The Navy's carrier program office said in an assessment that an inspection of the carrier's four main thrust bearings after the January failure revealed "machining errors" by GE workers at a Lynn, Massachusetts, facility during the original manufacturing as "the actual root cause." The bearing overheated, the Navy said in a March 8 memo to Congress, and "after securing the equipment to prevent damage, the ship safely returned to port." A failure review board is identifying "modifications required to preclude recurrence," it said. The bearing is one of four that transfers thrust from the ship's four propeller shafts. "The costs associated with repairing" the thrust bearings "are currently being assessed" and "this will include recovery of costs from the manufacturer of the Main Reduction Gear, General Electric (Lynn), as appropriate," the Navy said in the memo. Couch said the Navy doesn't expect similar propulsion problems with the next vessel in the class, the John F. Kennedy, because a different manufacturer made that carrier's propulsion train components. "Any propulsion train deficiencies identified" with the Ford "will be corrected and implemented" in "future ships of the class as necessary," he said. May 2018 Press Report A May 11, 2018, press report stated the following: The Navy's costliest vessel ever just got pricer, breaching a $12.9 billion cap set by Congress by $120 million, the service told lawmakers this week. The extra money for the U.S.S. Gerald R. Ford built by Huntington Ingalls Industries Inc. is needed to replace faulty propulsion components damaged in a January failure, extend the vessel's post-delivery repair phase to 12 months from the original eight months and correct deficiencies with the "Advanced Weapons Elevators" used to move munitions from deep in the ship to the deck. The elevators on the ship, designated CVN 78, need to be fixed "to preclude any effect on the safety of the ship and personnel," the Naval Sea Systems Command said in a statement to Bloomberg News on Friday. "Once the adjustment is executed, the cost for CVN 78 will stand at $13.027" billion, the Navy said. In addition to informing Congress that the spending lid has been breached, the Navy will have to let lawmakers know how it will shift funds to make up the difference. Navy officials didn't disclose the propulsion failure or elevator problems during budget hearings before Congress in recent weeks, and House and Senate lawmakers didn't ask about it.... The Ford's propulsion system and elevator flaws are separate from reliability issues on its troubled aircraft launch and recovery systems. After its delivery last May, the ship operated for 70 days and completed 747 shipboard aircraft launches and recoveries, exceeding the goal of about 400, the Navy said. None of the 11 weapons elevators are operational but at least two are being used for testing "to identify many of the remaining developmental issues for this first-of-class system," the Navy has said. The command said all 11 elevators "should have been complete and delivered with the ship delivery" in May 2017. April 2018 Press Report An April 16, 2018, press report stated the following: Huntington Ingalls Industries' Newport News Shipbuilding President Jennifer Boykin provided an update on the various stages of construction on several major Navy shipbuilding programs during the Navy League's Sea Air Space Expo last week. The future USS John F. Kennedy (CVN-79) is about 43 percent complete, with launch planned for the fourth quarter of 2019 and delivery set for 2022. Boykin said the company has achieved about 75 percent of the ship erected and they are on track for an 18 percent man-hour budget reduction. Boykin provided these updates during a press briefing at the conference. Boykin revealed that undocking of CVN-79 in the fourth quarter of 2019 will occur three months earlier than originally planned. September 2017 Press Report A September 26, 2017, press report states the following: Huntington Ingalls Industries Inc. is falling short of a U.S. Navy goal to reduce hours of labor on the second ship in the new Ford class of aircraft carriers in a drive to reduce costs, according to service documents. With 34 percent of construction complete on the USS John F. Kennedy, Huntington Ingalls estimates it will be able to reduce labor hours by 16 percent from the hours needed to construct the first vessel, the Gerald R. Ford. That's less than the 17 percent reduction reported at the end of last year and the 18 percent goal the Navy negotiated in the primary construction contract for the carrier. The "recent degradation in cost performance stems largely from the delayed availability of certain categories of material," such as pipe fittings, controllers, actuators and valves, according to the Navy's annual report on the program and updated figures obtained by Bloomberg News.... "We acknowledge that the cost reduction target for CVN-79," relative to the first carrier, "is challenging," Huntington Ingalls spokeswoman Beci Brenton said in an email, referring to the Kennedy by its Navy designation. "While it is still early in the ship's schedule, we are seeing positive results from" new initiatives to keep costs in check, she said.... Navy Secretary Richard Spencer told reporters last week that he will stay involved in monitoring the CVN-79's construction trends. "This is my personal approach—the CEO has to be involved." A close watch is required "because there are so many moving parts and so many opportunities to do things in a more efficient manner," Spencer said. The Navy has been working with the contractors "to mitigate technical risks and impacts of late material," Navy spokesman Victor Chen in an email. "The overall volume of late material items and associated impact to construction performance is declining. The Navy has hired third-party experts who are working collaboratively with the shipbuilder to identify manufacturing opportunities for efficiency gains" and to assist in implementing improvements.... The 18 percent reduction in labor hours was "quite optimistic" from the start, Michele Mackin, a Government Accountability Office director who oversees its shipbuilding assessments, said in an email. "Even based on that assumption, the $11.4 billion cost cap was unlikely to be met," she said. "If those labor-hour efficiencies are in fact not materializing, costs will go higher. Also, "with the ship being over 30 percent complete, it's unlikely the shipbuilder can get back enough efficiencies to further reduce labor hours—the more complicated work is yet to come," she said. June 2017 Navy Testimony At a June 15, 2017, hearing before the Senate Armed Services Committee on the Department of the Navy's proposed FY2018 budget, the following exchange occurred: SENATOR JOHN MCCAIN (CHAIRMAN) (continuing): Secretary Stackley, the Navy broached a cost cap for CVN-78. Do you believe that it has? SEAN STACKLEY, ACTING SECRETARY OF THE NAVY: Sir, right now our estimate for CVN-78, we're trying to hold it within the $12.887 billion number that was established several years ago. We have included a $20 million [procurement funding] request in this budget pending our determination regarding repairs that required for the... MCCAIN: Is that a breach of Nunn-McCurdy? STACKLEY: Not at this point in time, sir, we're continuing to evaluate whether that additional funding will be required. We're doing everything we can to stay within the existing cap and we'll keep Congress informed as we complete our post-delivery assessment. MCCAIN: Problem is we haven't been informed. So either you bust the cap and breach Nunn-McCurdy—Nunn-McCurdy or you notify us. You haven't done either one. STACKLEY: Sir, we've been submitting monthly reports regarding the carrier, we've alerted the concern regarding the repairs that are being required for the motor turbine generator set and we've acknowledged the risk associated with those repairs. However, what we're trying to do is not incur those costs, avoid cost by other means, and as of right now we're not ready to trip that cost cap. MCCAIN: Well, it's either not allowable or it's allowable. It's not allowable, then you take a certain course of action. If it's allowable then you're required to notify Congress. You have done neither. STACKLEY: If we need to incur those costs, they will be allowable costs. We're trying to avoid that at this stage of time, sir. MCCAIN: I agree, but we were supposed to be notified—OK. I can tell you that you are either in violation of Nunn-McCurdy or you are in violation of the requirement that we be notified. You have done neither. There's two scenarios. STACKLEY: Sir, we have not broached the cost cap. If it becomes apparent that we'll need to go above the cost cap, we will notify Congress within—within the terms that you all have established. MCCAIN: OK. Well, I'll get it to you in writing but you still haven't answered the question because when there's a $20 million cost overrun, it's either allowable and then we have to be notified in one way. If it's not allowable, Nunn-McCurdy is—is reached. But anyway, maybe you can give us a more satisfactory explanation in writing, Mr. Secretary. June 2017 GAO Report A June 2017 GAO report states the following: The cost estimate for the second Ford-Class aircraft carrier, CVN 79, is not reliable and does not address lessons learned from the performance of the lead ship, CVN 78. As a result, the estimate does not demonstrate that the program can meet its $11.4 billion cost cap. Cost growth for the lead ship was driven by challenges with technology development, design, and construction, compounded by an optimistic budget estimate. Instead of learning from the mistakes of CVN 78, the Navy developed an estimate for CVN 79 that assumes a reduction in labor hours needed to construct the ship that is unprecedented in the past 50 years of aircraft carrier construction.... After developing the program estimate, the Navy negotiated 18 percent fewer labor hours for CVN 79 than were required for CVN 78. CVN 79's estimate is optimistic compared to the labor hour reductions calculated in independent cost reviews conducted in 2015 by the Naval Center for Cost Analysis and the Office of Cost Assessment and Program Evaluation. Navy analysis shows that the CVN 79 cost estimate may not sufficiently account for program risks, with the current budget likely insufficient to complete ship construction. The Navy's current reporting mechanisms, such as budget requests and annual acquisition reports to Congress, provide limited insight into the overall Ford Class program and individual ship costs. For example, the program requests funding for each ship before that ship obtains an independent cost estimate. During an 11-year period prior to 2015, no independent cost estimate was conducted for any of the Ford class ships; however, the program received over $15 billion in funding. In addition, the program's Selected Acquisition Reports (SAR)—annual cost, status, and performance reports to Congress—provide only aggregate program cost for all three ships currently in the class, a practice that limits transparency into individual ship costs. As a result, Congress has diminished ability to oversee one of the most expensive programs in the defense portfolio. February 2016 Navy Testimony The Navy testified in 2016 that The Navy is committed to delivering the lead ship of the class, Gerald R Ford (CVN 78) within the $12.887 billion congressional cost cap. Sustained efforts to identify cost reductions and drive improved cost and schedule performance on this first-of-class aircraft carrier have resulted in highly stable cost performance since 2011. Based on lessons learned on CVN 78, the approach to carrier construction has undergone an extensive affordability review and the Navy and the shipbuilder have made significant changes on CVN 79 to reduce the cost to build the ship. The benefits of these changes in build strategy and resolution of first-of-class impacts experienced on CVN 78 are evident in early production labor metrics on CVN 79. These efforts are ongoing and additional process improvements continue to be identified. Alongside the Navy's efforts to reduce the cost to build CVN 79, the FY 2016 National Defense Authorization Act reduced the cost cap for follow ships in the CVN 78 class from $11,498 million to $11,398 million. To this end, the Navy has further emphasized stability in requirements, design, schedule, and budget, in order to drive further improvement to CVN 79 cost. The FY 2017 President's Budget requests funding for the most efficient build strategy for this ship and we look for Congress' full support of this request to enable CVN 79 procurement at the lowest possible cost.... ... The Navy will deliver the CVN 79 within the cost cap using a two-phased strategy wherein select ship systems and compartments that are more efficiently completed at a later stage of construction - to avoid obsolescence or to leverage competition or the use of experienced installation teams - will be scheduled for completion in the ship's second phase of production and test. Enterprise (CVN 80) began construction planning and long lead time material procurement in January 2016 and construction is scheduled to begin in 2018. The FY 2017 President's Budget request re-phases CVN 80 funding to support a more efficient production profile, critical to performance, below the cost cap. CVN 80 planning and construction will continue to leverage class lessons learned to achieve cost and risk reduction, including efforts to accelerate production work to earlier phases of construction, where work is more cost efficient. October 2015 Senate Armed Services Committee Hearing Cost growth and other issues in the CVN-78 program were reviewed at an October 1, 2015, hearing before the Senate Armed Services Committee. Below are excerpts from the prepared statements of the witnesses at the hearing. OSD ASD Testimony The prepared statement of the Assistant Secretary of Defense (Acquisition) within the Office of the Secretary of Defense (OSD) states the following in part: By 2000, the CVN(X) Acquisition Strategy that had been proposed by the Navy was an evolutionary, three-step development of the capabilities planned for the CVN. This evolutionary strategy intending to mature technology and align risk with affordability originally involved using the last ship of the CVN 68 NIMITZ Class, USS GEORGE H. W. BUSH (CVN 77), as the starting point for insertion of some near term technology improvements including information network technology and the new Dual Band Radar (DBR) system from the DD(X) (now DDG 1000) program, to create an integrated warfare system that combined the ship's combat system and air wing mission planning functions. However, the then incoming Secretary of Defense Donald Rumsfeld in 2002 directed re-examination of the CVN program, among others, to reduce the overall spend of the department and increase the speed of delivery to the warfighters. As a result of the SECDEF's direction, the Navy proposed to remove the evolutionary approach and included a new and enlarged flight deck, an increased allowance for future technologies (including electric weapons), and an additional manpower reduction of 500 to 800 fewer sailors to operate. On December 12, 2002, a Program Decision Memorandum approved by then Deputy Secretary of Defense Paul Wolfowitz codified this Navy proposal and gave this direction back to the DOD enterprise. The ship was renamed the CVN-21 to highlight these changes. By Milestone B in April 2004, the Navy had evaluated the technologies intended for three ships, removed some of them, and consolidated the remaining ones into a single step of capability improvement on the lead ship. The new plan acknowledged technological, cost, and schedule challenges were being put on a single ship, but assessed this was achievable. The Acting USD AT&L (Michael Wynne) at that milestone also directed the Navy to use a hybrid of the Service Cost Position and Independent Cost Estimate (ICE) to baseline the program funding in lieu of the ICE, (although one can easily argue even the ICE was optimistic given these imposed circumstances). By 2004, DOD and Congressional leadership had lost confidence in the acquisition system, and Deputy Secretary of Defense Gordon England established the Defense Acquisition Performance Assessment (DAPA) panel to conduct a sweeping and integrated assessment of "every aspect" of acquisition. The result was the discovery that the Industrial Base had consolidated, that excessive oversight and complex acquisition processes were cost and schedule drivers, and a focus on requirements stability was key to containing costs. From this, a review of the requirements of the CVN resulted in a revised and solidified "single ship" Operational Requirements Document (ORD) for the FORD Class as defined today, with the CVN 78 as lead ship. On the heels of a delay because of the budgetary constraints in 2006, the start of the construction of CVN 78 was delayed until 2008, but the schedule for delivery was held constant, further compounding risks and costs. The Navy's testimony covers these technical and schedule risks and concurrency challenges well. By 2009, this Committee had issued a floor statement in support of the Weapon Systems Acquisition Reform Act (WSARA). Congress was now united in its pursuit of acquisition reform and, in concert, USD AT&L re-issued and updated the Department of Defense's acquisition instruction (DoDI 5000.2) in 2008. WSARA included strengthening of the 'Nunn-McCurdy" process with requires DOD to report to Congress when cost growth on a major program breaches a critical cost growth threshold. This legislation required a root-cause assessment of the program and assumed program termination within 60 days of notification unless DOD certified in writing that the program remained essential to national security. WSARA had real impact on the CVN 78, as by 2008 and 2009 the results of all the previous decisions were instantiated in growth of cost and schedule. Then USD AT&L John Young required the Navy to provide a list of descoping efforts and directed the Navy to have an off-ramp back to steam catapults if the Electromagnetic Aircraft Launching System (EMALS) remained a problem for the program. He also directed an independent review of all of the CVN 78 technologies by a Defense Support Team (DST). Prior to the DST, the Navy had chartered a Program Assessment Review (PAR) with USD (AT&L) participation of EMALS/Advanced Arresting Gear (AAG) versus steam. One of the key PAR findings was converting the EMALS and AAG production contracts to firm, fixed price contracts to cap cost growth and imposed negative incentives for late delivery. The Dual Band Radar (DBR) cost and risk growth was a decision by-product of the DDG 1000 program Nunn-McCurdy critical unit cost breach in 2010. Faced with a need to reduce cost on the DDG 1000 program and the resultant curtailment of the program, the expectation of development costs being borne by the DDG 1000 program was no longer the case and all of the costs associated with the S-band element development and a higher share of the X-band element then had to be supported by the CVN 78 program. The design problems encountered with AAG development have had the most deleterious effects on CVN 78 construction of any of the three major advanced technologies including EMALS and DBR. Our view of AAG is that these engineering design problems are now in the past and although delivery of several critical components have been delayed, the system will achieve its needed capabilities before undergoing final operational testing prior to deployment of the ship. Again, reliability growth is a concern, but this cannot be improved until a fully functional system is installed and operating at the Lakehurst, New Jersey land based test site, and on board CVN 78. With the 2010 introduction by then USD AT&L Ashton Carter (now in its third iteration by under USD AT&L Frank Kendall) of the continuous process improvement initiative that was founded in best business practices and WSARA called "Better Buying Power," the CVN underwent affordability, "Should Cost," and requirements assessment. Navy's use of the "Gate" process has stabilized the cost growth and reset good business practices. However, there is still much to do. We are in the testing phase of program execution prior to deployment and we had been concerned about the timing of the Full Ship Shock Trial (FSST). After balancing the operational and technical risks, the Department decided to execute FSST on CVN 78 prior to deployment. EMALS and AAG are also a concern with regard to final operational testing stemming from the development difficulties that each experienced. The Navy still needs to complete a significant amount of land-based testing to enable certification of the systems to launch and recover the full range of aircraft that it is required to operate under both normal and emergency conditions. This land-based testing is planned to complete before the final at-sea operational testing for these systems begins.... USD AT&L continues to work with Navy to tailor the program and ensure appropriate oversight at both the Navy Staff level as well as OSD. Our review of the Navy's plan for maintaining control of the cost for CVN 79 included an understanding of the application of lessons learned from the construction of CVN 78 along with the application of a more efficient construction plan for the ship including introduction of competition where possible. We have established an excellent relationship with the Navy to work together to change process and policies that have impacted the ability of the program to succeed, to include revitalizing the acquisition workforce and their skills. We are confident in the Navy's plan for CVN 79 and CVN 80 and, as such, Under Secretary Kendall recently authorized the Navy to enter into the detail design and construction phase for CVN 79 and to enter into advanced procurement for long lead time materials for CVN 80 construction. OSD and the Navy are committed to delivering CVN 79 within the limits of the cost cap legislated for this ship. OSD DOT&E Testimony The prepared statement of the Director, Operational Test & Evaluation (DOT&E), within OSD states the following in part: The Navy intends to deliver CVN 78 early in calendar year 2016, and to begin initial operational test and evaluation (IOT&E) in late calendar year 2017. However, the Navy is in the process of developing a new schedule, so some dates may change. Based on the current schedule, between now and the beginning of IOT&E, the CVN 78 program is proceeding on an aggressive schedule to finish development, testing, troubleshooting, and correction of deficiencies for a number of new, complex systems critical to the warfighting capabilities of the ship. Low or unknown reliability and performance of the Advanced Arresting Gear (AAG), the Electromagnetic Aircraft Launch System (EMALS), the Dual Band Radar (DBR), and the Advanced Weapons Elevators (AWE) are significant risks to a successful IOT&E and first deployment, as well as to achieving the life-cycle cost reductions the Navy has estimated will accrue for the Ford-class carriers. The maturity of these systems is generally not at the level that would be desired at this stage in the program; for example, the CVN 78 test program is revealing problems with the DBR typical of discoveries in early developmental testing. Nonetheless, AAG, EMALS, DBR, and AWE equipment is being installed on CVN 78, and in some cases, is undergoing shipboard checkout. Consequently, any significant issues that testing discovers before CVN 78's schedule-driven IOT&E and deployment will be difficult, or perhaps impossible, to address. Resolving the uncertainties in the reliability and performance of these systems is critical to CVN 78's primary function of conducting combat operations. CVN 78 has design features intended to enhance its ability to launch, recover, and service aircraft. EMALS and AAG are key systems planned to provide new capabilities for launching and recovering aircraft that are heavier and lighter than typically operated on Nimitz-class carriers. DBR is intended to enhance radar coverage on CVN 78 in support of air traffic control and ship self-defense. DBR is planned to reduce some of the known sensor limitations on Nimitz-class carriers that utilize legacy radars. The data currently available to my office indicate EMALS is unlikely to achieve the Navy's reliability requirements. (The Navy indicates EMALS reliability is above its current growth curve, which is true; however, that growth curve was revised in 2013, based on poor demonstrated performance, to achieve EMALS reliability on CVN 78 a factor of 15 below the Navy's goal.) I have no current data regarding DBR or AWE reliability, and data regarding the reliability of the re-designed AAG are also not available. (Poor AAG reliability in developmental testing led to the need to re-design components of that system.) In addition, performance problems with these systems are continuing to be discovered. If the current schedule for conducting the ship's IOT&E and first deployment remain unchanged, reliability and performance shortfalls could degrade CVN 78's ability to conduct flight operations. Due to known problems with current aircraft carrier combat systems, there is significant risk CVN 78 will not achieve its self-defense requirements. Although the CVN 78 design incorporates several combat system improvements relative to the Nimitz-class, these improvements (if achieved) are unlikely to correct all of the known shortfalls. Testing on other ships with similar combat systems has highlighted deficiencies in weapon employment timelines, sensor coverage, system track management, and deficiencies with the recommended engagement tactics. Most of these limitations are likely to affect CVN 78 and I continue to view this as a significant risk to the CVN 78's ability to defend itself against attacks by the challenging anti-ship cruise missile and other threats proliferating worldwide. The Navy's previous decision to renege on its original commitment to conduct the Full Ship Shock Trial (FSST) on CVN 78 before her first deployment would have put CVN 78 at risk in combat operations. This decision was reversed in August 2015 by the Deputy Secretary of Defense. Historically, FSSTs for new ship classes have identified for the first time numerous mission-critical failures the Navy had to address to ensure the new ships were survivable in combat. We can expect that CVN 78's FSST results will have significant and substantial implications on future carriers in the Ford-class and any subsequent new class of carriers. I also have concerns with manning and berthing on CVN 78. The Navy designed CVN 78 to have reduced manning to reduce life-cycle costs, but Navy analyses of manning on CVN 78 have identified problems in manning and berthing. These problems are similar to those seen on other recent ship classes such as DDG 1000 and the Littoral Combat Ship (LCS).... There are significant risks to the successful completion of the CVN 78 IOT&E and the ship's subsequent deployment due to known performance problems and the low or unknown reliability of key systems. For AAG, EMALS, AWE and DBR, systems that are essential to the primary missions of the ship, these problems, if uncorrected, are likely to affect CVN 78's ability to conduct effective flight operations and to defend itself in combat. The CVN 78 test schedule leaves little or no time to fix problems discovered in developmental testing before IOT&E begins that could cause program delays. In the current program schedule, major developmental test events overlap IOT&E. This overlap increases the likelihood problems will be discovered during CVN 78's IOT&E, with the attendant risk to the successful completion of that testing and to the ship's first deployment. The inevitable lessons we will learn from the CVN 78 FSST will have significant implications for CVN 78 combat operations, as well as for the construction of future carriers incorporating the ship's advanced systems; therefore, the FSST should be conducted on CVN 78 as soon as it is feasible to do so. Navy Testimony The prepared statement of the Navy witnesses at the hearing states the following in part: In June 2000, the Department of Defense (DOD) approved a three-ship evolutionary acquisition approach starting with the last NIMITZ Class carrier (CVN 77) and the next two carriers CVNX1 (later CVN 78) and CVNX2 (later CVN 79). This approach recognized the significant risk of concurrently developing and integrating new technologies into a new ship design incrementally as follows: • The design focus for the evolutionary CVN 77 was to combine information network technology with a new suite of multifunction radars from the DDG 1000 program to transform the ship's combat systems and the air wing's mission planning process into an integrated warfare system. • The design focus for the evolutionary CVNX1 (future CVN 78) was a new Hull, Mechanical and Electrical (HM&E) architecture within a NIMITZ Class hull that included a new reactor plant design, increased electrical generating capacity, new zonal electrical distribution, and new electrical systems to replace steam auxiliaries under a redesigned flight deck employing new Electromagnetic Aircraft Launch System (EMALS) catapults together with aircraft ordnance and fueling "pit-stops". Design goals for achieving reduced manning and improved maintainability were also defined. • The design focus for the evolutionary CVNX2 (future CVN 79) was a potential "clean-sheet" design to "open the aperture" for capturing new but immature technologies such as the Advanced Arresting Gear (AAG) and Advanced Weapons Elevators (AWE) that would be ready in time for the third ship in the series; and thereby permit the experience gained from design and construction of the first two ships (CVN 77 and CVN 78) to be applied to the third ship (CVN 79). Early in the last decade, however, a significant push was made within DOD for a more transformational approach to delivering warfighting capability. As a result, in 2002, DOD altered the program acquisition strategy by transitioning to the new aircraft carrier class in a single transformational leap vice an incremental three ship strategy. Under the revised strategy, CVN 77 reverted back to a "modified-repeat" NIMITZ Class design to minimize risk and construction costs, while delaying the integrated warfare system to CVN 78. Further, due to budget constraints, CVN 78 would start construction a year later (in 2007) with a NIMITZ Class hull form but would entail a major re-design to accommodate all the new technologies from the three ship evolutionary technology insertion plan. This leap ahead in a single ship was captured in a revised Operational Requirements Document (ORD) in 2004, which defined a new baseline that is the FORD Class today, with CVN 78 as the lead ship. The program entered system development and demonstration, containing the shift to a single ship acquisition strategy. The start of CVN 78 construction was then delayed by an additional year until 2008 due to budget constraints. As a result, the traditional serial evolution of technology development, ship concept design, detail design, and construction – including a total of 23 developmental systems incorporating new technologies originally planned across CVN 77, CVNX1, CVNX2 - were compressed and overlapped within the program baseline for the CVN 78. Today, the Navy is confronting the impacts of this compression and concurrency, as well as changes to assumptions made in the program planning more than a decade ago.... Given the lengthy design, development, and build span associated with major warships, there is a certain amount of overlap or concurrency that occurs between the development of new systems to be delivered with the first ship, the design information for those new systems, and actual construction. Since this overlap poses cost and schedule risk for the lead ship of the class, program management activities are directed at mitigating this overlap to the maximum extent practicable. In the case of the FORD Class, the incorporation of 23 developmental systems at various levels of technical maturity (including EMALS, AAG, DBR, AWE, new propulsion plant, integrated control systems) significantly compounded the inherent challenges associated with accomplishing the first new aircraft carrier design in 40-years. The cumulative impact of this high degree of concurrency significantly exceeded the risk attributed to any single new system or risk issue and ultimately manifested itself in terms of delay and cost growth in each element of program execution; development, design, material procurement (government and contractor), and construction.... Shipbuilder actions to resolve first-of-class issues retired much of the schedule risks to launch, but at an unstable cost. First-of-class construction and material delays led the Navy to revise the launch date in March 2013 from July 2013 to November 2013. Nevertheless, the four-month delay in launch allowed increased outfitting and ship construction that were most economically done prior to ship launch, such as completion of blasting and coating operations for all tanks and voids, installation of the six DBR arrays, and increased installations of cable piping, ventilation, electrical boxes, bulkheads and equipment foundations. As a result, CVN 78 launched at 70 percent complete and 77,000 tons displacement – the highest levels yet achieved in aircraft carrier construction. This high state of completion at launch enabled improved outfitting, compartment completion, an efficient transition into the shipboard test program, and the on-time completion of key milestones such as crew move aboard. With the advent of the shipboard test program, first time energization and grooming of new systems have required more time than originally planned. As a result, the Navy expects the sea trial schedule to be delayed about six to eight weeks. The exact impact on ship delivery will be determined based on the results of these trials. The Navy expects no schedule delays to CVN 78 operational testing and deployability due to the sea trials delay and is managing schedule delays within the $12.887 billion cost cap. Additionally, at delivery, AAG will not have completed its shipboard test program. The program has not been able to fully mitigate the effect of a two-year delay in AAG equipment deliveries to the ship. All AAG equipment has been delivered to the ship and will be fully installed on CVN 78 at delivery. The AAG shipboard test and certification program will complete in time to support aircraft launch and recovery operations in summer 2016.... The Navy, in coordination with the shipbuilder and major component providers, implemented a series of actions and initiatives in the management and oversight of CVN 78 that crossed the full span of contracting, design, material procurement, GFE, production planning, production management and oversight. The Secretary of the Navy directed a detailed review of the CVN 78 program build plan to improve end-to-end aircraft carrier design, material procurement, production planning, build and test, the results of which are providing benefit across all carriers. These corrective measures include: • CVN 78 design was converted from a 'level of effort, fixed fee' contract to a completion contract with a firm target and incentive fee. Shipbuilder cost performance has been on-target or better since this contract change. • CVN 78 construction fee was reduced, consistent with contract provisions. However, the shipbuilder remains incentivized by the contract shareline to improve upon current cost performance. • Contract design changes are under strict control; authorized only for safety, damage control, and mission-degrading deficiencies. • Following a detailed "Nunn-McCurdy-like" review in 2008-2009, the Navy converted the EMALS and AAG production contract to a firm, fixed price contract, capping cost growth to each system. • In 2011, Naval Sea Systems Command completed a review of carrier specifications with the shipbuilder, removing or improving upon overly burdensome or unneeded specifications that impose unnecessary cost on the program. Periodic reviews continue. Much of the impact to cost performance was attributable to shipbuilder and government material cost overruns. The Navy and shipbuilder have made significant improvements upon material ordering and delivery to the shipyard to mitigate the significant impact of material delays on production performance. These actions include: • The Navy and shipbuilder instituted optimal material procurement strategies and best practices (structuring procurements to achieve quantity discounts, dual-sourcing to improve schedule performance and leveraging competitive opportunities) from outside supply chain management experts. • The shipbuilder assigned engineering and material sourcing personnel to each of their key vendors to expedite component qualifications and delivery to the shipyard. • The shipbuilder inventoried all excess material procured on CVN 78 for transfer to CVN 79. • The Program Executive Officer (Carriers) has conducted quarterly Flag-level GFE summits to drive cost reduction opportunities and ensure on-time delivery of required equipment and design information to the shipbuilder. The CVN 78 build plan, consistent with the NIMITZ Class, had focused foremost on completion of structural and critical path work to support launching the ship on-schedule. Achieving the program's cost improvement targets required that CVN 78 increase its level of completion at launch, from 60 percent to 70 percent. To achieve this and drive greater focus on system completion: • The Navy fostered a collaborative build process review by the shipbuilder with other Tier 1 private shipyards in order to benchmark its performance and identify fundamental changes that are yielding marked improvement. • The shipbuilder established specific launch metrics by system and increased staffing for waterfront engineering and material expediters to support meeting those metrics. This ultimately delayed launch, but drove up pre-outfitting to the highest levels for CVN new construction which has helped stabilize cost and improve test program and compartment completion performance relative to CVN 77. • The shipbuilder linked all of these processes within a detailed integrated master schedule that has provided greater visibility to performance and greater ability to control cost and schedule performance across the shipbuilding disciplines. These initiatives, which summarize a more detailed list of actions being implemented and tracked as a result of the end-to-end review, were accompanied by important management changes. • In 2011, the Navy assigned a second tour Flag Officer with considerable carrier operations, construction, and program management experience as the new Program Executive Officer (PEO). • The new PEO established a separate Program Office, PMS 379, to focus exclusively on CVN 79 and CVN 80, which enables the lead ship Program Office, PMS 378, to focus on cost control, schedule performance and the delivery of CVN 78. • In 2012, the shipbuilder assigned a new Vice President in charge of CVN 78, a new Vice President in charge of material management and purchasing, and a number of new general ship foremen to strengthen CVN 78 performance. • The new PEO and shipyard president began conducting bi-weekly launch readiness reviews focused on cost performance, critical path issues and accomplishment of the targets for launch completion. These bi-weekly reviews will continue through delivery. • Assistant Secretary of the Navy (Research, Development, and Acquisition) (ASN (RD&A)) conducts quarterly reviews of program progress and performance with the PEO and shipbuilder to ensure that all that can be done to improve on cost performance is being done. The series of actions taken by the Navy and the shipbuilder are achieving the desired effect of arresting cost growth, establishing stability, and have resulted in no changes in the Government's estimate at completion over the past four years. The Department of the Navy is continuing efforts to identify cost reductions, drive improved cost and schedule performance, and manage change. The Navy has established a rigorous process with the shipbuilder that analyzes each contract change request to approve only those change categories allowed within the 2010 ASN(RD&A) change order management guidance. This guidance only allows changes for safety, contractual defects, testing and trial deficiencies, statutory and regulatory changes that are accompanied by funding and value engineering change proposals with instant contract savings. While the historical average for contractual change level is approximately 10 percent of the construction cost for the lead ship of a new class, CVN 78 has maintained a change order budget of less than four percent to date despite the high degree of concurrent design and development. Finally, the Navy has identified certain areas of the ship whose completion is not required for delivery, such as berthing spaces for the aviation detachment, and has removed this work from the shipbuilder's contract. This deferred work will be completed within the ship's budgeted end cost and is included within the $12,887 million cost estimate. By performing this deferred work in the post-delivery period using CVN 78 end cost funding, it can be competed and accomplished at lower cost and risk to the overall ship delivery schedule.... The CVN 79 cost cap was established in 2006 and adjusted by the Secretary of the Navy in 2013, primarily to address inflation between 2006 and 2013 plus $325 million of the allowed increase for non-recurring engineering to incorporate design improvements for the CVN 78 Class construction. The Navy and the shipbuilder conducted an extensive affordability review of carrier construction and made significant changes to deliver CVN 79 at the lowest possible cost. These changes are focused on eliminating the largest impacts to cost performance identified during the construction of CVN 78 as well as furthering improvements in future carrier construction. The Navy outlined cost savings initiatives in its Report to Congress in May, 2013, and is executing according to plan. Stability in requirements, design, schedule, and budget, are essential to controlling and improving CVN 79 cost, and therefore is of highest priority for the program. Requirements for CVN 79 were "locked down" prior to the commencement of CVN 79 construction. The technical baseline and allocated budget for these requirements were agreed to by the Chief of Naval Operations and ASN(RD&A) and further changes to the baseline require their approval, which ensures design stability and increases effectiveness during production. At the time of construction contract award, CVN 79 has 100 percent of the design product model complete (compared to 65 percent for CVN 78) and 80 percent of initial drawings released. Further, CVN 79 construction benefits from the maturation of virtually all new technologies inserted on CVN 78. In the case of EMALS and AAG, the system design and procurement costs are understood, and CVN 79 leverages CVN 78 lessons learned.... A completed FORD Class design enabled the shipbuilder to fully understand the "whole ship" bill of materials for CVN 79 construction and to more effectively manage the procurement of those materials with the knowledge of material lead times and qualified sources accrued from CVN 78 construction. The shipbuilder is able to order ship-set quantities of material, with attendant cost benefits, and to ensure CVN 79 material will arrive on time to support construction need. Extensive improvements have been put in place for CVN 79 material procurement to drive both cost reductions associated with more efficient procurement strategies and production labor improvements associated with improved material availability. Improved material availability is also a critical enabler to many construction efficiency improvements in CVN 79. The shipbuilder has developed an entirely new material procurement and management strategy for CVN 79. This new strategy consists of eight separate initiatives.... The shipbuilder and the Navy have performed a comprehensive review of the build strategy and processes used in construction of CVN 78 Class aircraft carriers as well as consulted with other Navy shipbuilders on best practices. As a result, the shipbuilder has identified and implemented a number of changes in the way they build aircraft carriers, with a dedicated focus on executing construction activities where they can most efficiently be performed. The CVN 79 build sequence installs 20 percent more parts in shop, and 30 percent more parts on the final assembly platen, as compared to CVN 78. This work will result in an increase in pre-outfitting and work being pulled to earlier stages in the construction process where it is most efficiently accomplished.... In conjunction with the Navy and the shipbuilder's comprehensive review of the build strategy and processes used in construction of CVN 78 Class aircraft carriers, a number of design changes were identified that would result in more affordable construction. Some of these design changes were derived from lessons learned in the construction of CVN 78 and others seek to further simplify the construction process and drive cost down.... In addition to the major focus discussed above, the shipbuilder continues to implement capital improvements to facilities that serve to reduce risk and improve productivity.... To enhance CVN 79 build efficiency and affordability, the Navy is implementing a two-phase delivery plan. The two-phase strategy will allow the basic ship to be constructed and tested in the most efficient manner by the shipbuilder (Phase I) while enabling select ship systems and compartments to be completed in Phase II, where the work can be completed more affordably through competition or the use of skilled installation teams.... The CVN 80 planning and construction will continue to leverage class lessons learned in the effort to achieve cost and risk reduction for remaining FORD Class ships. The CVN 80 strategy seeks to improve on CVN 79 efforts to frontload as much work as possible to the earliest phases of construction, where work is both predictable and more cost efficient.... While delivery of the first-of-class FORD has involved challenges, those challenges are being addressed and this aircraft carrier class will provide great value to our Nation with unprecedented and greatly needed warfighting capability at overall lower total ownership cost than a NIMITZ Class CVN. The Navy has taken major steps to stem the tide of increasing costs and drive affordability into carrier acquisition. GAO Testimony The prepared statement of the GAO witness at the hearing states the following in part: The Ford-class aircraft carrier's lead ship began construction with an unrealistic business case. A sound business case balances the necessary resources and knowledge needed to transform a chosen concept into a product. Yet in 2007, GAO found that CVN 78 costs were underestimated and critical technologies were immature—key risks that would impair delivering CVN 78 at cost, on-time, and with its planned capabilities. The ship and its business case were nonetheless approved. Over the past 8 years, the business case has predictably decayed in the form of cost growth, testing delays, and reduced capability—in essence, getting less for more. Today, CVN 78 is more than $2 billion over its initial budget. Land-based tests of key technologies have been deferred by years while the ship's construction schedule has largely held fast. The CVN 78 is unlikely to achieve promised aircraft launch and recovery rates as key systems are unreliable. The ship must complete its final, more complex, construction phase concurrent with key test events. While problems are likely to be encountered, there is no margin for the unexpected. Additional costs are likely. Similarly, the business case for CVN 79 is not realistic. The Navy recently awarded a construction contract for CVN 79 which it believes will allow the program to achieve the current $11.5 billion legislative cost cap. Clearly, CVN 79 should cost less than CVN 78, as it will incorporate lessons learned on construction sequencing and other efficiencies. While it may cost less than its predecessor, CVN 79 is likely to cost more than estimated. As GAO found in November 2014, the Navy's strategy to achieve the cost cap relies on optimistic assumptions of construction efficiencies and cost savings—including unprecedented reductions in labor hours, shifting work until after ship delivery, and delivering the ship with the same baseline capability as CVN 78 by postponing planned mission system upgrades and modernizations until future maintenance periods. Today, with CVN 78 over 92 percent complete as it reaches delivery in May 2016, and the CVN 79 on contract, the ability to exercise oversight and make course corrections is limited. Yet, it is not too late to examine the carrier's acquisition history to illustrate the dynamics of shipbuilding—and weapon system—acquisition and the challenges they pose to acquisition reform. The carrier's problems are by no means unique; rather, they are quite typical of weapon systems. Such outcomes persist despite acquisition reforms the Department of Defense and Congress have put forward—such as realistic estimating and "fly before buy." Competition with other programs for funding creates pressures to overpromise performance at unrealistic costs and schedules. These incentives are more powerful than policies to follow best acquisition practices and oversight tools. Moreover, the budget process provides incentives for programs to be funded before sufficient knowledge is available to make key decisions. Complementing these incentives is a marketplace characterized by a single buyer, low volume, and limited number of major sources. The decades-old culture of undue optimism when starting programs is not the consequence of a broken process, but rather of a process in equilibrium that rewards unrealistic business cases and, thus, devalues sound practices. July 2015 Press Report A July 2, 2015, press report states the following: The Navy plans to spend $25 million per year beginning in 2017 as a way to invest in lowering the cost of building the services' new Ford-class aircraft carriers, service officials said. "We will use this design for affordability to make new improvements in cost cutting technologies that will go into our ships," said Rear Adm. Michael Manazir, Director, Air Warfare.... "We just awarded a contract to buy long lead item materials [for CVN-79] and lay out an allocated budget for each of the components of that ship. We want to build the ship in the most efficient manner possible," Rear Adm. Thomas Moore, Program Executive Officer, Carriers, said. Navy leaders say the service is making positive strides regarding the cost of construction for the USS Kennedy and plans to stay within the congressional cost cap of $11.498 billion.... The $25 million design for affordability initiative is aimed at helping to uncover innovative shipbuilding techniques and strategies that will accomplish this and lower costs. Moore said the goal of the program is to, among other things, remove $500 million from the cost of the third Ford-class carrier, the USS Enterprise, CVN 80. "It is finding a million here and a million there and eventually that is how you get a billion dollars out of the ship from (CVN) 78 to (CVN) 79. The goal is to get another $500 million out of CVN 80. The $25 million dollars is a pretty prudent investment if we can continue to drive the cost of this class of ship down," Moore told reporters recently. Moore explained that part of the goal is to get to the point where a Ford-class carrier can be built for the same amount of man-hours it took to build their predecessor ships, the Nimitz-class carriers. "We want to get back to the goal of being able to build it for historical Nimitz class levels in terms of man hours for a ship that is significantly more capable and more complex to build," Moore added. The money will invest in new approaches and explore the processes that a shipyard can use to build the ship, Moore added. "They've made a significant investment in these new welding machines. These new welding machines allow the welder to use different configurations. This has significantly improved the throughput that the shipyard has," Moore said, citing an example of the kind of thing the funds would be used for. The funds will also look into whether new coatings for the ship or welding techniques can be used and whether millions of feet of electrical cabling can be installed in a more efficient manner, Moore added. Other cost saving efforts assisted by the funding include the increased use of complex assemblies, common integrated work packages, automated plate marking, weapons elevator door re-design and vertical build strategies, Navy officials said. Shipbuilders could also use a new strategy of having work crews stay on the same kind of work for several weeks at a time in order to increase efficiency, Moore said. Also, some of the construction work done on the USS Ford while it was in dry dock is now being done in workshops and other areas to improve the building process, he added. June 2015 Press Reports A June 29, 2015, press report states the following: Newport News Shipbuilding will see cost reduction on the order of 18 percent fewer man hours overall from the first Ford-class aircraft carrier to the second, according to a company representative. Ken Mahler, Newport News vice president of Navy programs, touted the shipyard's cost savings on the John F. Kennedy (CVN-79) during a June 15 interview with Inside the Navy . This reduction was facilitated by the investments the shipyard is making in carrier construction, as well as lessons learned from the first ship, the Gerald R. Ford (CVN-78), which will deliver next year. A June 23, 2015, press report states the following: The Pentagon's cost-assessment office now says the Navy's second aircraft carrier in a new class will exceed a congressionally mandated cost cap by $235 million. That's down from an April estimate that the USS John F. Kennedy, the second warship in the new Ford class, would bust a $11.498 billion cap set by lawmakers by $370 million. The Navy maintains that it can deliver the ship within the congressional limit. "The original figure was a draft based on preliminary information," Navy Commander Bill Urban, a spokesman for the Pentagon's Cost Assessment and Program Evaluation office, said in an e-mail. As better information, such as updated labor rates, became available, the office "revised its estimate to a more accurate number," he said. A June 15, 2015, press report states the following: [Rear Admiral Tom] Moore [program executive officer for aircraft carriers]. said the program would save a billion dollars by decreasing the man hours needed to construct the ship by 18 percent from CVN-78 to 79—down to about 44 million manhours. He said this reduction is only a first step in taking cost ouot of the carrier program. The future Enterprise (CVN-80) will take about 4 million manhours out, or another 10 percent reduction, for a savings of about $500 million. But beyond seeking ways to take cost out, the contract itself reduces the risk to the government, Moore said. "The main construction of the ship is now in a fixed price environment, so that switchover really limits the government's liability," he said. Without getting into specific dollar amounts due to business sensitivities, Moore explained that "this is the lowest target fee we've ever had on any CVN new construction. Look at tghe shape of the share [government-contractor cost] share lines, because the share lines at the end of the day are a measure of risk. So where we'd like to get quickly to [a] 50/50 [share line], in past carrier contracts we've been out at 85/15, 90/10—which basically means for every dollar over [the target cost figure, up to the ceiling cost figure], the government picks up 85 cents on the dollar. And this contract very quickly gets to 50/50. The other thing is ceiling price—on a fixed-price contract, the ceiling price is the government's maximum liability. And on this particular contract, again, it is the lowest ceiling price we've ever had [for a CVN]." February 2015 Navy Testimony At a February 25, 2015, hearing on Department of the Navy acquisition programs, Department of the Navy officials testified the following: The Navy is committed to delivering CVN 78 within the $12.887 billion Congressional cost cap. Sustained efforts to identify cost reductions and drive improved cost and schedule on this first-of-class aircraft carrier have resulted in highly stable performance since 2011. Parallel efforts by the Navy and shipbuilder are driving down and stabilizing aircraft carrier construction costs for the future John F Kennedy (CVN 79) and estimates for the future Enterprise (CVN 80). As a result of the lessons learned on CVN 78, the approach to carrier construction has undergone an extensive affordability review. The Navy and the shipbuilder have made significant changes on CVN 79 to reduce the cost to build the ship as detailed in the 2013 CVN 79 report to Congress. The benefits of these changes in build strategy and resolution of first-of-class impacts on CVN 79 are evident in metrics showing significantly reduced man-hours for completed work from CVN 78. These efforts are ongoing and additional process improvements continue to be identified. The Navy extended the CVN 79 construction preparation contract into 2015 to enable continuation of ongoing planning, construction, and material procurement while capturing lessons learned associated with lead ship construction and early test results. The continued negotiations of the detail design and construction (DD&C) contract afford an opportunity to incorporate further construction process improvements and cost reduction efforts. Award of the DD&C contract is expected in third quarter FY 2015. This will be a fixed price-type contract. Additionally, the Navy will deliver the CVN 79 using a two-phased strategy. This enables select ship systems and compartments to be completed in a second phase, wherein the work can be completed more efficiently through competition or the use of skilled installation teams responsible for these activities. This approach, key to delivering CVN 79 at the lowest cost, also enables the Navy to procure and install shipboard electronic systems at the latest date possible. The FY 2014 NDAA adjusted the CVN 79 and follow ships cost cap to $11,498 million to account for economic inflation and non-recurring engineering for incorporation of lead ship lessons learned and design changes to improve affordability. In transitioning from first-of-class to first follow ships, the Navy has maintained Ford class requirements and the design is highly stable. Similarly, we have imposed strict interval controls to drive changes to the way we do business in order to ensure CVN 79 is delivered below the cost cap. To this same end, the FY 2016 President's Budget request aligns funding to the most efficient build strategy for this ship and we look for Congress' full support of this request to enable CVN 79 to be procured at the lowest possible cost. Enterprise (CVN 80) will begin long lead time material procurement in FY 2016. The FY 2016 request re-phases CVN 80 closer to the optimal profile, therefore reducing the overall ship cost. The Navy will continue to investigate and will incorporate further cost reduction initiatives, engineering efficiencies, and lessons learned from CVN 78 and CVN 79. Future cost estimates for CVN 80 will be updated for these future efficiencies as they are identified. May 2013 Navy Testimony In its prepared statement for a May 8, 2013, hearing on Navy shipbuilding programs before the Seapower subcommittee of the Senate Armed Services Committee, the Navy stated that In 2011, the Navy identified spiraling cost growth [on CVN-78] associated with first of class non-recurring design, contractor and government furnished equipment, and ship production issues on the lead ship. The Navy completed an end-to-end review of CVN 78 construction in December 2011 and, with the shipbuilder, implemented a series of corrective actions to stem, and to the extent possible, reverse these trends. While cost performance has stabilized, incurred cost growth is irreversible.... As a result of lessons learned on CVN 78, the approach to carrier construction has undergone an extensive affordability review; and the Navy and the shipbuilder have made significant changes on CVN 79 that will reduce the cost to build the ship. CVN 79 construction will start with a complete design, firm requirements, and material economically procured and on hand in support of production need. The ship's build schedule also provides for increased completion levels at each stage of construction with resulting improved production efficiencies.... Inarguably, this new class of aircraft carrier brings forward tremendous capability and life-cycle cost advantages compared to the NIMITZ-class it will replace. However, the design, development and construction efforts required to overcome the technical challenges inherent to these advanced capabilities have significantly impacted cost performance on the lead ship. The Navy continues implementing actions from the 2012 detailed review of the FORD-Class build plan to control cost and improve performance across lead and follow ship contracts. This effort, taken in conjunction with a series of corrective actions with the shipbuilder on the lead ship, will not recover costs to original targets for GERALD R. FORD [CVN-78], but should improve performance on the lead ship while fully benefitting CVN 79 and following ships of the class. In the discussion portion of the hearing, Sean Stackley, the Assistant Secretary of the Navy for Research, Development and Acquisition (i.e., the Navy's acquisition executive), testified that First, the cost growth on the CVN-78 is unacceptable. The cost growth dates back in time to the very basic concepts that went into take in the Nimitz-class and doing a total redesign of the Nimitz class to get to a level of capability and to reduce operating and support cost for the future carrier. Far too much risk was carried into the design of the first of the Ford-class. Cost growth stems to the design was moving at the time production started. The vendor base that was responsible for delivering new components and material to support the ship production was (inaudible) with new developments in the vendor base and production plan do not account for the material ordering difficulties, the material delivery difficulties and some of the challenges associated with building a whole new design compared to the Nimitz.... Sir, for CVN-79, we have—we have held up the expenditures on CVN-79 as we go through the details of—one, ensuring that the design of the 78 is complete and repeated for the 79s [sic] that we start with a clean design. Two, we're going through the material procurement. We brought a third party into assessment material-buying practices at Newport News to bring down the cost of material. And we're metering out the dollars for buying material until it hits the objectives that we're setting for CVN-79 through rewriting the build plan on CVN-79. If you take a look at how the 78 is being constructed, far too much work is being accomplished late in the build cycle. So we are rewriting the build plan for CVN-79, do more work in the shops where it's more efficient, more work in the buildings where it's more efficient, less work in the dry dock, less work on the water. And then we're going after the rates—the labor rates and the investments needed by the shipbuilder to achieve these efficiencies. Later in the hearing, Stackley testified that the history in shipbuilding is since you don't have a prototype for a new ship, the first of class referred to as the lead ship is your prototype. And so you carry a lot of risk into the construction of that first of class. Also, given the nature that there's a lengthy design development and build span associated with ships, so there is a certain amount of overlap or concurrency that occurs between the development of new systems that need to be delivered with the first ship, the incorporation of the design of those new systems and the actual construction. And so to the extent that there is change in a new ship class then the risk goes up accordingly. In the case of the CVN-78, the degree of change compared to the Nimitz was fairly extraordinary all for good reasons, good intentions, increased capability, increased survivability, significant reduction in operating and support costs. So there was a determination that will take on this risk in order to get those benefits, and the case of the CVN-78, those risks are driving a lot of the cost growth on the lead ship. When you think about the follow ships, now you've got a stable design, now your vendor base has got a production line going to support the production. Now you've got a build plan and a workforce that has climbed up on the learning curve to drive cost down. So you can look at—you can look at virtually every shipbuilding program and you'll see a significant drop-off in cost from that first of class to the follow ships. And then you look for a stable learning curve to take over in the longer term production of a ship class. Carriers are unique for a number of reasons, one of which we don't have an annual procurement of carriers. They're spread out over a five and, in fact, in the case of 78 as much as seven-year period. So in order to achieve that learning, there are additional challenges associated with achieving that learning. And so we're going at it very deliberately on the CVN-79 through the build plan with the shipbuilder to hit the line that we've got to have—the cost reductions that we've got to have on the follow ships of the class. March 2013 Navy Report A March 2013 report to Congress on the Navy's plan for building CVN-79 that was released to the public on May 16, 2013, states the following in its executive summary: As a result of the lessons learned on CVN 78, the approach to carrier construction has undergone an extensive affordability review and the Navy and the shipbuilder have made significant changes on CVN 79 that will significantly reduce the cost to build the ship. These include four key construction areas: —CVN 79 construction will start with a complete design and a complete bill of material —CVN 79 construction will start with a firm set of stable requirements —CVN 79 construction will start with the development complete on a host of new technologies inserted on CVN 78 ranging from the Electromagnetic Aircraft Launch System (EMALS), the Dual Band Radar, and the reactor plant, to key valves in systems throughout the ship —CVN 79 construction will start with an 'optimal build' plan that emphasizes the completion of work and ship outfitting as early as possible in the construction process to optimize cost and ultimately schedule performance. In addition to these fundamentals, the Navy and the shipbuilder are tackling cost through a series of other changes that when taken over the entire carrier will have a significant impact on construction costs. The Navy has also imposed cost targets and is aggressively pursuing cost reduction initiatives in its government furnished systems. A detailed accounting of these actions is included in this report. The actions discussed in this report are expected to reduce the material cost of CVN 79 by 10-20% in real terms from CVN 78, to reduce the number of man-hours required to build the CVN 79 by 15-25% from CVN 78, and to reduce the cost of government furnished systems by 5-10% in real terms from CVN 78. For the full text of the Navy's report, see the Appendix D . March 2012 Navy Letter to Senator McCain Secretary of the Navy Ray Mabus, in a letter with attachment sent in late March 2012 to Senator John McCain on controlling cost growth in CVN-78, stated the following: Dear Senator McCain: Thank you for your letter of March 21, 2012, regarding the first-of-class aircraft carrier, GERALD R. FORD (CVN 78). Few major programs carry greater importance or greater impact on national security, and no other major program comprises greater scale and complexity than the Navy's nuclear aircraft carrier program. Accordingly, successful execution of this program carries the highest priority within the Department of the Navy. I have shared in the past my concern when I took office and learned the full magnitude of new technologies and design change being brought to the FORD. Requirements drawn up more than a decade prior for this capital ship drove development of a new reactor plant, propulsion system, electric plant and power distribution system, first of kind electromagnetic aircraft launching system, advanced arresting gear, integrated warfare system including a new radar and communications suite, air conditioning plant, weapons elevators, topside design, survivability improvements, and all new interior arrangements. CVN 78 is a near-total redesign of the NIMITZ Class she replaces. Further, these major developments, which were to be incrementally introduced in the program, were directed in 2002 to be integrated into CVN 78 in a single step. Today we are confronting the cost impacts of these decisions made more than a decade ago. In my August 29, 2011 letter, I provided details regarding these cost impacts. At that time, I reported the current estimate for the Navy's share of the shipbuilder's construction overrun, $690 million, and described that I had directed an end-to-end review to identify the changes necessary to improve cost for carrier design, material procurement, planning, build and test. The attached white paper provides the findings of that review and the steps we are taking to drive affordability into the remaining CVN 78 construction effort. Pending the results of these efforts, the Navy has included the 'fact of life' portion of the stated overrun in the Fiscal Year 2013 President's Budget request. The review also highlighted the compounding effects of applying traditional carrier build planning to a radically new design; the challenges inherent to low-rate, sole-source carrier procurement; and the impact of external economic factors accrued over 15 years of CVN 78 procurement—all within the framework of cost-plus contracts. The outlined approach for ensuring CVN 79 and follow ship affordability focuses equally upon tackling these issues while applying the many lessons learned in the course of CVN 78 procurement. As always, if I may be of further assistance, please let me know. Sincerely, [signed] Ray Mabus Attachment: As stated Copy to: The Honorable Carl Levin, Chairman [Attachment] Improving Cost Performance on CVN 78 CVN 78 is nearing 40 percent completion. Cost growth to-date is attributable to increases in design, contractor furnished material, government furnished material (notably, the Electromagnetic Aircraft Launching System (EMALS), Advanced Arresting Gear (AAG), and the Dual Band Radar (DBR)), and production labor performance. To achieve the best case outcome, the program must execute with zero additional cost growth in design and material procurement, and must improve production performance. The Navy and the shipbuilder have implemented a series of actions and initiatives in the management and oversight of CVN 78 that cross the full span of contracting, design, material procurement, government furnished equipment, production planning, production, management and oversight. CVN 78 is being procured within a framework of cost-plus contracts. Within this framework, however, the recent series of action taken by the Navy to improve contract effectiveness are achieving the desired effect of incentivizing improved cost performance and reducing government exposure to further cost growth. CVN 78 design has been converted from a 'level of effort, fixed fee' contract to a completion contract with a firm target and incentive fee. Shipbuilder cost performance has been on-target or better since this contract was changed. CVN 78 construction fee has been retracted, consistent with contract performance. However, the shipbuilder is incentivized by the contract shareline to improve upon current performance to meet agreed-to cost goals. Contract design changes are under strict control; authorized only for safety, damage control, mission-degrading deficiencies, or similar. Adjudicated changes have been contained to less than 1 percent of contract target price. The Navy converted the EMALS and AAG production contract to a firm, fixed price contract, capping cost growth to that system and imposing negative incentives for late delivery. Naval Sea Systems Command is performing a review of carrier specifications with the shipbuilder, removing or improving upon overly burdensome or unneeded specifications that impose unnecessary cost on the program. The single largest impact to cost performance to-date has been contractor and government material cost overruns. These issues trace to lead ship complexity and CVN 78 concurrency, but they also point to inadequate accountability for carrier material procurement, primarily during the ship's advance procurement period (2002-2008). These effects cannot be reversed on CVN 78, but it is essential to improve upon material delivery to the shipyard to mitigate the significant impact of material delays on production performance. Equally important, the systemic material procurement deficiencies must be corrected for CVN 79. To this end, the Navy and shipbuilder have taken the following actions. The Navy has employed outside supply chain management experts to develop optimal material procurement strategies. The Navy and the shipbuilder are reviewing remaining material requirements to employ these best practices (structuring procurements to achieve quantity discounts, dual-sourcing to improve schedule performance and leverage competitive opportunities, etc.). The shipbuilder has assigned engineering and material sourcing personnel to each of their key vendors to expedite component qualifications and delivery to the shipyard. The shipbuilder is inventorying all excess material procured on CVN 78 for transfer to CVN 79 (cost reduction to CVN 78), as applicable. The Program Executive Officer (Carriers) is conducting quarterly flag-level government furnished equipment summits to drive cost reduction opportunities and ensure on-time delivery of required equipment and design information to the shipbuilder. The most important finding regarding CVN 78 remaining cost is that the CVN 78 build plan, consistent with the NIMITZ class, focuses foremost on completion of structural and critical path work to support launching the ship on-schedule. This emphasis on structure comes at the expense of completing ship systems, outfitting, and furnishing early in the build process and results in costly, labor-intensive system completion activity during later; more costly stages of production. Achieving the program's cost improvement targets will require that CVN 78 increase its level of completion at launch, from current estimate of 60 percent to no less than 65 percent. To achieve this goal and drive greater focus on system completion: the Navy fostered a collaborative build process review by the shipbuilder with other Tier 1 private shipyards in order to benchmark its performance arid identify fundamental changes that would yield marked improvement; the shipbuilder has established specific launch metrics by system (foundations, machinery, piping, power panels, vent duct, lighting, etc.) and increased staffing for waterfront engineering and material expediters to support meeting these metrics; the shipbuilder has linked all of these processes within a detailed integrated master schedule, providing greater visibility to current performance and greater ability to control future cost and schedule performance across the shipbuilding disciplines; the Navy and shipbuilder are conducting Unit Readiness Reviews of CVN 78 erection units to ensure that the outfitted condition of each hull unit being lifted into the dry-dock contains the proper level of outfitting. These initiatives, which summarize a more detailed list of actions being implemented and tracked as result of the end-to-end review, are accompanied by important management changes. The shipbuilder has assigned a new Vice President in charge of CVN 78, a new Vice President in charge of material management and purchasing, and a number of new general shop foreman to strengthen CVN 78 performance. The Navy has assigned a second tour Flag Officer with considerable carrier operations, construction, and program management experience as the new Program-Executive Officer (PEO). The PEO and shipyard president conduct bi-weekly launch readiness reviews focusing on cost performance, critical path issues and accomplishment of the target for launch completion. The Assistant Secretary of the Navy (Research, Development, and Acquisition) conducts a monthly review of program progress and performance with the PEO and shipbuilder, bringing to bear the full weight of the Department, as needed, to ensure that all that can be done to improve on cost performance is being done. Early production performance improvements can be traced directly to these actions, however, significant further improvement is required. To this end, the Navy is conducting a line-by-line review of all 'cost to-go' on CVN 78 to identify further opportunity to reduce cost and to mitigate risk. Improving Cost Performance on CVN 79 CVN 79 Advance Procurement commenced in 2007 with early construction activities following in 2011. Authorization for CVN 79 procurement is requested in Fiscal Year 2013 President's Budget request with the first year of incremental funding. Two years have been added to the CVN 79 production schedule in this budget request, afforded by the fact that CVN 79 will replace CVN 68 when she inactivates. To improve affordability for CVN 79, the Navy plans to leverage this added time by introducing a fundamental change to the carrier procurement approach and a corresponding shift to the carrier build plan, while incorporating CVN 78 lessons learned. The two principal 'documents' which the Navy and shipbuilder must ensure are correct and complete at the outset of CVN 79 procurement are the design and the build plan. Design is governed by rules in place that no changes will be considered for the follow ship except changes necessary to correct design deficiencies on the lead ship, fact of life changes to correct obsolescence issues, or changes that will result in reduced cost for the follow ship. Exceptions to these rules must be approved by the JROC, or designee. Accordingly, the Navy is requesting procurement authority for CVN 79 with the Design Product Model complete and construction drawings approximately 95 percent complete (compared to approximately 30 percent complete at time of lead ship authorization). As well, first article testing and certification will be complete for virtually all major new equipments introduced in the FORD Class. At this point in time, the shipbuilder has developed a complete bill of material for CVN 79. The Navy is working with the shipbuilder to ensure that the contractor's material estimates are in-line with Navy 'should cost' estimates; eliminating non-recurring costs embedded in lead ship material, validating quantities, validating escalation indices, incorporating lead ship lessons learned. The Navy has increased its oversight of contractor furnished material procurement, ensuring that material procurement is competed (where competition is available); that it is fixed priced; that commodities are bundled to leverage economic order quantity opportunities; and that the vendor base capacity and schedule for receipt supports the optimal build plan being developed for production. In total, the high level of design maturity and material certification provides a stable technical baseline for material procurement cost and schedule performance, which are critical to developing and executing an improved, reliable build plan. In order to significantly improve production labor performance, based on timely receipt of design and material, the Navy and shipbuilder are reviewing and implementing changes to the CVN 79 build plan and affected facilities. The guiding principles are: maximize planned work in the shops and early stages of construction; revise sequence of structural unit construction to maximize learning curve performance through 'families of units' and work cells; incorporate design changes to improve FORD Class producibility; increase the size of erection units to eliminate disruptive unit breaks and improve unit alignment and fairness; increase outfitting levels for assembled units prior to erection in the dry-dock; increase overall ship completion levels at each key event. The shipbuilder is working on detailed plans for facility improvements that will improve productivity, and the Navy will consider incentives for capital improvements that would provide targeted return on investment, such as: increasing the amount of temporary and permanent covered work areas; adding ramps and service towers for improved access to work sites and the dry-dock; increasing lift capacity to enable construction of larger, more fully outfitted super-lifts: An incremental improvement to carrier construction cost will fall short of the improvement necessary to ensure affordability for CVN 79 and follow ships. Accordingly, the shipbuilder has established aggressive targets for CVN 79 to drive the game-changing improvements needed for carrier construction. These targets include: 75 percent Complete at Launch (15 percent> [i.e., 15 percent greater than] FORD); 85-90 percent of cable pulled prior to Launch (25-30 percent> FORD); 30 percent increase in front-end shop work (piping details, foundations, etc); All structural unit hot work complete prior to blast and paint; 25 percent increase to work package throughput; 100 percent of material available for all work packages in accordance with the integrated master schedule; zero delinquent engineering and planning products; resolution of engineering problems in < 8 [i.e., less than 8] hours. In parallel with efforts to improve shipbuilder costs, the PEO is establishing equally aggressive targets to reduce the cost of government furnished equipment for CVN 79; working equipment item by equipment item with an objective to reduce overall GFE costs by ~$500 million. Likewise, the Naval Sea Systems Command is committed to continuing its ongoing effort to identify specification changes that could significantly reduce cost without compromising safety and technical rigor. The output of these efforts comprises the optimal build plan for CVN 79 and follow, and will be incorporated in the detail design and construction baseline for CVN 79. CVN 79 will be procured using a fixed price incentive contract. Appendix D. March 2013 Navy Report to Congress on Construction Plan for CVN-79 This appendix reprints a March 2013 Navy report to Congress on the Navy's construction plan for CVN-79. Appendix E. Shock Trial An earlier oversight issue for Congress for the CVN-78 program was whether to conduct the shock trial for the CVN-78 class in the near term, on the lead ship in the class, or years later, on the second ship in the class. This appendix presents background information on that issue. A shock trial, known formally as a full ship shock trial (FSST) and sometimes called a shock test, is a test of the combat survivability of the design of a new class of ships. A shock trial involves setting off one or more controlled underwater charges near the ship being tested, and then measuring the ship's response to the underwater shock caused by the explosions. The test is intended to verify the ability of the ship's structure and internal systems to withstand shocks caused by enemy weapons, and to reveal any changes that need to be made to the design of the ship's structure or its internal systems to meet the ship's intended survivability standard. Shock trials are nominally to be performed on the lead ship in a new class of ships, but there have also been cases where the shock trial for a new class was done on one of the subsequent ships in the class. The question of whether to conduct the shock trial for the CVN-78 class in the near term, on the lead ship in the class, or years later, on the second ship in the class, has been a matter of disagreement at times between the Navy and the office of the Secretary of Defense (OSD). The Navy has wanted to perform the shock trial on the second ship in the class, because performing it on the lead ship in the class, the Navy has argued, will cause a significant delay in the first deployment of the lead ship, effectively delaying the return of the carrier force to an 11-ship force level and increasing the operational strain on the other 10 carriers. The Navy has argued that the risks of delaying the shock trial on the CVN-78 to the second ship in the class are acceptable, because the CVN-78 class hull design is based on the Nimitz (CVN-68) class aircraft carrier hull design, whose survivability against shocks is understood, because systems incorporated into the CVN-78 design have been shock tested at the individual component level, and because computer modeling can simulate how the CVN-78 design as a whole will respond to shocks. OSD has argued that the risks of delaying the CVN-78 class shock trial to the second ship in the class are not acceptable, because the CVN-78 design is the first new U.S. aircraft carrier design in four decades; because the CVN-78 design has many internal design differences compared to the CVN-68 design, including new systems not present in the CVN-68 class design; and because computer modeling can only do so much to confirm how a complex new platform, such as an aircraft carrier and all its internal systems, will respond to shocks. The risk of delaying the shock trial, OSD has argued, outweighs the desire to avoid a delay in the first deployment of the lead ship in the class. OSD in 2015 directed the Navy to plan for conducting a shock trial on the lead ship. The Navy complied with this direction but has also sought to revisit the issue with OSD. The issue of the shock trial for the CVN-78 class has been a matter of legislative activity—see the provisions shown earlier in " Recent Related Legislative Provisions ," particularly the most recent such provision, Section 121(b) of the FY2018 National Defense Authorization Act ( H.R. 2810 / P.L. 115-91 of December 12, 2017). An April 5, 2018, press report states the following: The Pentagon's No. 2 civilian has said the Navy should perform shock-testing soon to determine how well its new $12.9 billion aircraft carrier—the costliest warship ever—could withstand an attack, affirming the service's recent decision to back down from a plan for delay. "We agree with your view that a test in normal sequence is more prudent and pragmatic," Deputy Defense Secretary Patrick Shanahan said in a newly released March 26 letter to Senate Armed Services Committee Chairman John McCain. The Arizona Republican and Senator Jack Reed, the panel's top Democrat, pressed for the shock-testing to go ahead as originally planned. James Guerts, the Navy's chiefs weapons buyer, told reporters last month that the Navy was acquiescing to the testing after initially asking Defense Secretary James Mattis to delay it for at least six years. In its push to maintain an 11-carrier fleet, the Navy wanted to wait and perform the test on a second carrier in the class rather than on the USS Gerald Ford.
Risk management, as applied to security of federal facilities, entails a continuous process of applying a series of mitigating actions—assessing risk through the evaluation of threats, vulnerabilities, and consequences; responding to risks with appropriate countermeasures; and monitoring risks using quality information (see fig. 1). In 1995, Executive Order 12977 established the ISC after the bombing of the Oklahoma City Alfred P. Murrah Federal Building in April 1995. The ISC’s mandate is to enhance the quality and effectiveness of security in and protection of federal facilities in the United States occupied by federal employees for nonmilitary activities. The order directs the ISC to develop and evaluate security standards for federal facilities, develop a strategy to ensure executive agencies and departments comply with such standards, and oversee the implementation of appropriate security measures in federal facilities. The ISC has released a body of standards, including the ISC Standard, designed to apply to the physical security efforts of all federal, non-military agencies. The ISC Standard prescribes a process for agencies to follow in developing their risk assessment methodologies (see fig. 2). Most federal departments and agencies are generally responsible for protecting their own facilities and have physical security programs in place to do so. The ISC Standard requires executive departments and agencies to follow the risk-management process when conducting risk assessments for each of their facilities. That process begins with determining the facility security level, ranging from level I (lowest risk) for facilities generally having 100 or fewer employees to level V (highest risk) for the most critical facilities and generally having greater than 750 employees. The security level designation determines the facility’s baseline countermeasures. For each facility, departments and agencies are required to (a) consider all of the “undesirable events” that could pose a risk to their facilities— such as active shooters, vandalism, and explosions—and (b) assess three factors of risk (threats, vulnerabilities, and consequences) to specific undesirable events. Subsequently, agencies are to combine all three factors to yield a measurable level of risk for each undesirable event (see app. III). Based on the results of these assessments, agencies should customize (either increase or decrease) the countermeasures to adequately reflect the assessed level of risk. In addition, as part of planning for physical security resources within an agency’s budget process, the ISC has identified the need to balance allocations for countermeasures with other operational needs and with competing priorities. The ISC Best Practices have some similarities with leading practices in capital decision-making. For example, both state that the allocation of resources should be integrated into the agency’s mission, objectives, goals, and budget process. However, beyond the ISC Best Practices, the Office of Management and Budget and we have developed more comprehensive leading practices in capital decision- making that provide agencies with guidance for prioritizing budget decisions such as for countermeasure projects. The Office of Management and Budget and our guidance also emphasize evaluating a full range of alternatives, informed by agency asset inventories that contain condition information, to bridge any identified performance gap. Furthermore, the guidance calls for a comprehensive decision-making framework to review, rank, and select from among competing project proposals. Such a framework should include the appropriate levels of management review, and selections should be based on the use of established criteria. The following describes the mission and physical security program characteristics for the agencies in our review: CBP, the nation’s largest law enforcement agency, has responsibility for securing the country’s borders. It also has responsibility for conducting security assessments at about 1,200 facilities, including approximately 215 federally owned and agency-controlled higher-level facilities (facility security levels III and IV). These facilities include border patrol stations with holding cells for people detained at the border, office buildings, and canine-training centers. CBP conducts these assessments. FAA’s mission is to provide a safe and efficient aerospace system for the country. According to agency data, FAA has 55 federally owned and agency-controlled higher-level facilities—including critical air traffic control towers. According to FAA officials, FAA specialists conduct security assessments. ARS conducts research related to agriculture and disseminates information to ensure high-quality safe food and to sustain a competitive agricultural economy. According to agency data, ARS has security responsibility for four domestic federally owned and agency- controlled higher-level facilities—including laboratories for research to improve food and crop quality, office buildings, and warehouses. ARS security personnel have responsibility for conducting security assessments. The Forest Service sustains the health, diversity, and productivity of the nation’s forests and grasslands. According to agency officials, the Forest Service has one federally owned and agency-controlled higher- level facility—a regional headquarters office building. The Forest Service’s security officials have responsibility for conducting security assessments, but at the time of our review, USDA security officials conducted the assessment at Forest Service’s one higher-level facility. None of the four selected agencies’ security assessment methodologies fully aligned with the ISC Standard. The ISC gives agencies some flexibility to design their own security-assessment methodologies for identifying necessary countermeasures as long as the chosen methodology adheres to fundamental principles of a sound risk- management methodology. Specifically, methodologies must: consider all of the undesirable events identified in the ISC Standard as possible risks to federal facilities, and assess three factors of risk (threats, vulnerabilities, and consequences) for each of the events. Furthermore, the ISC Standard requires executive departments and agencies to document decisions that deviate from the ISC Standard. Agencies’ policies and methodologies reference the ISC Standard. However, none of the agencies’ methodologies considered all of the undesirable events during assessments although they used some type of risk assessment methodology. In addition, the agencies did not always adhere to these principles of risk management (see table 1). At the time of our review, CBP’s methodology did not fully align with the ISC Standard because it did not consider all of the 33 undesirable events nor assess threat and consequence. CBP security specialists assessed vulnerabilities at building entrances and exits, in interior rooms, and around the perimeter using a yes/no checklist during the assessment process. However, assessment reports showed that specialists did not assess the threats and consequences of undesirable events at each facility. According to security officials, the gap occurred because they designed the checklist to meet requirements in the 2009 CBP Security Policy and Procedures Handbook, which predates the first edition of the ISC Standard issued in 2010. CBP officials told us that as of January 2017, they began using an improved methodology to assess the threats, vulnerabilities, and consequences for 30 of 33 undesirable events— omitting three now identified in the November 2016 revision to the ISC Standard. However, CBP has not yet updated its handbook to align with the ISC Standard, even though it started this effort over 3 years ago in December 2013. CBP officials did not provide a draft of its updated handbook, but they provided a plan with milestone dates for issuing the handbook by September 2018. CBP officials also told us that updates to the handbook may have to wait due to competing priorities, including efforts to address the backlog of assessments (which we discuss later in this report). Delays in updating the handbook mean that CBP’s policy will continue to not align with the ISC Standard. Furthermore, although CBP security officials told us that all of the agency’s security specialists have been trained to use the improved assessment methodology, without documentation of the methodology in agency policy, there may be greater risk of its inconsistent application. Standards for Internal Control emphasize the importance of agencies developing and documenting policies to ensure agency-wide objectives are met. Documentation serves to retain institutional knowledge over time when questions about previous decisions arise. Without an updated policy handbook that requires a methodology that assesses all undesirable events consistent with the ISC Standard, CBP cannot reasonably ensure that its facilities will have levels of protection commensurate to their risk. FAA’s methodology does not fully align with the ISC Standard because it does not consider all of the 33 undesirable events nor does it assess all three factors of risk. FAA security specialists assess vulnerabilities to the site perimeter, entryways, and interior rooms using a yes/no checklist, but the checklist does not assess the consequences from each of the undesirable events at each facility. With respect to threat, FAA applies the ISC’s baseline threat—a general federal facilities threat level that relates directly to a set of baseline countermeasures—across all its higher-level facilities because FAA policy states that there is no agency-specific threat that exceeds the current baseline threat. According to FAA officials, the baseline threat standardizes the security needs across their facilities rather than addressing the security needs of individual facilities from specific threats. When necessary, FAA policy allows specialists to modify countermeasures based on an evaluation of conditions at the facility. FAA realized that this approach was no longer appropriate given the agency-wide goal to make risk-based decisions, a review of the assessment process after a 2014 Chicago fire incident that destroyed critical FAA equipment, and an awareness of ISC initiatives to assess compliance. To address the resulting methodological gaps, FAA hired a contractor to design, develop, test, and validate an improved risk- assessment methodology. Subsequently, FAA improved its methodology in January 2017 to assess the threats, vulnerabilities, and consequences for 30 of the 33 undesirable events identified in the November 2016 revision to the ISC Standard —and tested the methodology at lower- and higher-level facilities. This revised methodology addresses the need to assess individual facility needs rather than using a standardized baseline approach. In April 2017, FAA officials told us of their plan for implementing this methodology and provided tentative milestone dates to conduct further testing, training, and analysis before deciding to use the improved methodology, which they expect to complete by January 2018. However, their plan lacks the necessary information to ensure successful implementation, such as detail on how many facilities they will test and how they will use the results of testing, training, and analysis to implement the improved methodology within the identified 9-month time frame. Furthermore, the improved methodology does not address undesirable events for which ISC issued countermeasures in May 2017. Without a detailed implementation plan to assess the methodology’s impact on its security program, FAA cannot reasonably ensure that its facilities have the proper countermeasures. With ongoing changes to its security program, FAA has an opportunity to fully align its improved methodology with the ISC Standard by including all 33 undesirable events and to update its policy requiring the use of such a methodology. Unlike CBP and FAA—which developed their own methodologies separate from their parent departments (Department of Homeland Security (DHS) and Department of Transportation (DOT), respectively)— ARS and the Forest Service follow an assessment methodology developed by USDA. USDA’s methodology does not fully align with the ISC Standard because it does not consider all of the 33 undesirable events for which ISC issued countermeasures in May 2017. Security specialists from USDA headquarters typically assess ARS’s and the Forest Service’s higher-level facilities using a risk-based methodology that considers the 31 undesirable events listed in the previous version of the ISC Standard dated August 2013. However, until recently, USDA did not assign ratings to each of the three risk factors—threat, vulnerability, and consequence—and then combine these ratings to yield a measurable level of risk for each undesirable event. USDA security officials said that they have revised the assessment-reporting format to include this risk calculation and trained their specialists to measure risk in this way. USDA officials provided us with a new assessment template that addresses all 33 undesirable events and includes measuring risk. Additionally, USDA officials said that they are revising their outdated physical security manual and expect to complete it by April 2018. With a revised manual and application of the new assessment template, USDA should be better positioned to assess risk at its facilities. When agencies do not use methodologies that fully align with the ISC Standard, they could face deleterious effects, ranging from facilities having inappropriate levels of protection to agencies having an inability to make informed resource allocation decisions for their physical security needs. Specifically, the ISC Standard states that facilities may face the effect of either having (1) less protection than needed resulting in inadequate security or (2) more protection than needed resulting in an unnecessary use of resources. The ISC Standard also states that these effects can be negated by determining the proper protection according to a risk assessment. Identified excess resources in one risk area then can be reallocated to underserved areas, thus ensuring the most cost- effective security program is implemented. As an illustration of such potential effects, we found that two agencies assessing two higher-level facilities came to two different conclusions in terms of their need for X-ray machines to screen for guns, knives, and other prohibitive items in federal facilities. Specifically, one agency based its decision on a policy that does not deviate from the ISC’s baseline set of countermeasures, and the other agency based its decision on professional judgement that deviated from the ISC’s baseline set of countermeasures. Neither agency based its decision on a risk assessment nor documented its decision—both ISC requirements, specifically: Without conducting a risk assessment, FAA recently expanded a policy requirement calling for all higher-level facilities to have X-ray machines and magnetometers. This new requirement poses a potentially sizeable investment for the agency with an estimated cost of X-ray machines of about $24,000 and magnetometers of about $4,000 each. FAA may need such equipment at all its higher-level facilities. However, the ISC Standard requires that agencies conduct risk assessments first to justify their needs. Without conducting risk assessments, FAA managers could unnecessarily use resources by installing such equipment in all higher-level air traffic facilities when there may be higher priority needs A USDA security specialist decided, despite an ISC baseline requirement that higher–level facilities have X-ray machines, not to recommend an X-ray machine at a higher-level Forest Service facility. The specialist reasoned that unlike other federal buildings with numerous unknown visitors, this facility receives mostly known individuals and a limited number of visitors. The ISC Standard allows for professional judgement; however, the ISC requires that agencies document deviations from the baseline set of countermeasures. Reducing the facility’s level of protection without documenting an assessment of risk could result in no record of the basis of the decision for current and future facility managers and security officials to review or use as justification in the case of a question of compliance. In another case, we found that one higher-level facility did not have access control for employees or visitors nor did it have armed guard patrols. The facility manager told us that intelligence and a history without incidents gave leadership reason to believe that these measures were not needed and that therefore the agency did not require and would not fund such protective measures for this facility—in effect, accepting the risks to the facility. Security officials said they also had the same understanding and did not document the matter in the assessment report even though agency policy and the ISC Standard require written documentation when officials deviate from the baseline requirement. Without security assessments that fully align with the ISC Standard and provide measureable levels of risk, agencies do not have the information they need to determine priorities and make informed resource allocation decisions. For example, they may not be able to assess whether to acquire or forego costly physical-security countermeasures—such as, X- ray machines, access control systems, and closed-circuit television systems—for facilities. Additionally, after determining the need to acquire a countermeasure, agencies must fund the countermeasure. As previously discussed, leading practices in capital decision-making include a comprehensive framework to review, rank, and select from competing project proposals for funding. In conducting risk assessments that do not fully align with the ISC Standard (i.e., not assessing threats, vulnerabilities, and consequences and measuring risks), agencies miss the opportunity for more informed funding decisions. Three of the four agencies (CBP, ARS, and the Forest Service) currently prioritize funding for operational needs over physical security needs (see table 2) when agencies’ priorities might be different if they based their decisions on an aligned risk assessment. Standards for Internal Control state that agencies should use quality information on an ongoing basis as a means to monitor program activities and take corrective action, as necessary. The ISC requires that agencies assess higher-level facilities at least once every 3 years—an interval requirement to identify and address evolving risks. We found that three of the four agencies (CBP, ARS, and the Forest Service) did not meet this requirement. Officials reported various challenges including (1) assessments competing with other security activities, (2) an insufficient number of qualified staff to conduct assessments when compared to the number of facilities, or (3) not knowing of the required assessment schedule. An “information system” is the people, processes, data, and technology that management organizes to obtain, communicate, or dispose of information. that had not been reassessed since 2010. CBP security officials attributed the backlog to (1) having too few security specialists assigned to assess about 1,200 facilities and (2) the specialists working on competing priorities, such as revising the security handbook, conducting technical inspections, and reviewing new construction designs and renovation projects. According to CBP security officials, they have developed a plan to eliminate the backlog by the end of fiscal year 2018 by prioritizing the completion of assessments. While we found the plan comprehensive, the schedule did not seem feasible. For example, the plan assumes that one specialist can complete six assessments in 3 consecutive days and that another specialist can complete three assessments in 1 day. In contrast, security officials told us specialists take about 20 work hours (or 2½ days) to conduct an on-site assessment of one facility. CBP officials said that they believe they can meet the time frames of the plan because they have set aside other priorities and have a thorough understanding of the scope of work involved at the facilities. They added that it will not be easy to meet the timeline, but they can accomplish it with a motivated and committed workforce, adequate financial resources, and absent activities that would otherwise require shifting of resources. We question the feasibility of setting aside important priorities, such as updating the policy manual and reviewing physical security elements in new construction designs, as well as the workload assumptions for completing the assessments. Further, these other priorities are also key to securing facilities. Without balancing assessments with competing priorities, CBP’s time frames for completing the assessments by the end of fiscal year 2018 may not be feasible and may also result in the agency’s not addressing other important physical security responsibilities. Since the ISC issued its standard in 2010, ARS and the Forest Service have assessed their higher-level facilities at least once. However, these agencies have not reassessed all of their higher-level facilities within the 3-year interval requirement. Specifically, security specialists have not conducted required reassessments of two ARS and one Forest Service higher-level facilities. The ARS headquarters official explained that the agency had not reassessed the two facilities due to competing priorities and insufficient internal resources. During the course of our review, ARS headquarters officials said they began assessing one of the two ARS facilities in May 2017 and will begin assessing the second facility in October 2017. The Forest Service official explained that the agency missed its security reassessment of the regional office because the facility staff had not requested one. During our visit, facility staff responsible for security told us that they were not aware of the ISC’s 3- year interval requirement. Facility staff requested a reassessment, and security officials told us that they expected to complete it by mid-June 2017. Completing this one-time assessment may address the facility’s security needs temporarily. However, ARS and the Forest Service have not implemented a long-term schedule with key milestones and lack a means to monitor completion of assessments of higher-level facilities at least once every 3 years. Consequently, these agencies cannot reasonably ensure that they have full knowledge of the risks to their facilities. FAA data from 2010 through 2016 show that FAA has assessed its 55 higher-level facilities at least once every 3 years. FAA policy requires that specialists schedule assessments of higher-level facilities every 12– 18 months depending on whether the facility has met FAA physical security standards. The ISC Standard states that to make appropriate resource decisions, agencies need information, such as what is being accomplished, what needs management attention, and what is performing at expected levels. We found that agencies’ methods of collecting and storing security information had limitations that affected agency and facility officials’ oversight of the physical security of their facilities (see table 3). Without having long-term, agency-wide information to monitor whether assessments are conducted on schedule, ARS and the Forest Service may not meet the ISC Standard, resulting in not adequately protecting their facilities and employees. The ISC Standard also states that agencies should measure their security program’s capabilities and effectiveness to demonstrate the need to fund facility security and to make appropriate decisions for allocating resources. However, the agencies in our review were unable to demonstrate appropriate oversight of their physical security programs because: CBP’s handbook does not include requirements for data collection and analysis for monitoring physical-security program activities. Facility managers and security officials do not enter assessment results, such as the countermeasures recommended for facilities, in the real property database. Consequently, they do not have comprehensive data to manage their security program, assess overall performance, and take any necessary corrective actions. A CBP official told us that a comprehensive database would allow CBP to set priorities for addressing countermeasures. Without including data collection and analysis requirements in its updated handbook, CBP may be unable to monitor the performance of its physical security program. FAA’s policy does not require ongoing monitoring of physical security information, such as the status of recommended countermeasures or assessment schedules. As a result, FAA officials do not proactively use physical security information to assess the overall performance of its physical security program and take corrective actions before an incident occurs. Without a policy requiring ongoing monitoring of information—an internal control activity, FAA may be unable to assess the overall performance of its security program and take necessary corrective actions. USDA has a decentralized security program and places the responsibility on agencies to create their physical security programs. Security officials from ARS and the Forest Service told us that USDA does not have a policy for collecting and managing agency-wide information; however, they said that USDA is drafting a new departmental regulation and manual that will specify (1) the roles and responsibilities of agency and facility managers and (2) electronic- data-reporting requirements for monitoring the performance of the physical security program. USDA officials provided a draft of USDA’s regulation and manual for our review. The draft regulation did not mention data reporting and monitoring, while the draft manual only contained a table of contents that included a section entitled “Facility Tracking Database.” USDA officials expect to issue new policies sometime between October 2017 and April 2018. In the absence of new departmental regulation and manual, USDA and Forest Service officials told us that they have begun to develop a Forest Service system for storing electronic copies of agency-wide assessments and that they plan to expand the use of this system to track site specific assessment dates and status of recommended countermeasures. Forest Service officials provided milestone dates and described the capabilities for a future information system, which they expect to complete in September 2017. However, we could not determine whether the manual will have information system requirements to monitor agencies’ physical security program, an internal control activity. Without USDA’s including data collection and analysis requirements in its manual, its agencies may not be able to monitor the performance of their physical security programs. Without agencies having information to monitor security activities, they were unable to provide us information on the status of countermeasures across their entire portfolio. In order to better understand the status of countermeasures implemented and facilities’ experiences when implementing countermeasures, we determined the status of countermeasures at 13 facilities we visited. As previously noted, risk management, as it pertains to physical security, involves agency officials monitoring their physical security programs. During our visits to 13 selected facilities, we found the four agencies differed in the number of countermeasures that they had not implemented. Facility officials provided us with some information on why countermeasures had not been implemented, specifically: CBP had a significant number of recommended countermeasures from 2010 through 2016 that remained open at the eight selected CBP facilities. CBP facility officials gave reasons why recommended countermeasures had not been implemented. At one facility, officials did not know about the recommended countermeasures from its last 2010 assessment because the individuals previously knowledgeable about the assessments left the organization without communicating the results. By taking action to improve facility security, they implemented some needed countermeasures. However, at the time of our review, a large number of the recommendations remained open. At another facility, officials told us that they too had not known (for the same reason mentioned above) of their 2010 assessment, which contained recommended countermeasures. However, these officials told us that they submitted a funding request a few weeks before our visit to address all except one of the open countermeasures. In other cases, facilities have not implemented needed countermeasures due to resource constraints or physical site limitations. FAA had a large number of recommended countermeasures from 2010 through 2016 that remained open at the time of our review for the two FAA facilities visited. In this case, the most recent security assessment, completed in late 2016, resulted in one facility’s having little time to implement countermeasures by the time we conducted our analysis. While ARS had closed almost all recommended countermeasures at two facilities at the time of our review, one Forest Service facility had not yet implemented a recommendation (to secure its entrance doors) that was identified in a 2013 security assessment (see bottom center photo, fig. 3). This countermeasure remained open because facility officials said they continued to explore alternatives to address the recommendation. Figure 3 shows examples of countermeasures not fully implemented at selected facilities we visited. During our site visits and discussions with facility staff, we found that physical site limitations or other priorities can make it difficult for facility managers to implement countermeasures. For example, a countermeasure might involve correcting a clear zone violation—that is, moving an object (such as a brick wall) a certain distance away from the facility’s perimeter fence to prevent a potential intruder from using the object to climb over the fence. However, when the object near the fence is a building and the property outside of the fence is not federally owned (see bottom right photo, fig. 3), it may not be cost effective to correct the clear zone violation. In this situation, the agency bears the responsibility for exploring ways to address the vulnerability. In following the ISC Standard, as previously noted, managers are required to justify and document why they could not implement recommended countermeasures—what the ISC calls risk acceptance. Selected agencies carry a great responsibility for protecting facilities that support border protection activities, provide safe and efficient air traffic around the country, and protect the quality of the nation’s food supply. With this responsibility comes the need to appropriately assess risk to ensure the security of these agencies’ facilities. However, 7 years after the ISC issued its initial risk-management process standard, each of four selected agencies continued to use assessment methodologies that did not fully align with this standard. During our review, agencies improved their methodologies to better align with the ISC Standard, but the agencies had not yet incorporated the methodologies into their policies and procedures. Without updated policies and procedures requiring a methodology that adheres to the ISC Standard (including all 33 undesirable events now identified in the November 2016 revision to the ISC Standard), agencies may not collect the information needed to assess risk and determine priorities for improved security. This situation could hamper the agencies’ ability to make informed resource allocation decisions or to recommend countermeasures commensurate to the needs at specific facilities. To address challenges in conducting timely assessments, agencies that had a backlog developed plans to address them, but the assumptions used in CBP’s plans and time frames did not appear to fully reflect the agency’s competing priorities and actual experience. Additionally, ARS and Forest Service have not implemented a long-term assessment schedule with key milestones to ensure that higher-level facilities are reassessed at least once every 3 years. Further, in cases where the agencies may have had risk assessment information, CBP, ARS, and the Forest Service lack the means to collect, store, and analyze this information in order to monitor the status of a facility’s security. Without these key aspects of a comprehensive security program—a methodology that meets the standard, policies, and procedures that incorporate that methodology; the ability to complete assessments on time; and information to perform monitoring—agencies remain vulnerable to substantial security risks. To improve agencies’ physical security programs’ alignment with the ISC Risk Management Process for Federal Facilities and Standards for Internal Control in the Federal Government for information and monitoring, we recommend that the Commissioner of U.S. Customs and Border Protection take the following three actions: with regard to the updated Security Policy and Procedures Handbook, the ISC’s Risk Management Process for Federal Facilities requirement to assess all undesirable events, consider all three factors of risk, and document deviations from the standard, and data collection and analysis requirements for monitoring the performance of CBP’s physical security program. revise the assumptions used in the plan to address the backlog to balance assessments with competing priorities, such as updating the policy manual and reviewing new construction design, to develop a feasible time frame for completing the assessment backlog. Secretary of Transportation direct the FAA Administrator to take the following three actions: develop a plan that provides sufficient details on the activities needed and time frames within the date when FAA will implement an improved methodology; update FAA’s policy to require the use of a methodology that fully aligns with the ISC’s Risk Management Process for Federal Facilities for assessing all undesirable events, considering all three factors of risk, and documenting all deviations from the standard countermeasures; and update FAA’s policy to include ongoing monitoring of physical security information. Secretary of Agriculture take the following two actions: include data collection and analysis requirements for monitoring the performance of agencies’ physical security programs, in the department’s revised physical-security manual, and direct the Administrator of the Agricultural Research Service and the Chief of the Forest Service to implement and monitor a long-term assessment schedule with key milestones to ensure that higher-level facilities are reassessed at least once every 3 years. We provided a draft of this report to the Departments of Homeland Security, Transportation, and Agriculture for review and comment. All three departments agreed with the findings and recommendations for their respective agencies. DHS agreed with our recommendations and provided actions and timeframes for completion. With regard to our recommendation to update the Security Policy and Procedures Handbook, DHS stated that CBP is updating the handbook to include: (1) a discussion and diagram of the ISC risk management process and its application within CBP’s assessment processes; (2) specific guidance for conducting risk assessments in accordance with the ISC’s Risk Management Process for Federal Facilities; and (3) a requirement and guidance for data collection and analysis in support of a robust physical security program. With regard to our recommendation to revise the assumptions used in the plan to address the assessment backlog, DHS stated that CBP has reevaluated current priorities and believes the current plan to eliminate the risk assessment backlog by the end of fiscal year 2018 is achievable. DHS also provided technical comments, which we incorporated as appropriate. DHS’s official written response is reprinted in appendix IV. DOT also agreed with our recommendations and by e-mail requested that we publish the response to the sensitive version of this report. DOT stated that FAA continues to refine its policy and develop processes that address the ISC threats, vulnerabilities, and consequences. Further, DOT stated that FAA would either validate that current mitigation strategies address those risks or apply additional appropriate countermeasures. DOT stated that it will provide a detailed response to each recommendation within 60 days from the date of this report. DOT’s official written response is reprinted in appendix V. USDA agreed with our recommendations and provided the agency-wide actions for completion. USDA provided a plan to ensure compliance with the ISC’s Risk Management Process for Federal Facilities by development of a standard physical-security assessment process and by initiation of a compliance program to track assessments and monitor the installation of countermeasures. In an e-mail, USDA provided milestone dates and planned completion by January 2019. USDA’s official written response is reprinted in appendix VI. If you or your staff has any questions about this report, please contact me at (202) 512-2834 or RectanusL@gao.gov. GAO staff who made key contributions to this report are listed in appendix VI. This report examines: (1) how selected agencies’ assessment methodologies align with the Interagency Security Committee’s (ISC) risk management standard for identifying necessary countermeasures and (2) what management challenges, if any, selected agencies reported facing in conducting physical security assessments and monitoring the results. To determine how selected agencies’ assessment methodologies align with ISC standards for identifying the necessary countermeasures, we identified federal executive branch departments and agencies reported by the Department of Homeland Security (DHS) to have received delegations of authority to protect their own buildings. We reviewed the Federal Real Property Council’s data on the Federal Real Property Profile to identify federally owned and agency-controlled buildings. We determined that these data were sufficiently reliable for the purpose of our reporting objectives based upon our recent report that reviewed these data fields. We selected four agencies based upon their large quantity of reported federally owned and agency-controlled buildings: DHS, U.S. Customs and Border Protection (CBP); Department of Transportation (DOT), Federal Aviation Administration (FAA); United States Department of Agriculture (USDA), Agricultural Research Service (ARS) and USDA’s United States Forest Service (Forest Service). This methodology purposely does not include federal buildings protected by FPS and under the control of the General Services Administration as well as other agencies that we reported on in our previous work. We obtained and reviewed one particular ISC standard, The Risk Management Process for Federal Facilities (the ISC Standard) and its related appendices for assessing physical security and providing recommended countermeasures at federal facilities. We obtained and analyzed the selected departments’ and agencies’ facility-security policies and procedures for a risk assessment methodology. According to the ISC Standard, agencies’ risk assessment methodologies must: consider all of the undesirable events identified in the ISC Standard as possible risks to federal facilities as listed in appendix III; assess the threat, consequences, and vulnerability to specific produce similar or identical results when applied by various security provide sufficient justification for deviations from the ISC-defined security baseline. We limited the scope of this review to the first two standards above because agencies’ adherence to these standards could be objectively verified by reviewing and analyzing agency documentation and interviewing agency officials, and their adherence to the two additional standards could not be verified in this manner. We did not conduct risk assessments with independent security professionals to evaluate: 1) the results from prior agency evaluations and 2) the sufficiency of justifications for deviations from the ISC-defined security baseline, as both evaluations were outside of the scope of the engagement. Therefore, for the purposes of this report, risk assessment policies, procedures and resulting methodology that align with ISC standards are those that consider all of the undesirable events and assess the threats, consequences, and vulnerabilities to specific undesirable events. We reviewed and analyzed information to answer the following five questions: 1. Do the policies and procedures mention the ISC standards? 2. Do the policies and procedures consider all of the undesirable events? 3. Do the policies and procedures assess the threat of specific undesirable events? 4. Do the policies and procedures assess the consequences of specific undesirable events? 5. Do the policies and procedures assess the vulnerability to specific undesirable events? We answered each of these questions as either a “Yes” or “No” for our selected agencies. The “No” answer to questions 3, 4, and 5 includes the following two possibilities: (a) the agency’s threat, consequence, or vulnerability ratings are not tied to specific undesirable events, or (b) the agency does not have a framework or formalized steps within which it collects and analyzes threat-, consequence-, or vulnerability-related information. If the answer to each of the five questions was “Yes,” then the agency’s overall risk assessment methodology aligns with ISC risk assessment standards for the purposes of this report. If the answer to one or more of the five questions was “No”, then the agency’s methodology does not to align with ISC standards for the purposes of this report. We interviewed security officials at ISC; three departments (DHS, DOT, and USDA); and four agencies (CBP, FAA, ARS, and the Forest Service). We obtained and analyzed agency guidance on prioritizing physical security needs and interviewed agencies’ facility maintenance and budget officials. We reviewed the ISC’s best practices for planning for physical security resources within an agency budget process. Additionally, we reviewed the Office of Management and Budget’s and our leading practices in capital decision-making that provide agencies with guidance for prioritizing budget decisions such as “countermeasure projects.” We also reviewed Standards for Internal Control in the Federal Government because internal controls play a significant role in helping agencies achieve their mission-related responsibilities. Our findings from our review of the selected agencies are not generalizable to all ISC member agencies, but provide insight into and illustrative examples about selected agencies’ facility risk-assessment methodologies. To determine what management challenges selected agencies reported facing in conducting physical security assessments and monitoring results, we interviewed agencies’ security, maintenance, and budget officials. We requested agency security officials to provide portfolio- wide data on facility security assessments for our review in order to select sites to visit and analyze data for dates of assessments and the status of findings. We assessed the reliability of this data through interviews with knowledgeable agency staff and a review for completeness and any unexpected values. We compiled information from physical security assessments when no portfolio-wide agency data were available. We determined that these data were sufficient for the purpose of our reporting objectives and selected geographically dispersed sites with buildings with higher reported security levels per the ISC Standard, as these higher security levels have greater requirements and therefore the potential for greater resource needs. See appendix II for the 13 sites we selected. For these selected sites, we interviewed agency staff concerning the assessment process, site-specific findings, recommendations, justification for deviations from ISC’s baseline standards, and management challenges faced in addressing physical security needs. We observed and photographed the status of the findings from the site physical security assessments. We did not independently determine what constitutes a management challenge or a physical security finding. Rather, we relied on these stakeholders to determine these physical security concerns as defined in their own standards and guidance. The information from our selected sites is illustrative and cannot be generalized to sites agency- wide. The performance audit upon which this report is based was conducted from June 2016 to August 2017 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate, evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. We subsequently worked with DHS, DOT and USDA from August 2017 to October 2017 to prepare this version of the original report for public release. This public version was also prepared in accordance with these standards. Error! No text of specified style in document. Error! No text of specified style in document. Appendix VII: GAO Contact and Staff Acknowledgments Error! No text of specified style in document. In addition to the contact named above, Amelia Shachoy (Assistant Director), Steve Martinez (Analyst-in-Charge), Jennifer Clayborne, George Depaoli, Geoffrey Hamilton, Joshua Ormond, Alison Snyder, Amelia Michelle Weathers, and Elizabeth Wood made key contributions to this report.
In accordance with the Improper Payments Information Act of 2002 (IPIA), as amended, and OMB guidance, CMS developed the PERM to estimate the national Medicaid improper payment rate. CMS has other mechanisms to review and assess program integrity risks in state Medicaid managed care programs, and it uses information from the PERM to target its program integrity activities and oversight of states’ Medicaid programs. IPIA requires federal executive branch agencies to, among other things, (1) identify programs and activities that may be susceptible to significant improper payments; and (2), on an annual basis, estimate the amount of improper payments for susceptible programs and activities. Agency heads must produce a statistically valid estimate or an estimate that is otherwise appropriate, using an OMB-approved alternate methodology. Those agencies with programs identified by OMB as being high priority for additional oversight and review are required to submit annual reports to their Inspectors General detailing the actions the agency plans to take to recover improper payments and prevent future improper payments. The Inspector General of each agency submitting such a report is required to review the quality of the improper payment estimates and methodology, among other things. OMB designated Medicaid as a high priority program. In addition, the Improper Payments Elimination and Recovery Act of 2010 requires the Inspector General of each agency to conduct a compliance review to report on the agency’s compliance with several criteria, one of which is that an agency has reported an improper payment rate of less than 10 percent for each program and activity. IPIA also directed OMB to issue guidance for agencies in implementing the IPIA improper payments requirements. Among other things, the OMB guidance requires that agencies review payments made at the point that federal funds are transferred to nonfederal entities and report on the root causes of identified improper payments. To calculate the Medicaid improper payment rate through the PERM, CMS computes an annual rolling average of improper payment rates across all states based on a 17-state, 3-year rotation cycle. In accordance with IPIA, as amended, OMB approved CMS’s PERM methodology, and the HHS-OIG conducts annual compliance reviews. Beginning with its annual improper payment compliance review for fiscal year 2014, the HHS-OIG established a rotating approach to reviewing the estimation methodology for high-priority programs, including Medicaid, that OMB deemed susceptible to improper payments. Due to the number and complexity of the programs, the HHS-OIG methodology reviews are scheduled to be performed over a 4-year period; the PERM estimation methodology will be reviewed as a part of its fiscal year 2017 compliance review. Each of the three components of the Medicaid PERM—FFS, managed care, and eligibility—is estimated differently: The FFS component of the PERM measures errors in a sample of FFS claims, which are records of services provided and the amount the Medicaid program paid for these services. For the majority of sampled FFS claims, the PERM review contractor performs a medical review, which includes a review of the medical documentation to determine errors that do not meet federal and state policies, such as medically unnecessary services, diagnosis coding errors, and policy violations. Any FFS claims that were paid for services that should have been covered under a managed care plan’s capitated payment are also considered errors. The managed care component of the PERM measures errors that occur in the capitated payments that state Medicaid agencies make to managed care organizations (MCO) on behalf of enrollees. Capitated payments are periodic payments approved by CMS that state Medicaid agencies make to contracted MCOs to cover the provision of medical services to enrollees, as well as the MCOs’ administrative expenses and their profits or earnings. The PERM assesses whether any payments made to the MCOs were in amounts different than those the state agency is contractually required to pay, which are approved by CMS. In contrast to the FFS component, the managed care component of the PERM neither includes a medical review of services delivered to enrollees, nor reviews of MCO records or data. The eligibility component of the PERM measures errors in state determinations of whether enrollees meet categorical and financial criteria for receipt of benefits under the Medicaid program. The eligibility component assesses determinations for both FFS and managed care enrollees. This component has not been calculated since 2014; instead, CMS piloted different approaches to update the methodologies used to assess enrollee eligibility, as the Patient Protection and Affordable Care Act changed income eligibility requirements for nonelderly, nonpregnant individuals who qualify for Medicaid. Beginning in the 2019 reporting year, eligibility reviews under the PERM will resume and will be conducted by a federal contractor. Medicaid program integrity consists of efforts to ensure that federal and state expenditures are used to deliver quality, necessary care to eligible enrollees, and efforts to prevent fraud, waste, and abuse. We have found in prior work that CMS’s and states’ program integrity efforts focused primarily on payments and services delivered under FFS and did not closely examine program integrity in Medicaid managed care. For Medicaid managed care, CMS has largely delegated program integrity oversight of MCOs to the states. States, in turn, generally oversee MCOs and the providers under contract to MCOs through their contracts with the MCOs and reporting requirements. Some program integrity risks for managed care are similar to those in FFS, including payments made for nonenrolled, ineligible, or deceased individuals; payments to ineligible, excluded, or deceased providers; and payments to providers for improper or false claims, such as payments for services that are not medically necessary. Other program integrity risks are more unique to managed care. For example, capitated payments generally reflect the average cost to provide covered services to enrollees, rather than a specific service. Federal law requires capitation rates to be actuarially sound, meaning that, among other things, they must be reasonably calculated for the populations expected to be covered and for the services expected to be furnished under contract. In order to receive federal funds for its managed care program, a state is required to submit the rates it pays MCOs and the methodology it uses to set those rates to CMS for review and approval. Additionally, federal and state oversight of Medicaid managed care can include ensuring that MCOs fulfill contractual provisions within their managed care contracts. In some cases, these provisions relate directly to program integrity activities, including plans and procedures for identifying, recovering, and reporting on overpayments made to providers. The managed care component of the PERM measures the accuracy of the capitated payments state Medicaid agencies make to MCOs. Specifically, a CMS contractor examines whether the state agency made capitated payments only for eligible enrollees, made capitated payments for the correct amount based on the contract and coverage requirements (time period and geographic location), made capitated payments based on the correct rate for enrollees, and did not make any duplicate payments for enrollees. CMS officials noted that the agency established capitated payments as the level of review, because the capitation rate is the transaction used to determine the federal match in managed care. In general, the federal government matches most state expenditures for Medicaid services on the basis of a statutory formula. In FFS, the federal match is provided for the amount the state pays a health care provider for delivering services to enrollees. With managed care, the federal match is provided for the amount of the capitation rate the state pays the MCO. Capitated payments do not directly relate to the provision of a specific service, but reflect the average cost to provide covered services to enrollees. As a result, CMS officials maintain that the capitated payment is the lowest transaction level at which the agency can clearly identify federal funds without making significant assumptions. Because the managed care component of the PERM review is limited to measuring capitated payments, it does not account for other program integrity risks—such as overpayments to providers and unallowable MCO costs. In addition to errors in capitated payments included in PERM reviews, CMS regulations state that overpayments in managed care include any payment made to an MCO or provider under contract to an MCO to which the MCO or provider is not entitled under Medicaid. Such overpayments included payments for services that were not provided or medically necessary; or to ineligible, excluded, or deceased providers, which are not measured by the PERM. Unallowable MCO costs refers to operating costs that MCOs cannot claim under their managed care contracts, such as certain marketing costs, or that the MCO reported incorrectly. Among the 27 audits and investigations of Medicaid managed care programs we reviewed, 10 identified about $68 million in MCO overpayments to providers and unallowable MCO costs that were not accounted for in PERM estimates. In addition, one investigation of an MCO operating in nine states resulted in a $137.5 million settlement to resolve allegations of false claims. (See app. I for a complete list of the audits and investigations we identified.) However, the full extent of these overpayments and unallowable costs is unknown, because these audits and investigations were conducted over more than 5 years and involved a small fraction of the more than 270 MCOs operating nationwide as of September 2017. Specifically, 24 of the audits and investigations represented reviews in 10 states and, in many cases, focused on individual providers or MCOs; there were about 90 MCOs operating in the 10 states as of September 2017, according to the Kaiser Family Foundation. Some examples of the audits and investigations that identified overpayments and unallowable costs include the following: The Washington State Auditor’s Office found that two MCOs made $17.5 million in overpayments to providers in 2010, which may have increased the state’s 2013 capitation rates. The New York State Comptroller found that two MCOs paid over $6.6 million to excluded and deceased providers from 2011 through 2014. The Massachusetts State Auditor found that one MCO paid $420,000 for health care services and unauthorized prescriptions from excluded providers in 2013 and 2014. The Department of Justice alleged that an MCO operating in several states submitted inflated expenditure information to the state Medicaid agencies, falsified encounter data, and manipulated claims costs and service provision costs in nine states. The MCO agreed to pay over $137.5 million to resolve these claims. The Texas State Auditor’s Office found that an MCO reported $3.8 million in unallowable costs for advertising, company events, gifts, and stock options, along with $34 million in other questionable costs in 2015. The New York State Comptroller also found that an MCO claimed over $260,000 in unallowable administrative expenses, which contributed to an increase in capitation rates across the state. To the extent that the state does not identify or know of MCO overpayments to providers or unallowable MCO costs, the overpayments and unallowable costs could inflate future capitation rates, as the Washington State Auditor and New York State Comptroller noted in their findings. The PERM assesses the accuracy of capitated payments that states make to MCOs. States set capitation rates based on cost data— historical utilization and spending—that MCOs submit to the state Medicaid agencies, but the PERM does not consider these data. Unless removed from these cost data, unidentified overpayments and unallowable costs would likely inflate the MCO cost data that states use to set capitation rates. (See fig. 1.) As a result, future capitation rates would also be inflated, resulting in higher state and federal spending. In fiscal year 2017, the Medicaid managed care improper payment rate was 0.3 percent, while the FFS improper payment rate was 12.9 percent, leading to an assumption that the estimated risks in managed care are less significant than those estimated in FFS. However, the managed care component of the PERM does not determine whether MCO payments to providers were for services that were medically necessary, actually provided, accurately billed and delivered by eligible providers, or whether the MCO costs were allowable and appropriate. As a result, the PERM improper payment estimate potentially understates the extent of program integrity risks in Medicaid managed care. Moreover, this potential understatement in the PERM’s improper payment rate estimate may curtail investigations into the appropriateness of MCO spending. We previously reported that CMS and state program integrity efforts did not closely examine program integrity in Medicaid managed care, focusing primarily on payments and services delivered under FFS. Our current review of the 27 audits we identified encompassed a 5-year period, suggesting that reviews of managed care continue to be limited. An official from a state auditor’s office we spoke with suggested that some states may not audit services delivered under managed care, because of a low improper payment rate. In addition, he noted that his state Medicaid agency used the relatively low payment error rate in managed care as an indicator of few program integrity problems. As noted, CMS has increased its focus on and worked with states to improve oversight of Medicaid managed care; however, these efforts and the oversight efforts of states do not ensure the identification and reporting of overpayments and unallowable costs. In recent years, the agency has sought to strengthen oversight of managed care programs through updated regulations; reviews of states’ managed care programs (Focused Program Integrity Reviews) and collaborative audits, which are conducted jointly by federal program integrity contractors and states; and state monitoring of overpayments. Regulations. In May 2016, CMS updated its regulations for managed care programs in order to strengthen oversight. The updated regulations require a number of additional program integrity activities, such as those listed below. If fully implemented, these updated regulations may help with the identification and removal of overpayments and unallowable costs from data used to set future capitation rates. Under these regulations States must arrange for an independent audit of the accuracy, truthfulness, and completeness of the encounter and financial data submitted by MCOs, at least once every 3 years. Through contracts with MCOs, states must require MCOs to have a mechanism through which providers report and return overpayments to the MCOs. States must also require MCOs to promptly report any identified or recovered overpayments—specifying those that are potentially fraudulent—and submit an annual report on recovered overpayments to their state. States must use this information when setting actuarially sound capitation rates. Through contracts with MCOs, states must also require MCOs to report specific data, information, and documentation. In addition, the MCO’s chief executive officer or authorized representative must certify the accuracy and completeness of the reported data, information, and documentation. States must enroll MCO providers that are not otherwise enrolled with the state to provide services to enrollees in Medicaid FFS, and revalidate the enrollment at least once every 5 years. Initially this requirement was to start for MCO contracts beginning on July 1, 2018. Subsequently enacted legislation codified this requirement in statute and moved the implementation to January 1, 2018. It is too early to know if these regulations will assure better oversight of MCO payments to providers and the data used to set future capitation rates. The above program integrity requirements only went into effect recently—for contracts starting on or after July 1, 2017, and January 1, 2018. In addition, CMS issued a notice in June 2017 stating that the agency will use its enforcement discretion to assist states that are unable to implement new requirements by the required compliance date. Also, CMS has delayed issuance of implementing guidance for certain provisions until the agency completes its review, a step that may further delay states’ implementation. The agency has designated Medicaid managed care for “deregulatory action” and plans to propose a new rule, but has not indicated which of these provisions, if any, would be revised. Focused Program Integrity Reviews. In fiscal year 2014, CMS implemented its Focused Program Integrity Reviews in order to target high-risk program integrity areas in each state, including managed care. As we previously reported, these focused reviews are narrower in scope than the prior reviews conducted by CMS, but they still involve on-site visits to states. In its focused reviews of managed care, CMS found that several states had incomplete oversight of MCO payments to providers, even though the agency relies on states to verify reported MCO overpayments and to ensure the overpayments are excluded from the data used to set capitation rates. In the 27 focused reviews of managed care from 2014 to 2017, CMS found that MCOs in 17 states reported fewer overpayments to their state Medicaid agencies than CMS would expect. For example, MCOs in at least 5 states reported that overpayments were less than 0.1 percent of their total managed care expenditures; while CMS noted in 1 focused review that overpayments typically equal 1 to 10 percent of total expenditures in managed care. CMS also found that 5 of the 27 states did not verify that MCOs excluded overpayments from these data, and 1 state did not exclude overpayments from the capitation rate setting. This is consistent with our March 2017 report in which we noted that CMS commonly found that MCOs reported low amounts of recovered overpayments and conducted few reviews to identify overpayments. Also, officials from three of the five states we interviewed for that report said the focused reviews gave them leverage in dealing with MCOs or led MCOs to focus more on program integrity. We also reported that CMS officials recommended states take steps to improve their oversight of MCOs, based on the focused review findings. The findings from CMS’s focused reviews of managed care also highlight the need for greater federal oversight of states. Without these reviews, it is unclear if states would independently identify MCOs’ reporting of overpayments or work to strengthen MCO reporting. Yet, CMS has not yet published the focused reviews of managed care in 13 states, and it may only conduct a focused review in a state once every three or more years. Given CMS’s timeline for the focused reviews, it may take years to determine if corrective actions result in improved program integrity in services delivered through managed care. Collaborative audits. CMS has expanded the federal-state collaborative audits beyond FFS, and has begun to engage states to participate in collaborative audits of MCOs and providers under contract to MCOs. As a part of the collaborative audit process, the state volunteers to jointly develop the audit processes the federal contractors follow. CMS officials told us that federal contractors have completed 14 collaborative audits of providers under contract to MCOs in three states—Arizona, the District of Columbia, and Tennessee. Only the audit of Trusted Healthcare, an MCO in the District of Columbia, has been published. That audit identified $129,000 in overpayments in a sample of MCO payments to providers, which, if generalized to all of the MCO’s payments over 6 months, would equate to over $4 million in overpayments. According to CMS, three additional states—Louisiana, Nebraska, and New Hampshire—have shown interest in collaborative audits of their MCOs, although such audits require states to prepare data files for the federal contractor and commit staff time. In our March 2017 report, we found that states’ participation in FFS collaborative audits varied and some states reported barriers to their participation. Expanding collaborative audits in managed care will require commitment from and coordination with states. State monitoring of overpayments in managed care. States are required to report overpayments they have identified and recouped along with state expenditures on a quarterly basis. However, based on the responses of the program integrity officials in 13 of the 16 states we contacted, most officials were unable to define the magnitude of overpayments in their managed care programs, which may signify a need for greater federal oversight or coordination. Specifically, officials in 7 of the 13 states could not or did not identify the share of total reported Medicaid overpayments that occurred in managed care. In 11 of the 13 states, officials responded that they did not directly monitor MCO payments to providers. Of those 11 states, officials in 4 said they depend on MCOs to report overpayments and exclude the overpayments from the data used to set capitation rates. As long as states are not taking action to identify overpayments in managed care, they cannot be assured that they are accurately paying MCOs for medically necessary services provided to enrollees. Federal internal control standards call for agency management to identify, analyze, and respond to risks. CMS has taken some steps to identify, analyze, and respond to risks through its regulations, Focused Program Integrity Reviews, and collaborative audits. However, key CMS and state oversight efforts fall short of mitigating the limitations of the PERM estimates of improper payments for managed care, because they do not ensure the identification and reporting of overpayments to providers and unallowable MCO costs. Without addressing these key risks, CMS and states cannot ensure the integrity of Medicaid managed care programs. The 0.3 percent improper payment rate for Medicaid managed care, as measured by the PERM, is significantly lower than the improper payment rate of 12.9 percent for Medicaid FFS. However, this difference does not signal better oversight; rather, it represents differences in the review criteria between FFS and managed care, which result in a less complete accounting for the program integrity risks in managed care. The PERM does not account for key program integrity risks in Medicaid managed care: specifically, unidentified overpayments and unallowable costs. One federal investigation of an MCO operating in nine states resulted in a settlement of $137.5 million to resolve allegations of false claims that were not captured in the national Medicaid improper payment rate estimate. Further, CMS found that MCOs and states do not provide sufficient oversight in Medicaid managed care to address the risks that are not accounted for in the PERM, findings that are reinforced by our reports on Medicaid managed care program integrity. CMS has taken steps to improve its oversight of Medicaid managed care, yet these efforts fall short of ensuring that the agency and states will be able to identify and address overpayments to providers and unallowable MCO costs. Without better measurement of program risks—particularly as expenditures for Medicaid managed care continue to grow—CMS cannot be certain that the low improper payment rate for managed care, as measured by the PERM, accurately reflects lower risks in managed care. The Administrator of CMS should consider and take steps to mitigate the program risks that are not measured in the PERM, such as overpayments and unallowable costs; such an effort could include actions such as revising the PERM methodology or focusing additional audit resources on managed care. (Recommendation 1) We provided a draft of this report to the Department of Health and Human Services (HHS) for comment. In its written comments, HHS concurred with our recommendation, and indicated that it will review regulatory authority and audit resources to determine the best way to account for Medicaid program risks that are not accounted for in the PERM. However, HHS stated that the PERM is not intended to measure all Medicaid program integrity risks, and utilizing the PERM measurement in that way would be a misunderstanding and misuse of the reported rate. HHS also commented that a review of payments from MCOs to providers is outside the scope of IPIA. In addition, HHS asserted that including such a review would diminish the value of PERM reporting—because it would require significant assumptions about the amount of federal share in MCO payments to providers. Further, HHS maintained that such a review also would result in a measurement that was not comparable to other programs or agencies, which would diminish the value of government- wide improper payment rate reporting. We acknowledge that the current PERM methodology has been approved by OMB. However, we maintain that the PERM likely underestimates program integrity risks in Medicaid managed care. To ensure the appropriate targeting of program integrity activities, CMS needs better information about these risks. Given the size of the Medicaid program, its vulnerability to improper payments, and the growth in managed care, it is critical to have a full accounting of program integrity risks in managed care in order to best ensure the integrity of the whole Medicaid program. In its written comments, HHS also summarized several activities it uses to oversee and support states’ Medicaid program integrity efforts, including state program integrity reviews; collaborative audits conducted by federal contractors; Medicaid Integrity Institute training for state employees; and the Medicaid Provider Enrollment Compendium. HHS also provided technical comments, which we incorporated as appropriate. HHS’s comments are reprinted in appendix II. As agreed with your offices, unless you publicly announce the contents of this report earlier, we plan no further distribution until 30 days from the report date. At that time, we will send copies to the Secretary of Health and Human Services, the Administrator of CMS, appropriate congressional committees, and other interested parties. In addition, the report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staff members have any questions about this report, please contact me at (202) 512-7114 or at yocomc@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff that made key contributions to this report are listed in appendix III. We reviewed 16 federal and state audits and 11 notices of investigations of Medicaid managed care organizations (MCO) and providers issued from January 2012 to September 2017. As the findings below show, the audits and investigations represent a limited number of reviews that, in many cases, focused on individual states and individual providers or MCOs within that state. Given the limited scope and number of states reviewed, the amount of the overpayments and unallowable costs occurring nationwide is unknown. These audits and investigations show cases of MCO overpayments to providers or unallowable costs, which are not accounted for by the Centers for Medicare & Medicaid Services’ Payment Error Rate Measurement (PERM) ; errors in capitated payments (e.g., capitated payments made for deceased individuals), which are accounted for in the PERM; and gaps in managed care oversight. When reporting overpayments and unallowable costs identified in the audits and investigations, we only include amounts specifically attributed to MCOs in our total. This total does not include the following: overpayments and unallowable costs identified in those audits and investigations that did not distinguish between the amounts attributable to MCOs, Medicaid fee-for-service, or Medicare; overpayments and unallowable costs identified in criminal proceedings that are not yet resolved; and errors in capitated payments, as those payments would be reviewed by the PERM. As a result, the total amount of overpayments and unallowable costs and capitated payment errors in this appendix exceed what we report. In addition to the contact named above, Leslie V. Gordon (Assistant Director), Pauline Adams (Analyst-in-Charge), Erika Huber, and Drew Long made key contributions to this report. Also contributing were Muriel Brown and Jennifer Whitworth.
The Federal Reserve's (the Fed's) responsibilities as the nation's central bank fall into four main categories: monetary policy, provision of emergency liquidity through the lender of last resort function, supervision of certain types of banks and other financial firms for safety and soundness, and provision of payment system services to financial firms and the government. Congress has delegated responsibility for monetary policy to the Fed, but retains oversight responsibilities to ensure that the Fed is adhering to its statutory mandate of "maximum employment, stable prices, and moderate long-term interest rates." The Fed has defined stable prices as a longer-run goal of 2% inflation—the change in overall prices, as measured by the Personal Consumption Expenditures (PCE) price index. By contrast, the Fed states that "it would not be appropriate to specify a fixed goal for employment; rather, the Committee's policy decisions must be informed by assessments of the maximum level of employment, recognizing that such assessments are necessarily uncertain and subject to revision." Monetary policy can be used to stabilize business cycle fluctuations (alternating periods of economic expansions and recessions) in the short run, while it mainly affects inflation in the long run. The Fed's conventional tool for monetary policy is to target the federal funds rate —the overnight, interbank lending rate. This report provides an overview of how monetary policy works and recent developments, a summary of the Fed's actions following the financial crisis, and ends with a brief overview of the Fed's regulatory responsibilities. In December 2008, in the midst of the financial crisis and the "Great Recession," the Fed lowered the federal funds rate to a range of 0% to 0.25%. This was the first time rates were ever lowered to what is referred to as the zero lower bound . The recession ended in 2009, but as the economic recovery consistently proved weaker than expected in the years that followed, the Fed repeatedly pushed back its time frame for raising interest rates. As a result, the economic expansion was in its seventh year and the unemployment rate was already near the Fed's estimate of full employment when it began raising rates on December 16, 2015. This was a departure from past practice—in the previous two economic expansions, the Fed began raising rates within three years of the preceding recession ending. Since then, the Fed has continued to raise rates in a series of steps to incrementally tighten monetary policy. The Fed raised rates once in 2016, three times in 2017, and four times in 2018, by 0.25 percentage points each time. The Fed has stated that "some further gradual increases in ... the federal funds rate" are necessary to fulfill its mandate. The Fed describes its plans as "data dependent," meaning they would be altered if actual employment or inflation deviate from its forecast. Although monetary policy is now less stimulative than it had been at the zero lower bound, the Fed is still adding stimulus to the economy as long as the federal funds rate is below what economists call the "neutral rate" (or the long-run equilibrium rate). To illustrate, the federal funds rate is currently similar to the inflation rate, meaning that the real (i.e., inflation-adjusted) federal funds rate is around zero. However, there is uncertainty as to what constitutes a neutral rate today. By historical standards, a zero real interest rate would be well below the neutral rate, but the neutral rate appears to have fallen following the financial crisis, so that current rates may be close to the neutral rate today. Typically, the Fed keeps interest rates below the neutral rate when the economy is operating below full employment, at neutral levels when the economy is near full employment, and above the neutral rate when the economy is at risk of overheating. Indeed, the Fed identifies this as one of its "three key principles of good monetary policy." Because of lags between changes in interest rates and their economic effects, in the past, the Fed has often preemptively changed its monetary policy stance before the economy reaches the state that the Fed is anticipating. In this business cycle, the Fed has maintained a (progressively less) stimulative monetary policy throughout the expansion, boosting economic activity. In one sense, this policy could be viewed as having successfully delivered on the Fed's mandated goals of full employment and stable prices. The unemployment rate has been below 5% since 2015 and is now lower than the rate believed to be consistent with full employment. Other labor market measures are also consistent with full employment, with the possible exception of the still-low labor force participation rate. Economic theory posits that lower unemployment will lead to higher inflation in the short run, but inflation has not proven responsive to lower unemployment in recent years. After remaining persistently below the Fed's 2% target from mid-2012 to early 2018 as measured by core PCE, inflation has remained around 2% in 2018 as measured by headline or core PCE. Economic growth has also picked up beginning in the second quarter of 2017, after being persistently low by historical standards throughout the expansion. Contributing to the 2018 growth acceleration, a more expansionary fiscal policy (larger structural budget deficit) added more stimulus to the economy in the short run. Two notable policy changes contributing to fiscal stimulus in 2018 were the 2017 tax cuts ( P.L. 115-97 ) and the boost to discretionary spending in FY2018 and FY2019 agreed to in P.L. 115-123 . The Fed did little to offset this fiscal stimulus, as the pace of monetary tightening in 2018 was only slightly faster than in 2017. Despite strong economic data (which is only available with a lag), the Fed announced in January 2019 that it would be "patient" before raising rates again in light of increased economic uncertainty and financial volatility. The Fed's intended policy path poses risks. If the Fed waits too long to raise rates again, the economy could overheat, resulting in high inflation and posing risk to financial stability. As an example of how overly stimulative monetary policy can lead to the latter, critics contend that the Fed contributed to the precrisis housing bubble by keeping interest rates too low for too long during the economic recovery starting in 2001. Critics see these risks as outweighing any marginal benefit associated with monetary stimulus when the economy is already so close to full employment. Raising rates more quickly would also provide more "headroom" for the Fed to lower rates more aggressively during the next economic downturn. The potential percentage point reduction in rates before hitting the zero bound is currently smaller than the rate cuts that the Fed has undertaken in past recessions. Alternatively, there is uncertainty about whether strong growth, low unemployment, inflation around 2%, and the generally benign economic environment will continue. Economic expansions do not "die of old age"; nevertheless, the current expansion is already the second longest on record and cannot last forever. The flattening of the yield curve (i.e., long-term Treasury yields are similar to short-term Treasury yields) is seen by some as a warning signal that rates are too high. Although there is a risk of stimulative monetary policy causing the economy to overheat, there is also a risk that tightening too quickly could be harmful if the economy slows. Some critics would prefer clear evidence that inflation is above the Fed's target or financial conditions are unstable before the Fed raises rates again. Monetary policy refers to the actions the Fed undertakes to influence the availability and cost of money and credit to promote the goals mandated by Congress, a stable price level and maximum sustainable employment. Because the expectations of households as consumers and businesses as purchasers of capital goods exert an important influence on the major portion of spending in the United States, and because these expectations are influenced in important ways by the Fed's actions, a broader definition of monetary policy would include the directives, policies, statements, economic forecasts, and other Fed actions, especially those made by or associated with the chairman of its Board of Governors, who is the nation's central banker. The Fed's Federal Open Market Committee (FOMC) meets every six weeks to choose a federal funds target and sometimes meets on an ad hoc basis if it wants to change the target between regularly scheduled meetings. The FOMC is composed of the 7 Fed governors, the President of the Federal Reserve Bank of New York, and 4 of the other 11 regional Federal Reserve Bank presidents serving on a rotating basis. The Fed targets the federal funds rate to carry out monetary policy. The federal funds rate is determined in the private market for overnight reserves of depository institutions (called the federal funds market). At the end of a given period, usually a day, depository institutions must calculate how many dollars of reserves they want or need to hold against their reservable liabilities (deposits). Some institutions may discover a reserve shortage (too few reservable assets relative to those they want to hold), whereas others may have reservable assets in excess of their wants. These reserves can be borrowed and lent on an overnight basis in a private market called the federal funds market. The interest rate in this market is called the federal funds rate. If it wishes to expand money and credit, the Fed will lower the target, which encourages more lending activity and, thus, greater demand in the economy. Conversely, if it wishes to tighten money and credit, the Fed will raise the target. The federal funds rate is linked to the interest rates that banks and other financial institutions charge for loans. Thus, whereas the Fed may directly influence only a very short-term interest rate, this rate influences other longer-term rates. However, this relationship is far from being on a one-to-one basis because longer-term market rates are influenced not only by what the Fed is doing today, but also by what it is expected to do in the future and by what inflation is expected to be in the future. This fact highlights the importance of expectations in explaining market interest rates. For that reason, a growing body of literature urges the Fed to be very transparent in explaining what its policy is, will be, and in making a commitment to adhere to that policy. The Fed has responded to this literature and is increasingly transparent in explaining its policy measures and what these measures are expected to accomplish. The Federal Reserve uses two methods to maintain its target for the federal funds rate: The Fed can also change the federal funds rate by changing reserve requirements, which specify what portion of customer deposits (primarily checking accounts) banks must hold as vault cash or on deposit at the Fed. Thus, reserve requirements affect the liquidity available within the federal funds market. Statute sets the numerical levels of reserve requirements, although the Fed has some discretion to adjust them. Currently, banks are required to hold 0% to 10% of customer deposits that qualify as net transaction accounts in reserves, depending on the size of the bank's deposits. This tool is used rarely—the percentage was last changed in 1992. Each of these tools works by altering the overall liquidity available for use by the banking system, which influences the amount of assets these institutions can acquire. These assets are often called credit because they represent loans the institutions have made to businesses and households, among others. The Fed's control over monetary policy stems from its exclusive ability to alter the money supply and credit conditions more broadly. The Fed directly controls the monetary base , which is made up of currency (Federal Reserve notes) and bank reserves. The size of the monetary base, in turn, influences broader measures of the money supply, which include close substitutes to currency, such as demand deposits (e.g., checking accounts) held at banks. The Fed's definition of monetary policy as the actions it undertakes to influence the availability and cost of money and credit suggests two ways to measure the stance of monetary policy. One is to look at the cost of money and credit as measured by the rate of interest relative to inflation (or inflation projections), and the other is to look at the growth of money and credit itself. Thus, it is possible to look at either interest rates or the growth in the supply of money and credit in coming to a conclusion about the current stance of monetary policy—that is, whether it is expansionary (adding stimulus to the economy), contractionary (slowing economic activity), or neutral. During the high inflation experience of the 1970s the Fed placed greater emphasis on money supply growth, but since then, most central banks including the Fed have preferred to formulate monetary policy in terms of the cost of money and credit rather than in terms of their supply. The Fed conducts monetary policy by focusing on the cost of money and credit as proxied by the federal funds rate. A simple comparison of market interest rates over time as an indicator of changes in the stance of monetary policy is potentially misleading, however. Economists call the interest rate that is essential to decisions made by households and businesses to buy capital goods the real interest rate. It is often proxied by subtracting from the market interest rate the actual or expected rate of inflation. If inflation rises and market interest rates remain the same, then real interest rates have fallen, with a similar economic effect as if market rates (called nominal rates) had fallen by the same amount with a constant inflation rate. The federal funds rate is only one of the many interest rates in the financial system that determines economic activity. For these other rates, the real rate is largely independent of the amount of money and credit over the longer run because it is determined by the interaction of saving and investment (or the demand for capital goods). The internationalization of capital markets means that for most developed countries the relevant interaction between saving and investment that determines the real interest rate is on a global basis. Thus, real rates in the United States depend not only on U.S. national saving and investment but also on the saving and investment of other countries. For that reason, national interest rates are influenced by international credit conditions and business cycles. How do changes in short-term interest rates affect the overall economy? In the short run, an expansionary monetary policy that reduces interest rates increases interest-sensitive spending, all else equal. Interest-sensitive spending includes physical investment (i.e., plant and equipment) by firms, residential investment (housing construction), and consumer-durable spending (e.g., automobiles and appliances) by households. As discussed in the next section, it also encourages exchange rate depreciation that causes exports to rise and imports to fall, all else equal. To reduce spending in the economy, the Fed raises interest rates and the process works in reverse. An examination of U.S. economic history will show that money- and credit-induced demand expansions can have a positive effect on U.S. GDP growth and total employment. The extent to which greater interest-sensitive spending results in an increase in overall spending in the economy in the short run will depend in part on how close the economy is to full employment. When the economy is near full employment, the increase in spending is likely to be dissipated through higher inflation more quickly. When the economy is far below full employment, inflationary pressures are more likely to be muted. This same history, however, also suggests that over the longer run, a more rapid rate of growth of money and credit is largely dissipated in a more rapid rate of inflation with little, if any, lasting effect on real GDP and employment. Economists have two explanations for this paradoxical behavior. First, they note that, in the short run, many economies have an elaborate system of contracts (both implicit and explicit) that makes it difficult in a short period for significant adjustments to take place in wages and prices in response to a more rapid growth of money and credit. Second, they note that expectations for one reason or another are slow to adjust to the longer-run consequences of major changes in monetary policy. This slow adjustment also adds rigidities to wages and prices. Because of these rigidities, changes in the growth of money and credit that change aggregate demand can have a large initial effect on output and employment, albeit with a policy lag of six to eight quarters before the broader economy fully responds to monetary policy measures. Over the longer run, as contracts are renegotiated and expectations adjust, wages and prices rise in response to the change in demand and much of the change in output and employment is undone. Thus, monetary policy can matter in the short run but be fairly neutral for GDP growth and employment in the longer run. In societies in which high rates of inflation are endemic, price adjustments are very rapid. During the final stages of very rapid inflations, called hyperinflation, the ability of more rapid rates of growth of money and credit to alter GDP growth and employment is virtually nonexistent, if not negative. Either fiscal policy (defined here as changes in the structural budget deficit, caused by policy changes to government spending or taxes) or monetary policy can be used to alter overall spending in the economy. However, there are several important differences to consider between the two. First, economic conditions change rapidly, and in practice monetary policy can be more nimble than fiscal policy. The Fed meets every six weeks to consider changes in interest rates and can call an unscheduled meeting any time. Large changes to fiscal policy typically occur once a year at most. Once a decision to alter fiscal policy has been made, the proposal must travel through a long and arduous legislative process that can last months before it can become law, whereas monetary policy changes are made instantly. Both monetary and fiscal policy measures are thought to take more than a year to achieve their full impact on the economy due to pipeline effects. In the case of monetary policy, interest rates throughout the economy may change rapidly, but it takes longer for economic actors to change their spending patterns in response. For example, in response to a lower interest rate, a business must put together a loan proposal, apply for a loan, receive approval for the loan, and then put the funds to use. In the case of fiscal policy, once legislation has been enacted, it may take some time for authorized spending to be outlayed. An agency must approve projects and select and negotiate with contractors before funds can be released. In the case of transfers or tax cuts, recipients must receive the funds and then alter their private spending patterns before the economy-wide effects are felt. For both monetary and fiscal policy, further rounds of private and public decisionmaking must occur before multiplier or ripple effects are fully felt. Second, monetary policy is determined based only on the Fed's mandate, whereas fiscal policy is determined based on competing political goals. Fiscal policy changes have macroeconomic implications regardless of whether that was policymakers' primary intent. Political constraints have prevented increases in budget deficits from being fully reversed during expansions. Over the course of the business cycle, aggregate spending in the economy can be expected to be too high as often as it is too low. This means that stabilization policy should be tightened as often as it is loosened, yet increasing the budget deficit has proven to be much more popular than implementing the spending cuts or tax increases necessary to reduce it. As a result, the budget has been in deficit in all but five years since 1961, which has led to an accumulation of federal debt that gives policymakers less leeway to potentially undertake a robust expansionary fiscal policy, if needed, in the future. By contrast, the Fed is more insulated from political pressures, as discussed in the previous section, and experience shows that it is willing to raise or lower interest rates. Third, the long-run consequences of fiscal and monetary policy differ. Expansionary fiscal policy creates federal debt that must be serviced by future generations. Some of this debt will be "owed to ourselves," but some (presently, about half) will be owed to foreigners. To the extent that expansionary fiscal policy crowds out private investment, it leaves future national income lower than it otherwise would have been. Monetary policy does not have this effect on generational equity, although different levels of interest rates will affect borrowers and lenders differently. Furthermore, the government faces a budget constraint that limits the scope of expansionary fiscal policy—it can only issue debt as long as investors believe the debt will be honored, even if economic conditions require larger deficits to restore equilibrium. Fourth, openness of an economy to highly mobile capital flows changes the relative effectiveness of fiscal and monetary policy. Expansionary fiscal policy would be expected to lead to higher interest rates, all else equal, which would attract foreign capital looking for a higher rate of return, causing the value of the dollar to rise. Foreign capital can only enter the United States on net through a trade deficit. Thus, higher foreign capital inflows lead to higher imports, which reduce spending on domestically produced substitutes and lower spending on exports. The increase in the trade deficit would cancel out the expansionary effects of the increase in the budget deficit to some extent (in theory, entirely if capital is perfectly mobile). Expansionary monetary policy would have the opposite effect—lower interest rates would cause capital to flow abroad in search of higher rates of return elsewhere, causing the value of the dollar to fall. Foreign capital outflows would reduce the trade deficit through an increase in spending on exports and domestically produced import substitutes. Thus, foreign capital flows would (tend to) magnify the expansionary effects of monetary policy. Fifth, fiscal policy can be targeted to specific recipients. In the case of normal open market operations, monetary policy cannot. This difference could be considered an advantage or a disadvantage. On the one hand, policymakers could target stimulus to aid the sectors of the economy most in need or most likely to respond positively to stimulus. On the other hand, stimulus could be allocated on the basis of political or other noneconomic factors that reduce the macroeconomic effectiveness of the stimulus. As a result, both fiscal and monetary policy have distributional implications, but the latter's are largely incidental whereas the former's can be explicitly chosen. In cases in which economic activity is extremely depressed, monetary policy may lose some of its effectiveness. When interest rates become extremely low, interest-sensitive spending may no longer be very responsive to further rate cuts. Furthermore, interest rates cannot be lowered below zero so traditional monetary policy is limited by this "zero lower bound." In this scenario, fiscal policy may be more effective. As is discussed in the next section, some argue that the U.S. economy experienced this scenario following the recent financial crisis. Of course, using monetary and fiscal policy to stabilize the economy are not mutually exclusive policy options. But because of the Fed's independence from Congress and the Administration, the two policy options are not always coordinated. If Congress and the Fed were to choose compatible fiscal and monetary policies, respectively, then the economic effects would be more powerful than if either policy were implemented in isolation. For example, if stimulative monetary and fiscal policies were implemented, the resulting economic stimulus would be larger than if one policy were stimulative and the other were neutral. Alternatively, if Congress and the Fed were to select incompatible policies, these policies could partially negate each other. For example, a stimulative fiscal policy and contractionary monetary policy may end up having little net effect on aggregate demand (although there may be considerable distributional effects). Thus, when fiscal and monetary policymakers disagree in the current system, they can potentially choose policies with the intent of offsetting each other's actions. Whether this arrangement is better or worse for the economy depends on what policies are chosen. If one actor chooses inappropriate policies, then the lack of coordination allows the other actor to try to negate its effects. When the United States experienced the worst financial crisis since the Great Depression, the Fed undertook increasingly unprecedented steps in an attempt to restore financial stability. These steps included reducing the federal funds rate to the zero lower bound, providing direct financial assistance to financial firms, and "quantitative easing." These unconventional policy decisions continue to have consequences for monetary policy today, as the Fed embarks on monetary policy "normalization." The bursting of the housing bubble led to the onset of a financial crisis that affected both depository institutions and other segments of the financial sector involved with housing finance. As the delinquency rates on home mortgages rose to record numbers, financial firms exposed to the mortgage market suffered capital losses and lost access to liquidity. The contagious nature of this development was soon obvious as other types of loans and credit became adversely affected. This, in turn, spilled over into the broader economy, as the lack of credit soon had a negative effect on both production and aggregate demand. In December 2007, the economy entered a recession. As the housing slump's spillover effects to the financial system, as well as its international scope, became apparent, the Fed responded by reducing the federal funds target and the discount rate. Beginning on September 18, 2007, and ending on December 16, 2008, the federal funds target was reduced from 5.25% to a range between 0% and 0.25%, where it remained until December 2015. Economists call this the zero lower bound to signify that once the federal funds rate is lowered to zero, conventional open market operations cannot be used to provide further stimulus. The Fed attempted to achieve additional monetary stimulus at the zero bound through a pledge to keep the federal funds rate low for an extended period of time, which has been called forward guidance or forward commitment . The decision to maintain a target interest rate near zero was unprecedented. First, short-term interest rates have never before been reduced to zero in the history of the Federal Reserve. Second, the Fed waited much longer than usual to begin tightening monetary policy in the current recovery. For example, in the previous two expansions, the Fed began raising rates less than three years after the preceding recession ended. With liquidity problems persisting as the federal funds rate was reduced, it appeared that the traditional transmission mechanism linking monetary policy to activity in the broader economy was not working. Monetary authorities became concerned that the liquidity provided to the banking system was not reaching other parts of the financial system. As noted above, using only traditional monetary policy tools, additional monetary stimulus cannot be provided once the federal funds rate has reached its zero bound. To circumvent this problem, the Fed decided to use nontraditional methods to provide additional monetary policy stimulus. First, the Federal Reserve introduced a number of emergency credit facilities to provide increased liquidity directly to financial firms and markets. The first facility was introduced in December 2007, and several were added after the worsening of the crisis in September 2008. These facilities were designed to fill perceived gaps between open market operations and the discount window, and most of them were designed to provide short-term loans backed by collateral that exceeded the value of the loan. A number of the recipients were nonbanks that are outside the regulatory umbrella of the Federal Reserve; this marked the first time that the Fed had lent to nonbanks since the Great Depression. The Fed authorized these actions under Section 13(3) of the Federal Reserve Act, a seldom-used emergency provision that allowed it to extend credit to nonbank financial institutions and to nonfinancial firms as well. The Fed provided assistance through liquidity facilities, which included both the traditional discount window and the newly created emergency facilities mentioned above, and through direct support to prevent the failure of two specific institutions, American International Group (AIG) and Bear Stearns. The amount of assistance provided was an order of magnitude larger than normal Fed lending, as shown in Figure 1 . Total assistance from the Federal Reserve at the beginning of August 2007 was approximately $234 million provided through liquidity facilities, with no direct support given. In mid-December 2008, this number reached a high of $1.6 trillion, with a near-high of $108 billion given in direct support. From that point on, it fell steadily. Assistance provided through liquidity facilities fell below $100 billion in February 2010, when many facilities were allowed to expire, and support to specific institutions fell below $100 billion in January 2011. The last loan from the crisis was repaid on October 29, 2014. Central bank liquidity swaps (temporary currency exchanges between the Fed and central foreign banks) are the only facility created during the crisis still active, but they have not been used on a large scale since 2012. All assistance through expired facilities has been fully repaid with interest. In 2010, the Dodd-Frank Act changed Section 13(3) to rule out direct support to specific institutions in the future. From the introduction of its first emergency lending facility in December 2007 to the worsening of the crisis in September 2008, the Fed sterilized the effects of lending on its balance sheet (i.e., prevented the balance sheet from growing) by selling an offsetting amount of Treasury securities. After September 2008, assistance exceeded remaining Treasury holdings, and the Fed allowed its balance sheet to grow. Between September 2008 and November 2008, the Fed's balance sheet more than doubled in size, increasing from less than $1 trillion to more than $2 trillion. The loans and other assistance provided by the Federal Reserve to banks and nonbank institutions are considered assets on this balance sheet because they represent money owed to the Fed. With the federal funds rate at its zero bound and direct lending falling as financial conditions began to normalize in 2009, the Fed faced the decision of whether to try to provide additional monetary stimulus through unconventional measures. It did so through two unconventional tools—large-scale asset purchases (quantitative easing) and forward guidance. With short-term rates constrained by the zero bound, the Fed hoped to reduce long-term rates through large-scale asset purchases, which were popularly referred to as quantitative easing (QE). Between 2009 and 2014, the Fed undertook three rounds of QE, buying U.S. Treasury securities, agency debt, and agency mortgage-backed securities (MBS). These securities now comprise most of the assets on the Fed's balance sheet. To understand the effect of quantitative easing on the economy, it is first necessary to describe its effect on the Fed's balance sheet. In 2009, the Fed's emergency lending declined rapidly as market conditions stabilized, which would have caused the balance sheet to decline if the Fed took no other action. Instead, asset purchases under the first round of QE (QE1) offset the decline in lending, and from November 2008 to November 2010, the overall size of the Fed's balance sheet did not vary by much. Its composition changed because of QE1, however—the amount of Fed loans outstanding fell to less than $50 billion at the end of 2010, whereas holdings of securities rose from less than $500 billion in November 2008 to more than $2 trillion in November 2010. The second round of QE, QE2, increased the Fed's balance sheet from $2.3 trillion in November 2010 to $2.9 trillion in mid-2011. It remained around that level until September 2012, when it began rising for the duration of the third round, QE3. It was about $4.5 trillion (comprised of $2.5 trillion of Treasury securities, $1.7 trillion MBS, and $0.4 trillion of agency debt) when QE3 ended in October 2014, and has remained at that level since. Table 1 summarizes the Fed's QE purchases. In total, the Fed's balance sheet increased by more than $2.5 trillion over the course of the three rounds of QE, making it about five times larger than it was before the crisis. This increase in the Fed's assets must be matched by a corresponding increase in the liabilities on its balance sheet. The Fed's liabilities mostly take the form of currency, bank reserves, and cash deposited by the U.S. Treasury at the Fed. QE has mainly resulted in an increase in bank reserves, from about $46 billion in August 2008 to $820 billion at the end of 2008. Since October 2009, bank reserves have exceeded $1 trillion, and they have been between $2.5 trillion and $2.8 trillion since 2014. The increase in bank reserves can be seen as the inevitable outcome of the increase in assets held by the Fed because the bank reserves, in effect, financed the Fed's asset purchases and loan programs. Reserves increase because when the Fed makes loans or purchases assets, it credits the proceeds to the recipients' reserve accounts at the Fed. The intended purpose of QE was to put downward pressure on long-term interest rates. Purchasing long-term Treasury securities and MBS should directly reduce the rates on those securities, all else equal. The hope is that a reduction in those rates feeds through to private borrowing rates throughout the economy, stimulating spending on interest-sensitive consumer durables, housing, and business investment in plant and equipment. Indeed, Treasury and mortgage rates have been unusually low since the crisis compared with the past few decades, although the timing of declines in those rates does not match up closely to the timing of asset purchases. Determining whether QE reduced rates more broadly and stimulated interest-sensitive spending requires controlling for other factors, such as the weak economy, which tends to reduce both rates and interest-sensitive spending. The increase in the Fed's balance sheet has the potential to be inflationary because bank reserves are a component of the portion of the money supply controlled by the Fed (called the monetary base ), which grew at an unprecedented pace during QE. In practice, overall measures of the money supply have not grown as quickly as the monetary base, and inflation has remained below the Fed's goal of 2% for most of the period since 2008. The growth in the monetary base has not translated into higher inflation because bank reserves have mostly remained deposited at the Fed and have not led to increased lending or asset purchases by banks. Another concern is that by holding large amounts of MBS, the Fed is allocating credit to the housing sector, putting the rest of the economy at a disadvantage compared with that sector. Advocates of MBS purchases note that housing was the sector of the economy most in need of stabilization, given the nature of the crisis (this argument becomes less persuasive as the housing market continues to rebound); that MBS markets are more liquid than most alternatives, limiting the potential for the Fed's purchases to be disruptive; and that the Fed is legally permitted to purchase few other assets, besides Treasury securities. On October 29, 2014, the Fed announced that it would stop making large-scale asset purchases at the end of the month. Now that QE is completed, attention has turned to the Fed's "exit strategy" from QE and zero interest rates. The Fed laid out its plans to normalize monetary policy in a statement in September 2014. It plans to continue implementing monetary policy by targeting the federal funds rate. The basic challenge to doing so is that the Fed cannot effectively alter the federal funds rate by altering reserve levels (as it did before the crisis) because QE has flooded the market with excess bank reserves. In other words, in the presence of more than $2 trillion in bank reserves, the market-clearing federal funds rate is close to zero even if the Fed would like it to be higher. The most straightforward way to return to normal monetary policy would be to remove those excess reserves by shrinking the balance sheet through asset sales. The Fed does not intend to sell any securities, however. Instead, it is gradually reducing the balance sheet by ceasing to roll over securities as they mature, which began in September 2017—almost three years after QE ended. Initially, it allowed only $6 billion of Treasuries and $4 billion of MBS to run off each month, which was gradually increased to $30 billion of Treasuries and $20 billion of MBS per month, where it will remain until normalization is completed. The Fed believes that it would only cease shrinking the balance sheet or use QE again in the future if it its ability to stimulate the economy using reductions in the federal funds rate were insufficient. The Fed intends to ultimately reduce the balance sheet until it holds "no more securities than necessary to implement monetary policy efficiently and effectively." The Fed has stated that it foresees a balance sheet size that is consistent with this goal will be larger than it was before the crisis. In part, that is because other liabilities on the Fed's balance sheet are larger—there is more currency in circulation now than there was before the crisis, and the Treasury has kept larger balances on average in its account at the Fed. But the balance sheet will also be significantly larger because the Fed decided in January 2019 to continue using its new method of targeting the federal funds rate even after normalization is completed. Under the new method, the federal funds rate is not determined by supply and demand in the market for bank reserves, and the Fed would prefer to maintain abundant bank reserves so that it does not have to use open market operations to respond to changes in banks' demand for reserves. By contrast, if it went back to the pre-crisis method of targeting the federal funds rate, only minimal excess reserve balances would be necessary (but perhaps more than before the crisis), so its balance sheet could be much smaller. The Fed has not yet announced when the wind-down will be completed or how large the balance sheet would be upon completion, but the January 2019 FOMC minutes noted the wind-down could be completed as soon as this year. In that case, the balance sheet would not be much smaller than its current size of $4 trillion when normalization is completed—more than four times larger than its pre-crisis size. Although the Fed has stated that it intends to eventually stop holding MBS, the Fed would still have sizable MBS holdings in 2025, according to projections from the New York Fed. In order to raise the federal funds rate in the presence of large reserves, the Fed has raised the two market interest rates that are close substitutes—it has directly raised the rate it pays banks on reserves held at the Fed and used large-scale reverse repurchase agreements (repos) to alter repo rates. In 2008, Congress granted the Fed the authority to pay interest on reserves. Because banks can earn interest on excess reserves by lending them in the federal funds market or by depositing them at the Fed, raising the interest rate on bank reserves should also raise the federal funds rate. In this way, the Fed can lock up excess liquidity to avoid any potentially inflationary effects because reserves kept at the Fed cannot be put to use by banks to finance activity in the broader economy. In practice, the interest rate that the Fed has paid banks on reserves has been slightly higher than the federal funds rate, which some have criticized as a subsidy to banks. Reverse repos are another tool for draining liquidity from the system and influencing short-term market rates. They drain liquidity from the financial system because cash is transferred from market participants to the Fed. As a result, interest rates in the repo market, one of the largest short-term lending markets, rise. The Fed has long conducted open market operations through the repo market, but since 2013 it has engaged in a much larger volume of reverse repos with a broader range of nonbank counterparties, including the government-sponsored enterprises (such as Fannie Mae and Freddie Mac) and certain money market funds, through a new Overnight Reverse Repurchase Operations Facility. The Fed is currently not capping the amount of overnight reverse repos offered through this facility. There has been some concern about the potential ramifications of the Fed becoming a dominant participant in this market and expanding its counterparties. For example, will counterparties only be willing to transact with the Fed in a panic, and will the Fed be exposed to counterparty risk with nonbanks that it does not regulate? The Fed has distinct roles as a central bank and a regulator. Its main regulatory responsibilities are as follows: B ank regulation . The Fed supervises bank holding companies (BHCs) and thrift holding companies (THCs), which include all large and thousands of small depositories, for safety and soundness. The Dodd-Frank Act requires the Fed to subject BHCs with more than $50 billion in consolidated assets to enhanced prudential regulation (i.e., stricter standards than are applied to similar firms) in an effort to mitigate the systemic risk they pose. The Fed is also the prudential regulator of U.S. branches of foreign banks and state banks that have elected to become members of the Federal Reserve System. Often in concert with the other banking regulators, it promulgates rules and supervisory guidelines that apply to banks in areas such as capital adequacy, and examines depository firms under its supervision to ensure that those rules are being followed and those firms are conducting business prudently. The Fed's supervisory authority includes consumer protection for banks under its jurisdiction that have $10 billion or less in assets. P rudential regulat ion of nonbank systemically important financial institutions . The Dodd-Frank Act allows the Financial Stability Oversight Council (FSOC) to designate nonbank financial firms as systemically important (SIFIs). Designated firms are supervised by the Fed for safety and soundness. Since enactment, the number of designated firms has ranged from four, initially, to none today. R egulation of the payment system . The Fed regulates the retail and wholesale payment system for safety and soundness. It also operates parts of the payment system, such as interbank settlements and check clearing. The Dodd-Frank Act subjects payment, clearing, and settlement systems designated as systemically important by the FSOC to enhanced supervision by the Fed (along with the Securities and Exchange Commission and the Commodity Futures Trading Commission, depending on the type of system). M argin requirements . The Fed sets margin requirements on the purchases of certain securities, such as stocks, in certain private transactions. The purpose of margin requirements is to mandate what proportion of the purchase can be made on credit. The Fed attempts to mitigate systemic risk and prevent financial instability through these regulatory responsibilities, as well as through its lender of last resort activities and participation on the FSOC (whose mandate is to identify risks and respond to emerging threats to financial stability). The Fed has focused more on attempting to mitigate systemic risk through its regulations since the financial crisis, and has also restructured its internal operations to facilitate a macroprudential approach to supervision and regulation.
The Buy American Act of 1933 was enacted during the Great Depression when there was a need to create and preserve jobs for American workers, and it established a preference for the federal government to buy domestic end products. Many of the products the federal government buys—including aircraft engines and medical supplies—are end products that may be subject to the requirements of the Buy American Act. Further, the Buy American Act does not apply to products that are purchased for use outside the United States or obtained through contracts under the micro-purchase threshold, which was generally $3,500 in fiscal year 2017. end products manufactured in the United States provided that (a) the product is a commercially available off-the-shelf item; or (b) the cost of the components mined, produced, or manufactured in the United States exceeds 50 percent of the total cost of all components. End products that are not considered domestic under the Buy American Act are treated as foreign. This characterization is based on the origin of the end product—that is, where the product is manufactured or produced—and not the vendor’s location. For example, a vendor located in Finland may supply end products manufactured in the United States, in which case these products would be treated as domestic products. Conversely, a vendor located in the United States may supply end products manufactured in Finland. In this case, the end products would be considered foreign. Although the Buy American Act establishes a preference for domestic end products, there are situations in which agencies can procure foreign end products through established exceptions to the Buy American requirements. In addition, under the Trade Agreements Act of 1979, the United States has waived domestic purchasing requirements—including the Buy American Act—for certain acquisitions of foreign end products from countries that are party to international trade agreements or are considered designated countries by the U.S. Trade Representative. In implementing the Buy American Act, the FAR sets forth several exceptions that permit federal agencies to buy foreign end products. These include situations when a domestic end product is not produced in sufficient quantities or cases where the cost would be unreasonable to buy a domestic end product. The steps that contracting officers must take to determine or document an exception will vary depending on the circumstances of the acquisition. For example, a written determination from the Head of Contracting Activity (HCA) or a delegate may be necessary to determine non-availability in some cases. However, a written determination may not be required when an acquisition is conducted through full and open competition, is synopsized, and no domestic offer is received. Other exceptions to the Buy American Act restrictions on the purchase of foreign products, such as the exception for commercial information technology, are blanket exceptions that do not require a written determination. In addition, some agencies have specified additional considerations that must precede a determination and what level of authority is appropriate for certain determinations. The five Buy American Act exceptions that apply government-wide and the corresponding determination standards in the FAR are listed in Table 1. Individual federal agencies may make blanket determinations of situations in which the Act’s restrictions should not apply to that agency’s procurements, when it is not in the public interest to restrict the purchase of foreign end products. For example, over the years, DOD has entered into reciprocal procurement agreements with 27 foreign counterparts. DOD determined that it would be inconsistent with the public interest to apply the Buy American Act restrictions on products from these 27 qualifying countries. Thus, if an offer includes end products from a qualifying country, those products are not restricted by the Buy American Act and the acquisition of qualifying country end products does not require higher approval. This public interest exception for qualifying countries applies only to contracts awarded by DOD. Federal agencies can purchase eligible foreign end products from designated countries when the Buy American Act’s requirements are waived because of the terms of an international trade agreement or other criteria, such as a designation by the U.S. Trade Representative as a least developed country. In accordance with the Trade Agreements Act of 1979, the president has the authority to waive the Buy American Act. For eligible products that come from countries covered by the World Trade Organization’s Government Procurement Agreement, Free Trade Agreements, and the Israeli Trade Act, the Buy American Act has been waived so that these items receive nondiscriminatory consideration and are on equal footing with domestic end products. In total, these agreements cover approximately 60 countries—overlapping with all but two of the DOD qualifying countries. Appendix II highlights the overlap. Unlike DOD’s blanket public interest exception for qualifying countries, the Buy American Act requirements are only waived under a trade agreement if the acquisition is of a certain value set by the U.S. Trade Representative. Current trade agreement thresholds, at or above which the requirements are waived, range from $25,000 for contracts for eligible products from Canada to $180,000 for the 45 other parties to the World Trade Organization’s Government Procurement Agreement. Table 2 lists the parties eligible for trade agreements and the associated threshold for supply contracts. The FAR specifies certain conditions in which trade agreements do not apply, even if the acquisition is above the requisite threshold value set by the U.S. Trade Representative. In these cases, the Buy American Act would apply. These conditions include, but are not limited to: acquisitions that do not use full and open competition, when the limitation of competition would preclude the procedures applicable to acquisitions covered by trade agreements; certain sole-source acquisitions for commercial items using simplified acquisition procedures; acquisitions set aside for small businesses; acquisition of ammunition, arms, or war materials, or for purchases indispensable for national security or national defense purposes; and acquisitions from federal prison industries or nonprofit agencies employing people who are blind or severely disabled. If the contracting officer determines that a trade agreement applies to a particular acquisition, which waives the Buy American restrictions, that determination does not require additional review at a higher level. This is similar to other circumstances where Buy American Act restrictions do not apply, such as for the acquisition of products for use outside the United States or contracts valued below the micro-purchase threshold. The Buy American Act’s applicability is based on the country of origin of the product being supplied, rather than the country of the vendor offering the product to the government. Vendors who propose to do business with the U.S. government are required to certify as to where their products are manufactured or produced—whether in the United States or in a designated country covered by the Trade Agreements Act. Vendors can provide an annual certification applicable to all of their contracts through the federal government’s contractor registry, known as the System for Award Management (SAM). Through SAM, a vendor identifies the country of origin for foreign products associated with a broad category of products. For example, a vendor could state that it provides aircraft components that originate in France and Mexico. Vendors also have the option not to certify the origin of their products in SAM, but instead provide information about foreign end products in their individual offers for contracts. Contracting officials include the relevant clauses in solicitations and contracts in accordance with regulation to require vendor certification. For example, the clause at FAR 52.225-2, Buy American Certificate, requires the offeror to certify that each end product is a domestic end product, or list any foreign end products and their country of origin. Once a contract is awarded, the awarding agency must enter certain information into FPDS-NG, a government-wide database for contract awards and obligations. The Office of Federal Procurement Policy (OFPP) within the Office of Management and Budget provides the overall direction for FPDS-NG, which is managed by the General Services Administration. FPDS-NG data can be populated through the individual systems agencies use to develop contracts. Agencies are responsible for the quality of the information transmitted to FPDS-NG, including data captured on the contract value and whether the foreign product acquisition is authorized by one of the Buy American Act exceptions or a trade agreement. This information is recorded at the contract level, or at the delivery order level for orders from indefinite delivery contracts. For certain product categories—essentially those that represent end products—FPDS-NG requires that contracting staff enter information in the “Place of Manufacture” drop-down data field, as shown in Figure 1. This field must be populated for all reported manufactured end products, including those valued under the micro-purchase threshold, which at the time of our review was generally $3,500. Options in this field include indicating that the product is made in the United States, or that it is made outside the United States and qualifies under one of the Buy American Act exceptions, or that it is subject to the requirements of a trade agreement instead of the Buy American Act requirements. In 2018, FPDS-NG data on agencies’ historical reporting of the use of Buy American exceptions were added to the website on which agencies post contracting opportunities (www.fbo.gov). According to OFPP, this allows vendors selling domestic products to more easily see how agencies acquire foreign goods pursuant to Buy American Act exceptions. In fiscal year 2017, the federal government obligated approximately $7.8 billion for the acquisition of foreign end products, which accounts for less than 5 percent of total federal contract obligations for end products in that year. We observed differences in how civilian agencies and DOD apply Buy American Act exceptions and waivers. In our review of 38 contracts and orders from four agencies—DOD, HHS, DHS, and VA—we found 6 instances where the place of manufacture information was misreported in FPDS-NG. We further identified system limitations in how FPDS-NG captures information. Based on our analysis of FPDS-NG data, almost 40 percent of federal contract obligations in fiscal year 2017—totaling approximately $196 billion—were for domestic and foreign end products, such as aircraft parts, that may be subject to the Buy American Act. Less than 5 percent of these obligations—approximately $7.8 billion—were reported as foreign end products. This is consistent with the information agencies reported in FPDS-NG in the previous 4 years, with foreign end products accounting for approximately 3 to 8 percent of goods subject to Buy American Act restrictions between fiscal years 2013 through 2016. The foreign end products in fiscal year 2017 primarily came from South Korea, the United Kingdom, Afghanistan, Canada, Mexico, and the United Arab Emirates, which together accounted for almost half of the total foreign end products reported. Appendix III shows the federal government’s obligations for foreign end products from various countries for fiscal year 2017. The procurement of foreign end products is permitted by the flexibilities available under the Buy American Act’s exceptions and waivers. Agencies also procured foreign end products through means separate from the exceptions allowed under the Buy American Act, primarily in cases where the Act would not apply. Agencies reported obligating more than $700 million to procure foreign end products by applying one of the five government-wide Buy American Act exceptions—such as domestic non-availability or unreasonable cost—in FPDS-NG for fiscal year 2017. Agencies reported obligating approximately $550 million to procure foreign end products as permitted by the Trade Agreements Act, which waives the Buy American Act’s domestic preference requirements for US trading partners when eligible products are covered by trade agreements and are above certain dollar thresholds. DOD also obligated nearly $2.9 billion to procure foreign products from countries with which it has reciprocal procurement agreements, using what is referred to as the DOD qualifying country exception. This is an exercise of the authority available to agencies under the Buy American Act’s public interest exception. DOD determined that it is not in the public interest to restrict the purchase of foreign end products from 27 countries. All but two of these qualifying countries are also US trading partners, so some of these awards for eligible products may be authorized by a trade agreement. However, the qualifying country exception allows DOD to procure foreign end products without regard to dollar thresholds or other trade agreement eligibility limitations. Agencies also procured foreign end products, such as fuel, to be used outside the United States, in which circumstance the Buy American Act’s requirements do not apply. For fiscal year 2017, these obligations accounted for almost $3.7 billion—about 47 percent of all dollars obligated for foreign end products, as reported in FPDS-NG. Figure 2 highlights fiscal year 2017 obligations, including agencies’ reported spending on foreign end products under the Buy American Act exceptions and other means. DOD accounted for more than 80 percent—roughly $6.4 billion—of the total obligations for foreign end products in fiscal year 2017. Almost all of DOD purchases were either for use outside of the United States, so were not subject to Buy American Act restrictions, or were reported under the public interest exception for DOD qualifying countries. In contrast, civilian agencies report a more varied mix of the exceptions and waivers of the Buy American Act. The civilian agencies—which are unable to apply DOD’s qualifying country exception—were more likely to report buying foreign end products based on trade agreements or another exception to the Buy American Act requirements. Figure 3 shows how DOD and the civilian agencies acquired foreign end products authorized by the various exceptions and waivers of the Buy American Act. From our review of FPDS-NG data, the civilian agencies are more likely to cite one of the five Buy American Act exceptions or a trade agreement waiver when buying foreign end products, and thus take corresponding actions to document or approve the authority cited. For example, in our review of contracts from four agencies, VA obligated $71,000 for medical imaging equipment from Canada, and had to consider whether a trade agreement waiver applied. The manufacturer was determined to be the only source available and the contracting officer determined the acquisition was authorized by a Buy American exception based on domestic non-availability, which can require additional review. In contrast, DOD may make a similar contract award for equipment from Canada based on the qualifying countries exception. DOD acquisitions, then, may be authorized by exceptions such as domestic non-availability when a required item does not come from a qualifying country. For example, we reviewed a $744,000 DOD award for vehicle equipment that was only available from South Africa—which is not one of the DOD qualifying countries and not covered by any of the trade agreements—so the acquisition was authorized by the domestic non-availability exception. In addition, the civilian agencies also reported buying foreign end products for use outside the United States but to a lesser extent than DOD. For example, this included one of the contracts we reviewed, an HHS award for Ebola vaccines manufactured in the Netherlands, with $44.7 million obligated in fiscal year 2017. This contract was reported as used outside the United States because it is primarily stored overseas. FPDS-NG is the primary means for capturing procurement data regarding the Buy American Act, but we found that agencies may not always input reliable information on the extent to which exceptions or waivers authorized the acquisition of foreign end products. In addition, some aspects of how FPDS-NG is structured could lead to additional data reporting errors. In the non-generalizable sample of 38 contracts and orders we examined from DOD, HHS, DHS, and VA, we found 6 awards where information related to the Buy American Act was incorrectly reported in FPDS-NG. In three of the six contracts, agencies recorded the wrong exception or waiver, most often because of an error when reporting the place of manufacture in FPDS-NG. For example, DOD reported a $22,000 contract for vehicle equipment from South Africa as a Buy American Act exception due to unreasonable cost. But the contract file indicated that the exception that applied was domestic non-availability. DOD officials acknowledged the error and corrected it in FPDS-NG during the course of our review. In the three remaining contracts, agencies misreported whether an end product came from the United States or another country. For example, DHS incorrectly recorded that an $18 million contract was for aircraft accessories and other parts manufactured in the United States, even though file documentation showed the contract was for Italian-produced spare parts from the original equipment manufacturer. The Italian- produced spare parts were available from existing inventory maintained by the manufacturer and were needed immediately to meet a mandatory operational requirement. Officials from DHS acknowledged the recording oversight, attributed it to a mistake when entering information in FPDS- NG, and have since corrected the error in response to our observation. Additionally, FPDS-NG has system limitations that could hinder complete and accurate reporting of Buy American Act information: DOD Qualifying Country Exceptions and Trade Agreement Waivers. FPDS-NG requires that information on the type of Buy American Act exception or waiver applied be provided when end products are reported as foreign. But FPDS-NG does not identify errors associated with this process. For example, we reviewed an $8.3 million DHS contract for engines manufactured in Germany that was recorded as a DOD qualifying country exception in FPDS-NG, although this exception is not available to civilian agencies. Contracting officials corrected the data in FPDS-NG during the course of our review. Further, FPDS-NG does not prevent agencies from reporting trade agreement waivers when the contracts are valued below applicable thresholds or waivers do not apply, such as for small business set asides. For example, in the fiscal year 2017 data we reviewed, more than 5 percent of contract obligations reported for trade agreement waivers were for awards set-aside for small businesses, which would not be eligible under the Trade Agreements Act. OFPP officials noted that because of the various dollar thresholds applicable to different trade agreements, adding automatic thresholds in FPDS-NG to guide contracting staff in reporting an applicable trade agreement could lead to additional data errors in the procurement database. Awards under the Micro-purchase Threshold. Although the Buy American Act requirements do not apply to contract awards valued below the micro-purchase threshold—generally $3,500 in fiscal year 2017—the FPDS-NG ‘Place of Manufacture’ field does not have an option to indicate whether a contract is under the threshold. Instead, contracting officers entering information for awards under the micro- purchase amount must still state whether the product is domestic or foreign. If the product is foreign, the officials must select a Buy American Act exception authorizing the purchase, even though no exception is needed at these dollar levels. As a result, when agencies report in FPDS-NG that a Buy American Act exception or waiver applied for a procurement valued at less than $3,500, that information would not be accurate. Based on our review, this may have involved about $16 million in fiscal year 2017 obligations. Awards for both Foreign and Domestic Products. When reporting data for contracts that include multiple end products from both the United States and a foreign country, FPDS-NG only allows for one country of origin to be identified. Contracting officers told us that they typically will report a foreign end product in FPDS-NG when the foreign products account for the preponderance of the contract value. Thus, in cases where a contract includes foreign end products that do not account for the preponderance of the contract’s value, the value of these foreign end products would not be reported in FPDS-NG. We have previously reported that FPDS-NG has similar limitations in other fields, such the type of product or service provided, which prevent contracting officers from identifying more than one condition. According to OFPP, a recent change in the FAR requiring contract reporting at the line item level should provide greater transparency of all products included in a contract. Buy American Act Exceptions and Waivers under Indefinite Delivery Contracts. The way FPDS-NG captures data for Buy American Act exceptions and waivers for some indefinite-delivery contracts results in inaccurate data reporting. When an indefinite- delivery contract is initially awarded, FPDS-NG functionality does not give contracting staff the option to enter information for the ‘Place of Manufacture’ field. Instead, this information is typically captured once an order is placed on the contract. In our review of FPDS-NG data across the four agencies, however, we found that in some cases obligations are reported on the initial indefinite delivery contract so the Buy American Act exceptions or waivers are not recorded. This occurred with multiple agencies, but particularly at HHS, where information for almost 28 percent of HHS obligations for end products in fiscal year 2017 was not captured in FPDS-NG because the obligations were reported in the system through the initial contracts rather than orders. As a result, the applicability of the Buy American Act for HHS contracts totaling almost $1.9 billion in fiscal year 2017 was unreported in FPDS-NG. DOD, DHS, and VA officials told us they identified FPDS-NG reporting as an area of concern. GAO Standards for Internal Controls in the Federal Government state that management should use quality information to support objectives, and that such data should be complete and accurate. In response to the 2017 Executive Order calling for federal agencies to assess their implementation of the Buy American Act requirement, OFPP officials told us they are identifying potential strategies for improving the information agencies submit to FPDS-NG. As OFPP weighs potential options for FPDS-NG reporting, implementing enhancements to reduce data entry errors and ensure that the data collected are complete and accurate would help enable the system to provide the most useful information possible. Ensuring information is correctly reported in FPDS- NG is critical because the data are used to inform procurement policy decisions and facilitate congressional oversight. The four agencies we reviewed—DOD, HHS, DHS, and VA—took different approaches to provide training and guidance for the Buy American Act requirements. Contracting officers faced challenges when procuring products subject to the Buy American Act. For example, we found instances in which contracting officers applied a waiver or exception to contracts where the waiver did not apply and did not have complete guidance for required determinations or reviews. There also were challenges in confirming product origin information when vendors did not provide consistent information. The four agencies we reviewed varied in the mix of training and guidance provided to aid contracting officers in implementing the requirements of the Buy American Act. Three of the four agencies—DOD, DHS and VA— supplemented the federal acquisition regulation, which implements the requirements of the Buy American Act and Trade Agreements Act, with their own acquisition regulations. In addition, DHS and DOD have recently updated existing training or added new training and guidance. VA issued policy memoranda in 2017, emphasizing the importance of meeting Buy American Act requirements, but has not added training or provided specific guidance. HHS does not provide department-level training or guidance related to the Buy American Act. Most of the DHS and DOD contracting officers we spoke to reported that they had attended training and several found the guidance provided by the training to be helpful. HHS and VA contracting officials described confusion due to the lack of resources available at their respective agencies. In 2017, in response to a series of recommendations from the DOD Inspector General to re-emphasize Buy American Act training and guidance, the Defense Acquisition University introduced an updated training course that specifically focuses on the requirements and implementation of the Buy American Act. While not mandatory, a June 2017 memo notified all DOD services and the defense agencies that members of their contracting workforce should complete this training as part of their professional development. At the current pace of enrollment, DOD officials anticipate approximately 18,000 people will have taken this course by the end of September 2018, which is a seven-fold increase over previous graduation rates. Incorporated into these trainings were supplemental on-the-job tools to assist contracting officers when awarding contracts for end products subject to the Buy American Act requirements. One such tool is a flowchart outlining applicable solicitation provisions or contract clauses based upon the awarded contract’s total dollar value. DOD contracting officials we interviewed from Defense Logistics Agency’s (DLA) Land and Maritime division had completed the agency-level Buy American Act training and said it served as a good refresher, with some noting that most of the training they had received on the subject came when they were first hired. DOD provides regulations and guidance on Buy American Act requirements through both the Defense Federal Acquisition Regulation Supplement (DFARS) and the accompanying Procedures, Guidance and Information. DOD contracting officers use the provisions and clauses in DFARS to address the public interest exception for DOD qualifying countries. In addition, as a part of the updated training, the Defense Pricing and Contracting Office developed two documents to provide additional Buy American Act guidance. One outlines a step-by-step approach contracting officers can follow to determine whether the Buy American Act applies to their particular procurement and, if so, whether the use of an exception or waiver is appropriate. The second assists contracting officers with evaluating all offers—foreign and domestic— when price is the determining factor. In addition, we found that DLA supplements the available Defense Acquisition University training and guidance with a robust level of support, including annual training and subject matter expertise. DLA contracting officers told us that while they found the updated training helpful, they also appreciated the training course internal to their agency, as it addresses the types of procurements they typically handle in their day-to- day work, such as buying spare parts. Further, DLA contracting officers noted that they use the job aid provided through the local training. DHS introduced training courses in 2017 that specifically focus on the requirements and implementation of the Buy American Act, including a mandatory training course for DHS contracting officers. DHS reported that 94 percent of contracting staff had taken the required course as of April 2018. DHS developed these courses in response to the 2017 Executive Order to ensure its staff was familiar with the Buy American Act requirements. Incorporated into these training courses are supplemental on-the-job tools to assist contracting officers when awarding contracts for end products subject to the Buy American Act requirements, such as a flowchart outlining applicable solicitation provisions or contract clauses based upon contract dollar value. Contracting officials generally view the training and tools they received as beneficial. For example, several DHS contracting officials we interviewed said that the agency’s new course provided a helpful review on the topic, while one contracting officer specifically noted that the course materials are useful to new staff, to help them understand the Act’s waivers and exceptions. DHS also revised its acquisition manual in December 2017 to add further detail regarding the Buy American Act requirements. Specifically, DHS updated its acquisition manual to provide contracting officers more explicit FPDS-NG reporting instructions for procurements subject to the Buy American Act, as well as discretion to purchase domestic end products at or below the micro-purchase threshold. Additional changes include increasing the documentation and level of managerial review required to use several of the exceptions to the Buy American Act. For example, prior to 2018—which includes the time period in which the DHS contracts and orders we reviewed were awarded—the head of individual contracting offices had the authority to approve domestic non-availability and unreasonable cost exceptions, with a notification made to the DHS Chief Procurement Officer. But under the new policy, the use of these exceptions must have the concurrence of the HCA—who is responsible for contracting activities within individual DHS components—and be approved by the department’s Chief Procurement Officer. Table 3 outlines these changes. In September 2017, VA issued guidance to reinforce existing Buy American Act requirements. The policy memorandum encourages the HCAs within VA to institute reviews of awarded contracts subject to the Buy American Act to ensure compliance. As of September 2018, policy officials did not know how many HCAs had taken this step. Further, the guidance emphasizes the importance of Buy American Act training for its acquisition workforce. VA policy officials explained that the Buy American Act is introduced in several VA training courses, but the agency does not have a specific course on implementing the Buy American Act requirements or provide additional instruction or tools. During the course of our review, VA officials said that some of the HCAs had added internal training on the Buy American Act. In addition, VA contracting staff has the option of taking training offered outside the agency, such as the updated Defense Acquisition University course on the Buy American Act. This training is not required. Contracting officials we spoke to at VA said they struggled with the details of awarding contracts subject to Buy American Act requirements because they are not provided sufficient agency-specific training and guidance on the topic. Moreover, several contracting staff noted an increased need for training due to recent changes in VA contracting practices. Specifically, in response to a 2016 Supreme Court decision, VA has increased contracting efforts with veteran-owned small businesses through the Veterans First Contracting Program. As a result, contracting officials explained they have reduced their use of schedule contracts, in which the determinations related to the Buy American Act requirements were made with the initial awards. As one contracting officer explained, prior to this change, more than 90 percent of her division’s procurements were through VA schedule contracts in which Buy American Act applicability had already been established. However, this shift in contracting practices means contracting officers will more frequently need to consider the applicability of the Buy American Act, but contracting officers have not received specific guidance or training to do so. Noting the significance of this change, one contracting officer stated she approached VA management to obtain Buy American Act training for her division, but such training was not available. Federal internal controls state that agencies should ensure that training is aimed at developing and retaining employee knowledge, skills, and abilities to meet changing organizational needs. In September 2018, we reported that VA was experiencing difficulties implementing multiple aspects of the Veterans First policy, and we recommended that VA provide more targeted implementation training. As VA moves forward to implement this training, incorporating the Buy American Act requirements will be important to provide greater assurance that staff has the knowledge and skills needed to navigate the changing procurement environment. HHS does not have agency-level Buy American training or guidance. The HHS Acquisition Regulation Supplement does not address foreign acquisitions. HHS officials told us that efforts to develop guidance that would address Buy American Act requirements are underway, but they do not know when they will be finalized and made available to contracting officers, and could not describe the extent to which they will address Buy American Act implementation. The HHS contracting officers we interviewed discussed informal Buy American Act training their divisions had developed because department-level training was not available. For example, at HHS’ National Institutes of Health, a contracting official told us about a training course she recently developed because her office was taking on the administration of additional contracts for which the Buy American Act requirements would apply. Contracting officers at HHS’ Office of Biomedical Advanced Research and Development Authority described informal training on the agency’s contract writing system— included as part of their weekly internal staff meetings—that provides additional guidance on how to appropriately complete certain data fields relevant to the Buy American Act. In our analysis of 38 contracts from across the four agencies, we found that agencies faced various levels of challenge in applying the Trade Agreements Act waivers and Buy American Act exceptions to acquire foreign end products. This was particularly apparent in cases where contracting officers had to determine if a trade agreement applied or cases which required a determination that a domestic end product was not sufficiently available, in accordance with the domestic non-availability exception to the Buy American Act requirements. Contracting staff also had difficulty determining the origin of products in light of incomplete or conflicting information. Of the six contracts we reviewed reporting that a trade agreement applied to the foreign end products purchased, we found two cases in which this waiver did not apply to the contracts in question. The value of the contract is one determining factor for whether a trade agreement waives the Buy American Act requirements, although the FAR also states additional factors that would affect applicability under a trade agreement. The two contracts we found, both from VA, had total dollar values at award— $8,435 and $11,950, respectively—that were less than any of the thresholds at which trade agreement waivers of the Buy American Act are applicable. Both contracts were for products from countries that are party to the World Trade Organization Government Procurement Agreement, so the value of the acquisition would have to be equal to or exceed $191,000—the threshold that was in effect at the time of award—for waivers from Buy American requirements to apply. Contracting officials in both cases were generally unaware that the applicable threshold was not met, making the trade agreement waiver inapplicable. Although VA has added Buy American Act guidance since these contracts were awarded early in fiscal year 2017, the information currently available does not provide sufficient detail to assist contracting officers when awarding contracts in these situations. For example, the guidance VA provided contracting officers in September 2017 does not emphasize consideration of the applicable trade agreement thresholds or include information on how contracting officers should determine the applicable waiver or exception. When contracting officers procure foreign end products, the type of waiver or exception used to support the purchase matters—particularly when required additional steps and review are not completed because the wrong waiver or exception was applied. We found that the two VA contracts with foreign end products were incorrectly reported as the Trade Agreements Act waiver having applied. If one of the other Buy American Act exceptions permitting purchases of foreign end products had applied, contracting officers may have been required to obtain higher-level review or complete a written determination. In addition, we reviewed contracts that show some of the complexities contracting officers face beyond applying the dollar thresholds when determining if an award for foreign end products is eligible under the Trade Agreements Act waiver of the Buy American Act. Specifically, we found instances where DHS contracting officials took different approaches for non-competed awards for similar foreign-manufactured products. For example, we reviewed a non-competed $58 million DHS award for acquiring spare aircraft parts from an original equipment manufacturer located in a foreign country that is party to the World Trade Organization Government Procurement Agreement. DHS reported in FPDS-NG that the procurement was waived by the Trade Agreements Act. However, we also reviewed two other sole-source awards from DHS for similar products—spare aircraft parts from two separate manufacturers in foreign countries that are also party to the World Trade Organization Government Procurement Agreement—that were instead reported as subject to the Buy American Act, but excepted due to the non-availability of domestic products. Contracting officers may come to different conclusions for similar products, in part, because of the multiple factors that have to be considered when determining whether an acquisition is subject to the Buy American Act and whether any waivers or exceptions apply. However, available guidance does not always address these complexities. For example, agencies need to decide if other conditions, such as the procurement of products deemed indispensable for national security or national defense purposes apply to an acquisition that would make a trade agreement inapplicable. Further, if the product’s country of origin is considered a designated country under the World Trade Organization Government Procurement Agreement, officials need to determine that the product is eligible under that agreement. DHS updated its training and guidance for the Buy American Act, which includes a job aid outlining at what dollar values solicitation provisions and contract clauses under a trade agreement waiver are applicable. However, it does not address other situations in which contracts may not be eligible under the Trade Agreements Act, such as non-eligible products or products for national defense purposes. For the other agencies in our review, we found that DOD’s updated Buy American Act training and its acquisition supplement both address trade agreement eligibility, but HHS does not yet have Buy American guidance to address this topic. Federal internal control standards state that agencies should communicate quality information internally to achieve their objectives and that they should select the appropriate methods of communication. When written guidance is not available, agencies may miss opportunities to ensure appropriate steps are taken to meet Buy American Act requirements. Our review of 38 contracts also included 8 contracts for foreign end products pursuant to the domestic non-availability exception. In certain situations, such as when contracts are awarded without full and open competition, this exception requires an approved written determination. The FAR establishes requirements for domestic non-availability determinations, but agencies can delegate the level of review required or specify information to be included in the determination. Three of the agencies we reviewed—DOD, DHS, and VA—provide supplemental guidance on the process for making determinations, including who must make the determination when applying a domestic non-availability exception. However, DHS policy officials told us that when the agency uses the domestic non-availability exception for a sole-source acquisition, the written justification that the FAR requires for non- competed awards should suffice as the documentation to support the non-availability determination as well. The practice of using sole-source justifications to support Buy American determinations is not addressed in DHS guidance. According to DHS policy updated in 2018, determinations of domestic non-availability must be concurred with by the HCA and approved by the Chief Procurement Officer. Federal and DHS acquisition regulations, however, state that some justifications can be approved at a lower level. In the absence of further guidance, this difference in approval levels could result in inconsistent application within the department. In addition, as previously noted HHS does not yet have Buy American Act guidance so the department does not provide information on how to make determinations. According to federal internal control standards, agencies should communicate quality information internally to achieve their objectives and that they should select appropriate communication methods. When written guidance is not available, agencies may miss opportunities to ensure that contracting officers take the steps needed to meet requirements when applying a domestic non-availability exception. Knowing the country of origin of the products the federal government buys is necessary to implement the Buy American Act, but contracting officers do not always have access to accurate information on originating countries. The FAR and the DFARS provide various clauses which, when incorporated into contracts, require vendors to certify that the end products they provide to the government are domestic and, if necessary, declare the foreign countries from which they provide products. Vendors frequently certify this information through the System for Award Management (SAM), the government-wide system used to collect vendors’ annual representations and certifications. Contracting officers may rely on the information vendors provide about their product origins, but they are generally expected to take actions to verify incomplete or conflicting information when they have reason to believe that a vendor will be providing a non-compliant product. We found that SAM certifications and offers did not always include accurate information on end products from foreign countries. In 6 of the 38 contracts that we reviewed—from DHS, HHS, and VA—the vendors certified that they only provided domestic end products although the end products provided were foreign. In all of these cases, the contracting officers knew that the acquisitions included foreign end products. For example, we reviewed two DHS awards for spare aircraft parts from an Italian-based company, one of which was reported in FPDS-NG under the domestic non-availability exception to the Buy American Act, and the other which was incorrectly reported as being manufactured in the United States but has since been corrected. Contracting officials said they knew the parts were made in Italy based on extensive experience contracting with the company and, in part, because they had visited the production location. Contracting officials—including some at HHS and VA—said they use SAM as their primary source to determine whether the vendor is offering domestic end products. Others reported some awareness of the limitations of SAM certifications. At all four agencies, contracting officials emphasized that it is important to ask questions when end product origin information is not readily available—or if there is conflicting information—but agency guidance that we reviewed does not address this need or provide information on how to do so. Only the local training offered by DOD’s DLA addresses other sources of information, which officials said was helpful because it is specific to the industries with which they work. Instead, some officials described how they rely on their experience to know how to verify products’ origins but this can be problematic, particularly with newer staff. For example, in one contract we reviewed VA contracting officials acknowledged that a new contracting specialist at VA did not follow-up when the product origin certification was not provided and assumed all of the items procured were domestic. During the course of our review, the contracting specialist’s supervisor said that she contacted the vendor and learned that some of the items provided were in fact foreign end products. The foreign products were not considered to account for the preponderance of the contract so were not reported in FPDS-NG, but the contracting officer was acting with incomplete information at the time of award. Further, in 4 of the 38 contracts that we reviewed, it is not clear how contracting staff took steps to obtain product origin information in situations where it was not provided in SAM. In these cases—which include contracts for both domestic and foreign end products—the vendors had opted not to certify their product origins in SAM, but instead said that they would provide the information with their individual proposals. However, based on the information in the contract files, the proposals did not include this information. For example: Three of the contracts we reviewed from HHS—all reported as purchasing end items manufactured in the United States—did not certify product origin in SAM. The supervising contracting officer for two of the awards explained that his contracting staff regularly check the vendor’s written representations and certifications provided in the offer, because the SAM certifications are general and do not always apply to the specific equipment they buy. However, the three contract files we reviewed did not include manufacturing or origin information. The vendor for a DHS contract that was reported as manufactured in the United States did not certify this information in SAM. The contracting officer said that he checks SAM for product origin information, but in the documents we reviewed there is no evidence of the information in the contract file. Federal internal control standards state that agencies should communicate the necessary quality information needed to achieve the agency’s objectives, thereby enabling personnel to address risks. Providing guidance regarding the situations in which contracting officers should verify product origin information with vendors may help agencies better meet the requirements of the Buy American Act. Although purchases for foreign end products account for less than 5 percent of federal procurement spending in fiscal year 2017, it is important that these purchases be consistent with the domestic- purchasing restrictions in the Buy American Act. This requires that Buy American Act exceptions and trade agreement waivers be used only when applicable, and that agencies report accurate data on the extent to which they are used. However, data reporting errors by contracting staff and FPDS-NG limitations mean that data on the use of exceptions and waivers are not fully captured. The federal agencies all have responsibilities to ensure Buy American Act data are accurate and complete. The lack of good data can hinder congressional oversight of the extent to which foreign end products are procured as authorized by one of the exceptions or waivers of the Buy American Act. Agencies have taken varied approaches for providing information to contracting officers that navigate the complexities and nuances associated with applying the different Buy American Act exceptions or trade agreement waivers. DOD has added such detailed information through its revised training course and policy guidance. Adding these types of targeted information to address challenging areas would help contracting officers at other agencies implement the Buy American Act’s domestic preferences, as well as related exceptions and waivers. Further, to accurately determine how exceptions and waivers apply requires complete product origin information. Although the responsibility to certify the origins of products supplied to the federal government rests with the contractors, contracting officers would benefit from resources that help them identify information that may be inconsistent, to ensure that accurate information is available. We are making four recommendations, one each to the Office of Management and Budget, DHS, VA, and HHS. The Director of the Office of Management and Budget should instruct the Office of Federal Procurement Policy: To facilitate additional training to improve the understanding of the contracting workforce regarding the Buy American Act requirements; and To facilitate clarifying revisions to FPDS-NG, where needed, and provide training and guidance for recording Buy American Act information in FPDS-NG to improve the accuracy of the Buy American data. (Recommendation 1) The Secretary of Homeland Security should clarify existing guidance in the Homeland Security Acquisition Manual or update training to help contracting officials: Identify the factors that should be considered in order to determine the applicability of the Trade Agreements Act and waiver of the Buy American Act; Document determinations of the use of Buy American exception for domestic non-availability and ensure the required approvals are obtained, particularly when such determinations are evidenced through justifications for other than full and open competition; and Identify sources of information available for determining product origin and the steps they should take to verify information that is inconsistent. (Recommendation 2) The Secretary of Veterans Affairs should clarify existing guidance, or provide training or other instruction, to help contracting officials: Address the applicability of the Buy American Act requirements and provide instruction on how to implement the requirements, including in any training developed to implement the Veterans First policy; Identify the factors that should be considered in order to determine the applicability of the Trade Agreements Act and waiver of the Buy American Act; and Identify sources of information available for determining products’ origins and the steps they should take to verify information that is inconsistent. (Recommendation 3) The Secretary of Health and Human Services should provide guidance, training, or other instruction to help contracting officials: Identify the factors that should be considered in order to determine the applicability of the Trade Agreements Act and waiver of the Buy American Act; Document determinations of the use of Buy American exceptions for domestic non-availability and ensure the required approvals are obtained; and Identify sources of information available for determining products’ origins and the steps they should take to verify information that is inconsistent. (Recommendation 4) We provided a draft of this report to DOD, HHS, DHS, VA, and the Office of Management and Budget for review and comment. DOD reviewed the report, but did not offer comments. HHS, DHS, and VA provided written responses, which are reproduced in Appendices IV, V, and VI of this report, respectively. A senior official within the Office of Federal Procurement Policy (OFPP) at the Office of Management and Budget provided a response via email. In addition, HHS, DHS, and OFPP provided technical comments, which we incorporated into the report where appropriate. In their responses, HHS, DHS, VA agreed, and OFPP generally agreed, with our findings and recommendations. The written response from HHS and DHS included information on the steps each agency plans to take to address the recommendations. Specifically, HHS stated that the agency will evaluate ways to provide additional training and guidance to contracting officials. DHS stated that it will provide guidance on the applicability of the Buy American Act and the Trade Agreements Act in certain situations and the documentation and approvals required when awarding non-competed contracts that require an exception. Additionally, DHS plans to update training regarding actions contracting officers should take when there are discrepancies in product origin information. VA concurred with our three-part recommendation and described some of the actions the agency plans to take in response. However, VA’s comments do not fully address our recommendation. Specifically, we recommended that VA clarify guidance or provide training to identify factors that could help contracting officers determine the applicability of Trade Agreements Act waivers of the Buy American Act. The comments from VA, however, only restate the existing Buy American Act exceptions and make no mention of Trade Agreements Act waivers. Further, we recommended that VA identify sources of information regarding product origin and the steps to be taken to verify inconsistent product origin information. VA’s response only noted that contracting officers are responsible for conducting market research and ensuring that all product origin requirements are met. VA did not outline any additional steps the agency would take to help contracting officers navigate the complexities inherent in this area. Going forward, VA will need to develop a more robust and responsive approach in order to fully implement our recommendation. We are sending copies of this report to the appropriate congressional committees; the Secretaries of the Departments of Defense, Health and Human Services, Homeland Security, and Veterans Affairs; the Director of the Office of Management and Budget; and other interested parties. In addition, the report is available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-4841 or woodsw@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix VII. The objectives of this report are to assess the extent to which (1) the federal government procures foreign products through Buy American Act exceptions and waivers; and (2) selected agencies provide training and guidance to implement the Buy American Act requirements. To address both of these objectives, we reviewed relevant laws and policies, such as sections of the Federal Acquisition Regulation (FAR); the Buy American Act as amended; the Trade Agreements Act of 1979 as amended; federal acquisition regulation supplements from audited agencies such as the Department of Defense Federal Acquisition Regulation Supplement (DFARS); the Executive Order “Buy American, Hire American” of 2017; the World Trade Organization’s Agreement on Government Procurement; and memorandums, policy, guidance, and instructions related to the Buy American Act. To assess the federal government procurement of foreign products, including those procured through citing exceptions and waivers of the Buy American Act, we analyzed data from the Federal Procurement Data System-Next Generation (FPDS-NG) for fiscal year 2017, which was the most recent and complete data available at the time of our review. We analyzed procurement data in FPDS-NG across the federal government in fields relevant to the Buy American Act’s domestic preference requirements, including the product service code, country of product origin, and place of manufacture, in addition to fields such as the contract value and dollars obligated. We reviewed the place of manufacture field in particular as it contains information on how the Buy American Act applies to the contract, including whether the preponderance of the obligations is for manufactured end products and, if so, whether they are manufactured in or outside of the United States. When manufactured outside of the United States, this field also captures the reason the purchase was permissible, which we analyzed to assess the dollar obligations associated with the various Buy American exceptions or trade agreement waiver reported, as well as when products were used outside of the United States. We also analyzed data from FPDS-NG to identify the countries where foreign end products were reported to be manufactured and the associated dollars obligated in fiscal year 2017. In addition, we met with officials from the Office of Management and Budget, Office of Federal Procurement Policy to better understand ongoing reviews of the data in FPDS-NG that pertains to the Buy American Act. In our analysis of FPDS-NG data, we took steps to minimize issues that might affect data reliability. Specifically, we analyzed FPDS-NG data to identify potential errors and inconsistencies, such as non-eligible agencies reporting the use of exceptions for DOD qualifying countries, or reporting trade agreement waivers for contracts valued less than minimum thresholds for trade agreements. We made minor adjustments to minimize potential data reporting issues, including aggregating the exceptions reported, and where appropriate, limiting our analysis to one year of data, fiscal year 2017. Based on these steps, we determined that FPDS-NG data were sufficiently reliable to allow us to calculate the approximate extent of obligations for foreign end products and the use of the Buy American Act exceptions and the Trade Agreements Act waiver. However, we are unable to precisely determine the amount spent on foreign end products through the use of exceptions and waivers because of the reporting errors and data system limitations we identified in this report. Using FPDS-ND data, we identified four agencies—the Departments of Defense (DOD), Health and Human Services (HHS), Homeland Security (DHS), and Veterans Affairs (VA)—that had the highest fiscal year 2017 obligations in the product codes for manufactured products, which are potentially subject to the Buy American Act restrictions. In addition, to identify trends and determine if there were variations in reported obligations for foreign end products in the past, we reviewed FPDS-NG data on the Buy American exceptions and trade agreement waivers in fiscal years 2013 through 2017. To assess the extent to which selected agencies are providing training and guidance to implement the requirements of the Buy American Act, we reviewed training course materials and regulations, policies, and other guidance available at the four agencies in our review—DOD, HHS, DHS, and VA—to determine the extent to which they address the Buy American Act requirements. In addition, we reviewed training materials available to government employees through sources such as the Federal Acquisition Institute. We interviewed policy officials from the four agencies to understand how training and guidance had been implemented. We further reviewed relevant inspector general reports from the DOD Inspector General issued between 2015 and 2018, which made several recommendations to improve compliance with the Buy American Act, among other requirements. Within the four agencies, we selected contracting offices that reported obligating fiscal year 2017 dollars for awards with foreign end products and awards with US-manufactured end products. We specifically focused on offices that reported a sufficient amount of foreign end product obligations and a sufficient number of contract awards to allow us to select multiple contracts. We also considered offices with a variety of Buy American exceptions and waiver types reported, in order to select a mix of contracts. The contracting offices selected were as follows: DOD: Defense Logistics Agency, Land and Maritime HHS: National Institutes of Health and the HHS Office of the Assistant Secretary for Preparedness and Response DHS: United States Coast Guard VA: Veterans Health Administration From these offices, we selected a non-generalizable sample of 38 contracts and delivery orders awarded in fiscal year 2017. At each agency, we selected awards to include a mix of end items produced by domestic and foreign manufacturers and, when products were reported as foreign manufactured, a mix of the various exceptions and waivers cited. We also include awards across a range of value for dollars obligated above the micro purchase threshold—ranging from approximately $5,000 to more than $100 million—to ensure we reviewed awards both above and below the various thresholds at which the Trade Agreements Act waiver might apply. Additionally, our sample included awards for similar types of end products across agencies, including aircraft parts at DOD and DHS and medical supplies at HHS and VA, to compare practices in different agencies. We originally selected 40 awards for review—10 from each agency—but removed two awards from our sample. One was an HHS award that we determined was awarded using Other Transaction Authority and was not subject to the Buy American Act. The second excluded contract was from DHS, which was modified after award to reflect that it was an information technology service rather than a product. As a service, it would not be subject to the Buy American Act. We reviewed the contract files for each of the 38 awards in our sample, including documentation such as the contract and task order award, solicitations, vendors’ offers or response to proposals, determination and finding memos, and FPDS-NG output documents. In addition, we reviewed the certifications each vendor provided in the System for Award Management (SAM) at the time of contract award. We interviewed contracting officials responsible for each of the 38 contracts and task orders to understand how they addressed the Buy American Act requirements, including how they determined exception or waiver applicability and product origin. We also reviewed any agency-specific or local training and guidance, tools, or job aids available to assist contracting officers in implementing the Act’s requirements We conducted this performance audit from October 2017 to December 2018 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on audit objectives. The United States maintains trade relationships with other countries whose specific negotiated terms results in different levels and types of applicability for waivers and exceptions to the Buy American Act. Figure 4 depicts the range of relationships that the United States maintains with other nations that allow for less restrictive purchasing of foreign end products by the federal government. The federal government purchases foreign end products from various countries. Figure 5 highlights the different amounts of contract obligations for foreign end products from these countries for fiscal year 2017. The highest category, over $500 million, includes 4 countries that account for almost 40 percent of all federal procurement of foreign end products. Countries where the federal government obligated less than $5 million for the procurement of foreign end products are not included. In addition to the contact named above, Candice Wright, Assistant Director; and Jennifer Dougherty, Analyst-in-Charge, managed this review. Skip McClinton; Erin Stockdale; Adam Cowles; Stephanie Gustafson; Julia Kennon; Anne Louise Taylor; and Robin Wilson made key contributions to this report.
As we have previously reported, 911 services have evolved from basic 911—which provided Americans with a universally recognized emergency number—to Enhanced 911 which also routes calls to the appropriate call center and provides information about the caller’s location and a call back number. NG911 represents the next evolution in 911 services by using IP-based technology to deliver and process 911 traffic. Under NG911, call centers will continue to receive voice calls and location information, but will also be able to accommodate emergency communications from the range of technologies in use today. In addition, NG911 systems provide call centers with enhanced capabilities to route and transfer calls and data, which could improve call centers’ abilities to handle overflow calls and increase information sharing with first responders. Generally speaking, 911 communications begin when a caller dials 911 using a landline, wireless, or Voice over Internet Protocol (VoIP) system. Once a 911 caller places an emergency call, a communications provider receives and routes the call to the appropriate call center, along with the caller’s phone number and location (i.e., street address for a landline caller, approximate geographic location for a wireless caller, and the subscriber’s address for VoIP). Calls and data may be routed to 911 call centers using legacy methods (i.e., routing calls across traditional telephone networks) or NG911 methods (i.e., routing calls and other data through IP-networks). Once the call reaches a call center, trained call takers and dispatchers determine the nature of the emergency and dispatch first responders, typically using a variety of equipment and systems, including call handling systems, mapping programs, and computer aided dispatch. Figure 1 illustrates the 911 communications and dispatch process. As illustrated in figure 1, NG911 systems use IP-networks capable of carrying voice plus large amounts of data. These emergency-services networks are typically deployed at the state or regional level with multiple call centers connecting to the network. However, the existence of an IP- network alone does not constitute an NG911 system. As defined by standards developed by the emergency communications community, an NG911 system should have the capability to, among other things: provide a secure environment for emergency communications; acquire and integrate additional data for routing and answering calls; process all types of emergency calls, including multimedia messages; transfer calls with added data to other call centers or first responders. While NG911 systems must possess certain capabilities, it is important to note that states and localities may make decisions about which capabilities they intend to use to best meet their needs. In addition, states and localities have the authority to make decisions about what NG911 equipment, systems, and vendors to use; thus, the configurations of these systems vary. According to a panel of experts convened by the National 911 Program, the transition to NG911 may require a variety of technical and operational changes to current 911 systems and processes. For example, technical changes can include upgrades to networks or installing new hardware or software in 911 call centers. Operational changes can include the need for additional training or the development of new policies and procedures (e.g., new procedures for processing or storing multimedia). These technical and operational changes may also have effects on 911 funding and state and local governance structures, which we will discuss in more detail later in this report. According to an FCC advisory body that examined NG911 systems architecture in 2016, while NG911 systems are implemented in a variety of ways at the state or local level, NG911 implementation can occur gradually and in phases. According to this model, NG911 implementation occurs on a continuum that begins with legacy 911 systems and ends with a fully deployed NG911 national end-state where all individual 911 call centers nationwide would be connected. The NG911 implementation model identifies activities that take place as part of the NG911 transition, many of which occur concurrently, such as: planning (e.g., conducting feasibility studies, preparing databases, establishing governance models); acquiring, testing, and implementing NG911 system elements (e.g., establishing an emergency-services IP-network, location-based call routing, processing multimedia); connecting call centers within a jurisdiction (i.e., jurisdictional end- state in which all call centers are fully NG911 operational, supported by agreements, policies, and procedures); and connecting NG911 systems nationwide (i.e., national end-state in which all call centers in the nation are fully NG911 operational, supported by agreements, policies, and procedures). In addition, because 911 services provide an essential function, the implementation of NG911 generally involves using both the legacy system and the NG911 system simultaneously for a period of time, according to the FCC advisory body, to ensure 911 services are not disrupted as new system elements are tested and implemented. Deploying and operating 911 is the responsibility of 911 authorities at the state and local level. As we have previously reported, all 50 states and the District of Columbia collect—or have authorized local entities to collect—funding for 911 from telephone service subscribers, and methods within each state for collecting funds vary. FCC, as required by statute, reports to Congress annually on the states’ collection and distribution of 911 fees and charges. There are approximately 6,000 call centers nationwide that process 911 calls, often at the county or city level, and these centers can vary greatly in size and technical sophistication. The state and local governance structures that oversee 911 operations also vary by location. For example, we previously reported that some states collect fees or charges for 911 and administer a statewide 911 program. Other states authorize local entities to collect fees or charges for 911 and administer 911 programs at the local level. Still other states use a combination of these approaches. According to a panel of experts convened by the National 911 Program, historically, 911 authority has been coordinated and maintained locally with no requirement to coordinate with other jurisdictions. However, the transition to NG911 enables connection of 911 systems. Thus, as previously mentioned, the NG911 transition may require technological and operational changes, as well as changes to 911 policies and governance responsibilities for states and localities. While deploying and operating 911 is the responsibility of entities at the state and local level, federal agencies—including NHTSA, NTIA, FCC, and DHS—have responsibilities to support state and local implementation, including through facilitating coordination of activities among 911 stakeholders and administering federal grants, for example: NHTSA houses the National 911 Program as part of its Office of Emergency Medical Services (Office of EMS) to provide national leadership and coordination for the NG911 transition throughout the United States, as previously mentioned. According to NHTSA, the fiscal year 2017 budget for the National 911 Program was $2.74 million. Among other activities, which we will discuss later in this report, the National 911 Program surveys states on progress implementing NG911 and reports this survey data annually. FCC issues orders and regulations for 911 service providers on topics relevant to NG911, such as 911 reliability, location accuracy, and text- to-911. FCC also sponsors advisory bodies comprised of government and industry experts that study relevant topics and provide recommendations related to NG911, such as the Task Force on Optimal Public Safety Answering Point Architecture and the Communications, Security, Reliability, and Interoperability Council. While there are no federally mandated time frames for implementing NG911, the Next Generation 911 Advancement Act of 2012 requires specific actions of some federal agencies as outlined in table 1, below. In addition, according to the National 911 Program, as states and localities continue to implement NG911, and begin to explore interconnection with other states’ 911 systems, federal agencies may need to take steps to help ensure state NG911 networks are interoperable and connected. We will discuss actions taken by federal agencies to assist states and localities to implement NG911 later in this report. According to NHTSA’s most recent national survey, state and local progress implementing NG911 varies, and about half of all states reported being in some phase of transition to NG911 in 2015. While a few states are well into statewide implementation, NHTSA officials told us that no state had completely implemented all NG911 functions. Additionally, as of the fall of 2017, none of the selected states we spoke with were processing multimedia—such as images or audio/video recordings—through their 911 systems due to concerns related to privacy, liability, and the ability to store and manage these types of data, among other things. The national survey data, based on responses from 45 states, measured the extent to which NG911 planning and acquisition of NG911 equipment and services were occurring, and the extent to which basic NG911 functions were operational at the state and local levels in 2015. Planning: This measure includes state and local NG911 plans for governance, funding, system components, and operations. In this context, system components refer to an emergency services IP-based network, NG911 software, system and information security, and databases, among other things, according to NHTSA’s survey. In total, 25 of 45 states reported having a state or at least one local NG911 plan in place; conversely, 18 states reported having no NG911 plan in place at either the state or local level—which may indicate they are in the early stages of planning for the NG911 transition or have not yet begun the transition to NG911. Acquisition: These measures identify states or local entities that have defined their NG911 needs and awarded contracts, and then installed and tested acquired NG911 components and services. Twenty-four states reported awarding at least one contract at the state or local level for NG911 components and services. Twenty-three states reported having installed and tested NG911 components and services at either the state or local level. NG911 services: This is a measure of 911 authorities that have some basic, functioning NG911 infrastructure in place. In total, 21 states reported having some level of basic NG911 services in place at the state or local level. Of these 21 states, 10 reported that all 911 authorities within the state were using NG911 technology to process emergency calls. Another 7 of these states reported that 25 percent or less of their state’s 911 authorities were using NG911 technology to process emergency calls. Federal officials, industry stakeholders, and state and local 911 officials we interviewed from nine states identified a number of challenges to implementing NG911, including challenges related to funding, evolving technology and operations, and governance. Funding: State and local officials in four of nine selected states identified insufficient funding as one of the challenges they face in implementing NG911. Additionally, FCC, NHTSA, and industry reports noted that state and local financing strategies are generally insufficient to fully implement NG911. Specifically, these reports note that the need to provide new capital for NG911 implementation while simultaneously funding legacy operational costs during the transition can strain state and local funding. Limited funding: Officials in three states told us that their current funding may not be able to support the upfront costs of infrastructure and equipment acquisitions associated with the transition to NG911. Further, officials said they will need to simultaneously fund both the new NG911 and legacy 911 systems currently in operation until the NG911 systems are fully operational. To address these challenges, a Minnesota official told us about how the state leveraged economies of scale to reduce overall costs through cost sharing between multiple call centers and of call centers consolidating operations from 114 to 104 call centers. Additionally, a Virginia official told us that to cover the upfront costs of transitioning to NG911, the state plans to borrow from the state treasury and then repay the treasury with future-year fee collections. Fee diversion: Diversion of fees intended for 911 costs to non-911 activities may affect a state’s or locality’s ability to cover NG911 transition costs and necessitate identifying alternative funding sources. The FCC’s 2016 annual report on 911 fees indicates that for calendar year 2015, all but two of the states that responded to FCC’s 911 fee survey affirmed that their state or jurisdiction collects fees from phone users to support or implement 911 services. State and local authorities also determine how these 911 fees can be used. FCC’s report also indicated that eight states and Puerto Rico reported diverting a total of more than $220 million (or approximately 8.4 percent) of 911 fees collected to non-911 purposes. Some of these diverted funds were directed to other public safety programs, and others were diverted to either non-public safety or unspecified purposes. According to one state official, had it not been for 911 fees being diverted to non-911 purposes, funding would have been sufficient to cover the NG911 transition without having to go to the state legislature for additional funding. However, officials in the other eight selected states told us that either fee diversion was not an issue in their state or that the diversion of funds had not affected their state’s ability to implement NG911. Evolving technology and operations: Officials in eight states told us that the retirement of legacy infrastructure and the transition to IP-based systems introduces new technical and operational challenges for call centers and states, as well as for equipment and service providers. Interoperability: Officials in three selected states mentioned that connecting to neighboring networks—whether within or between states—could pose challenges. For example, officials mentioned that states and localities may have obtained different equipment, software applications, or service providers – all of which can make interconnections difficult. Officials in Maine and New Hampshire told us that differences in service providers can also be a challenge to seamlessly connecting to neighboring systems. In an instance where two states (Minnesota and North Dakota) have worked to connect their 911 systems, both states used the same service provider, which officials said allowed for fewer barriers to connection. Cyber risks: Officials in three states told us that the transition from a traditional system that only transmits voice traffic to an IP-based system that transmits voice and data traffic has significantly increased the risk of a cyber-attack. This can be a challenge because managing cyber risks is a new and evolving role for state and local 911 authorities. Approaching the transition to NG911 without managing these risks could result in disrupted or disabled call center operations and ultimately a delayed response to an emergency situation. Multimedia: Officials in three states mentioned potential implementation challenges related to accepting and processing multimedia such as audio recordings, images, and videos. More specifically, one official said they did not have procedures to manage or store these multimedia files once received. In addition, another official raised privacy and liability concerns. Call routing: One of the core services of an NG911 system is the ability to have calls routed to the appropriate call center based on a wireless caller’s physical location, instead of the location of the cellular tower that receives and transmits the call. An FCC-sponsored working group reported that there are several options for achieving this and each option has unique positive and negative aspects. One challenge officials in two states noted was that rather than a single, nationwide approach to routing these calls, state and local 911 authorities would need to work individually with the wireless carriers to determine how to best implement location-based call routing. Governance: FCC has noted that transitioning to NG911 will likely result in new roles and levels of coordination between state 911 authorities, local 911 authorities, 911 call centers, and 911 service providers. Further, relationships among authorities at the state and local level may change as states work to interconnect NG911 systems. State and local officials noted that these types of governance challenges can apply in a variety of situations, including within or between states. Evolving roles: As previously mentioned, 911 governance structures vary among states. These varying governance structures may pose different challenges. For example, some states have a centralized structure in which a single government agency is responsible for statewide 911 system’s administration and policy. Officials in two states told us that although they faced challenges transitioning to NG911, their states’ centralized 911 structure eased the transition in their states because there was uniformity in policy and technology, among other things, coming from a single statewide authority. In other states, 911 systems are primarily a local responsibility and organized with decentralized authorities and resources. In these instances, there may be specific challenges related to transitioning to an interconnected NG911 system. Such challenges may include the need for increased levels of coordination among numerous jurisdictions with potentially disparate organizational structures, levels of funding, and priorities. An official also noted that there are governance challenges related to connecting states and evolving relationships between 911 authorities and service providers. Informing decision makers: One of the challenges identified by officials in two states is differing levels of experience and understanding by state and local officials as to what NG911 priorities should be for timely implementation. To help with this understanding, the federal government is making efforts to educate state and local authorities on how to facilitate policymaker understanding as well as provide regular updates to stakeholders on recent NG911 developments. We discuss some of these efforts later in this report. While state and local entities have the primary responsibility for implementing NG911 technology and services, federal agencies are taking actions to assist state and local 911 entities to address NG911 implementation challenges. Actions taken include developing resources, offering technical assistance, and convening stakeholders. More specifically, we identified selected activities that were taken by NHTSA, NTIA, FCC, and DHS that address some of the funding, technology, and governance challenges raised by state and local 911 stakeholders, for example: Cost study: NHTSA’s National 911 Program and NTIA, in consultation with FCC and DHS, plan to issue a study of the range of costs for 911 call centers and service providers to implement NG911 systems. According to NHTSA officials, the cost study will present a nationwide view, rather than a state-by-state view, on the progress of NG911 implementation and its associated costs. Grant program: NHTSA and NTIA are preparing to jointly administer a $115 million grant program to improve 911 services, including the adoption and operation of NG911 services. In September 2017, NHTSA and NTIA issued a notice of proposed rulemaking outlining implementing regulations for the grant program. NHTSA and NTIA expect to award the grants in 2018. Technology standards: The National 911 Program issued an annual guide in 2017 that stressed the importance of using open technology standards for NG911 services. The guide provides a list of standards that have been recently updated and an analysis that identifies whether existing standards fully address NG911 processes and protocols. Cybersecurity guides: DHS issued a guide in 2016 that identified cybersecurity risks for NG911 and risk mitigation strategies. According to DHS officials, the National 911 Program provided input on this guide. In addition, an advisory body tasked by FCC to examine 911 call-centers’ architecture issued a report in 2016 that provided a cybersecurity self-assessment tool for call centers and guidance on cybersecurity strategies. Governance plans: To address challenges related to the evolving roles for state and local 911 authorities, the National 911 Program issued a guide in 2016 that provided practices for states to consider when interconnecting NG911 networks, and DHS issued a guide in 2015 for emergency communications officials for establishing, assessing, and updating their governance structures. In addition, an FCC advisory body issued a report in 2016 that identified NG911 governance approaches, issues, and recommendations for states, localities, and call centers to consider when planning for the deployment of NG911. In addition to federal agency efforts to assist the state and local 911 community, the National 911 Program is in the early stages of establishing an interagency initiative to create a National NG911 Roadmap. As part of this initiative, the National 911 Program plans to convene the 911 stakeholder community to identify tasks that need to be completed at the national level by the federal government and other public and private-sector organizations to support the creation of a national, interconnected NG911 system. Additional details regarding this planned activity are described in further detail later in this report. For additional information on federal actions to address state and local NG911 challenges, see appendix II. As the lead entity for coordinating federal NG911 activities, the National 911 Program has taken a variety of actions to assist the state and local 911 community, in collaboration with other federal agencies. However, the program lacks goals and performance measures to assess whether these activities are achieving desired results. National 911 Program officials stated that they initiate program activities based on feedback received from the 911 community. In addition, officials said the program’s activities fall within the tasks established in the Next Generation 911 Advancement Act of 2012. However, the National 911 Program does not have a means to assess its progress toward meeting its responsibilities established in the 2012 Act. National 911 Program officials said the Office of EMS—the office within NHTSA in which the program is housed—has a strategic plan, but it is outdated and does not contain specific goals or performance measures related to 911 or NG911 implementation. Officials said the Office of EMS has held preliminary discussions to begin updating its strategic plan by January 2019 and plans to include goals and performance measures related to 911 and NG911 services. Office of EMS officials told us the Office of EMS strategic plan will be jointly developed with the National 911 Program. However the Office of EMS had not yet developed a draft strategic plan during the time of our review. Federal internal control standards call for management to clearly define objectives in order to achieve desired results. According to these standards, an entity determines its mission, establishes specific measurable objectives, and formulates plans to achieve its objectives. These standards state that management sets objectives in order to meet the entity’s mission, strategic plan, and goals and requirements of applicable laws and regulations. In addition, our work on leading practices for managing for results indicated that an agency’s strategic goals should also explain what results are expected from the agency and when to expect those results. Further, these goals form a basis for an entity to identify strategies to fulfill its mission and improve its operations to support the achievement of that mission. As the lead entity for coordinating federal NG911 efforts, the National 911 Program faces a complex and challenging task of assisting the 911 community while the nation’s 911 systems undergo a major transformation. However, without specific goals and related performance measures, the National 911 Program is unable to assess how well its activities are achieving results in relation to its responsibilities identified in the 2012 Act. As the National 911 Program and the Office of EMS consider creating a strategic plan, ensuring that the plan includes specific goals and related measures for the National 911 Program would help officials better understand whether the program’s activities are effectively assisting states and localities in transitioning to a fully integrated national NG911 system, and help identify any programmatic changes that might be needed. As previously mentioned, the National 911 Program is in the early stages of establishing an interagency initiative to create a National NG911 Roadmap. This initiative will convene the 911 stakeholder community to identify national-level tasks that need to be completed by federal agencies and other organizations to realize a national, interconnected NG911 system. According to the National 911 Program, a list of the national-level tasks needed to advance NG911 implementation nationwide has not been created to date. In addition, state officials we spoke with said there are certain issues related to interoperability and cybersecurity that federal agencies need to address before states can connect their respective state NG911 systems. To address these issues, NHTSA’s National 911 Program issued a request for proposal (RFP) in August 2017 for managing the roadmap development process and awarded a contract in September 2017. While the National 911 Program is taking steps to develop a National NG911 Roadmap, the program does not have a plan to identify: (1) roles or responsibilities for federal entities to carry out national-level tasks or (2) how the program plans to achieve the roadmap’s objectives. NHTSA’s NG911 roadmap RFP specifies that by identifying a list of national-level tasks that are developed and adopted by the 911 stakeholder community, the roadmap could serve as a blueprint to carry out these tasks and thereby ensure the interoperability of the nation’s NG911 system. However, the National 911 Program does not have plans for the entities participating in the development of the roadmap to be assigned roles and responsibilities for executing the roadmap’s national- level tasks. National 911 Program officials told us the National 911 Program does not plan to assign roles and responsibilities because NHTSA does not have the authority to require or assign tasks for other entities. Additionally, program officials view the simultaneous identification of tasks and assignments of responsibility for those tasks as a risk to facilitating a candid and productive discussion with entities participating in the roadmap initiative. However, officials stated it may be appropriate for agencies participating in the roadmap initiative to perform specific tasks after the roadmap is finalized. We have previously examined interagency collaborative mechanisms and identified certain key issues for federal agencies to consider when using these mechanisms to achieve results. Our prior work has found that following leading collaboration practices, such as clarifying roles and responsibilities of agencies engaged in collaboration, can enhance and sustain collaboration among agencies and provide an understanding of who will do what in support of meeting the aims of the collaborative group. As stated above, the RFP specifies that a roadmap developed by and adopted by 911 stakeholders could serve as a blueprint to carry out the roadmap’s tasks. Securing the commitment of agencies to assigned roles could help organize the collaborative group’s joint and individual efforts and thereby better facilitate decision making. As we have previously found, a lack of clarity on the roles and responsibilities of agencies participating in an interagency effort—such as the execution of the roadmap’s tasks—may limit agencies’ abilities to effectively achieve shared objectives. Given the complexity of the task and the number of agencies that could be involved, following selected leading collaboration practices for the roadmap initiative—particularly with regard to collaborating with roadmap stakeholders to clarify their roles and responsibilities (whether during the creation of the task list or afterwards)—could reduce barriers to agencies effectively working together to achieve the national-level tasks. While clarifying the roles and responsibilities of roadmap stakeholders for the execution of the roadmap’s tasks is an important collaborative step, the National 911 Program has additional responsibilities as the lead entity for the initiative. However, National 911 Program officials are unable to clearly articulate how the program will proceed following the completion of the roadmap. National 911 Program officials said without knowing the contents of the roadmap, it would be premature to specify how the roadmap’s national-level tasks would be completed. Officials stated that once the roadmap is completed, possible next steps may include identification of timelines, deadlines, and a mechanism for tracking progress, among other things, but officials stated that these steps are not required in the roadmap RFP. As stated above, federal internal control standards call for management to clearly define objectives in specific terms. According to these standards, management defines what is to be achieved, who is to achieve it, how it will be achieved, and the time frames for achievement. Without a clear plan for how the National 911 Program would take next steps to support the implementation of the roadmap’s objectives and tasks, the National 911 Program may not be prepared to take effective action once the roadmap is completed. We have previously found that having an implementation plan can assist agencies to better focus and prioritize goals and objectives, and align planned activities. Once the roadmap is completed, developing an implementation plan that details what is to be achieved and how it will be accomplished will place the National 911 Program in a better position moving forward to support the completion of the national-level tasks. The current 911 system is undergoing a historic transition. With no federal requirement that states transition to NG911 services, federal leadership is critical to addressing interoperability challenges and promoting the goal of an interconnected national system. As the lead federal entity for fostering coordination and collaboration among federal, state, and local 911 authorities, the National 911 Program plays a critical role in coordinating NG911 implementation efforts to improve the nation’s 911 services. However, this program—in collaboration with other federal agencies— faces a complex and challenging task to help move approximately 6,000 independent 911 call centers toward an interconnected national NG911 system. In addition, given that the NG911 transition is still in its early stages and is an ongoing effort, it is difficult to assess the effectiveness of various federal actions to assist states and localities in the transition. In light of these challenges, without specific goals and related measures to assess effectiveness, the National 911 Program may be hindered in determining whether it is making progress towards its stated mission. Through the roadmap initiative, the National 911 Program has taken important first steps in identifying the need for actions at the national level, in order to fully realize the desired end-state of a national, interconnected NG911 system. However, while identifying needed next steps is essential, equally important to the collaborative effort’s success is (1) defining and agreeing on the roles and responsibilities of the entities best suited to undertake these actions, and (2) developing plans for how the National 911 Program will support implementation to achieve the roadmap’s objectives. If taken, these actions could help further NG911 implementation nationwide and help the National 911 Program and federal agencies in assisting states and localities to improve these lifesaving services. We are making the following three recommendations to the Administrator of NHTSA regarding the National 911 Program: develop specific program goals and performance measures related to NG911 implementation. (Recommendation 1) in collaboration with the appropriate federal agencies, determine roles and responsibilities of federal agencies participating in the National NG911 Roadmap initiative in order to carry out the national-level tasks over which each agency has jurisdiction. (Recommendation 2) develop an implementation plan to support the completion of the National NG911 Roadmap’s national-level tasks. (Recommendation 3) We provided a draft of this report to the Departments of Transportation, Commerce, and Homeland Security and FCC for their review and comment. In its comments, reproduced in appendix III, the Department of Transportation agreed with the recommendations. The Departments of Transportation and Homeland Security also provided technical comments, which we incorporated as appropriate. The Department of Commerce and FCC had no comments. As agreed with your office, unless you publicly announce the contents of this report earlier, we plan no further distribution until 30 days from the report date. At that time, we will send copies of this report to the appropriate congressional committees, the Secretary of the Department of Transportation, the Secretary of the Department of Commerce, the Secretary of the Department of Homeland Security, the Managing Director of the FCC, and other interested parties. In addition, the report will be available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact me at (202) 512-2834 or goldsteinm@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. Staff who made key contributions to this report are listed in appendix IV. Our objectives were to examine (1) progress states and localities are making to implement Next Generation 911 (NG911) and the challenges they have faced and (2) how federal agencies have addressed state and local implementation challenges and planned next steps. To describe state and local progress in implementing NG911 and background information on fee collection and costs, we analyzed select survey data elements from the 2016 National 911 Progress Report and the Eighth Annual Report to Congress on State Collection and Distribution of 911 and Enhanced 911 Fees and Charges, maintained by the National Highway Traffic Safety Administration (NHTSA) and the Federal Communications Commission (FCC) respectively. More specifically, we analyzed the most recent state-provided data (from calendar year 2015) related to the planning and implementation of NG911 at the state and local levels, as well as NG911 cost and 911-related revenue data. We assessed the reliability of these data by reviewing relevant documents and discussing data elements with staff responsible for collecting and analyzing the data. We also conducted our own testing to check the consistency of the data. We found the data from both sources to be sufficiently reliable for our purposes to describe states’ progress in implementing NG911 and provide background on 911 fee collection and costs. While these data provide the best nationwide picture of NG911 implementation and fee collection, and are reliable for our purposes, there are some limitations on how the data can be used. Since we did not validate the state-reported responses, our findings based on these data are limited to what states reported. Additionally, regarding the 2016 National 911 Progress Report data, there are limitations to (1) making comparisons between states because states have different approaches to implementing NG911 and (2) ascertaining year-over-year progress because reporting is voluntary and states’ response rates can vary year to year. To describe implementation challenges that states and local authorities may be encountering, we selected a non-generalizable sample of 10 states as case studies, based upon a variety of factors, including reported progress in implementing NG911, statewide planning and coordination, reported number of annual 911 calls, whether states diverted 911 fees to other uses, and variation in geographic location. We selected these states, in part, based on their responses to the two aforementioned surveys. Based on the aforementioned criteria, we selected the following states to include as case studies: California, Maine, Maryland, Minnesota, Nevada, New Hampshire, North Dakota, South Dakota, Vermont, and Virginia. We reviewed documents and interviewed state officials from all of these states except Nevada about NG911 implementation progress, challenges, federal actions, and any additional assistance needed. We contacted 911 officials in Nevada but did not receive responses. We also interviewed local officials in four of the selected states. While not generalizable to all states, the information obtained from our case studies provides examples of broader issues faced by states and localities in managing the NG911 transition. To determine how federal agencies have addressed state and local implementation challenges and planned next steps, we reviewed relevant statutes, regulations, and documentation of federal agency actions and plans, and our prior reports. We also interviewed officials from federal agencies, including NHTSA, the National Telecommunications and Information Administration (NTIA), FCC, and the U.S. Department of Homeland Security (DHS), about federal actions taken and plans for next steps. To understand planning activities undertaken by NHTSA’s National 911 Program, and its planned project to develop a National NG911 Roadmap, we reviewed the National 911 Program’s internal planning documents, the program’s request for proposal to develop a national roadmap, the program’s written responses to our questions, and interviewed National 911 Program officials. In addition, we interviewed officials from national associations representing emergency-response- technology companies, wireless and wireline phone carriers, emergency- communications entities, and groups representing deaf and hard-of- hearing consumers to gain their perspectives on federal actions taken and next steps. We assessed the National 911 Program’s strategic- planning activities against leading practices for performance management found in our prior work on strategic planning and goal setting and federal internal control standards. We assessed the National 911 Program’s planned activities for the national roadmap project against federal internal control standards and selected key practices to enhance interagency collaboration identified in our prior work. We conducted our work from January 2017 to January 2018 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. Description of challenge State and local funding may not be sufficient to support costs associated with transitioning to NG911 equipment and infrastructure. Transitioning from legacy infrastructure to Internet Protocol-based systems presents technical and operational challenges such as interoperability and cybersecurity risks. Federal actions Grant resources: The National Highway Traffic Safety Administration’s (NHTSA) National 911 Program issued on its website a list clarifying which of the fiscal year 2016 emergency-communications grants may be used for NG911 services. Program officials said they developed this list in collaboration with the Department of Homeland Security (DHS). Cost study: NHTSA’s National 911 Program and the National Telecommunications and Information Administration (NTIA), in consultation with the Federal Communications Commission (FCC) and DHS, plan to issue a study of the range of costs for 911 call centers and service providers to implement NG911 systems and on the nationwide progress of implementing NG911 services. Grant program: NHTSA and NTIA are preparing to jointly administer a $115 million grant program to improve 911 services, including the adoption and operation of NG911 services. NHTSA and NTIA expect to award the grants in 2018. Funding mechanisms: An advisory body tasked by FCC issued a report in 2016 that identified common costs and funding mechanisms for 911 officials to consider. The report also introduced a 911 funding sustainment model designed for use by 911 officials to calculate their financial needs to support a transition to NG911 implementation. Guides on technology standards and procurement practices: In 2017, NHTSA’s National 911 Program issued an annual guide on emergency- communications technology standards that stressed the importance of using open technology standards for NG911 services. The National 911 Program issued another guide in 2016 that provides information on procuring goods and services related to NG911 such as practices for call centers to consider when developing their request for proposals and contracts. Examining emerging technology issues: In 2017, FCC tasked a public- private advisory council to recommend how FCC can promote the NG911 transition, enhance the reliability of NG911, and mitigate the threat of 911 outages. Prior to that tasking, the FCC advisory council issued a report in 2016 that explored location-based routing issues and discussed transition considerations from legacy 911 to NG911. NG911 cybersecurity guide and technical assistance: DHS, with input from NHTSA’s National 911 Program according to DHS officials, issued a guide in 2016 that identifies cybersecurity risks for NG911 and risk mitigation strategies. In addition, DHS provides NG911 technical assistance for states seeking assistance with strategic planning and technology integration. In a separate effort, an advisory body tasked by FCC to examine 911 call center architecture issued a report in 2016 that provides a cybersecurity self- assessment tool for call centers and guidance on cybersecurity strategies. Description of challenge States may face a range of challenges related to evolving roles for state and local 911 authorities that could hinder NG911 implementation. Federal actions Guides on state and legislative planning: NHTSA’s National 911 Program issued guides on state 911 planning and legislative issues to consider for NG911 and awarded a contract in September 2017 to update those guides. In 2016, the National 911 Program issued a guidebased on the experiences of Iowa, Minnesota, North Dakota, and South Dakota that identifies practices to consider for states interconnecting NG911 networks across state lines. Exploring NG911 governance implementation issues: In 2016, an advisory body tasked by FCC issued a report that identifies NG911 governance approaches, issues, and recommendations for states, localities, and call centers to consider when planning for the deployment of NG911. In 2013, FCC also issued a report that details recommendations to Congress for transitioning from legacy 911 to NG911 networks. Guide on emergency communications governance structures: In 2015, DHS and the National Council of Statewide Interoperability Coordinators issued a guide that provides characteristics of effective governance approaches and best practices for officials to establish, assess, and update their governance structures. In addition to the contact named above, Andrew Huddleston (Assistant Director), Jean Cook (Analyst in Charge), Camilo Flores, Steven Rabinowitz, Malika Rice, Kelly L. Rubin, Michael Sweet, Hai Tran, Marika Van Laan, and Michelle Weathers made key contributions to this report.
The Railroad Retirement Board (RRB), an independent federal agency, administers retirement, survivor, disability, unemployment, and sickness insurance for railroad workers and their families under the Railroad Retirement Act (RRA) and the Railroad Unemployment Insurance Act (RUIA). These acts cover workers who are employed by railroads engaged in interstate commerce and related subsidiaries, railroad associations, and railroad labor organizations. Lifelong railroad workers receive railroad retirement benefits instead of Social Security benefits; railroad workers with nonrailroad experience receive benefits either from railroad retirement or Social Security, depending on the length of their railroad service. The number of railroad workers has been declining since the 1950s, although the rate of decline has been irregular and recent years have seen increases in railroad employment after reaching an all-time low of 215,000 workers in January 2010. Recently, railroad employment peaked in April 2015 to 253,000 workers, the highest level since November 1999, and then declined through FY2017, falling to 221,000 workers. The total number of beneficiaries under the RRA and RUIA decreased from 623,000 in FY2008 to 574,000 in FY2017, and total benefit payments increased from $10.1 billion to $12.6 billion during the same time. During FY2017, the RRB paid nearly $12.5 billion in retirement, disability, and survivor benefits to approximately 548,000 beneficiaries. Almost $105.4 million in unemployment and sickness benefits were paid to approximately 28,000 claimants. This report explains the programs under RRA and RUIA, including how each program is financed, the eligibility rules, and the types of benefits available to railroad workers and family members. It also discusses how railroad retirement relates to the Social Security system. For a quick overview of this topic, see CRS In Focus IF10481, Railroad Retirement Board: Retirement, Survivor, Disability, Unemployment, and Sickness Benefits . The RRA authorizes retirement, survivor, and disability benefits for railroad workers and their families. In December 2017, there were a total of 526,100 RRA beneficiaries, decreasing from 672,400 in 2001. This decline might partly result from the decline in railroad employment in the past five decades. The average monthly benefit for each beneficiary was about $1,986 in 2017, which increased from $1,043 in 2001, reflecting the growth in average wages and prices (see Figure 1 ). The railroad retirement, disability, and survivor program is mainly financed by payroll taxes, financial interchanges from Social Security, and transfers from the National Railroad Retirement Investment Trust (NRRIT) (see Figure 2 ), all of which accounted for 93.9% of the $12.7 billion gross funding of the RRA program during FY2017. The remaining 6.1% of the program was financed by federal income taxes levied on railroad retirement benefits, interest on investment and other revenue, and general appropriations to pay the costs of phasing out vested dual benefits. Payroll taxes, which provided 47.0% of gross RRA funding in FY2017, are the largest funding source for railroad retirement, survivor, and disability benefits. Railroad retirement payroll taxes are divided into two tiers—Tier I and Tier II taxes. The Tier I tax is the same as the Social Security payroll tax: railroad employers and employees each pay 6.2% on earnings up to $132,900 in 2019. The Tier II tax is set each year based on the railroad retirement system's asset balances, benefit payments, and administrative costs. In 2019, the Tier II tax is 13.1% for employers and 4.9% for employees on earnings up to $98,700. Tier II taxes are used to finance Tier II benefits, the portion of Tier I benefits in excess of Social Security retirement benefits (such as unreduced early retirement benefits for railroad employees with at least 30 years of railroad service), and supplemental annuities. Tier I payroll taxes are deposited in the Social Security Equivalent Benefit Account (SSEBA), which pays the Social Security level of benefits and administrative expenses allocable to those benefits. The SSEBA also receives or pays the financial interchange transfers between the railroad retirement and Social Security systems. The financial interchange with Social Security provided 32.6% of gross RRA funding in FY2017. The purpose of the financial interchange is to place the Social Security trust funds in the same position they would have been in, if railroad employment had been covered under Social Security since that program's inception. Tier II tax revenues that are not needed to pay current benefits or associated administrative costs are held in the National Railroad Retirement Investment Trust (NRRIT), which is invested in both government securities and private equities. NRRIT transfers provide another revenue source for railroad benefits, and they were 14.3% of gross RRA funding in FY2017. Prior to the Railroad Retirement and Survivors' Improvement Act of 2001 ( P.L. 107-90 ), surplus railroad retirement assets could only be invested in U.S. government securities—just as the Social Security trust funds must be invested in securities issued or guaranteed by the U.S. government. The 2001 act established the NRRIT to manage and invest the assets in the Railroad Retirement Account in the same way that the assets of private-sector and most state and local government pension plans are invested. The remainder of the railroad retirement system's assets, such as assets in SSEBA, continues to be invested solely in U.S. government-issued or -granted securities. The combined fair market value of Tier II taxes and NRRIT assets is designed to maintain four to six years' worth of RRB benefits and administrative expenses. To maintain this balance, the Railroad Retirement Tier II tax rates automatically adjust as needed. This tax adjustment does not require congressional action, according to Section 204 of the 2001 act. To be insured for railroad benefits, a worker must generally have at least 10 years of covered railroad work or 5 years performed after 1995 and "insured status" under Social Security rules (generally 40 earnings credits) based on combined railroad retirement and Social Security-covered earnings. An insured railroad worker's family may be entitled to receive railroad retirement benefits. If a worker does not qualify for railroad retirement benefits, his or her railroad work counts toward Social Security benefits. Of the total $12.5 billion benefit payments during FY2017, 60.0% (or $7.5 billion) were paid in retirement annuities to retired workers, 8.0% (or $1.0 billion) in disability annuities, 14.4% (or $1.8 billion) in spouse annuities, and 16.8% (or $2.1 billion) in survivor annuities. Tier I annuities are designed to be nearly equivalent to Social Security Old Age, Survivors, and Disability Insurance benefits. Tier I annuities are calculated using the Social Security benefit formula and are based on both railroad retirement and Social Security-covered employment. However, Tier I annuities are more generous than Social Security benefits in certain situation. For example, at the age of 60, railroad workers with at least 30 years of covered railroad work may receive unreduced retirement annuities. At the full retirement age (FRA), which is gradually increasing from 65 to 67 for Social Security and railroad retirement beneficiaries, insured workers with fewer than 30 years of service may receive full retirement ann uities. Alternatively, workers with fewer than 30 years of service may, starting at the age of 62, receive annuities that have been reduced actuarially for the additional years the worker is expected to spend in retirement. Tier I benefit reductions for early retirement are similar to those in the Social Security system. As the FRA rises, so will the reduction for early retirement. If a railroad employee delays retirement past FRA, Tier I annuities are increased by a certain percentage for each month up until the age of 70, which is identical to the benefit increase provided by Delayed Retirement Credits under the Social Security system. In general, Social Security benefits are subtracted from Tier I annuities, because work covered by Social Security is counted toward Tier I annuities. Beneficiaries insured by both systems receive a single check from the RRB. Railroad retirement annuities may also be reduced for certain pensions earned through federal, state, and local government work that is not covered by Social Security. For early retirees who continue to work for a nonrailroad employer while receiving the retirement benefit during the year prior to FRA, Tier I benefits are reduced by $1 for every $2 earned above an exempt amount ($17,040 in 2018). After Tier I benefits are first paid, they increase annually with a cost-of-living adjustment (COLA) in the same manner as Social Security benefits. Retirement annuities are not payable to workers who continue to work in a covered railroad job or who return to railroad work after retirement. Tier II retirement annuities are paid in addition to Tier I annuities and any private pension and retirement saving plans offered by railroad employers. They are similar to private pensions and based solely on covered railroad service. Tier II annuities for current retirees are equal to seven-tenths of 1% of the employee's average monthly earnings in the 60 months of highest earnings, times the total number of years of railroad service. Tier II annuities are increased annually by 32.5% of the Social Security COLA. Tier II annuities are not (in contrast to Tier I annuities) reduced if a worker receives Social Security benefits or a government pension that was not covered by Social Security. For railroad retirees and spouses who work for their last pre-retirement nonrailroad employer while receiving retirement benefits, Tier II annuities are reduced by $1 for every $2 earned, capped at 50% of the Tier II annuity. There is no cap to the earnings-related reduction in railroad Tier I or Social Security benefits. In addition, the earnings-related reduction applies to all Tier II beneficiaries regardless of age, whereas for railroad Tier I and Social Security benefits, the earnings-related reduction applies only until the beneficiary reaches FRA. Tier II payroll taxes also finance a supplemental annuity program. Supplemental annuities are payable to employees first hired before October 1981, aged 60 with at least 30 years of covered railroad service or aged 65 and older with at least 25 years of covered railroad service, and a current connection with the railroad industry. In addition, general revenues finance a vested dual benefit for those who were insured for both railroad retirement and Social Security in 1974 when the two-tier railroad retirement benefit structure was established. Neither supplemental annuities nor vested dual benefits are adjusted for changes in the cost of living during retirement. Supplemental annuities are subject to the same earnings reductions as Tier II benefits; vested dual benefits are subject to the same earnings reductions as Tier I benefits. Railroad workers may be eligible for disability annuities if they become disabled regardless of whether the disability is caused by railroad work. The RRB determines whether a worker is disabled based on the medical evidence provided during the application process. Railroad workers found to be totally and permanently disabled from all work may be eligible for Tier I benefits at any age if the worker has at least 10 years of railroad service. Totally disabled workers may also receive Tier II benefits at the age of 62 if they have 10 or more years of service. Occupational disability annuities are also payable to workers found to be permanently disabled from their regular railroad occupations, if the worker is at least 60 years old with 10 years of service (or any age with 20 years of service), and with a current connection to the railroad industry. A five-month waiting period after the onset of disability is required before any disability annuity can be payable. Disability annuities are not payable if a worker is currently employed in a covered railroad job. Disability benefits are suspended if a beneficiary earns more than a certain amount after deducting certain disability-related work expenses. The Tier I portion of disability benefits may be reduced for the receipt of workers compensation or government disability benefits. In any month that a worker collects a railroad retirement or disability annuity, his or her spouse may also be eligible for a spousal annuity equal to or greater than the benefit he or she would have received if the worker's railroad work had been covered by Social Security. A spouse is eligible for a spousal annuity when he or she reaches the same minimum age required for the worker (i.e., either at the age of 60 or 62, depending on years of the worker's service). At any age, a spouse may be eligible for a spousal annuity if he or she cares for the worker's unmarried child under the age of 18 (or a child of any age that was disabled before the age of 22). An individual must have been married to the railroad worker for at least one year before he or she applies for the spousal annuities, with certain exceptions. A qualifying spouse receives 50% of the worker's Tier I benefit before any reductions (or, if higher, a Social Security benefit based on his or her own earnings). Spouses may also receive 45% of the worker's Tier II benefit before any reductions. Divorced spouses of retired or disabled railroad workers may also be eligible for spousal annuities. A divorced spouse may receive 50% of the worker's Tier I benefit before reductions, but no Tier II benefits. To qualify, the former spouse must have been married to the worker for at least 10 years and must not currently be married (remarriages if any must have terminated); both the worker and former spouse must be at least 62 years old. For spouses, as for railroad workers, Social Security benefits are subtracted from Tier I annuities. The Tier I portion of a spouse annuity may also be reduced for receipt of any pension from government employment not covered by Social Security based on the spouse's own earnings. Spouses are subject to reductions based on the primary worker's earnings as well as on their own earnings. For example, for early retirement, spouses are subject to different benefit reductions from workers. Finally, spouse annuities are reduced by the amount of any railroad benefits earned based on their own work. After the worker's death, surviving spouses, former spouses, children, and other dependents may be eligible to receive survivor annuities, which are paid in addition to any private life insurance offered by railroad employers. To be insured for survivor annuities, the worker must have had a current connection with the railroad industry at the time of death. Railroad survivor annuities are generally higher than comparable Social Security benefits because railroad workers' families may be entitled to Tier II annuities as well as Tier I annuities (as noted above, Tier I annuities are equivalent to Social Security benefits). In cases where no monthly survivor annuities are paid, a lump-sum payment may be made to certain survivors. The widows and widowers of railroad workers may be eligible to receive survivor annuities. At FRA, a surviving spouse may be eligible for 100% of the worker's Tier I annuity (or his or her own Social Security or railroad retirement Tier I benefit, if higher). The widow(er) may also receive up to 100% of the worker's Tier II annuity. As early as the age of 60 (or age 50, if disabled), widows and widowers may receive reduced survivor annuities. A qualifying widow(er) must have been married to the deceased railroad worker for at least nine months, with certain exceptions. At any age, a widow(er) caring for a deceased worker's child under the age of 18 may receive a survivor annuity equal to 75% of the worker's Tier I annuity, as well as up to 100% of the worker's Tier II annuity. Widow(er)s who are the natural or adoptive parent of the deceased worker's child do not have to meet the length of marriage requirement. Survivor annuities may also be payable to a surviving divorced spouse or remarried widow(er). To qualify for benefits, a surviving divorced spouse has to be married to the employee for at least 10 years and is unmarried or remarried after age 60 (age 50 for disabled surviving divorced spouse). A surviving divorced spouse who is unmarried can qualify for benefits at any age if caring for the employee's child who is under age 16 or disabled. Benefits are limited to the amounts Social Security would pay (Tier I only) and therefore are less than the amount of the survivor annuity otherwise payable. Railroad workers' children may also receive survivor annuities. To qualify, a child must be unmarried and under the age of 18 (or 19 if still in high school). Disabled adult children may qualify if their disability began before the age of 22. Eligible children receive 75% of the worker's Tier I annuity and 15% of the worker's Tier II annuity. In addition, if a worker's parent was dependent on the worker for at least half of the parent's support, he or she may receive 82.5% of the worker's Tier I annuity and 35% of the worker's Tier II annuity after reaching age 60. Survivor annuities are not payable to a current railroad employee, and survivor annuities are reduced by any railroad retirement benefit the survivor has earned through his or her own railroad work. Survivors receive the same reductions as retired workers for Social Security benefit receipt; they also have reductions from government pension receipts that are not covered by Social Security. A family maximum applies to survivor benefits, usually applicable when three or more survivors receive benefits on a worker's record (not counting divorced spouses). In summary, Table 1 provides data on railroad retirement, survivor, and disability annuities as of June 2018. Railroad workers may qualify for daily unemployment and sickness benefits under the Railroad Unemployment Insurance Act (RUIA). These monetary benefits are paid in addition to any paid leave or private insurance an employee may have. For sickness benefits, a worker must be unable to work because of illness or injury. Sickness benefits are distinct from disability benefits because they are intended to cover a finite, temporary period of time. Workers may not earn any money while receiving unemployment or sickness benefits. Figure 3 displays the monthly number of beneficiaries with unemployment and sickness benefits from January 2002 to July 2018, respectively. Although the number of sickness beneficiaries stayed relatively stable over time, the number of unemployment insurance beneficiaries increased significantly during and after the most recent economic recession from 2007 to 2009. Railroad unemployment and sickness benefits are financed solely by railroad employers' payroll taxes, based on the taxable earnings of their employees. Employers' tax rates depend on the past rates of unemployment and employees' sickness claims. For calendar year 2018, the employer tax rate ranges from 2.2% to 12.0% on the first $1,560 of each employee's monthly earnings. The payroll tax proceeds not needed immediately for unemployment and sickness insurance benefits or operating expenses are deposited in the Railroad Unemployment Insurance Account maintained by the Treasury. This account, together with similar unemployment insurance accounts for each state, forms a Federal Unemployment Insurance Trust Fund whose deposits are invested in U.S. government securities, and the Railroad Unemployment Insurance Account receives interest based on these deposits. During FY2017, payroll tax contributions from railroad employers totaled $126.4 million and interest income was about $4 million. The RUIA provides for employers to pay a surcharge if the Railroad Unemployment Insurance Account falls below an indexed threshold amount. The surcharge is added to the employer's tax rate. However, the total tax rate plus the surcharge cannot exceed the maximum rate of 12.0%, unless the surcharge is 3.5%, in which case the maximum tax rate is increased to 12.5%. From 2004 through 2010, the surcharge was 1.5%. The surcharge in 2011 was 2.5% and 1.5% in 2012 with no surcharges in 2013 or 2014. The surcharge in 2018 was 1.5%, the same as the level in the past three years. Eligibility for railroad unemployment and sickness benefits is based on recent railroad service and earnings. The annual benefit year begins on July 1. Eligibility is based on work in the prior year, or the base year. To qualify in the benefit year beginning July 1, 2018, railroad workers must have base year earnings of $3,862.50 in calendar year 2017, counting no more than $1,545 per month. New railroad workers must also have at least five months of covered railroad work in the base year. To receive unemployment benefits, a worker must be ready, willing, and able to work. The maximum daily unemployment and sickness benefit payable in the benefit year that began July 1, 2018, is $77, and the maximum benefit for a biweekly claim is $770. However, due to sequestration pursuant to the Budget Control Act of 2011 ( P.L. 112-25 , as amended), the maximum daily benefit of $77 is reduced by 6.2% to $72.23 and the maximum biweekly benefit is reduced by 6.2% to $722.26 through September 30, 2019. Railroad workers receive these benefits only to the extent that they are higher than other benefits they receive under the RRA, the Social Security Act, or certain other public programs, including workers compensation. Unemployment and sickness beneficiaries may receive normal benefits for up to 26 weeks in a benefit year or until the benefits they receive equal their creditable earnings in the base year if sooner. Employees with at least 10 years of covered railroad service may qualify for extended benefits for 13 weeks after they have exhausted normal benefits. Table 2 displays the number and average weekly amount of RUIA benefits paid in June 2018. Workers who apply for unemployment benefits are automatically enrolled in a free job placement service operated by railroad employers and the RRB. 
VA’s mission is to promote the health, welfare, and dignity of all veterans in recognition of their service to the nation by ensuring that they receive medical care, benefits, social support, and lasting memorials. In carrying out this mission, the department operates one of the largest health care delivery systems in America, providing health care to millions of veterans and their families at more than 1,500 facilities. The department’s three major components—the Veterans Health Administration (VHA), the Veterans Benefits Administration (VBA), and the National Cemetery Administration (NCA)—are primarily responsible for carrying out its mission. More specifically, VHA provides health care services, including primary care and specialized care, and it performs research and development to improve veterans’ needs. VBA provides a variety of benefits to veterans and their families, including disability compensation, educational opportunities, assistance with home ownership, and life insurance. Further, NCA provides burial and memorial benefits to veterans and their families. Collectively, the three components rely on approximately 340,000 employees to provide services and benefits. These employees work in VA’s Washington, D.C. headquarters, as well as 170 medical centers, approximately 750 community-based outpatient clinics, 300 veterans centers, 56 regional offices, and more than 130 cemeteries situated throughout the nation. The use of IT is critically important to VA’s efforts to provide benefits and services to veterans. As such, the department operates and maintains an IT infrastructure that is intended to provide the backbone necessary to meet the day-to-day operational needs of its medical centers, veteran- facing systems, benefits delivery systems, memorial services, and all other systems supporting the department’s mission. The infrastructure is to provide for data storage, transmission, and communications requirements necessary to ensure the delivery of reliable, available, and responsive support to all VA staff offices and administration customers, as well as veterans. According to department data as of October 2016, there were 576 active or in-development systems in VA’s inventory of IT systems. These systems are intended to be used for the determination of benefits, benefits claims processing, and access to health records, among other services. VHA is the parent organization for 319 of these systems. Of the 319 systems, 244 were considered mission-related and provide capabilities related to veterans’ health care delivery. For example, VHA’s systems provide capabilities to establish and maintain electronic health records that health care providers and other clinical staff use to view patient information in inpatient, outpatient, and long-term care settings. VistA serves an essential role in helping the department to fulfill its health care delivery mission. Specifically, VistA is an integrated medical information system for all veterans’ health information. It was developed in-house by the department’s clinicians and IT personnel and has been in operation since the early 1980s. As such, the system has long been vital to helping ensure the quality of health care received by the nation’s veterans and their dependents. VistA is comprised of more than 200 applications that assist in the delivery of health care and perform other important functions within the department, including financial management, enrollment, and registration. Some of these applications have been in operation for over 30 years and, according to VA, have become increasingly difficult and costly to maintain. As such, the department has expended extensive resources to modernize the system and increase its ability to allow for the viewing or exchange of patient information with the Department of Defense (DOD) and private sector health providers. In addition, as we recently reported, VHA has unaddressed needs that indicate its current health IT systems, including VistA, do not fully support the organization’s business functions. Specifically, about 39 percent of all requests related to health IT needs have remained unaddressed after more than 5 years. Electronic health records are particularly crucial for optimizing the health care provided to veterans, many of whom may have health records residing at multiple medical facilities within and outside the United States. Taking steps toward interoperability—that is, collecting, storing, retrieving, and transferring veterans’ health records electronically—is significant to improving the quality and efficiency of care. One of the goals of interoperability is to ensure that patients’ electronic health information is available from provider to provider, regardless of where it originated or resides. Since 2007, VA has been operating a centralized organization, the Office of Information and Technology (OI&T), in which most key functions intended for effective management of IT are performed. This office is led by the Assistant Secretary for Information and Technology—VA’s Chief Information Officer (CIO). The office is responsible for providing strategy and technical direction, guidance, and policy related to how IT resources are to be acquired and managed for the department, and for working closely with its business partners—such as VHA—to identify and prioritize business needs and requirements for IT systems. Among other things, OI&T has responsibility for managing the majority of VA’s IT-related functions, including the maintenance and modernization of VistA. As of 2016, OI&T was comprised of more than 15,000 staff, with more than half of these positions filled by contractors. For fiscal year 2018, the department’s budget request included nearly $4.1 billion for IT. The department requested approximately $359 million for new systems development or modernization efforts, approximately $2.5 billion for maintaining existing systems, and approximately $1.2 billion for payroll and administration. For example, in its fiscal year 2018 budget submission, the department requested appropriations to support five IT portfolios, including the development and operations and maintenance for programs and projects related to the: Medical portfolio, which provides technology solutions to deliver modern, high-quality medical care capabilities to veterans ($944.2 million); Benefit portfolio, which addresses the technology needs managed by the Veterans Benefit Administration ($296.9 million); Memorial Affairs portfolio, which provides support for the modernization of applications and services for National Cemeteries at 133 locations nationwide ($24.5 million); Corporate portfolio, which consists of back office operations supporting the major business lines and department management ($270.6 million); and Enterprise IT, which provides the underlying infrastructure to enable the other portfolios to operate and includes such things as cybersecurity, data centers, cloud services, telephony, enterprise software, and data connectivity ($1.289 billion). In 2015, we designated VA Health Care as a high-risk area for the federal government and, currently, we continue to be concerned about the department’s ability to ensure that its resources are being used cost- effectively and efficiently to improve veterans’ timely access to health care. In part, we identified limitations in the capacity of VA’s existing systems, including the outdated, inefficient nature of certain systems and a lack of system interoperability—that is, the ability to exchange and use electronic health information—as contributors to the department’s IT challenges related to health care. These challenges present risks to the timeliness, quality, and safety of the health care. While we recently reported that the department has begun to demonstrate leadership commitment to addressing IT challenges, more work remains. Also, in February 2015, we added Improving the Management of IT Acquisitions and Operations to our list of high-risk areas. Specifically, federal IT investments too frequently fail or incur cost overruns and schedule slippages while contributing little to mission-related outcomes. We have previously testified that the federal government has spent billions of dollars on failed IT investments, including, for example, VA’s Scheduling Replacement Project, which was terminated in September 2009 after spending an estimated $127 million over 9 years; and its Financial and Logistics Integrated Technology Enterprise program, which was intended to be delivered by 2014 at a total estimated cost of $609 million, but was terminated in October 2011 due to challenges in managing the program. This high-risk area highlighted several critical IT initiatives in need of additional congressional oversight, including (1) reviews of troubled projects; (2) efforts to increase the use of incremental development; (3) efforts to provide transparency relative to the cost, schedule, and risk levels for major IT investments; (4) reviews of agencies’ operational investments; (5) data center consolidation; and (6) efforts to streamline agencies’ portfolios of investments. We noted that agencies’ implementation of these initiatives was inconsistent and that more work remained to demonstrate progress in achieving IT acquisition and operation outcomes. We also recently issued an update to our high-risk report and noted that, while progress has been made in addressing the high-risk area of IT acquisitions and operations, significant work remains to be completed. For example, we noted, among other things, that additional work was needed to establish action plans for federal agencies to modernize or replace obsolete systems. Specifically, we pointed out that many federal systems use outdated software languages and hardware, which has increased spending on operations and maintenance of technology investments. VA was among a handful of departments with one or more archaic legacy systems. As discussed in our recent report on legacy systems used by federal agencies, we identified 2 of the department’s systems as being over 50 years old, and among the 10 oldest investments and/or systems that were reported by 12 selected agencies. Personnel and Accounting Integrated Data (PAID)—This 53-year old system automates time and attendance for employees, timekeepers, payroll, and supervisors. It is written in Common Business Oriented Language (COBOL), a programming language developed in the late 1950s and early 1960s, and runs on IBM mainframes. Benefits Delivery Network (BDN)—This 51-year old system tracks claims filed by veterans for benefits, eligibility, and dates of death. It is a suite of COBOL mainframe applications. Ongoing uses of antiquated systems, such as PAID and BDN, contribute to agencies spending a large, and increasing, proportion of their IT budgets on operations and maintenance of systems that have outlived their effectiveness and are consuming resources that outweigh their benefits. Accordingly, we have recommended that VA identify and plan to modernize or replace its legacy systems. The department concurred with our recommendation and stated that it plans to retire and replace PAID with the Human Resources Information System Shared Service Center in 2017. The department also stated that it has general plans to roll the capabilities of BDN into another system and to retire BDN in 2018. Congress enacted federal IT acquisition reform legislation (commonly referred to as the Federal Information Technology Acquisition Reform Act, or FITARA) in December 2014. This legislation was intended to improve agencies’ acquisitions of IT and enable Congress to monitor agencies’ progress and hold them accountable for reducing duplication and achieving cost savings. The law applies to VA and other covered agencies. It includes specific requirements related to seven areas, including data center consolidation and optimization, agency CIO authority, and government-wide software purchasing. Federal data center consolidation initiative (FDCCI). Agencies are required to provide the Office of Management and Budget (OMB) with a data center inventory, a strategy for consolidating and optimizing their data centers (to include planned cost savings), and quarterly updates on progress made. The law also requires OMB to develop a goal for how much is to be saved through this initiative, and provide annual reports on cost savings achieved. Agency CIO authority enhancements. CIOs at covered agencies are required to (1) approve the IT budget requests of their respective agencies, (2) certify that IT investments are adequately implementing incremental development, as defined in capital planning guidance issued by OMB, (3) review and approve contracts for IT, and (4) approve the appointment of other agency employees with the title of CIO. Government-wide software purchasing program. The General Services Administration is to develop a strategic sourcing initiative to enhance government-wide acquisition and management of software. In doing so, the law requires that, to the maximum extent practicable, the General Services Administration should allow for the purchase of a software license agreement that is available for use by all executive branch agencies as a single user. Expanding upon FITARA, the Making Electronic Government Accountable by Yielding Tangible Efficiencies Act of 2016, or the “MEGABYTE Act,” further enhanced CIOs’ management of software licenses by requiring agency CIOs to establish an agency software licensing policy and a comprehensive software license inventory to track and maintain licenses, among other requirements. In June 2015, OMB released guidance describing how agencies are to implement FITARA. This guidance is intended to, among other things: assist agencies in aligning their IT resources with statutory establish government-wide IT management controls that will meet the law’s requirements, while providing agencies with flexibility to adapt to unique agency processes and requirements; clarify the CIO’s role and strengthen the relationship between agency CIOs and bureau CIOs; and strengthen CIO accountability for IT costs, schedules, performance, and security. In our draft report that is currently with VA for comments, we discuss the history of VA’s efforts to modernize its health information system, VistA. These four efforts—HealtheVet, the integrated Electronic Health Record (iEHR), VistA Evolution, and the Electronic Health Record Modernization (EHRM)—reflect varying approaches that the department has considered to achieve a modernized health care system over the course of nearly two decades. The modernization efforts are described as follows. In 2001, VA undertook its first VistA modernization project, the HealtheVet initiative, with the goals of standardizing the department’s health care system and eliminating the approximately 130 different systems used by its field locations at that time. HealtheVet was scheduled to be fully implemented by 2018 at a total estimated development and deployment cost of about $11 billion. As part of the effort, the department had planned to develop or enhance specific areas of system functionality through six projects, which were to be completed between 2006 and 2012. Specifically, these projects were to provide capabilities to support VA’s Health Data Repository and Patient Financial Services System, as well as the Laboratory, Pharmacy, Imaging, and Scheduling functions. In June 2008, we reported that the department had made progress on the HealtheVet initiative, but noted issues with project planning and governance. In June 2009, the Secretary of Veterans Affairs announced that VA would stop financing failed projects and improve the management of its IT development projects. Subsequently, in August 2010, the department reported that it had terminated the HealtheVet initiative. In February 2011, VA began its second modernization initiative, the iEHR program, in conjunction with DOD. The program was intended to replace the two separate electronic health record systems used by the two departments with a single, shared system. Moreover, because both departments would be using the same system, this approach was expected to largely sidestep the challenges that had been encountered in trying to achieve interoperability between their two separate systems. Initial plans called for the development of a single, joint system consisting of 54 clinical capabilities to be delivered in six increments between 2014 and 2017. Among the agreed-upon capabilities to be delivered were those supporting laboratory, anatomic pathology, pharmacy, and immunizations. According to VA and DOD, the single iEHR system had an estimated life cycle cost of $29 billion through the end of fiscal year 2029. However, in February 2013, the Secretaries of VA and DOD announced that they would not continue with their joint development of a single electronic health record system. This decision resulted from an assessment of the iEHR program that the secretaries had requested in December 2012 because of their concerns about the program facing challenges in meeting deadlines, costing too much, and taking too long to deliver capabilities. In 2013, the departments abandoned their plan to develop the integrated system and stated that they would again pursue separate modernization efforts. In December 2013, VA initiated its VistA Evolution program as a joint effort of VHA and OI&T that was to be completed by the end of fiscal year 2018. The program was to be comprised of a collection of projects and efforts focused on improving the efficiency and quality of veterans’ health care by modernizing the department’s health information systems, increasing the department’s data exchange and interoperability with DOD and private sector health care partners, and reducing the time it takes to deploy new health information management capabilities. Further, the program was intended to result in lower costs for system upgrades, maintenance, and sustainment. According to the department’s March 2017 cost estimate, VistA Evolution was to have a life cycle cost of about $4 billion through fiscal year 2028. Since initiating VistA Evolution in December 2013, VA has completed a number of key activities that were called for in its plans. For example, the department delivered capabilities, such as the ability for health providers to have an integrated, real-time view of electronic health record data through the Joint Legacy Viewer, as well as the ability for health care providers to view sensitive DOD notes and highlight abnormal test results for patients. VA also initiated work to standardize VistA across the 130 VA facilities and released enhancements to its legacy scheduling, pharmacy, and immunization systems. In addition, the department released the enterprise Health Management Platform, which is a web- based user interface that assembles patient clinical data from all VistA instances and DOD. Although VistA Evolution is ongoing, VA is currently in the process of revising its plan for the program as a result of the department recently announcing its pursuit of a fourth VistA modernization program (discussed below). For example, the department determined that it would no longer pursue additional development or deployment of the enterprise Health Management Platform—a major VistA Evolution component— because the new modernization program is envisioned to provide similar capabilities. In June 2017, the VA Secretary announced a significant shift in the department’s approach to modernizing VistA. Specifically, rather than continue to use VistA, the Secretary stated that the department plans to acquire the same electronic health record system that DOD is implementing. In this regard, DOD has contracted with the Cerner Corporation to provide a new integrated electronic health record system. According to the Secretary, VA has chosen to acquire this same product because it would allow all of VA’s and DOD’s patient data to reside in one system, thus enabling seamless care between the department and DOD without the manual and electronic exchange and reconciliation of data between two separate systems. The VA Secretary added that this fourth modernization initiative is intended to minimize customization and system differences that currently exist within the department’s medical facilities, and ensure the consistency of processes and practices within VA and DOD. When fully operational, the system is intended to be the single source for patients to access their medical history and for clinicians to use that history in real time at any VA or DOD medical facility, which may result in improved health care outcomes. According to VA’s Chief Technology Officer, Cerner is expected to provide integration, configuration, testing, deployment, hosting, organizational change management, training, sustainment, and licenses necessary to deploy the system in a manner that meets the department’s needs. To expedite the acquisition, in June 2017, the Secretary signed a “Determination and Findings,” which noted a public interest exception to the requirement for full and open competition, and authorized VA to issue a solicitation directly to the Cerner Corporation. According to the Secretary, VA expects to award a contract to Cerner in December 2017, and deployment of the new system is anticipated to begin 18 months after the contract has been signed. VA’s Executive Director for the Electronic Health Records Modernization System stated that the department intends to incrementally deploy the new system to its medical facilities. Each facility is expected to continue using VistA until the new system has been deployed at that location. All VA medical facilities are anticipated to have the new system implemented within 7 to 8 years after the first deployment. Figure 1 shows a timeline of the four efforts that VA has pursued to modernize VistA since 2001. For iEHR and VistA Evolution, the two modernization initiatives for which VA could provide contract data, the department obligated approximately $1.1 billion for contracts with 138 different contractors during fiscal years 2011 through 2016. Specifically, the department obligated approximately $224 million and $880 million, respectively, for contracts associated with these efforts. Of the 138 contractors, 34 of them performed work supporting both iEHR and VistA Evolution. The remaining 104 contractors worked exclusively on either iEHR or VistA Evolution. Funding for the 34 contractors that worked on both iEHR and VistA Evolution totaled about $793 million of the $1.1 billion obligated for contracts on the two initiatives. Obligations for contracts awarded to the top 15 of these 34 contractors (which we designated as key contractors) accounted for about $741 million (about 67 percent) of the total obligated for contracts on the two initiatives. The remaining 123 contractors were obligated about $364 million for their contracts. The 15 key contractors were obligated about $564 million and $177 million for VistA Evolution and iEHR contracts, respectively. Table 1 identifies the key contractors and their obligated dollar totals for the two efforts. Additionally, we determined that, of the $741 million obligated to the key contractors, $411 million (about 55 percent) was obligated for contracts supporting the development of new system capabilities, $256 million (about 35 percent) was obligated for contracts supporting project management activities, and $74 million (about 10 percent) was obligated for contracts supporting operations and maintenance for iEHR and VistA Evolution. VA obligated funds to all 15 of the key contractors for system development, 13 of the key contractors for project management, and 12 of the key contractors for operations and maintenance. Figure 2 shows the amounts obligated for each of these areas. Further, based on the key contractors’ documentation, for the iEHR program, VA obligated $102 million for development, $65 million for project management, and $10 million for operations and maintenance. For the VistA Evolution Program, VA obligated $309 million for development, $191 million for project management, and $64 million for operations and maintenance. Figure 3 shows the amounts obligated for contracts on the VistA Evolution and iEHR programs for development, project management, and operations and maintenance. In addition, table 2 shows the amounts that each of the 15 key contractors were obligated for the three types of contract activities performed on iEHR and VistA Evolution. Industry best practices and IT project management principles stress the importance of sound planning for system modernization projects. These plans should identify key aspects of a project, such as the scope, responsible organizations, costs, schedules, and risks. Additionally, planning should begin early in the project’s lifecycle and be updated as the project progresses. Since the VA Secretary announced that the department would acquire the same electronic health record system as DOD, VA has begun planning for the transition from VistA Evolution to EHRM. However, the department is still early in its efforts, pending the contract award. In this regard, the department has begun developing plans that are intended to guide the new EHRM program. For example, the department has developed a preliminary description of the organizations that are to be responsible for governing the EHRM program. Further, the VA Secretary announced in congressional testimony in November 2017, a key reporting responsibility for the program—stating that the Executive Director for the Electronic Health Records Modernization System will report directly to the department’s Deputy Secretary. In addition, the department has developed a preliminary timeline for deploying its new electronic health record system to VA’s medical facilities, and a 90-day schedule that depicts key program activities. The department also has begun documenting the EHRM program risks. Beyond the aforementioned planning activities undertaken thus far, the Executive Director stated that the department intends to complete a full suite of planning and acquisition management documents to guide the program, including a life cycle cost estimate and an integrated master schedule to establish key milestones over the life of the project. To this end, the Executive Director told us that VA has awarded two program management contracts to support the development of these plans to MITRE Corporation and Booz Allen Hamilton. According to the Executive Director, VA also has begun reviewing the VistA Evolution Roadmap, which is the key plan that the department has used to guide VistA Evolution since 2014. This review is expected to result in an updated plan that is to prioritize any remaining VistA enhancements needed to support the transition from VistA Evolution to the new system. According to the Executive Director, the department intends to complete the development of its plans for EHRM within 90 days after award of the Cerner contract, which is anticipated to occur in December 2017. Further, beyond the development of plans, VA has begun to staff an organizational structure for the modernization initiative, with the Under Secretary of Health and the Assistant Secretary for Information and Technology (VA’s Chief Information Officer) designated as executive sponsors. It has also appointed a Chief Technology Officer from OI&T, and a Chief Medical Officer from VHA, both of whom are to report to the Executive Director. VA’s efforts to develop plans for EHRM and to staff an organization to manage the program encompass key aspects of project planning that are important to ensuring effective management of the department’s latest modernization initiative. However, the department remains early in its modernization planning efforts, many of which are dependent on the system acquisition contract award, which has not yet occurred. The department’s continued dedication to completing and effectively executing the planning activities that it has identified will be essential to helping minimize program risks and guide this latest electronic health record modernization initiative to a successful outcome—one which VA, for almost two decades, has yet to achieve. Beyond managing its system modernization efforts, such as VistA, VA has to ensure the effective implementation of the IT acquisition requirements called for in FITARA. Pursuant to FITARA, in August 2016, the Federal CIO issued a memorandum that announced the Data Center Optimization Initiative (DCOI). According to OMB, this new initiative supersedes and builds on the results of FDCCI, and is also intended to improve the performance of federal data centers in areas such as facility utilization and power usage. Among other things, DCOI requires 24 federal departments and agencies, including VA, to develop plans and report on strategies (referred to as DCOI strategic plans) to consolidate inefficient infrastructure, optimize existing facilities, improve security posture, and achieve costs savings. Further, the memorandum establishes a set of five data center optimization metrics and performance targets intended to measure agency’s progress in the areas of (1) server utilization and automated monitoring, (2) energy metering, (3) power usage effectiveness, (4) facility utilization, and (5) virtualization. The guidance also indicates that OMB is to maintain a public dashboard that will display consolidation-related costs savings and optimization performance information for the agencies. However, in a series of reports that we issued from July 2011 through August 2017, we noted that, while data center consolidation could potentially save the federal government billions of dollars, weaknesses existed in several areas, including agencies’ data center consolidation plans, data center optimization, and OMB’s tracking and reporting on related cost savings. Further, we previously reported that VA’s progress toward closing data centers, and realizing the associated cost savings, lagged behind that of other covered agencies. More recently, VA reported a total inventory of 415 data centers, of which 39 had been closed as of August 2017. While the department anticipates another 10 data centers will be closed by the end of fiscal year 2018, these closures fall short of the targets set by OMB. Specifically, even if VA meets all of its planned targets for closure, it will only close about 9 percent of its tiered data centers and about 18.7 percent of its non-tiered data centers by the end of fiscal year 2018, which is short of the respective 25 and 60 percent targets set by OMB. Further, while VA has reported $23.61 million in data center-related cost savings and avoidances for 2012 through August 2017, the department does not expect to realize further savings from the additional 10 data center closures in the next year. In addition, in August 2017 we reported that agencies needed to address challenges in optimizing their data centers in order to achieve cost savings. Specifically, we noted that, according to the 24 agencies’ data center consolidation initiative strategic plans as of April 2017, most agencies were not planning to meet OMB’s optimization targets by the end of fiscal year 2018. As of February 2017, VA reported meeting one of the five data center optimization metrics related to power usage effectiveness. Also, the department’s data center optimization strategic plan indicates that the department plans to meet three of the five metrics by the end of fiscal year 2018. Further, while OMB directed agencies to replace manual collection and reporting of metrics with automated tools no later than fiscal year 2018, VA had only implemented automated tools at 6 percent of its data centers. OMB has emphasized the need to deliver investments in smaller parts, or increments, in order to reduce risk, deliver capabilities more quickly, and facilitate the adoption of emerging technologies. In 2010, it called for agencies’ major investments to deliver functionality every 12 months and, since 2012, every 6 months. Subsequently, FITARA codified a requirement that agency CIOs certify that IT investments are adequately implementing incremental development, as defined in the capital planning guidance issued by OMB. Later OMB guidance on the law’s implementation—issued in June 2015—directed agency CIOs to define processes and policies for their agencies which ensure that they certify that IT resources are adequately implementing incremental development. Between May 2014 and November 2017, we reported on agencies’ efforts to utilize incremental development practices for selected major investments. In November 2017, we noted that agencies reported that 62 percent of major IT software development investments were certified by the agency CIO as using adequate incremental development in fiscal year 2017, as required by FITARA. VA’s CIO certified the use of adequate incremental development for all 10 of its major IT investments. However, VA had not yet updated the department’s policy and process for the CIO’s certification of major IT investments’ adequate use of incremental development, in accordance with OMB’s guidance on the implementation of FITARA as we recommended. The department stated that it plans to address our recommendation to establish a policy and that the policy is targeted for completion in 2017. Federal agencies engage in thousands of licensing agreements annually. Effective management of software licenses can help organizations avoid purchasing too many licenses that result in unused software. In addition, effective management can help avoid purchasing too few licenses, which results in noncompliance with license terms and causes the imposition of additional fees. Federal agencies are responsible for managing their IT investment portfolios, including the risks from their major information system initiatives, in order to maximize the value of these investments to the agency. OMB developed a policy that requires agencies to conduct an annual, agency-wide IT portfolio review to, among other things, reduce commodity IT spending. Such areas of spending could include software licenses. We previously identified seven elements that a comprehensive software licensing policy should address: identify clear roles, responsibilities, and central oversight authority within the department for managing enterprise software license agreements and commercial software licenses; establish a comprehensive inventory (at least 80 percent of software license spending and/or enterprise licenses in the department) by identifying and collecting information about software license agreements using automated discovery and inventory tools; regularly track and maintain software licenses to assist the agency in implementing decisions throughout the software license management life cycle; analyze software usage and other data to make cost-effective provide training relevant to software license management; establish goals and objectives of the software license management consider the software license management life-cycle phases (i.e., requisition, reception, deployment and maintenance, retirement, and disposal phases) to implement effective decision making and incorporate existing standards, processes, and metrics. We previously made recommendations to VA to (1) develop an agency- wide comprehensive policy for the management of software licenses that includes guidance for using analysis to better inform investment decision making, (2) employ a centralized software license management approach that is coordinated and integrated with key personnel, (3) establish a comprehensive inventory of software licenses using automated tools, (4) track and maintain a comprehensive inventory of software licenses using automated tools and metrics, (5) analyze agency-wide software license data to identify opportunities to reduce costs and better inform investment decision making, and (6) provide software license management training to appropriate personnel. Consistent with our recommendation, in July 2015, VA issued a comprehensive software licensing policy that addressed weaknesses we previously identified. The department also issued a directive that documents VA’s software license management policy and responsibilities for central management of agency-wide software licenses, consistent with our recommendations. By implementing our recommendations, VA should be better positioned to consistently and cost-effectively manage software throughout the agency. In August 2017, the department also provided documentation showing that it had generated a comprehensive inventory of software licenses using automated tools for the majority of agency software license spending or enterprise-wide licenses. This inventory can serve to reduce redundant applications and help identify other cost saving opportunities. Further, the department implemented a solution to analyze agency-wide software license data, including usage and costs. This solution should allow VA to identify cost saving opportunities and inform future investment decisions. In addition, the department has provided information indicating that appropriate personnel receive software license management training. In conclusion, VA has made extensive use of numerous contractors and has obligated more than $1 billion for contracts that supported two of four VistA modernization programs that the department has initiated. VA has recently begun the fourth modernization program in which it plans to replace VistA with the same commercially available electronic health record system that is used by DOD. However, the department’s latest modernization effort is in the early stages of planning and is dependent on the system acquisition contract award in December 2017. VA’s completion and effective execution of plans will be essential to guiding this latest electronic health record modernization initiative to a successful outcome. Beyond VistA, the department continues to make progress on key FITARA-related initiatives. Although the department has made progress in the area of software licensing, additional actions in the areas of data center consolidation and optimization, as well as incremental system development can better position VA to effectively manage its IT. We plan to continue to monitor the department’s progress on these important activities. Chairman Hurd, Ranking Member Kelly, and Members of the Subcommittee, this completes my prepared statement. I would be pleased to respond to any questions that you may have. If you or your staffs have any questions about this testimony, please contact David A. Powner at (202) 512-9286 or pownerd@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this testimony statement. GAO staff who made key contributions to this statement are Mark Bird (Assistant Director), Jacqueline Mai (Analyst in Charge), Justin Booth, Chris Businsky, Rebecca Eyler, Paris Hawkins, Valerie Hopkins, Brandon S. Pettis, Jennifer Stavros-Turner, Eric Trout, Christy Tyson, Eric Winter, and Charles Youman. This is a work of the U.S. government and is not subject to copyright protection in the United States. The published product may be reproduced and distributed in its entirety without further permission from GAO. However, because this work may contain copyrighted images or other material, permission from the copyright holder may be necessary if you wish to reproduce this material separately.
According to international and U.S. government sources, climate change poses serious risks to many of the physical and ecological systems upon which society depends, although the exact details of these impacts are uncertain. Climate change may intensify slow-onset disasters, such as drought, crop failure, and sea level rise. Climate change is also increasing the frequency and intensity of extreme weather events, including sudden- onset disasters, such as floods, according to key scientific assessments. These effects of climate change may alter existing migration trends across the globe, according to IOM. (See appendix II for further discussion of climate change as a driver of migration in seven geographic regions.) For example, sea level rise, a slow-onset disaster, may result in the salinization of soil and drinking water, thereby undermining a country or community’s ability to sustain livelihoods and maintain critical services, which could cause some people to migrate. Sudden-onset disasters may also contribute to migration as people flee natural disasters, in most cases leading to temporary displacement. For example, people may either voluntarily migrate, or be forced to migrate, to earn money needed to rebuild damaged homes after flooding, especially as extreme weather events increase in intensity and number. If unable or unwilling to migrate, people may find themselves trapped or choosing to stay in deteriorating conditions. Sources agree that the effects of climate change generally impact internal migration, while migration across international borders due to climate change is less common. In deciding whether to migrate, people weigh multiple factors including economic and political factors, social or personal motives, or demographic pressures. The effects of climate change add another layer of complexity to this decision, but there is debate about the role climate change plays in migration. Figure 1 depicts how climate change may influence other factors that drive the decision to migrate or stay. There are limitations to reliably estimating the number of people displaced by climate change because there are no reliable global estimates for those migrating due to slow-onset disasters, and estimates for those migrating due to sudden-onset disasters are based on limited data, according to IOM. The lack of reliable data is due in part to the multi- causal nature of migration. Further, IOM notes that forecasts for the number of environmental migrants by 2050 vary from 25 million to 1 billion. They and others have questioned the methodologies used to arrive at even these broad estimates. Migration, potentially driven by climate change, may contribute to instability and result in national security challenges, according to some international organizations and national governments. For example, an influx of migrants to a city may put pressure on existing resources, resulting in tensions between new migrants and residents, or between the population and its government. The U.S. Global Change Research Program has also stated that migration, such as displacement resulting from extreme weather events, is a potential national security issue. At different times, the United Nations General Assembly and, in 2014, DOD have deemed climate change to be a threat multiplier, as the effects of climate change could increase competition for resources, reduce government capacity, and threaten livelihoods, thereby causing instability and migration. Further, the U.S. intelligence community considers climate change to increase the risks of humanitarian disasters, conflict, and migration. Identifying the cause of a conflict, however, is complicated, and experts debate the connections linking climate, migration, and national security. For example, IOM has reported that existing evidence on climate migration and instability must be considered with caution. Further, some studies stress that other factors can mitigate the effects of climate change on migration and stability, including governance and community resilience, as the World Bank has reported. State, USAID, and DOD are among the U.S. government agencies with a role in responding to issues related to climate change, including as a driver of migration. State interacts with foreign governments and international organizations focused on climate change and migration primarily through the Bureau of Oceans and International Environmental and Scientific Affairs (State/OES) and the Bureau of Population, Refugees, and Migration (State/PRM). USAID supports a range of development programs that help to mitigate the effects of climate change through the Bureaus for Economic Growth, Education and Environment; Democracy, Conflict and Humanitarian Assistance; Food Security; Asia; and Africa; and individual USAID missions. Additionally, USAID’s Offices of U.S. Foreign Disaster Assistance (USAID/OFDA) and Food for Peace (USAID/FFP) lead and coordinate the U.S. government’s emergency responses to sudden- and slow-onset disasters, and complex emergencies overseas. DOD assists in the United States’ humanitarian response to sudden- onset disasters abroad through its six geographic combatant commands, with support from the Assistant Secretary of Defense for Special Operations and Low Intensity Conflict and the Joint Staff’s Office of Humanitarian Engagement. Climate change as a driver of migration was not a focus of the policy documents we reviewed for either the current or previous administrations during fiscal years 2014 through 2018. Our review of executive actions, budget requests, and executive branch strategies that affected State, USAID, and DOD found only brief mentions of climate change as a driver of migration. None of the documents we reviewed reflected a priority for assessing or addressing climate change as a driver of migration, although these documents reflect a shift in administrations’ climate change priorities more generally. The previous administration issued two executive orders and a presidential memorandum related to climate change. These executive actions had a policy of improving climate preparedness and resilience, factoring climate-resilience considerations into agencies’ international development decisions, and creating forums for interagency coordination. In March 2017, the current administration issued a subsequent executive order revoking some of the previous executive actions related to climate change. See figure 2 for a timeline of these executive actions. The previous administration issued three executive actions related to climate change, which included requirements focused on agencies’ considerations of the impacts of climate change and established forums for interagency coordination. The current administration issued an executive action related to energy independence and climate change. Executive Order 13653: Preparing the United States for the Impacts of Climate Change. Executive Order 13653 stated that agencies—including State, USAID, and DOD—shall, among other things, develop, implement, and update comprehensive Agency Adaptation Plans that integrate consideration of climate change into agency operations and overall mission objectives. Executive Order 13653 also established the Council on Climate Preparedness and Resilience. Executive Order 13677: Climate-Resilient International Development. Executive Order 13677 requires State, USAID, and other U.S. government agencies with direct international development programs and investments to incorporate climate-resilience considerations into decision making by assessing climate-related risks to agency strategies, and to adjust relevant strategies as appropriate, among other things. Executive Order 13677 also established the Working Group on Climate-Resilient International Development as part of the Council on Climate Preparedness and Resilience. 2016 Presidential Memorandum on Climate Change and National Security. The 2016 presidential memorandum required, among other things, that agencies, including State, USAID, and DOD, develop an agency-specific approach to address climate-related threats to national security. It also required agencies to develop implementation plans that would describe how they would identify the potential impact of climate change on human mobility, including migration and displacement, and the resulting impacts on national security, among other requirements, and stated that the effects of climate change can lead to population migration within and across international borders, spur crises, and amplify or accelerate conflict in countries or regions already facing instability. The 2016 memorandum also established the Climate and National Security Working Group. Executive Order 13783, Promoting Energy Independence and Economic Growth. Executive Order 13783 revoked Executive Order 13653 and the 2016 presidential memorandum, among other things, as seen in figure 2. Priorities related to climate change shifted between the past two administrations as reflected in a recent budget request that reduced some climate change funding affecting U.S. foreign assistance. 2017 Presidential Budget Request. The previous administration stated in its fiscal year 2017 budget request that “the challenge of climate change will define the contours of this century more dramatically than any other” and that “it is imperative for the United States to couple action on climate change at home with leadership internationally.” The fiscal year 2017 budget request sought $1.3 billion in discretionary funding to advance the goals of the Global Climate Change Initiative, which was established in 2010 and aimed to promote resilient, low-emission development, and integrate climate change considerations into U.S. foreign assistance. The $1.3 billion in requested funding included $750 million in U.S. funding for the Green Climate Fund, a multilateral trust fund designed to foster resilient low-emission development in developing countries. 2018 Presidential Budget Request. The current administration, in its fiscal year 2018 budget request, did not include any funding for the Global Climate Change Initiative. In addition, the current administration’s budget request stated that it “Eliminate the Global Climate Change Initiative and fulfill the President’s pledge to cease payments to United Nations’ (UN) climate change programs by eliminating U.S. funding related to the Green Climate Fund. . .” Some strategies from the current and previous administrations that affect State, USAID, and DOD, among other agencies, reflect a shift in priorities related to climate change. For example, the previous administration cited climate change as a “top strategic risk” in its 2015 National Security Strategy and stated that climate change is an urgent and growing threat to U.S. national security, contributing to increased natural disasters, refugee flows, and conflicts over basic resources like food and water. The current administration does not discuss climate change in its 2017 National Security Strategy. Additionally, State and USAID have a Joint Strategic Plan to help the agencies achieve the objectives of the National Security Strategy. The previous State-USAID Joint Strategic Plan included a strategic goal on “promoting the transition to a low-emission, climate-resilient world” that proposed leading international actions to combat climate change. The current State-USAID Joint Strategic Plan does not have a climate change goal. State, USAID, and DOD were required by executive orders to assess climate change-related risks to their missions and, for State and USAID, to their strategies, among other things. In response to Executive Order 13653, which has since been revoked, the agencies completed adaptation plans that integrated considerations of climate change into agency operations and overall mission objectives. In response to Executive Order 13677, which has not been revoked, State and USAID developed processes for climate change risk assessments for their country and regional planning documents. Although these executive orders did not require a specific assessment of climate change as a driver of migration, all three agencies have discussed the effects of climate change on migration in their adaptation plans and risk assessments. However, State lacks clear guidance on its process for assessing climate change-related risks to its integrated country strategies. State, USAID, and DOD each completed adaptation plans in 2014 that included limited discussions of migration as one potential effect of climate change. Executive Order 13653 directed the agencies to develop or continue to develop, implement, and update comprehensive Agency Adaptation Plans that integrate consideration of climate change into agency operations and overall mission objectives. Each adaptation plan was to include, among other things, a description of how the agency would consider the need to improve climate adaptation and resilience. State. In its 2014 adaptation plan, State included a brief discussion of climate change as one of multiple factors that potentially will drive migration and impact its mission. State reported that the specific impacts of climate change on the ability of the department to promote peace and stability in regions of vital interest to the United States were unknown. For example, according to the plan, an increase in heavy precipitation events around the world could damage the electric grid and transportation and energy water infrastructure, upon which State depends, making it difficult to maintain operations and diplomatic relations. In its plan, State reported that climate change impacts may threaten international peace, civil stability, and economic growth through aggravating existing problems related to poverty and environmental degradation. Further, environmental and poverty- related issues and regional instability could stress relationships with some foreign governments. However, the plan noted that specific impacts of climate change on conflict, migration, terrorism, and complex disasters were still unknown. USAID. In its 2014 adaptation plan, USAID included a brief discussion of migration as one potential effect of climate change that could also impact security. USAID stated that the impact of climate change on its programs and operations, if left unaddressed, could compromise the agency’s ability to achieve its mission. Further, USAID’s plan referred to increased migration as a potential risk of climate change. Flooding and other extreme climate events can result in increased migration, among other impacts, that could affect existing and planned USAID programming. In particular, programs in areas like agriculture and food security, global health, water and sanitation, infrastructure, and disaster readiness and humanitarian response are vulnerable to climate change, according to USAID. In the infrastructure area, climate change may necessitate new protective measures for coastal homes and infrastructure, and in some cases even mass evacuations or permanent migration. USAID stated that climate change could further reduce or alter the distribution of already limited resources like food and water, or force temporary or permanent migration of communities. According to the plan, in areas with high risk factors for conflict, climate change stresses can aggravate tensions and contribute to conflict. DOD. In its 2014 adaptation roadmap, DOD included a brief discussion of migration as one of multiple potential effects of climate change that could impact national security. DOD referred to climate change as a threat multiplier that can aggravate other risks around the world, with migration being one effect that could increase requests for DOD to provide assistance. The roadmap stated that as climate change affects the availability of food and water, human migration, and competition for natural resources, the department’s unique capability to provide logistical, material, and security assistance on a massive scale or in rapid fashion may be called upon with increasing frequency. Furthermore, DOD stated that the impacts of climate change may cause instability in other countries by, among other things, impairing access to food and water, damaging infrastructure, uprooting and displacing large numbers of people, and compelling mass migration. These developments, according to the department, could undermine already fragile governments that are unable to respond effectively, or challenge currently stable governments, as well as increase competition and tension between countries vying for limited resources. In response to Executive Order 13677, State and USAID developed processes for climate change risk assessments for their country and regional planning documents. Though these assessments are not specific to migration, a few of the assessments identified the nexus of climate change and migration. State. State required climate change risk assessments for all new integrated country strategies drafted in 2016 or later. We reviewed 10 integrated country strategies from the two regions that were the first to implement the climate change risk assessment requirement— Africa, and East Asia and the Pacific. All 10 of the strategies included climate change risk assessments, one of which—Cambodia— identified migration as a risk for the country. The Cambodia strategy states that internal migration due to climate change hinders access to health care and the prevention of infectious diseases like malaria. We also reviewed 10 strategies from State’s functional and regional bureaus for assessments of climate-related risks, including 3 functional bureau strategies (State/PRM, State/OES, and State’s Bureau of International Organization Affairs) and 7 regional bureau strategies. All of the functional bureau strategies we reviewed identified climate change as a risk and State/PRM cited the impact of climate change on migration. Of the regional bureau strategies we reviewed, we found that one, the Bureau for East Asian and Pacific Affairs, identified climate change as a driver of migration as a challenge or risk in its region. For example, the strategy states that climate change is becoming increasingly disruptive, potentially increasing migration due to rising sea levels. None of the other six regional bureau strategies we reviewed identified the nexus of climate change and migration as a risk or challenge. However, five regional bureaus identified climate change as a risk or challenge and one identified migration as a risk or challenge. USAID. USAID also requires the integration of climate risk management into all country or regional development cooperation strategies drafted since October 1, 2015. Missions must document in a climate change appendix to the strategy any climate risks they identified and how they considered climate change in their strategy. As of August 2018, USAID had completed five country or regional development cooperation strategy updates initiated since October 1, 2015—Uganda, Tunisia, East Africa, Sri Lanka, and Zimbabwe—and all five included the required appendix. Of the five updated strategies, three—Uganda, Tunisia, and East Africa—discuss the indirect effect of climate change on migration, among other issues. For example, Uganda’s 2016-2021 country strategy states that increased frequency and duration of droughts is likely to be the most significant climate‐related change in Uganda. The strategy also notes that droughts have affected, and will continue to affect, water resources, hydroelectricity production, and agriculture, among other sectors. As agriculture, forestry, and fisheries decline in Uganda, the strategy asserts that people will migrate to urban areas, leading to the formation of slums. We also reviewed USAID’s nine regional development cooperation strategies, one of which—East Africa—had been updated since the requirement to include climate risk management. Of the other eight strategies that have yet to be updated, seven identified climate change as a challenge or risk and three identified climate change as a driver of migration as a challenge or risk. For example, the Southern Africa regional development cooperation strategy states that water scarcity, natural disasters, and other climate change related events will most likely increase migration throughout the region. Additionally, the Asia regional development cooperation strategy discusses the risks of climate change in urban areas. In Asia, the number of migrants seeking economic opportunities in urban centers is likely to increase. According to the strategy, migrants are moving into hazard-prone areas located along coastlines, flood plains, and other low-lying areas in many Asian primary and secondary cities—areas that experts predict will experience more frequent and intense storm surges, floods, and coastal erosion as a result of climate change. The requirement in Executive Order 13677 to assess climate change- related risks to agency strategies remains unchanged; however, State now lacks clear guidance on its process for assessing climate change- related risks to its integrated country strategies. Specifically, State’s 2016 guidance for developing integrated country strategies stated that all missions should assess the risk of climate change on their strategies’ goals and objectives and included reference to the climate risk screening tool—a method that missions could use to assess climate change risks. State issued new guidance to its missions in 2018, but this guidance does not include information on the process for assessing climate change-related risks to agency strategies. According to State officials, the 2018 guidance for integrated country strategies does not reference climate change risk assessments because, in September 2017, State decided that the strategies should not single out climate change risks in a separate appendix. State officials said this decision resulted, in part, from the new administration’s shift in priorities on climate change. Officials also said that this decision reflects a new approach to risk management by State and that the missions could choose to include climate change and other potential risks in the general risk discussion section of their strategies. Officials from State’s Office of U.S. Foreign Assistance Resources said that it is now up to each mission to decide whether a strategic objective may have a climate challenge. However, those missions that choose to include an assessment of climate change risks are not provided guidance on the process for doing so and there is no reference to the climate risk screening tool—or to climate change at all—in the 2018 guidance. Executive Order 13677 directed State to incorporate climate-resilience considerations into decision making by assessing climate-related risks to agency strategies, among other things. Subsequently, a State cable from September 2016 further explained that State would implement the executive order’s requirement by screening for climate risks as part of the process for drafting all new integrated country strategies. Additionally, the Standards for Internal Control in the Federal Government state that documentation is a necessary part of an effective internal control system. If management determines that a principle is not relevant, management must support that determination with documentation that includes the rationale of how, in the absence of that principle, the associated component could be designed, implemented, and operated effectively. Because State lacks clear guidance on its process for assessing climate change-related risks to its integrated country strategies, it is less likely that the current round of strategies will include the assessment of climate- related risks. It is also possible that those missions that choose to conduct climate change risk assessments will not do so in a consistent manner. Such assessments might identify climate change as a driver of migration, as at least one previous assessment did under the 2016 guidance. Thus, without clear guidance, missions may not examine climate change as a risk to their strategic objectives and could miss opportunities to improve the climate resilience of foreign assistance activities. For fiscal years 2014 through 2017, State, USAID, and DOD had some activities that could potentially address climate change as a driver of migration, although none of these activities specifically focused on the issue. For example, USAID has climate change adaptation activities, but to date migration has not been a focus of this programming. With the shift in priorities related to climate change in fiscal year 2017, agencies have reduced some of these activities. State’s offices that are focused on the issues of climate change (State/OES) and migration (State/PRM) have participated in multilateral activities related to climate change as a driver of migration and funded adaptation and other activities related to the issue. State officials said that the agency does not, however, have any activities that specifically address migration due to climate change or environmental factors. State has participated in multilateral activities related to climate change and migration. With the shift in priorities related to climate change in fiscal year 2017, the United States has disengaged from some of these multilateral activities (see table 1). In addition to State’s participation in the multilateral activities described in table 2, State has provided funding for activities related to climate change and capacity building that address natural disasters. These activities may involve efforts potentially related to migration. For example, according to State: State provided about $2 million per year, between fiscal years 2014 and 2016, to the Intergovernmental Panel on Climate Change, which analyzed the impacts of climate change on migration in its most recent assessment report. State/PRM provided about $4 million, between fiscal years 2014 through 2018, for IOM’s Migrants in Countries in Crisis Initiative, which provides guidelines to protect migrants in countries experiencing conflict or natural disasters. IOM provides training to countries on these guidelines. State/PRM officials said that this initiative is not specifically related to climate change and does not focus on specific types of disasters but does mention sudden-onset disasters. Officials also said that IOM tries to promote a climate change perspective in its trainings. State/OES provided about $78 million in adaptation funding from the Global Climate Change Initiative to eight projects during fiscal years 2014 through 2017. (See appendix III for a description of all eight projects.) State/OES officials said that these projects help countries prepare for the impacts of climate change, potentially reducing the pressure to migrate. However, to these officials’ knowledge, none of these projects directly supported activities related to migration. For example, State/OES provided a $4 million grant to the National Adaptation Plans Global Network. This network focuses on increasing the capacity of governments to identify and assess climate risks, integrate these risks in planning, develop a pipeline of projects to address these risks, identify and secure funding for projects, and track progress toward resilience targets. Adaptation activities occurred in over 35 countries. With the shift in priorities related to climate change in fiscal year 2017, State discontinued some of these efforts. For example, funding for the Global Climate Change Initiative was not included in the President’s budget request for fiscal year 2018. State/OES officials said that the agency does not plan to fund additional adaptation activities and has not requested additional funding for the activities. According to a State official, PRM had been in discussion with IOM to develop a project proposal that would have assisted the governments of Small Island Developing States in adapting their migration policies to account for challenges and opportunities associated with environmental degradation, ecosystem loss, climate change impacts, and natural disasters. State/PRM stopped further development of the proposal following the change in administrations. Additionally, according to a State official, the department made some efforts at the end of the previous administration to develop a formal position on the topic of climate change as a driver of migration. For example, State drafted an internal document to help clarify its role in responding to the humanitarian aspects of sudden-onset and slow-onset climate events. This initial work stopped under the current administration. USAID officials said that, with respect to the agency’s climate-related programming, its climate change adaptation programming was the most likely to include activities related to migration or displacement, although a broad swath of USAID development programming has the potential to build host country resilience. Officials stated that, to date, migration has not been a primary motivation for the agency’s climate-related or disaster assistance programming. However, officials said that, in a humanitarian crisis or under some economic conditions, development programming can reduce displacement or the pressure to migrate—such as by fostering greater resilience to drought or other adverse conditions—and that this is also true of climate-related programming. USAID also provides humanitarian assistance in response to natural disasters that displace people. Officials said that USAID recognizes the links between displacement and natural disasters, but that the agency does not have specific programs linking disaster assistance, migration, and climate change. USAID identified about 250 activities that received adaptation funding from the Global Climate Change Initiative during fiscal years 2014 through 2016. Our analysis of the descriptions of these activities determined that none directly mentioned any efforts specifically related to migration. Officials emphasized that the connection between climate change and migration tends to be indirect and shaped by other more immediate factors. USAID’s data on activities that received adaptation funding identified 38 beneficiary countries, as well as activities described generally as implemented at the regional or global level. For activities where USAID’s data identified a specific region, most activities were located in Africa followed by Asia and Latin America and the Caribbean. Examples of the types of activities that received adaptation funding from the Global Climate Change Initiative during fiscal years 2014 through 2016 include: The Mali Climate Change Adaptation Activity, which aims to build resilience to current climate variability and increase resilience to longer-term climate change effects. This activity is also working to strengthen the capacity of Mali’s meteorological agency to provide improved climate information as well as to incorporate climate considerations into local-level planning. The total estimated cost is about $13 million over 5 years. The activity for Climate-Resilient Ecosystems and Livelihoods, which ended in September 2018, aimed to increase Bangladesh’s resilience to natural hazards by working with community-based organizations, government ministries, and technical agencies. This activity provided technical assistance to the Government of Bangladesh and local communities to improve ecosystem conservation and resilience capacity. The total estimated cost was about $33 million in funding over 6 years. The activity for Pastoralist Areas Resilience Improvement through Market Expansion, which aims to support pastoralists in Ethiopia via expansion of markets and long-term behavior change (see fig. 3). USAID officials cited this activity as an example of adaptation efforts that indirectly address the issue of climate change as a driver of migration. The activity has three interrelated objectives: increasing household incomes, enhancing resilience, and bolstering adaptive capacity to climate change among pastoral people in Ethiopia. An evaluation of the activity found that migration is a coping strategy for dealing with climate shocks, although participants said that drought is becoming more frequent, placing a severe strain on traditional coping mechanisms, such as migration and selling cattle, and that permanent migration is not a preferred strategy. The total estimated cost is about $60 million in funding over 6 years. With the shift in priorities related to climate change, funding for USAID’s climate change adaptation activities has decreased. Missions may continue to fund their adaptation activities with discretionary funds or other earmarked, sector funding, provided the activities further the funding source’s objective, according to USAID. For example, in some cases, missions are using Water sector funding to continue some of their adaptation work. USAID also said that among the agency’s goals are to increase the resilience of USAID partner countries to recurrent crises, including climate variability and change. In addition to USAID’s climate change adaptation programming, USAID/OFDA and USAID/FFP provide emergency humanitarian assistance to people affected by sudden-onset disasters—such as hurricanes and floods—and slow-onset and extended disasters, including droughts and conflicts. Some of this assistance helps people who have been displaced by disaster. USAID officials stated that although disasters cause mainly temporary displacement, the relationship among humanitarian assistance, climate change, and migration is very complex and depends on both climatic and non-climatic factors. USAID/OFDA responded to 267 disasters from fiscal year 2014 through June 2018, according to agency data. For example, USAID/OFDA responded to the effects of Hurricane Matthew in Haiti in October 2016, as seen in figure 4, including helping temporarily displaced people. DOD assists in the U.S. government response to overseas disasters, including helping people displaced by such disasters, regardless of the cause of the disaster. These efforts are not specific to climate change as a driver of migration. For example, officials from DOD’s geographic combatant commands said that, to the extent they address climate change, migration is not a focus of those efforts and they view migration as caused by security and economic issues. Between fiscal years 2014 and 2018, Congress has appropriated to DOD between $103 and $130 million per year for Overseas Humanitarian, Disaster, and Civic Aid. Officials said that the geographic combatant commands use most of this funding for steady state humanitarian assistance related to health, education, basic infrastructure, and disaster preparedness with a smaller amount set aside for immediate disaster assistance although that varies based on emergency requirements. DOD officials said that they have not seen any changes to this funding or associated activities with the change of administrations in fiscal year 2017. DOD officials we spoke with also emphasized that USAID/OFDA is the lead agency for the U.S. government’s response to disasters overseas. USAID/OFDA formally requested DOD support on about 10 percent of the foreign disaster assistance provided by USAID/OFDA, according to USAID data for fiscal year 2014 through June 2018 and DOD officials. DOD assistance is typically provided for the largest, most complex disasters, according to agency officials. According to a July 2015 assessment conducted by the geographic combatant commands, while their activities vary, each command works with partner nations to increase their abilities to reduce the risks and effects from environmental impacts and climate-related events, including severe weather and other hazards. For example, in the report, U.S. Southern Command stated that it had requested funding to pre-position assets for when a severe storm threatens Haiti to be able to respond immediately to a potential disaster. U.S. Southern Command officials said that they work with partner nations to encourage residents experiencing extreme weather to remain where they are because it is easier to provide help to people who stay in one place. Officials from U.S. Southern Command and U.S. Africa Command also said that the major factors driving migration in their regions are security and economic issues. State, USAID, and DOD have participated in interagency forums regarding climate change, which may have addressed its effects on migration. With changes to priorities regarding climate change in fiscal year 2017, these forums have been disbanded or are not meeting. The Council on Climate Preparedness and Resilience. The Council on Climate Preparedness and Resilience, of which State, USAID, and DOD were members, was established to facilitate the integration of climate science in policies and planning of government agencies, including by promoting the development of climate change related information, data, and tools, among other things. Additionally, the council was to develop, recommend, and coordinate interagency efforts on priority federal government actions related to climate preparedness and resilience. According to State officials, the council began working with the National Security Council and other agencies to facilitate greater interagency cooperation on adaptation. In addition, a task force on the council was discussing the federal role in addressing displacement related to climate change. The council was disbanded when Executive Order 13783 revoked Executive Order 13653, which had established the council. The Working Group on Climate-Resilient International Development. The Working Group on Climate-Resilient International Development, of which State and USAID were members, was established by Executive Order 13677 and placed under the Council on Climate Preparedness and Resilience. The working group’s mission includes developing guidelines for integrating considerations of climate-change risks and climate resilience into agency strategies, plans, programs, projects, investments, and related funding decisions, among other things. Additionally, the working group was tasked with facilitating the exchange of knowledge and lessons learned in assessing climate risks to agency strategies, among other things. USAID officials said that the working group had not discussed climate change as a driver of migration. While the working group has not been formally disbanded, it has not met since at least November 2017 according to USAID. The Climate and National Security Working Group. The Climate and National Security Working Group, of which State, USAID, and DOD were members, was established by the 2016 presidential memorandum. The chairs of the working group were to coordinate the development of a strategic approach to identify, assess, and share information on current and projected climate-related impacts on national security interests and to inform the development of national security doctrine, policies, and plans, among other things. According to the memorandum, the working group was to provide a venue for enhancing the understanding of the links between climate change- related impacts and national security interests and for discussing opportunities for climate mitigation and adaptation activities to address national security issues. This working group was disbanded when Executive Order 13783 revoked the 2016 presidential memorandum, which had established the working group. State, USAID, and DOD assessments and activities have not focused specifically on the nexus of climate change and migration. State did identify migration as a risk of climate change in at least one of its climate change risk assessments for the department’s country strategies. However, State now lacks clear guidance on its process for assessing climate change-related risks to its integrated country strategies. State’s current guidance for these country strategies no longer mentions a climate change risk assessment and does not provide missions with information about the climate risk screening tool that can be used to conduct such an assessment. As such, missions are less likely to examine climate change as a risk to their strategic objectives, or to do so in a consistent manner, and thus may not have the information they would need to identify migration as a risk of climate change. By clearly documenting and providing guidance on how to assess the risk of climate change, State would ensure that the department examines the potential risks of climate change on its foreign assistance activities. We are making the following recommendation to State: The Secretary of State should ensure that the Director of the Office of U.S. Foreign Assistance Resources provides missions with guidance that clearly documents the department’s process for climate change risk assessments for integrated country strategies. (Recommendation 1) We provided a draft of this product to State, USAID, and DOD for review and comment. State provided written comments, which we have reprinted in appendix IV. In its comments, State did not oppose the recommendation and noted that the agency will update its integrated country strategy guidance by June 30, 2019 to inform missions that they have the option to include an annex on climate resilience, as well as other topics. However, State also indicated that the agency will begin working with stakeholders to consider whether to recommend that the Secretary of State ask the President to rescind Executive Order 13677: Climate- Resilient International Development. USAID also provided written comments, which we have reprinted in appendix V. In its letter, USAID provided some additional information about its programs and its proposed transformation effort. USAID and DOD provided technical comments, which we incorporated as appropriate. We are sending copies of this report to the appropriate congressional requesters, Secretary of State, the Administrator of USAID, and the Secretary of Defense. In addition, the report is available at no charge on the GAO website at http://www.gao.gov. If you or your staff have any questions about this report, please contact David Gootnick at (202) 512-3149 or gootnickd@gao.gov, or Brian J. Lepore at (202) 512-4523 or leporeb@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix VI. This report (1) describes executive branch actions related to climate change and migration from fiscal years 2014 through 2018; (2) examines the extent to which the Department of State (State), the U.S. Agency for International Development (USAID), and the Department of Defense (DOD) have discussed the potential effects of climate change on migration in their plans and risk assessments; and (3) describes State, USAID, and DOD activities, if any, that are related to climate change and global migration. We chose fiscal years 2014 through 2018 as our time frame based on our review of recent executive orders related to climate change. We selected State, USAID, and DOD because the agencies’ missions of diplomacy, development, and defense provide the foundation for promoting and protecting U.S. interests abroad. To describe executive branch actions related to climate change and migration from fiscal years 2014 through 2018, we reviewed documents that reflect priorities of the previous and current administrations. Specifically, we reviewed budget requests and enacted appropriations between fiscal years 2014 through 2018 for funding priorities related to climate change and U.S. foreign assistance. In addition, we reviewed executive actions and executive branch strategies that applied to State, USAID, and DOD between fiscal years 2014 through 2018 for executive and national security priorities related to climate change. For example, we reviewed the current and previous national security strategies. strategies and seven regional bureau strategies. For USAID, we examined the five country and regional strategies that were required to include a climate risk assessment at the time of our review: Uganda, Tunisia, East Africa, Sri Lanka, and Zimbabwe. We also reviewed all nine USAID regional strategies. For both State and USAID, we reviewed the selected strategies by searching for information related to migration and climate change. To determine whether State clearly documents the department’s current climate risk assessment process for integrated country strategies, we compared State’s 2018 guidance for developing integrated country strategies with standards related to documentation in Standards for Internal Control in the Federal Government and previous State guidance issued in 2016, which was created in response to Executive Order 13677’s requirements to assess climate change risks to strategies, among other things. to these issues. The agency then provided us with data for about 250 activities from its annual operational plans for fiscal years 2014 through 2016, the 3 years during the period we reviewed in which it received adaptation funding. USAID identified these activities based on whether the agency had tagged them in its plans as having an “adaptation key issue.” USAID excluded projects that had planned attributions to the adaptation key issue of less than $250,000 in a given fiscal year, as well as certain other activities such as those that focused on project support. We then conducted an automated review of the activity description fields provided by USAID for terms related to migration and other descriptive information such as locations of activities. Because no USAID adaptation activities specifically mentioned migration, for the purposes of this report we chose illustrative examples to provide context for the types of activities the agency has funded. DOD officials we met with did not identify any specific activities related to climate change as a driver of migration. DOD officials from the Assistant Secretary of Defense for Special Operations and Low Intensity Conflict and the geographic combatant commands generally discussed DOD activities related to humanitarian assistance and disaster response as most relevant to our inquiry. Because DOD works in coordination with USAID’s Office of U.S. Foreign Disaster Assistance on disaster assistance we also reviewed USAID data on its disaster response activities during this period. We determined that the USAID and State adaptation project data and USAID disaster assistance data were sufficiently reliable for the purposes of describing these efforts. State, USAID, and DOD to obtain information on whether changes in government priorities related to climate change affected their activities. We conducted this performance audit from October 2017 to January 2019 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. This appendix provides a review by region of observed and projected climate change effects, migration trends, and challenges in stability and security. Multiple sources we used for this overview make a connection between climate change and such events as rising sea levels, higher temperatures, and an increase in the number and severity of extreme weather events. The following regions are discussed: Asia, South America, the Arctic, Sub-Saharan Africa, the Middle East and North Africa, Oceania, and Central America and the Caribbean. We have provided an overview for each region and a focus on one country or territory in the region. international and regional organizations, including a variety of organizations within the United Nations, the World Bank, regional development banks, the European Union, and others. Third, we reviewed relevant public documents from U.S. government agencies, including the Department of Defense, the U.S. Agency for International Development (USAID), and the United States Institute of Peace (USIP). Fourth, we reviewed academic sources, research institutions, and documents from the relevant country’s national government. population. Economic conditions may be a factor for people deciding whether to migrate or stay in their country of origin. Remittances as Percent of GDP: The money international migrants transfer to recipients in their country of origin, expressed as a percentage of the origin country’s GDP. Sources agree that remittances support resilience in origin countries. Agriculture, Fishing, Forestry as Percent of GDP: A measure of the value added to an economy from the agricultural sector, which includes forestry, hunting, fishing, and the cultivation of crops and livestock, expressed as a percentage of the country’s GDP. Countries that depend on the agricultural sector may be vulnerable to the effects of climate change, according to the World Bank. Percent of Population in Cities: The population living in areas classified as urban according to criteria each country uses. Today, more than half of the global population lives in cities. Migration, in some cases due to climate change, is an important driver of urban growth, according to IOM. Cities are also expected to face increasing risks from rising sea levels, flooding, storms, and other climate change effects. Net Migration Rate: A measure of the number of people leaving a country compared to the number of people entering a country, expressed as a number per 1,000 people. The effects of climate change in Asia may impact migration and stability according to the Intergovernmental Panel on Climate Change (IPCC) and the Asian Development Bank (ADB). In coastal areas, effects of climate change include rising sea levels, storm surges, and others. Receding glaciers in mountanous areas may also cause flooding, and monsoons in a warmer climate may be more severe. Heat extremes and more rainfall are a particular concern in Southeast Asia. Changes in precipitation and drought in Asia may exacerbate food security challenges, and contribute to people deciding to migrate. Increases in migration, partly stemming from the effects of climate change in surrounding rural areas, may put pressure on existing urban infrastructure. Rural migrants may settle in informal communities on the outskirts of cities, areas that have little resilience to natural disasters. Although the World Bank and others agree that climate change largely causes internal migration, some evidence shows that the impact of climate change contributes to cross-border migration in Asia. Large numbers of migrants, along with other destabilizing factors, may contribute to instability and conflict, according to the IPCC. The effects of climate change on livelihoods, for example, could increase migration, strain governance, and contribute to conflict as a result. Bangladesh is one example where decreased yields from agriculture and fisheries have contributed to migration to the country’s coastal cities, which face their own climate change challenges. Bangladesh’s high population density and geography make the country susceptible to the effects of climate change, according to the World Bank, and others. Bangladesh’s coasts and river banks are vulnerable to sudden-onset events such as tropical cyclones and flooding. Cyclone Aila in 2009, for example, caused widespread flooding in the southern coastal areas of Bangladesh and impacted millions of people. The storm washed away embankments that protected coastlines and caused severe damage to crops and livelihoods. Tropical Cyclone Mora in 2017 damaged thousands of homes and displaced an estimated 200,000 people. Increases in the number and intensity of tropical cyclones, which some predict will occur in a warmer climate, could have severe impacts on homes, livelihoods, and food security. Bangladesh also experiences many slow-onset climate change events, such as rising sea levels and increasingly severe droughts, which are projected to intensify with climate change. Bangladesh would lose an estimated 17.5 percent of its land if the sea level rose 1 meter, as the International Organization for Migration (IOM) has reported. Projected changes in precipitation levels could cause drought and food insecurity in the northwest and salt-water intrusion could reduce crop yields in the southwest. Migration is a common adaptation strategy to climate change in Bangladesh, according to the ADB. For example, some farmers have adapted to salt water intrusion and destroyed crops by switching to salt- tolerant rice production or shrimp cultivation. Others have migrated, often to Bangladesh’s cities to find work less dependent on agriculture. Many new migrants to Bangladesh’s cities live in informal settlements that lack the resilience to withstand sudden-onset climate events. The capital city, Dhaka, is a common destination for migrants displaced by salt-water intrusion, flooding, and river erosion, according to IOM. Dhaka, like many coastal cities in South Asia, is located on a low-lying riverbank and faces increasing risks of extreme flooding. For example, past floods in Dhaka have destroyed homes and contaminated drinking water, creating significant health hazards. In some cases, individuals migrate to cities temporarily for work and return home after the agricultural off season ends. Bangladeshis also provide a significant number of labor migrants to the Gulf States and Malaysia. Remittances from international migrants represent 5.4 percent of the country’s GDP, and may help to support resilience to climate change, according to IOM, and others. These migration trends may intensify in the future. One study estimates 9.6 million people will migrate from 2011 to 2050 due to the effects of climate change. Challenges in Stability and Security Migration due to climate change is cited as a potential destabilizing factor in Bangladesh by ADB, and others. The low-income population in Bangladesh is dependent on agriculture, making the effects of climate change—including impacts on food security—a particular concern. By 2030, these effects on livelihoods and food security could increase the poverty rate in Bangladesh by 15 percent, as the IPCC has reported. Given the proximity of Bangladesh to India, some individuals may also choose to cross the border. Increased migration to India is a potential concern, according to some sources, as India may not have the resources to absorb large numbers of Bangladeshi migrants. The CNA Corporation, National Security and the Threat of Climate Change (Alexandria, VA: 2007); and Population Council, “Effects of Future Climate Change on Cross-Border Migration in North Africa and India,” Population and Development Review, Vol. 36, No. 2 (2010). The effects of climate change in South America vary by region, according to the the Intergovernmental Panel on Climate Change (IPCC) and International Organization for Migration (IOM), as well as potentially impacting migration and stability. On the coast, risks include sea level rise, depletion of fisheries, and coral reef bleaching, according to IOM. Coastal cities with growing populations are particularly vulnerable. Melting glaciers in the Andean mountain region, and increased rainfall are expected to change the distribution of water resources, and impact food production as global demand for food is growing. Desertification and land degradation, complicated by the effects of climate change, are contributing to migration from rural areas to cities in South America, as IOM has reported. An estimated 77 percent of people living in high risk areas in South America are located in cities, according to IOM. IOM predicts that as these people feel the effects of sea level rise and water scarcity, they will migrate from the large coastal cities to smaller urban areas. While South America has experienced economic growth in the last decade, poverty rates remain high, and the effects of climate change, including possible migration, may exacerbate inequalities, putting further pressure on cities to meet the needs of their populations. Water security in particular is expected to disproportionaly impact low-income communities, according to the IPCC. For example, in Brazil, drought in the northeast may increase migration to southern cities that are facing rising sea levels and landslides, with consequences for food, water, and energy security. Observed and Projected Effects of Climate Change Brazil’s cities and rural regions may encounter a range of climate change effects, according to the IPCC and IOM. Rural areas, particularly in the northeast, could experience significant impacts from climate change partly due to poverty rates, and historical vulnerability to drought. Higher temperatures are expected to affect crop yields and household incomes, especially for low-income communities. In northeastern Brazil, temperatures are expected to increase and rainfall to decrease. The northeast could see a 22 percent reduction in precipitation by 2100, according to IPCC projections. Brazil’s coastal areas, including cities, are also vulnerable to rising sea levels, heavy precipitation, flooding, and landslides. The vast majority of Brazil’s population, about 86 percent, lives in cities, many in coastal areas, according to the United Nations Development Program. As their populations have grown, urban areas have extended out. This urban growth in Brazil’s megacities has caused further increases in temperature, rainfall, and landslides. For example, current levels of urbanization in the metropolitan area of Sao Paulo may already be responsible for the 2°C warming observed in the city over the last 50 years, as well as the rise in extreme rainfall, according to the IPCC. The metropolitan area is expected to extend its area 38 percent by 2030. Multiple studies of the effects of urbanization on Sao Paulo’s climate suggest higher temperatures affect convective rainfall, which occurs when warm air rises, condenses to form clouds, and produces extreme rain. Other concerns are the depletion of coral reefs and mangrove forests on Brazil’s coastlines, and decreases in biodiversity. Migration from drought in northeastern Brazil to cities has increased urban populations, putting more people at risk of displacement from flooding and landslides. Migration from the northeast is a historical trend in Brazil, as economic migrants have sought seasonal jobs in more productive agricultural regions, or moved permanently to southern cities. Projected declines in rainfall have led some to predict further increases in migration in northeastern Brazil, as the IPCC has reported. However, remittances from family members who leave Brazil’s northeast support resilience for those who remain and may help to reduce migration. Already environmental factors contribute to migration to cities, including to favelas, informal settlements often constructed in hilly areas and floodplains outside of Brazilian cities. A significant number of the favela residents in Rio de Janeiro are migrants from northeastern Brazil, according to IOM. These new migrants may be at risk of further displacement if heavy rainfall, flooding, and other climate change effects destroy their vulnerable homes. For example, heavy rainfall in April 2010 resulted in landslides across Rio de Janeiro, displacing an estimated 5,000 people, according to a report from the World Bank. Brazil is also a destination for migrants from other countries in the region. Migrants from Venezuela searching for jobs and improved food security have come in growing numbers in recent years, as have migrants from Haiti fleeing a series of natural disasters, as IOM has reported. Challenges in Stability and Security Although Brazil ranks 106th out of 178 countries on the Fragile States Index, the effects of climate change may contribute to challenges with water, food, and energy access according to the IPCC. Decreased rainfall could decrease agricultural productivity, with potential health impacts for poor populations. These conditions are of particular concern in northeastern Brazil, as extreme weather and low crop yields are associated with more violence, according to the IPCC. Brazil also receives about 70 percent of its electricity from hydroelectric power, according the United Nations Environment Programme, and recent droughts caused power cuts across many major cities. Although not linked to the effects of climate change, absorbing a growing number of migrants fleeing political and economic instability in Venezuela may impact the broader region, according to the U.S. Department of Defense and the National Intelligence Council. Neighboring countries, including Brazil, may struggle to absorb the influx of migrants. On average, 800 Venezuelans are crossing the border to Brazil every day in need of urgent humanitarian assistance, according to the UNHCR, the UN Refugee Agency. The effects of climate change in the Arctic, including higher temperatures and melting ice, have contributed to shifts in migration across the Arctic, and may have security implications. Increasing temperatures may have a variety of impacts in the Arctic, according to the Intergovernmental Panel on Climate Change (IPCC). The effects of rising temperatures are disrupting livelihoods and food security, especially for indigenous communities, and opening up untapped natural resources to extraction. Both trends have impacted migration flows in the Arctic. Rising temperatures and melting ice have opened up previously inaccessible waterways in the Arctic, with implications for national security, according to the Department of Defense and others. Greenland, located in the Arctic and considered part of Kingdom of Denmark, exhibits many of these trends. Greenland is experiencing the effects of climate change, including glacial and ice melt, shifts in wildlife distribution, and newly available oil and mineral deposits, among others. The Greenland Ice Sheet covers approximately 80 percent of Greenland’s land mass. The ice sheet’s melting rate is slow, but uncertain. Increases in temperature greater than 1°C may result in the near loss of the entire ice sheet over a millennium and significant sea level rise, according to the IPCC. In the short term, predicting the ice sheet’s melting rate is a challenge as predictions vary in the scientific community. Accurate predictions would support mitigation and adaptation efforts in vulnerable areas. Rising temperatures and shrinking ice cover have shifted the distribution and migration patterns of marine mammals and fish, and impacted food security according to the IPCC and the Arctic Council, an intergovernmental forum for Arctic states. For example, the economy in Paamiut, Greenland, depended primarily on cod fisheries until changing climate conditions caused cod to disappear, and the town was slow to adapt to newly available shrimp. Similarly, fisheries in Disko Bay, Greenland, have struggled to adapt to new conditions. Rising temperatures and the resulting reduction in ice cover have required a shift to fishing from boats in open water instead of hunting and fishing over ice cover. Lastly, warming and ice melt may make significant oil and mineral deposits accessible for extraction in the future. The potential expansion of extraction industries makes environmental sustainability another possible concern. For example, an estimated 31 billion barrels of oil and gas may exist off the coast of Northeast Greenland, according to the Kingdom of Denmark’s 2011-2020 Arctic Strategy. The strategy stresses the importance of assessing and reducing risks to the environment resulting from the exploration and extraction of oil and gas. The effects of climate change are predicted to contribute to internal and external migration in Greenland. For example, young people are increasingly leaving indigenous communities in rural areas for cities in Greenland in search of work, as traditional livelihoods become unsustainable. Greenland is home to a majority indigenous population, primarily Inuit, whose traditional hunting and fishing practices require travel across ice. In the past, people adapted to seasonal changes to support livelihoods by migrating, and the practice was embedded into indigenous social structures. With reduced ice cover, however, migrating to hunt, fish, and maintain connections to community is more dangerous or restricted. Government policies promoting centralized services, such as health care and education, have also played a role in the shift away from migration as a way of life. As a result, indigenous livelihoods are more difficult to maintain, and young people often migrate to towns and cities in Greenland, or to Denmark, for education. At the same time, warmer temperatures have made mineral extraction feasible. As the extraction industry grows, new jobs may draw migrants from outside the Arctic region. In 2011 companies spent $100 million on the exploration of minerals in the Artic, and the estimated number of new mines is expected to require more workers than now live in the region.17 79Currently, more people leave than migrate to Greenland. The local Inuit population in Uummannaq, Greenland relies heavily on ice coverage for fishing and travel by traditional dog-sled. Brookings-LSE Project on Internal Displacement, A Complex Constellation: Displacement, Climate Change and Arctic Peoples (January 30, 2013). Brookings-LSE Project on Internal Displacement. The effects of climate change on Sub-Saharan Africa vary depending on the region and have impacts on migration and security, according to the International Organization for Migration (IOM). Coastal areas, for example, in West and East Africa are at risk from sea level rise that could affect major cities. Drought and the risk of desertification in the Sahel is cited as a concern, as is increased rainfall in parts of Central Africa accompanied by lower agricultural yields. As desertification threatens the livelihoods of farmers and herders, and drought makes fishing more challenging, rural dwellers may be more likely to migrate to cities, according to the United Nations Environment Programme (UNEP). Urbanization and population growth across Sub-Saharan Africa is already making densely populated cities vulnerable to flooding, storms, and erosion, increasing the number of people at risk of displacement by sudden-onset disasters. Climate change effects and changing migration flows across Sub-Saharan Africa may impact access to natural resources and contribute to existing tensions and conflicts, according to UNEP and the Intergovernmental Panel on Climate Change (IPCC). In Nigeria, the effects of climate change may effect a variety of livelihoods and increase migration south, while also exacerbating existing conflicts. The effects of climate change on Nigeria may impact the country’s agriculture and economy, according to the United States Institute of Peace (USIP). Higher temperatures and decreased rainfall have contributed to drought in northern Nigeria. Desertification is also a concern. Some regions in northern Nigeria have less than 10 inches of rain a year, an amount that has decreased by 25 percent since the 1980’s, according to USIP. In other areas across Nigeria flooding has resulted in major crop losses, according to UNEP. Rising sea level, water inundation, and erosion are concerns in Nigeria’s coastal areas. Rising sea level is predicted to pose medium to very high risks to Africa’s coastal areas by 2100, according to the IPCC. Future sea level rise could result in the inundation of over 70 percent of the Nigerian coast. A rise of 0.2 meters in sea level could risk billions of dollars in assets, including oil wells near the coast. Even without a rapid rise in sea level, Nigeria’s coastal areas could experience erosion and significant land loss by 2100, as the IPCC has reported. The effects of climate change on livelihoods in northern Nigeria may contribute to migration to the south according to UNEP, while conflict in the north drives separate migration trends. As the effects of climate change make farming and fishing more challenging elsewhere in Nigeria, migration to southern coastal cities may increase. Traditionally, farmers, herders, and fishery workers migrated for temporary employment during the off season, including migration to Nigeria’s cities to work in the oil industry. Permanent migration south as well as to cities may become more common if land suitable for farming decreases. As fish habitats like Lake Chad dry up, fishery workers may also migrate. Larger urban populations on the coast will put more people at risk of sea level rise, water inundation, and erosion, according to the IPCC. A rise in sea level of 1 meter could put over 3 million people at risk of displacement as the IPCC has reported. Herders have also moved further south due to increased drought in northern Nigeria, as UNEP and USIP have reported. A 2010 survey of herdsmen in Nigeria, for example, found that nearly one-third of them had migrated southeast as a result of changes in the natural environment, according to the UNEP. The ongoing conflict with Boko Haram, while not caused by climate change, has further resulted in millions of displaced people across the Lake Chad region, including many Nigerians who have fled to Cameroon, Chad, and Niger. Nigerian refugees at the Minawao camp in Cameroon. Challenges in Stability and Security The effects of climate change, migration, and conflict are interconnected in Nigeria, as USIP has reported. The country is ranked 14th of 178 countries on the Fragile States Index. Events in northwest Africa, including Boko Haram’s attacks in Nigeria, have underscored concerns about the region’s vulnerability to the spread of violent extremism. The effects of climate change may exacerbate these concerns, according to USIP. Nigerians fleeing attacks from Boko Haram in the north have gone to communities in neighboring Chad, Cameroon, and Niger that are already experiencing food shortages due in part to climate change. These neighboring countries as a result have fewer resources to support both their own residents and the newer refugees. Non-state actors may also take advantage of government inaction on the effects of climate change. Boko Haram, for example, has justified its acts of violence by pointing to government failures, according to the USIP. Separately, increased drought in the north may aggravate historic tensions over land and water use between farmers in the south and herders migrating from the north, according to UNEP. Nigeria’s oil fields on the coast, which represent a significant part of the economy, are also at risk from sea level rise. Potential losses in oil revenue could impact Nigeria’s ability to respond to humanitarian crises and conflict at home. Increased violence within its borders could also affect Nigeria’s ability to support regional peacekeeping missions, such as the United Nations Mission in Liberia from 2003 to 2018, where Nigerian troops worked to restore security after a civil war. The effects of climate change in the Middle East and North Africa, including on its desert regions, may impact water access and compound migration and stability challenges, according to the United Nations Environmental Programme (UNEP). Over 60 percent of the population already experiences high or very high water stress, according to the World Bank. Coupled with unsustainable water use, climate change may further exacerbate challenges with water security. The region continues to experience rising temperatures and declining annual rainfall, trends that contribute to the severity and length of drought, land degradation, and desertification. Decreased water security affects the livelihood and quality of life of farmers in the region, contributing to an increase in their migration to the cities and more urbanization, according to the World Bank. In contrast, many people are expected to migrate away from coastal cities as a result of sea level rise, according to UNEP. These potential migrations would be taking place in a region that already hosts large numbers of migrants such as those displaced by conflict and violence, including 18 percent of the world’s refugees, according to the International Organization for Migration. Challenges in water security may put greater pressure on unstable governments in the region, by intensifying existing tensions and conflicts between populations and their governments as well as between countries that share sources of water. The conflict in Syria illustrates the complex nature of climate change, migration, and conflict in the region, and the challenges to accurately assessing the links among the three, as noted in a technical paper commissioned by the U.S. Agency for International Development (USAID). Rising temperatures and declining rainfall have contributed to recent droughts in Syria, a trend that may continue. The country underwent an extended drought from about 2006 until 2011. During the drought an estimated 60 percent of Syria experienced severe crop failure, and accompanying impacts on food security. Some studies have linked the length and severity of the drought in Syria to climate change, as USAID has reported. Others, however, have pointed to government land and water use policies, combined with the effects of climate change, as responsible for the severity of the drought. Agricultural policies, for example, encouraged farmers to grow water intensive crops like wheat, and supported inefficient irrigation practices, policies which further depleted ground water and made the region more vulnerable to decreases in rainfall linked to climate change. Across the Middle East, the rising temperatures and declining rainfalls of recent decades may worsen, according to the World Bank. If these trends continue, countries in the Middle East, including Syria, could continue to experience periods of severe drought and reduced crop yields. Migration Trends The ongoing conflict in Syria, in which migration due to climate change may have been a contributing factor, has caused large-scale migration to neighboring countries in the Middle East and to Europe. Leading up to the civil war, prolonged drought, among other factors, had increased migration to Syrian cities. Because of the drought, in 2009, over 800,000 Syrians lost their livelihoods in the agricultural sector, while nearly 1 million experienced food insecurity. In 2010, an estimated 200,000 people migrated from farms in rural areas to cities, according to a UN report. The conflict in Syria, which began in 2011, has further displaced large numbers of people within the country and across the Middle East, as we have previously reported.At the beginning of the conflict, Syrians, as well as Iraqi and Palestinian refugees who had been residing in Syria, fled mainly to Jordan, Lebanon, and Turkey. As the conflict persisted, refugees fled in larger numbers to Turkey, with the UNHCR reporting that nearly 1 million Syrians sought protection in that country in 2015. Starting that year, a growing number of Syrians risked dangerous sea voyages to reach countries in Europe, such as Greece, Germany, and Sweden. As of June 2017, more than 5 million registered Syrian refugees were living in neighboring countries, including more than 3 million in Turkey, and more than 1 million in Lebanon. Challenges in Stability and Security Sources agree that the Syrian conflict is a significant security challenge that has resulted in large scale migration across the Middle East and to Europe. Yet the link between prolonged drought, rural to urban migration, and the current conflict in Syria is uncertain. Some academic sources argue that the increased strain on urban infrastructure and resources due to the rural to urban migration played a role in Syria’s growing instability. Others highlight the complex nature of the Syrian conflict, pointing to broader political factors that exacerbated resource scarcity and inequality. For example, as the drought intensified, the Syrian government downplayed the severity of the humanitarian crisis, as described in research cited in a technical report commissioned by USAID.result, appeals to the international community for emergency aid received minimal support. Combined with existing sectarian divisions, ongoing revolutions across the Middle East, and other factors, the government’s response to the drought may have contributed to the current conflict. Migration and displacement are a concern in the region, according to the Department of Defense and others. The U.S. government has provided significant humanitarian assistance for Syrian refugees in the Middle East, including in Lebanon and Jordan, as we have previously reported.However, a technical report commissioned by USAID has cautioned that the ongoing conflict in Syria makes it difficult to conduct research and draw conclusions related to climate, migration and conflict. As a The effects of climate change on Oceania, particularly rising seas, may significantly impact coastal populations and increase migration in the future, as the Asian Development Bank (ADB) and the Intergovernmental Panel on Climate Change (IPCC) have reported. Rising temperatures and declining rainfall may also contribute to lower yields from fisheries and agriculture, and a significant decrease in coral reef cover. Extreme weather events, including higher temperatures, wind, and rainfall, have already increased in number and intensity across the region. In the majority of Pacific island nations, of those who migrate, more people leave than come, according to the African, Caribbean, and Pacific Observatory on Migration. The majority of migration in the region is economically driven. In the future, climate change may further impact these migration patterns across the region, according to the IPCC. Climate change has already exacerbated challenges that aid-dependent nations in the region face, restricting livelihoods and resources and contributing to pressures to migrate. The costs of climate change, including a decline in crop yields, a rise in energy demands, and a loss of coastal land, are predicted to be significant. The ADB estimates these costs will reach 12.7 percent of the Pacific regions’ GDP by 2100. Increased migration may also impact political stability and play a role in geopolitical rivalries within the region, according to the IPCC. The effects of climate change, especially rising sea levels, may result in forced migration from the Republic of the Marshall Islands (the Marshall Islands) and have additional impacts on the U.S. defense infrastructure on the islands. Observed and Projected Effects of Climate Change Rising sea levels are a grave threat to the Marshall Islands.The country consists of islands, low-lying atolls—coral caps sitting on top of submerged volcanoes—making it particularly vulnerable to rising sea levels. On average, the Marshall Islands are 2 meters above sea level. In Majuro, the country’s most populous atoll, observed rates of sea level rise are already twice as fast as the global average. Population centers experience significant flooding, with damage to roads, houses, and infrastructure, especially during La Niña years, which are significantly wetter and more prone to extreme rainfall. Flooding is expected to worsen with rising sea levels, with consequences for the availabity of drinking water. On Roi-Namur island, for example, a 0.4 meter rise in sea level combined with wave-driven flooding is predicted to make groundwater undrinkable year round as early as 2055. This salt water inundation may contaminate already limited groundwater across the Marshall Islands. Lastly, during the 1940s and 1950s, the Marshall Islands was the site of 67 U.S. nuclear weapons tests on or near Bikini and Enewetak Atolls. Projected increases in frequency of flooding may negatively impact efforts to contain radioactive material stored on Runit Island. A number of factors have increased migration from the Marshall Islands, including to the United States. In 1986, the United States entered into a compact of free association with the country that allowed its citizens to migrate to the United States, as we have previously reported. As a result, more than 20,000 Marshallese now live in the United States.People are more likely to migrate abroad as the effects of climate change on the Marshall Islands—including rising sea levels—increasingly impact livelihoods.The threat of mass displacement and forced migration is also a concern, as the International Organization for Migration has reported. However, Marshallese culture has a strong connection to the land, which means that many view migration as a last resort. For people still living in the Marshall Islands, they face overpopulation in urban centers and displacement by sudden-onset disasters like cyclones and flooding. Factors influencing people deciding to move abroad include displacement, lack of economic opportunity—sometimes exacerbated by climate change—and limited access to health care. Climate change is likely to increase risks to public health in the country.Increased rainfall, for instance, may expand mosquito breeding grounds, raising the risk of diseases like dengue fever. The country’s limited health care system may further contribute to migration from the islands. Challenges in Stability and Security In the future, the Marshall Islands may become uninhabitable. This prospect threatens the existence of the Marshall Islands as a sovereign state, as well as the United States defense facilities located on the islands. The total loss of land could result in the Marshall Islands being uninhabitable, which raises problems of migration, resettlement, cultural survival, and sovereignty. Relocation of the population of the Marshall Islands, and of other Pacific Island nations at risk of rising seas, could cause significant geopolitical challenges.The Marshall Islands are also of strategic importance for the United States. Under the Compact of Free Association, the United States has permission to use several islands— including Kwajalein Atoll, the location of the Ronald Reagan Ballistic Missile Defense Test Range—until 2066. The country’s proximity to the equator makes the Marshall Islands ideal for missile defense and space work. Yet the island’s defense infrastructure and operations are at significant risk due to rising sea levels, flooding, and diminishing supplies of potable water. As the Department of Defense has noted, climate change will have serious implications for the department’s ability to maintain its infrastructure and ensure military readiness in the future. DOD, 2014 Climate Change Adaptation Roadmap (Alexandria, VA: June 2014). The effects of climate change on Central America and the Caribbean may increase migration and exacerbate poverty rates, as the National Intelligence Council has reported. The climate in Central America and the Caribbean is predicted to be warmer and dryer. The Caribbean’s extensive coastlines and low-lying areas are vulnerable to sea level rise and an increase in sudden-onset disasters, including hurricanes and storm surges. Drought is a particular concern in Central America, where declines in rainfall have reduced crop yields and threatened livelihoods in recent years. Some evidence shows that drought in parts of Central America has contributed to migration north, including to the United States. Population growth, especially in coastal cities, has increased the number of people at risk during hurricane season, and the number and intensity of hurricanes have grown in recent years. Some attribute the increase in intensity to higher sea surface temperatures caused by climate change. However, there remains debate about long term hurricane trends. Recent hurricanes have caused displacement, and significant losses and damages—including to infrastructure—across the region. The depletion of coral reefs and mangrove trees, natural barriers to coastal erosion and flooding, has exacerbated vulnerability to storms in coastal areas. Climate change is likely to have negative impacts on tourism in the Caribbean, where the industry is an important part of the economy, according to Inter-American Development Bank. Climate change impacts on the economy may make it increasingly difficult for governments to reduce poverty and move towards environmental sustainability. Haiti’s geography, location, and high poverty rates make the country especially vulnerable. Haiti is highly vulnerable to climate change effects, partly due to its long coastline.Hurricanes routinely make landfall in the country, and increases in rainfall and wind speeds associated with hurricanes are likely. Severe hurricanes, including Hurricane Matthew in September 2016, have hit Haiti in recent years. Hurricane Matthew was the first category 4 storm in Haiti since 1964. Damage from severe flooding and severe winds during the hurricane affected over 2 million people and created significant food security and public health challenges. Significant deforestation has further exacerbated Haiti’s vulnerability to hurricanes, as trees previously provided a natural barrier to the erosion that strong winds and more rainfall can cause. Rising temperature and highly variable rainfall have led to extreme drought and flash flooding, according to the U.S. Agency for International Development (USAID).32 2 These trends decrease crop yields, affecting the livelihoods of farmers, and threaten water access. Projected increase in temperature and decreases in rainfall are likely to intensify drought in Haiti’s interior. USAID, Haiti: Environment and Climate Change Fact Sheet (January 2016). Migration Trends Slow-onset climate events, such as drought, and rising sea levels, and sudden-onset events, including earthquakes, affect Haiti, according to the International Organization for Migration (IOM). Haiti is also particularly exposed to extreme weather events, such as hurricanes, which can lead to displacement. In January 2010, a catastrophic earthquake in Haiti killed an estimated 230,000 people and left close to 1.5 million people homeless. According to IOM, the recurrence of environmental disruptions increases risks and vulnerabilities. When Hurricane Sandy struck Haiti in October 2012, the country had still not recovered from the 2010 earthquake. The worsening of climate change effects around the world, particularly in low-income countries, may increase the number of people wanting to immigrate to the United States, where approximately 700,000 Haitians live today.Remittances from family members living outside Haiti make up a significant portion of the economy, at 24.7 percent of GDP. The majority of these remittances come from the United States, as we have previously reported.34 4Remittances may support resilience to climate change effects as migrants send money home for disaster recovery and adaptation. Challenges in Stability and Security Haiti, the poorest country in the western hemisphere, has experienced political instability for most of its history, and ranks 12th of 178 on the Fragile States Index. The government has a low capacity to respond to additional challenges like those related to climate change, according to USAID. The Ministry of Environment, for example, is a relatively new organization within the Haitian government, and local and regional governments have a limited ability to enforce environmental laws and regulations. The United States has provided substantial aid to Haiti, both in disaster response and broader development projects. Official development assistance for Haiti in 2015, for instance, totaled slightly more than $1 billion. According to a January 2018 UN report, 2.8 million people were still in need of humanitarian assistance. GAO, Remittances To Fragile Countries: Treasury Should Assess Risks from Shifts to Non-Banking Channels, GAO-18-313 (Washington, D.C., March 8, 2018). The Department of State’s Bureau of Oceans and International Environmental and Scientific Affairs (State/OES) provided about $78 million in adaptation funding from the Global Climate Change Initiative for eight projects for fiscal years 2014 through 2017 (see table 2). The Global Climate Change Initiative was established in 2010 to promote resilient, low- emission development, and integrate climate change considerations into U.S. foreign assistance and was divided into three main programmatic initiatives: (1) Adaptation assistance, (2) Clean Energy assistance, and (3) Sustainable Landscapes assistance. The primary purpose of these contributions to the LDCF was to address the adaptation needs of the least developed countries, which are especially vulnerable to the adverse impacts of climate change. The LDCF financed the preparation and implementation of National Adaptation Programs of Action, which identify a country’s priorities for adaptation actions. Initial grant to the National Adaptation Plans Global Network. The network is focused on increasing the capacity of national and subnational governments to identify and assess climate risks, integrate these risk considerations in sector planning, develop a pipeline of projects to address risks, identify and secure funding for projects, and track progress toward resilience targets. Colombia, East Caribbean (Guyana, Saint Lucia, Saint Vincent and the Grenadines), Ethiopia, Peru, South Africa, Uganda, West Africa (Côte d’Ivoire, Ghana, Guinea, Sierra Leone, Togo) and, under current consideration, East Caribbean (Dominica, Suriname), and Pacific (Fiji, Kiribati, Tuvalu) The cost amendment intensified the technical support on National Adaptation Plans to select countries dependent upon specific country adaption needs. In addition, the cost amendment continued the learning and progress from the initial grant. Implemented through the Department of Treasury, this funding supported a Treasury grant to the Pacific Catastrophe Risk Assessment and Financing Initiative Multi Donor Trust Fund at the World Bank. This activity established the Pacific Catastrophe Risk Insurance Foundation and the Pacific Catastrophe Risk Insurance Company, among other things. The goal of PIER is to increase private sector investment in resilience to climate change in eight developing countries. The first phase of the project will assess and identify opportunities for private investment in resilience, as well as build public and private capacity for climate risk assessment in all the countries. In the second phase, public and private sector partners will develop and pilot climate risk-reduction investment models in four of the countries. The third phase will publicize the piloted investment models and lessons learned among the eight countries. Implemented through the National Oceanic and Atmospheric Administration, this activity aims to implement a capacity-building partnership with India to promote effective climate resilient decision making at national, state, and local levels. In addition to the contacts named above, the following individuals made key contributions to this report: Miriam Carroll Fenton (Assistant Director), Kristy Williams (Assistant Director), Rachel Girshick (Analyst-in-Charge), Nancy Santucci, Miranda Cohen, Aldo Salerno, Neil Doherty, and Judith Williams. Alexander Welsh, Justin Fisher, and Joseph Thompson provided technical and other support. Climate Change Adaptation: DOD Needs to Better Incorporate Adaptation into Planning and Collaboration at Overseas Installations. GAO-18-206. Washington, D.C.: November 13, 2017. Compacts Of Free Association: Actions Needed to Prepare for The Transition of Micronesia and the Marshall Islands to Trust Fund Income. GAO-18-415. Washington, D.C.: May 17, 2018. Remittances to Fragile Countries: Treasury Should Assess Risks from Shifts to Non-Banking Channels. GAO-18-313. Washington, D.C.: March 8, 2018. Syrian Refugees: U.S. Agencies Conduct Financial Oversight Activities for Humanitarian Assistance but Should Strengthen Monitoring. GAO-18-58. Washington, D.C.: October 31, 2017. International Food Assistance: Agencies Should Ensure Timely Documentation of Required Market Analyses and Assess Local Markets for Program Effects. GAO-17-640. Washington, D.C.: July 13, 2017. High-Risk Series: Progress on Many High-Risk Areas, While Substantial Efforts Needed on Others. GAO-17-317. Washington, D.C.: February 15, 2017. Federal Disaster Assistance: Federal Departments and Agencies Obligated at Least $277.6 Billion during Fiscal Years 2005 through 2014. GAO-16-797. Washington, D.C.: September 22, 2016. Coast Guard: Arctic Strategy Is Underway, but Agency Could Better Assess How Its Actions Mitigate Known Arctic Capability Gaps. GAO-16-453. Washington, D.C.: July 12, 2016. Climate Information: A National System Could Help Federal, State, Local, and Private Sector Decision Makers Use Climate Information. GAO-16-37. Washington, D.C.: November 23, 2015. Hurricane Sandy: An Investment Strategy Could Help the Federal Government Enhance National Resilience for Future Disasters. GAO-15-515. Washington, D.C.: July 30, 2015. High-Risk Series: An Update. GAO-15-290. Washington, D.C.: February 11, 2015. Standards for Internal Control in the Federal Government. GAO-14-704G. Washington, D.C.: September 10, 2014. Combating Terrorism: U.S. Efforts in Northwest Africa Would Be Strengthened by Enhanced Program Management. GAO-14-518. Washington, D.C.: June 24, 2014. Climate Change Adaptation: DOD Can Improve Infrastructure Planning and Processes to Better Account for Potential Impacts. GAO-14-446. Washington, D.C.: May 30, 2014. Extreme Weather Events: Limiting Federal Fiscal Exposure and Increasing the Nation’s Resilience. GAO-14-364T. Washington, D.C.: February 12, 2014. Climate Change: State Should Further Improve Its Reporting on Financial Support to Developing Countries to Meet Future Requirements and Guidelines. GAO-13-829. Washington, D.C.: September 19, 2013. High-Risk Series: An Update. GAO-13-283. Washington, D.C.: February 14, 2013. International Climate Change Assessments: Federal Agencies Should Improve Reporting and Oversight of U.S. Funding. GAO-12-43. Washington, D.C.: November 17, 2011. Climate Change Adaptation: Federal Efforts to Provide Information Could Help Government Decision Making. GAO-12-238T. Washington, D.C.: November 16, 2011. Foreign Relation: Kwajalein Atoll Is the Key U.S. Defense Interest in Two Micronesian Nations, GAO-02-119. Washington D.C.: January 22, 2002.
The issue of executive discretion has been at the center of constitutional debates in liberal democracies throughout the twentieth century. How to balance a commitment to the rule of law with the exigencies of modern political and economic crises has engaged legislators and scholars in the United States and around the world. The United States Constitution is silent on questions of emergency power. As such, over the past two centuries, Congress and the President have answered those questions in varied and often ad hoc ways. In the eighteenth and nineteenth centuries, the answer was often for the President to act without congressional approval in a time of crisis, knowingly risking impeachment and personal civil liability. Congress claimed primacy over emergency action and would decide subsequently to either ratify the President's actions or indemnify the President for any civil liability. By the twentieth century, a new pattern had begun to emerge. Instead of retroactively judging an executive's extraordinary actions in a time of emergency, Congress created statutory bases permitting the President to declare a state of emergency and make use of extraordinary delegated powers. The expanding delegation of emergency powers to the executive and the increase of governing via emergency power by the executive has been a common trajectory among twentieth-century liberal democracies. As innovation has quickened the pace of social change and global crises, some legislatures have felt compelled to delegate to the executive, who traditional political theorists assumed could operate with greater "dispatch" than deliberate, future-oriented legislatures. Whether such actions subvert the rule of law or are a standard feature of healthy modern constitutional orders has been a subject of extensive debate. The International Emergency Economic Powers Act (IEEPA) is one such example of a twentieth-century delegation of emergency authority. One of 123 emergency statutes under the umbrella of the National Emergencies Act (NEA), IEEPA grants the President extensive power to regulate a variety of economic transactions during a state of emergency. Congress enacted IEEPA in 1977 to rein in the expansive emergency economic powers that it had been delegated to the President under the Trading with the Enemy Act (TWEA). Nevertheless, some scholars argue that judicial and legislative actions subsequent to IEEPA's enactment have made it, like TWEA, a source of expansive and unchecked executive authority in the economic realm. Others, however, argue that Presidents often use IEEPA to implement the will of Congress either as directed by law or as encouraged by congressional activity. Until recently, there has been little congressional discussion of modifying either IEEPA or its umbrella statute, the NEA. Recent presidential actions, however, have drawn attention to presidential emergency powers under the NEA of which IEEPA is the most frequently used. Should Congress consider changing IEEPA, there are two issues that Congress may wish to address. The first pertains to how Congress has delegated its authority under IEEPA and its umbrella statute, the NEA. The second pertains to choices made in the Export Control Reform Act of 2018. The First World War (1914-1918) saw an unprecedented degree of economic mobilization. The executive departments of European governments began to regulate their economies with or without the support of their legislatures. The United States, in contrast, was in a privileged position relative to its allies in Europe. Separated by an ocean from Germany and Austria-Hungary, the United States was never under substantial threat of invasion. Rather than relying on the inherent powers of the presidency, or acting unconstitutionally and waiting for congressional ratification, President Wilson sought explicit pre-authorization for expansive new powers to meet the global crisis. Between 1916 and the end of 1917, Congress passed 22 statutes empowering the President to take control of private property for public use during the war. These statutes gave the President broad authority to control railroads, shipyards, cars, telegraph and telephone systems, water systems, and many other sectors of the American economy. TWEA was one of those 22 statutes. It granted to the executive an extraordinary degree of control over international trade, investment, migration, and communications between the United States and its enemies. TWEA defined "enemy" broadly and included "any individual, partnership, or other body of individuals [including corporations], of any nationality, resident within the territory ... of any nation with which the United States is at war, or resident outside of the United States and doing business within such a territory ...." The first four sections of the act granted the President extensive powers to limit trading or communication with, or transporting enemies (or their allies) of the United States. These sections also empowered the President to censor foreign communications and place extensive restrictions on enemy insurance or reinsurance companies. It was Section 5(b) of TWEA, however, that would form one of the central bases of presidential emergency economic power in the twentieth century. Section 5(b), as originally enacted, states: That the President may investigate, regulate, or prohibit, under such rules and regulations as he may prescribe, by means of licenses or otherwise, any transactions in foreign exchange, export or earmarkings of gold or silver coin or bullion or currency, transfers of credit in any form (other than credits relating solely to transactions to be executed wholly within the United States), and transfers of evidences of indebtedness or of the ownership of property between the United States and any foreign country, whether enemy, ally of enemy or otherwise, or between residents of one or more foreign countries, by any person within the United States; and he may require any such person engaged in any such transaction to furnish, under oath, complete information relative thereto, including the production of any books of account, contracts, letters or other papers, in connection therewith in the custody or control of such person, either before or after such transaction is completed. The statute gave the President exceptional control over private international economic transactions in times of war. While Congress terminated many of the war powers in 1921, TWEA was specifically exempted because the U.S. Government had yet to dispose of a large amount of alien property in its custody. The Great Depression, a massive global economic downturn that began in 1929, presented a challenge to liberal democracies in Europe and the Americas. To deal with the complexities presented by the crisis, nearly all such democracies began delegating discretionary authority to their executives to a degree that had only previously been done in times of war. The U.S. Congress responded, in part, by dramatically expanding the scope of TWEA, delegating to the President the power to declare states of emergency in peacetime and assume expansive domestic economic powers. Such a delegation was made possible by analogizing economic crises to war. In public speeches about the crisis, President Franklin D. Roosevelt asserted that the Depression was to be "attacked," "fought against," "mobilized for," and "combatted" by "great arm[ies] of people." The economic mobilization of the First World War had blurred the lines between the executive's military and economic powers. As the Depression was likened to "armed strife" and declared to be "an emergency more serious than war" by a Justice of the Supreme Court, it became routine to use emergency economic legislation enacted in wartime as the basis for extraordinary economic authority in peacetime. As the Depression entered its third year, the newly-elected President Roosevelt sought from Congress "broad Executive power to wage a war against the emergency, as great as the power that would be given to me if we were in fact invaded by a foreign foe." In his first act as President, Roosevelt proclaimed a bank holiday, suspending all transactions at all banking institutions located in the United States and its territories for four days. In his proclamation, Roosevelt claimed to have authority to declare the holiday under Section 5(b) of TWEA. However, because the United States was not in a state of war and the suspended transactions were primarily domestic, the President's authority to issue such an order was dubious. Despite the tenuous legality, Congress ratified Roosevelt's actions by passing the Emergency Banking Relief Act three days after his proclamation. The act amended Section 5(b) of TWEA to read: During time of war or during any other period of national emergency declared by the President , the President may, through any agency that he may designate, or otherwise, investigate, regulate, or prohibit.... This amendment gave the President the authority to declare that a national emergency existed and assume extensive controls over the national economy previously only available in times of war. By 1934, Roosevelt had used these extensive new powers to regulate "Every transaction in foreign exchange, transfer of credit between any banking institution within the United States and any banking institution outside of the United States." With America's entry into the Second World War in 1941, Congress again amended TWEA to grant the President extensive powers over the disposition of private property, adding the so-called "vesting" power, which authorized the permanent seizure of property. Now in its most expansive form, TWEA authorized the President to declare a national emergency and, in so doing, to regulate foreign exchange, domestic banking, possession of precious metals, and property in which any foreign country or foreign national had an interest. The Second World War ended in 1945. Following the conflict, the allied powers constructed institutions and signed agreements designed to keep the peace and to liberalize world trade. However, the United States did not immediately resume a peacetime posture with respect to emergency powers. Instead, the onset of the Cold War rationalized the continued use of TWEA and other emergency powers outside the context of a declared war. Over the next several decades, Presidents declared four national emergencies under Section 5(b) of TWEA and assumed expansive authority over economic transactions in the postwar period. During the Cold War, economic sanctions became an increasingly popular foreign policy and national security tool, and TWEA was a prominent source of presidential authority to use the tool. In 1950, President Harry S. Truman declared a national emergency, citing TWEA, to impose economic sanctions on North Korea and China. Subsequent Presidents referenced that national emergency as authority for imposing sanctions on Vietnam, Cuba, and Cambodia. Truman likewise used Section 5(b) of TWEA to maintain regulations on foreign exchange, transfers of credit, and the export of coin and currency that had been in place since the early 1930s. Presidents Richard M. Nixon and Gerald R. Ford invoked TWEA to continue export controls established under the Export Administration Act when the act expired. TWEA was also a prominent instrument of postwar presidential monetary policy. Presidents Dwight D. Eisenhower and John F. Kennedy used TWEA and the national emergency declared by President Roosevelt in 1933 to maintain and modify regulations controlling the hoarding and export of gold. In 1968, President Lyndon B. Johnson explicitly used Truman's 1950 declaration of emergency under Section 5(b) of TWEA to limit direct foreign investment by U.S. companies in an effort to strengthen the balance of payments position of the United States after the devaluation of the pound sterling by the United Kingdom. In 1971, after President Nixon ended the convertibility of the U.S. dollar to gold, effectively ending the postwar monetary order, he made use of Section 5(b) of TWEA to declare a state of emergency and place a 10% ad valorem supplemental duty on all dutiable goods entering the United States. The reliance by the executive on the powers granted by Section 5(b) of TWEA meant that postwar sanctions regimes and significant parts of U.S. international monetary policy relied on continued states of emergency for their operation. By the mid-1970s, in the wake of U.S. military involvement in Vietnam, revelations of domestic spying, assassinations of foreign political leaders, the Watergate break-in, and other related abuses of power, Congress increasingly focused on checking the executive branch. The Senate formed a bipartisan special committee chaired by Senators Frank Church and Charles Mathias to reevaluate the expansive delegations of emergency authority to the President. The special committee issued a report surveying the President's emergency powers in which it asserted that the United States had technically "been in a state of national emergency since March 9, 1933" and that there were four distinct declarations of national emergency in effect. The report also noted that the United States had "on the books at least 470 significant emergency statutes without time limitations delegating to the Executive extensive discretionary powers, ordinarily exercised by the Legislature, which affect the lives of American citizens in a host of all-encompassing ways." In the course of its investigations, Senator Mathias, committee co-chair, noted, "A majority of the people of the United States have lived all of their lives under emergency government." Senator Church, the other co-chair, said the central question before the committee was "whether it [was] possible for a democratic government such as ours to exist under its present Constitution and system of three separate branches equal in power under a continued state of emergency." Among the more controversial statutes highlighted by the committee was TWEA. In 1977, during the House markup of a bill revising TWEA, Representative Jonathan Bingham, Chairperson of the House International Relations Committee's Subcommittee on Economic Policy, described TWEA as conferring "on the President what could have been dictatorial powers that he could have used without any restraint by Congress." According to the Department of Justice, TWEA granted the President four major groups of powers in a time of war or other national emergency: (a) Regulatory powers with respect to foreign exchange, banking transfers, coin, bullion, currency, and securities; (b) Regulatory powers with respect to "any property in which any foreign country or a national thereof has any interest"; (c) The power to vest "any property or interest of any foreign country or national thereof"; and (d) The powers to hold, use, administer, liquidate, sell, or otherwise deal with "such interest or property" in the interest of and for the benefit of the United States. The House report on the reform legislation called TWEA "essentially an unlimited grant of authority for the President to exercise, at his discretion, broad powers in both the domestic and international economic arena, without congressional review." The criticisms of TWEA centered on the following: (a) It required no consultation or reports to Congress with regard to the use of powers or the declaration of a national emergency. (b) It set no time limits on a state of emergency, no mechanism for congressional review, and no way for Congress to terminate it. (c) It stated no limits on the scope of TWEA's economic powers and the circumstances under which such authority could be used. (d) The actions taken under the authority of TWEA were rarely related to the circumstances in which the national emergency was declared. In testimony before the House Committee on International Relations, Professor Harold G. Maier summed up the development and the main criticisms of TWEA: Section 5(b)'s effect is no longer confined to "emergency situations" in the sense of existing imminent danger. The continuing retroactive approval, either explicit or implicit, by Congress of broad executive interpretations of the scope of powers which it confers has converted the section into a general grant of legislative authority to the President…" Congress's reforms to emergency powers under TWEA came in two acts. First, Congress enacted the National Emergencies Act (NEA) in 1976. The NEA provided for the termination of all existing emergencies in 1978, except those making use of Section 5(b) of TWEA, and placed new restrictions on the manner of declaring and the duration of new states of emergency, including: Requiring the President to immediately transmit to Congress of the declaration of national emergency. Requiring a biannual review whereby "each House of Congress shall meet to consider a vote on a concurrent [now joint, see below] resolution to determine whether that emergency shall be terminated." Authorizing Congress to terminate the national emergency through a privileged concurrent [now joint] resolution. Second, Congress tackled the thornier question of TWEA. Because the authorities granted by TWEA were heavily entwined with postwar international monetary policy and the use of sanctions in U.S. foreign policy, unwinding it was a difficult undertaking. The exclusion of Section 5(b) reflected congressional interest in preserving existing regulations regarding foreign assets, foreign funds, and exports of strategic goods. Similarly, establishing a means to continue existing uses of TWEA reflected congressional interest in "improving future use rather than remedying past abuses." The subcommittee charged with reforming TWEA spent more than a year preparing reports, including the first complete legislative history of TWEA, a tome that ran nearly 700 pages. In the resulting legislation, Congress did three things. First, Congress amended TWEA so that it was, as originally intended, only applicable "during a time of war." Second, Congress expanded the Export Administration Act to include powers that previously were authorized by reference to Section 5(b) of TWEA. Finally, Congress wrote the International Emergency Economic Powers Act (IEEPA) to confer "upon the President a new set of authorities for use in time of national emergency which are both more limited in scope than those of section 5(b) and subject to procedural limitations, including those of the [NEA]." The Report of the House Committee on International Relations summed up the nature of an "emergency" in their "new approach" to international emergency economic powers: [G]iven the breadth of the authorities, and their availability at the President's discretion upon a declaration of a national emergency, their exercise should be subject to various substantive restrictions. The main one stems from a recognition that emergencies are by their nature rare and brief, and are not to be equated with normal ongoing problems. A national emergency should be declared and emergency authorities employed only with respect to a specific set of circumstances which constitute a real emergency, and for no other purpose. The emergency should be terminated in a timely manner when the factual state of emergency is over and not continued in effect for use in other circumstances. A state of national emergency should not be a normal state of affairs. IEEPA, as currently amended, empowers the president to: (A) investigate, regulate, or prohibit: (i) any transactions in foreign exchange, (ii) transfers of credit or payments between, by, through, or to any banking institution, to the extent that such transfers or payments involve any interest of any foreign country or national thereof, (iii) the importing or exporting of currencies or securities; and (B) investigate, block during the pendency of an investigation, regulate, direct and compel, nullify, void, prevent or prohibit, any acquisition, holding, withholding, use, transfer, withdrawal, transportation, importation or exportation of, or dealing in, or exercising any right, power, or privilege with respect to, or transactions involving, any property in which any foreign country or a national thereof has any interest by any person, or with respect to any property, subject to the jurisdiction of the United States. (C) when the United States is engaged in armed hostilities or has been attacked by a foreign country or foreign nationals, confiscate any property, subject to the jurisdiction of the United States, of any foreign person, foreign organization, or foreign country that he determines has planned, authorized, aided, or engaged in such hostilities or attacks against the United States; and all right, title, and interest in any property so confiscated shall vest, when, as, and upon the terms directed by the President, in such agency or person as the President may designate from time to time, and upon such terms and conditions as the President may prescribe, such interest or property shall be held, used, administered, liquidated, sold, or otherwise dealt with in the interest of and for the benefit of the United States, and such designated agency or person may perform any and all acts incident to the accomplishment or furtherance of these purposes. These powers may be exercised "to deal with any unusual and extraordinary threat, which has its source in whole or substantial part outside the United States, to the national security, foreign policy, or economy of the United States, if the President declares a national emergency with respect to such threat." Presidents may invoke IEEPA under the procedures set forth in the NEA. When declaring a national emergency, the NEA requires that the President "immediately" transmit the proclamation declaring the emergency to Congress and publish it in the Federal Register . The President must also specify the provisions of law that he or she intends to use. In addition to the requirements of the NEA, IEEPA provides several further restrictions. Preliminarily, IEEPA requires that the President consult with Congress "in every possible instance" before exercising any of the authorities granted under IEEPA. Once the President declares a national emergency invoking IEEPA, he or she must immediately transmit a report to Congress specifying: (1) the circumstances which necessitate such exercise of authority; (2) why the President believes those circumstances constitute an unusual and extraordinary threat, which has its source in whole or substantial part outside the United States, to the national security, foreign policy, or economy of the United States; (3) the authorities to be exercised and the actions to be taken in the exercise of those authorities to deal with those circumstances; (4) why the President believes such actions are necessary to deal with those circumstances; and (5) any foreign countries with respect to which such actions are to be taken and why such actions are to be taken with respect to those countries. The President subsequently is to report on the actions taken under the IEEPA at least once in every succeeding six-month interval that the authorities are exercised. As per the NEA, the emergency may be terminated by the President, by a privileged joint resolution of Congress, or automatically if the President does not publish in the Federal Register and transmit to Congress a notice stating that such emergency is to continue in effect after such anniversary. Congress has amended IEEPA eight times ( Table 1 ). Five of the eight amendments have altered civil and criminal penalties for violations of orders issued under the statute. Other amendments excluded certain informational materials and expanded IEEPA's scope following the terrorist attacks of September 11, 2001. Congress also amended the NEA in response to a ruling by the Supreme Court to require a joint rather than a concurrent resolution to terminate a national emergency. As originally enacted, IEEPA protected the rights of U.S. persons to participate in the exchange of "any postal, telegraphic, telephonic, or other personal communication, which does not involve a transfer of anything of value" with a foreign person otherwise subject to sanctions. Amendments in 1988 and 1994 updated this list of protected rights to include the exchange of published information in a variety of formats. The act currently protects the exchange of "information or informational materials, including but not limited to, publications, films, posters, phonograph records, photographs, microfilms, microfiche, tapes, compact disks, CD ROMs, artworks, and news wire feeds," provided such exchange is not otherwise controlled for national security or foreign policy reasons related to weapons proliferation or international terrorism. Unlike the Trading with the Enemy Act (TWEA), IEEPA did not allow the President to vest assets as originally acted. In 2001, at the request of George W. Bush Administration, Congress amended IEEPA as part of the USA PATRIOT Act to return to the President the authority to vest frozen assets, but only under certain circumstances: ... the President may ... when the United States is engaged in armed hostilities or has been attacked by a foreign country or foreign nationals, confiscate any property, subject to the jurisdiction of the United States, of any foreign person, foreign organization, or foreign country that [the President] determines has planned, authorized, aided, or engaged in such hostilities or attacks against the United States; and all right, title, and interest in any property so confiscated shall vest, when, as, and upon the terms directed by the President, in such agency or person as the President may designate from time to time, and upon such terms and conditions as the President may prescribe, such interest or property shall be held, used, administered, liquidated, sold, or otherwise dealt with in the interest of and for the benefit of the United States, and such designated agency or person may perform any and all acts incident to the accomplishment or furtherance of these purposes. Speaking about the efforts of intelligence and law enforcement agencies to identify and disrupt the flow of terrorist finances, Attorney General John Ashcroft told Congress: At present the President's powers are limited to freezing assets and blocking transactions with terrorist organizations. We need the capacity for more than a freeze. We must be able to seize. Doing business with terrorist organization must be a losing proposition. Terrorist financiers must pay a price for their support of terrorism, which kills innocent Americans. Consistent with the President's [issuance of E.O. 13224 ] and his statements [of September 24, 2001], our proposal gives law enforcement the ability to seize the terrorists' assets. Further, criminal liability is imposed on those who knowingly engage in financial transactions, money-laundering involving the proceeds of terrorist acts. The House Judiciary Committee report explaining the amendments described its purpose as follows: Section 203 of the International Emergency Economic Powers Act (50 U.S.C. § 1702) grants to the President the power to exercise certain authorities relating to commerce with foreign nations upon his determination that there exists an unusual and extraordinary threat to the United States. Under this authority, the President may, among other things, freeze certain foreign assets within the jurisdiction of the United States. A separate law, the Trading With the Enemy Act, authorizes the President to take title to enemy assets when Congress has declared war. Section 159 of this bill amends section 203 of the International Emergency Economic Powers Act to provide the President with authority similar to what he currently has under the Trading With the Enemy Act in circumstances where there has been an armed attack on the United States, or where Congress has enacted a law authorizing the President to use armed force against a foreign country, foreign organization, or foreign national. The proceeds of any foreign assets to which the President takes title under this authority must be placed in a segregated account can only be used in accordance with a statute authorizing the expenditure of such proceeds. Section 159 also makes a number of clarifying and technical changes to section 203 of the International Emergency Economic Powers Act, most of which will not change the way that provision currently is implemented. The government has apparently never employed the vesting power to seize Al Qaeda assets within the United States. Instead, the government has sought to confiscate them through forfeiture procedures. The first, and to date, apparently only, use of this power under IEEPA occurred on March 20, 2003. On that date, in Executive Order 13290, President George W. Bush ordered the blocked "property of the Government of Iraq and its agencies, instrumentalities, or controlled entities" to be vested "in the Department of the Treasury.... [to] be used to assist the Iraqi people and to assist in the reconstruction of Iraq." However, the President's order excluded from confiscation Iraq's diplomatic and consular property, as well as assets that had, prior to March 20, 2003, been ordered attached in satisfaction of judgments against Iraq rendered pursuant to the terrorist suit provision of the Foreign Sovereign Immunities Act and § 201 of the Terrorism Risk Insurance Act (which reportedly totaled about $300 million) . A subsequent executive order blocked the property of former Iraqi officials and their families, vesting title of such blocked funds in the Department of the Treasury for transfer to the Development Fund for Iraq (DFI) to be "used to meet the humanitarian needs of the Iraqi people, for the economic reconstruction and repair of Iraq's infrastructure, for the continued disarmament of Iraq, for the cost of Iraqi civilian administration, and for other purposes benefitting of the Iraqi people." The DFI was established by UN Security Council Resolution 1483, which required member states to freeze all assets of the former Iraqi government and of Saddam Hussein, senior officials of his regime and their family members, and transfer such assets to the DFI, which was then administered by the United States. Most of the vested assets were used by the Coalition Provision Authority (CPA) for reconstruction projects and ministry operations. The USA PATRIOT Act made three other amendments to Section 203 of IEEPA. After the power to investigate, it added the power to block assets during the pendency of an investigation. It clarified that the type of interest in property subject to IEEPA is an "interest by any person, or with respect to any property, subject to the jurisdiction of the United States." It also added subsection (c), which provides: In any judicial review of a determination made under this section, if the determination was based on classified information (as defined in section 1(a) of the Classified Information Procedures Act) such information may be submitted to the reviewing court ex parte and in camera. This subsection does not confer or imply any right to judicial review. As described in the House Judiciary Committee report, these provisions were meant to clarify and codify existing practices. Like TWEA prior to its amendment in 1977, the President and Congress together have often turned to IEEPA to impose economic sanctions in furtherance of U.S. foreign policy and national security objectives. While initially enacted to rein in presidential emergency authority, presidential emergency use of IEEPA has expanded in scale, scope, and frequency since the statute's enactment. The House report on IEEPA stated, "emergencies are by their nature rare and brief, and are not to be equated with normal, ongoing problems." National emergencies invoking IEEPA, however, have increased in frequency and length since its enactment. Since 1977, Presidents have invoked IEEPA in 54 declarations of national emergency. On average, these emergencies last nearly a decade. Most emergencies have been geographically specific, targeting a specific country or government. However, since 1990, Presidents have declared non-geographically-specific emergencies in response to issues like weapons proliferation, global terrorism, and malicious cyber-enabled activities. The erosion of geographic limitations has been accompanied by an expansion in the nature of the targets of sanctions issued under IEEPA authority. Originally, IEEPA was used to target foreign governments; however, Presidents have increasingly targeted groups and individuals. While Presidents usually make use of IEEPA as an emergency power, Congress has also directed the use of IEEPA or expressed its approval of presidential emergency use in several statutes. IEEPA is the most frequently cited emergency authority when the President invokes NEA authorities to declare a national emergency. ( Figure 1 ). Rather than referencing the same set of emergencies, as had been the case with TWEA, IEEPA has required the President to declare a national emergency for each independent use. As a result, the number of national emergencies declared under the terms of the NEA has proliferated over the past four decades. Presidents declared only four national emergencies under the auspices of TWEA in the four decades prior to IEEPA's enactment. In contrast, Presidents have invoked IEEPA in 54 of the 61 declarations of national emergency issued under the National Emergen cies Act. As of March 1, 2019, there were 32 ongoing national emergencies; all but three involved IEEPA. Each year since 1990, Presidents have issued roughly 4.5 executive orders citing IEEPA and declared 1.5 new national emergencies citing IEEPA. ( Figure 2 ). On average, emergencies invoking IEEPA last nearly a decade. The longest emergency was also the first. President Jimmy Carter, in response to the Iranian hostage crisis of 1979, declared the first national emergency under the provisions of the National Emergencies Act and invoked IEEPA. Six successive Presidents have renewed that emergency annually for nearly forty years. As of March 1, 2019, that emergency is still in effect, largely to provide a legal basis for resolving matters of ownership of the Shah's disputed assets. That initial emergency aside, the length of emergencies invoking IEEPA has increased each decade. The average length of an emergency invoking IEEPA declared in the 1980s was four years. That average extended to 10 years for emergencies declared in the 1990s and 11 years for emergencies declared in the 2000s ( Figure 3 ). As such, the number of ongoing national emergencies has grown nearly continuously since the enactment of IEEPA and the NEA ( Figure 4 ). Between January 1, 1979, and January 1, 2019, there were on average 14 ongoing national emergencies each year, 13 of which invoked IEEPA. In most cases, the declared emergencies citing IEEPA have been geographically specific ( Figure 5 ). For example, in the first use of IEEPA, President Jimmy Carter issued an executive order that both declared a national emergency with respect to the "situation in Iran" and "blocked all property and interests in property of the Government of Iran [...]." Five months later, President Carter issued a second order dramatically expanding the scope of the first EO and effectively blocked the transfer of all goods, money, or credit destined for Iran by anyone subject to the jurisdiction of the United States. A further order expanded the coverage to block imports to the United States from Iran. Together, these orders touched upon virtually all economic contacts between any place or legal person subject to the jurisdiction of the United States and the territory and government of Iran. Many of the executive orders invoking IEEPA have followed this pattern of limiting the scope to a specific territory, government, or its nationals. Executive Order 12513, for example, prohibited "imports into the United States of goods and services of Nicaraguan origin" and "exports from the United States of goods to or destined for Nicaragua." The order likewise prohibited Nicaraguan air carriers and vessels of Nicaraguan registry from entering U.S. ports. Executive Order 12532 prohibited various transactions with the "Government of South Africa or to entities owned or controlled by that Government." While the majority (38) of national emergencies invoking IEEPA have been geographically specific, ten have lacked explicit geographic limitations. President George H.W. Bush declared the first geographically nonspecific emergency in response to the threat posed by the proliferation of chemical and biological weapons. Similarly, President George W. Bush declared a national emergency in response to the threat posed by "persons who commit, threaten to commit, or support terrorism." President Barack Obama declared emergencies to respond to the threats of "transnational criminal organizations" and "persons engaging in malicious cyber-enabled activities." Without explicit geographic limitations, these orders have included provisions that are global in scope. These geographically nonspecific emergencies have increased in frequency over the past 40 years—three of the ten have been declared since 2015. In addition to the erosion of geographic limitations, the stated motivations for declaring national emergencies have expanded in scope as well. Initially, stated rationales for declarations of national emergency citing IEEPA were short and often referenced either a specific geography or the specific actions of a government. Presidents found that circumstances like "the situation in Iran," or the "policies and actions of the Government of Nicaragua," constituted "unusual and extraordinary threat[s] to the national security and foreign policy of the United States" and would therefore declare a national emergency. The stated rationales have, however, expanded over time in both the length and subject matter. Presidents have increasingly declared national emergencies, in part, to respond to human and civil rights abuses, slavery, denial of religious freedom, political repression, public corruption, and the undermining of democratic processes. While the first reference to human rights violations as a rationale for a declaration of national emergency came in 1985, most of such references have come in the past twenty years. Table A-2 . Presidents have also expanded the nature of the targets of IEEPA sanctions. Originally, the targets of sanctions issued under IEEPA were foreign governments. The first use of IEEPA targeted "Iranian Government Property." Use of IEEPA quickly expanded to target geographically defined regions. Nevertheless, Presidents have also increasingly targeted groups, such as political parties or terrorist organizations, and individuals, such as supporters of terrorism or suspected narcotics traffickers. The first instances of orders directed at groups or persons were limited to foreign groups or persons. For example, in Executive Order 12978, President Bill Clinton targeted specific "foreign persons" and "persons determined [...] to be owned or controlled by, or to act for or on behalf of" such foreign persons. An excerpt is included below: Except to the extent provided in section 203(b) of IEEPA (50 U.S.C. 1702(b)) and in regulations, orders, directives, or licenses that may be issued pursuant to this order, and notwithstanding any contract entered into or any license or permit granted prior to the effective date, I hereby order blocked all property and interests in property that are or hereafter come within the United States, or that are or hereafter come within the possession or control of United States persons, of: (a) the foreign persons listed in the Annex to this order; (b)  foreign persons determined by the Secretary of the Treasury, in consultation with the Attorney General and the Secretary of State: (i) to play a significant role in international narcotics trafficking centered in Colombia; or (ii) materially to assist in, or provide financial or technological support for or goods or services in support of, the narcotics trafficking activities of persons designated in or pursuant to this order; and (c) persons determined by the Secretary of the Treasury, in consultation with the Attorney General and the Secretary of State, to be owned or controlled by, or to act for or on behalf of, persons designated in or pursuant to this order. However, in 2001, President George W. Bush issued Executive Order 13219 to target "persons who threaten international stabilization efforts in the Western Balkans." While the order was similar to that of Executive Order 12978, it removed the qualifier "foreign." As such, persons in the United States, including U.S. citizens, could be targets of the order. The following is an excerpt of the order: Except to the extent provided in section 203(b)(1), (3), and (4) of IEEPA (50 U.S.C. 1702(b)(1), (3), and (4)), the Trade Sanctions Reform and Export Enhancement Act of 2000 (title IX, P.L. 106-387 ), and in regulations, orders, directives, or licenses that may hereafter be issued pursuant to this order, and notwithstanding any contract entered into or any license or permit granted prior to the effective date, all property and interests in property of: (i)  the persons listed in the Annex to this order; and (ii)  persons designated by the Secretary of the Treasury, in consultation with the Secretary of State, because they are found: (A) to have committed, or to pose a significant risk of committing, acts of violence... Several subsequent invocations of IEEPA have similarly not been limited to foreign targets. In sum, presidential emergency use of IEEPA was directed at foreign states initially, with targets that were delimited by geography or nationality. Since the 1990s, however, Presidents have expanded the scope of their declarations to include individual persons, regardless of nationality or geographic location, who are engaged in specific activities. While IEEPA is often categorized as an emergency statute, Congress has used IEEPA outside of the context of national emergencies. When Congress legislates sanctions, it often authorizes or directs the President to use IEEPA authorities to impose those sanctions. In the Nicaragua Human Rights and Anticorruption Act of 2018, the most recent example, Congress directed the President to exercise "all powers granted to the President [by IEEPA] to the extent necessary to block and prohibit [certain transactions]." Penalties for violations by a person of a measure imposed by the President under the Act would be, likewise, determined by reference to IEEPA. The trend has been long-term. Congress first directed the President to make use of IEEPA authorities in 1986 as part of an effort to assist Haiti in the recovery of assets illegally diverted by its former government. That statute provided: The President shall exercise the authorities granted by section 203 of the International Emergency Economic Powers Act [50 USC 1702] to assist the Government of Haiti in its efforts to recover, through legal proceedings, assets which the Government of Haiti alleges were stolen by former president-for-life Jean Claude Duvalier and other individuals associated with the Duvalier regime. This subsection shall be deemed to satisfy the requirements of section 202 of that Act. [50 USC 1701] In directing the President to use IEEPA, Congress waived the requirement that he declare a national emergency (and none was declared). Subsequent legislation has followed this general pattern, with slight variations in language and specificity. The following is an example of current legislative language that has appeared in several recent statutes: (a) IN GENERAL.—The President shall impose the sanctions described in subsection (b) with respect to— ... (b) SANCTIONS DESCRIBED.— (1) IN GENERAL.—The sanctions described in this subsection are the following: (A) ASSET BLOCKING.—The exercise of all powers granted to the President by the International Emergency Economic Powers Act (50 U.S.C. 1701 et seq.) to the extent necessary to block and prohibit all transactions in all property and interests in property of a person determined by the President to be subject to subsection (a) if such property and interests in property are in the United States, come within the United States, or are or come within the possession or control of a United States person. ... (2) PENALTIES.—A person that violates, attempts to violate, conspires to violate, or causes a violation of paragraph (1)(A) or any regulation, license, or order issued to carry out paragraph (1)(A) shall be subject to the penalties set forth in subsections (b) and (c) of section 206 of the International Emergency Economic Powers Act (50 U.S.C. 1705) to the same extent as a person that commits an unlawful act described in subsection (a) of that section. Congress has also expressed, retroactively, its approval of unilateral presidential invocations of IEEPA in the context of a national emergency. In the Countering Iran's Destabilizing Activities Act of 2017, for example, Congress declared, "It is the sense of Congress that the Secretary of the Treasury and the Secretary of State should continue to implement Executive Order No. 13382." Presidents, however, have also used IEEPA to preempt or modify parallel congressional activity. On September 9, 1985, President Reagan, finding "that the policies and actions of the Government of South Africa constitute an unusual and extraordinary threat to the foreign policy and economy of the United States," declared a national emergency and limited transactions with South Africa. The President declared the emergency despite the fact that legislation limiting transactions with South Africa was quickly making its way through Congress. In remarks about the declaration, President Reagan stated that he had been opposed to the bill contemplated by Congress because unspecified provisions "would have harmed the very people [the U.S. was] trying to help." Nevertheless, members of the press at the time (and at least one scholar since) noted that the limitations imposed by the Executive Order and the provisions in legislation then winding its way through Congress were "substantially similar." In general, IEEPA has served as an integral part of the postwar international sanctions regime. The President, either through a declaration of emergency or via statutory direction, has used IEEPA to limit economic transactions in support of administrative and congressional national security and foreign policy goals. Much of the action taken pursuant to IEEPA has involved blocking transactions and freezing assets. Once the President declares that a national emergency exists, he may use the authority in Section 203 of IEEPA (Grants of Authorities; 50 U.S.C. § 1702) to investigate, regulate, or prohibit foreign exchange transactions, transfers of credit, transfers of securities, payments, and may take specified actions relating to property in which a foreign country or person has interest—freezing assets, blocking property and interests in property, prohibiting U.S. persons from entering into transactions related to frozen assets and blocked property, and in some instances denying entry into the United States. Pursuant to Section 203, Presidents have prohibited transactions with and blocked property of those designated as engaging in malicious cyber-enabled activities, including "interfering with or undermining election processes or institutions" [Executive Order 13694 of April 1, 2015, as amended; 50 U.S.C. § 1701 note. See also Executive Order 13848 of September 12, 2018; 83 F.R. 46843.]; prohibited transactions with and blocked property of those designated as illicit narcotics traffickers including foreign drug kingpins; prohibited transactions with and blocked property of those designated as engaging in human rights abuses or significant corruption; prohibited transactions related to illicit trade in rough diamonds; prohibited transactions with and blocked property of those designated as Transnational Criminal Organizations; prohibited transactions with "those who disrupt the Middle East peace process;" prohibited transactions related to overflights with certain nations; instituted and maintained maritime restrictions; prohibited transactions related to weapons of mass destruction, in coordination with export controls authorized by the Arms Export Control Act and the Export Administration Act of 1979, and in furtherance of efforts to deter the weapons programs of specific countries (i.e., Iran, North Korea); prohibited transactions those designated as "persons who commit, threaten to commit, or support terrorism;" maintained the dual-use export control system at times when its then-underlying authority, the Export Administration Act authority had lapsed; blocked property of and transactions with those designated as engaged in cyber activities that compromise critical infrastructures including election processes or the private sector's trade secrets; blocked property of and prohibited transactions with those designated as responsible for serious human rights abuse or engaged in corruption; blocked certain property of and transactions with foreign nationals of specific countries those designated as engaged in activities that constitute an extraordinary threat. No President has used IEEPA to place tariffs on imported products from a specific country or on products imported to the United States in general. However, IEEPA's similarity to TWEA, coupled with its relatively frequent use to ban imports and exports, suggests that such an action could happen. In addition, no President has used IEEPA to enact a policy that was primarily domestic in effect. Some scholars argue, however, that the interconnectedness of the global economy means it would probably be permissible to use IEEPA to take an action that was primarily domestic in effect. The ultimate disposition of assets frozen under IEEPA may serve as an important part of the leverage economic sanctions provide to influence the behavior of foreign actors. The President and Congress have each at times determined the fate of blocked assets to further foreign policy goals. Presidents have used frozen assets as a bargaining tool during foreign policy crises and to bring a resolution to such crises, at times by unfreezing the assets, returning them to the sanctioned entity or channeling them to a follow-on government. The following are some examples of how Presidents have made use of blocked assets to resolve foreign policy issues. President Carter invoked authority under IEEPA to impose trade sanctions against Iran, freezing Iranian assets in the United States, in response to the hostage crisis in 1979. On January 19, 1981, the United States and Iran entered into a series of executive agreements brokered by Algeria under which the hostages were freed, a portion of the blocked assets ($5.1 billion) was used to repay outstanding U.S. bank loans to Iran, another part ($2.8 billion) was returned directly to Iran, another $1 billion was transferred into a security account in the Hague to pay other U.S. claims against Iran as arbitrated by the Iran-U.S. Claims Tribunal (IUSCT), and an additional $2 billion remained blocked pending further agreement with Iran or decision of the Tribunal. The United States also undertook to freeze the assets of the former Shah's estate along with those of the Shah's close relatives pending litigation in U.S. courts to ascertain Iran's right to their return. Iran's litigation was unsuccessful, and none of the contested assets were returned to Iran. Presidents have also been able to channel frozen assets to opposition governments in cases where the United States continued to recognize a previous government that had been removed by coup d'état or otherwise replaced as the legitimate government of a country. For example, after Panamanian President Eric Arturo Delvalle tried to dismiss de facto military ruler General Manuel Noriega from his post as head of the Panamanian Defense Forces, which resulted in Delvalle's own dismissal by the Panamanian Legislative Assembly, President Reagan recognized Delvalle as the legitimate head of government and instituted economic sanctions against the Noriega regime. The Department of State advised U.S. banks not to disburse funds to the Noriega regime, and Delvalle was able to obtain court orders permitting him access to the funds. President Reagan issued Executive Order 12635, which blocked all property and interests in payments of the government of Panama, and the Department of the Treasury issued regulations requiring companies who owed money to Panama to pay those funds into an escrow account established at the Federal Reserve Bank of New York, which also held payments owed by the United States for the operation of the Panama Canal Commission. Some of the funds in the escrow account were used to pay the operating expenses of the Delvalle government. After the U.S. invasion of Panama, President George H.W. Bush lifted economic sanctions and used some of the frozen funds to repay debts owed by Panama to foreign creditors, with remaining funds returned to the successor government. In a similar more recent case, the Trump Administration's recognition of Venezuelan opposition leader Juan Guaidó as Venezuela's interim president permitted Guaidó access to Venezuelan government assets held at the United States Federal Reserve and other insured United States financial institutions. President Barrack Obama initially froze Venezuelan government assets in 2015, pursuant to IEEPA and the Venezuela Defense of Human Rights and Civil Society Act of 2014. After official recognition of Guaidó, the Trump Administration imposed new sanctions under IEEPA to freeze the assets of the main Venezuelan state-owned oil company, Petróleos de Venezuela (Pdvsa), which could both significantly reduce funds available to the regime of Nicolas Maduro and channel them to Guaidó. There is also precedent for using frozen foreign assets for purposes authorized by the U.N. Security Council. After the first war with Iraq, President George H.W. Bush ordered the transfer of frozen Iraqi assets derived from the sale of Iraqi petroleum held by U.S. banks to be transferred to a holding account in the Federal Reserve Bank of New York to fulfill "the rights and obligations of the United States under U.N. Security Council Resolution No. 778." The President cited a section of the United Nations Participation Act (UNPA), as well as IEEPA, as authority to take the action. The transferred funds were used to provide humanitarian relief and to finance the United Nations Compensation Commission, which was established to adjudicate claims against Iraq arising from the invasion. Other Iraqi assets remained frozen and accumulated interest until they were vested in 2003 (see below). In some cases, the United States has ended sanctions and returned frozen assets to successor governments. In the case of the former Yugoslavia, for example, in 2003, $237.6 million in frozen funds belonging to the Central Bank of the Socialist Federal Republic of Yugoslavia were transferred to the central banks of the successor states. In the case of Afghanistan, $217 million in frozen funds belonging to the Taliban were released to the Afghan Interim Authority in January 2002. The executive branch has traditionally resisted congressional efforts to vest foreign assets to pay U.S. claimants without first obtaining a settlement agreement with the country in question. Congress has overcome such resistance in the case of foreign governments that have been designated as "State Supporters of Terrorism." U.S. nationals who are victims of state-supported terrorism involving designated states have been able to sue those countries for damages under an exception to the Foreign Sovereign Immunities Act (FSIA) since 1996. To facilitate the payment of judgments under the exception, Congress passed Section 117 of the Treasury and General Government Appropriations Act, 1999, which further amended the FSIA by allowing attachment and execution against state property with respect to which financial transactions are prohibited or regulated under Section 5(b) TWEA, Section 620(a) of the Foreign Assistance Act (authorizing the trade embargo against Cuba), or Sections 202 and 203 of IEEPA, or any orders, licenses or other authority issued under these statutes. Because of the Clinton Administration's continuing objections, however, Section 117 also gave the President authority to "waive the requirements of this section in the interest of national security," an authority President Clinton promptly exercised in signing the statute into law. The Section 117 waiver authority protecting blocked foreign government assets from attachment to satisfy terrorism judgments has continued in effect ever since, prompting Congress to take other actions to make frozen assets available to judgment holders. Congress enacted §2002 of the Victims of Trafficking and Violence Protection Act of 2000 (VTVPA) to mandate the payment from frozen Cuban assets of compensatory damages awarded against Cuba under the FSIA terrorism exception on or prior to July 20, 2000. The Department of the Treasury subsequently vested $96.7 million in funds generated from long-distance telephone services between the United States and Cuba in order to compensate claimants in Alejandre v. Republic of Cuba , the lawsuit based on the1996 downing of two unarmed U.S. civilian airplanes by the Cuban air force. Another payment of more than $7 million was made using vested Cuban assets to a Florida woman who had won a lawsuit against Cuba based on her marriage to a Cuban spy. As unpaid judgments against designated state sponsors of terrorism continued to mount, Congress enacted the Terrorism Risk Insurance Act (TRIA). Section 201 of TRIA overrode long-standing objections by the executive branch to make the frozen assets of terrorist states available to satisfy judgments for compensatory damages against such states (and organizations and persons) as follows: Notwithstanding any other provision of law, and except as provided in subsection (b), in every case in which a person has obtained a judgment against a terrorist party on a claim based upon an act of terrorism, or for which a terrorist party is not immune under section 1605(a)(7) of title 28, United States Code, the blocked assets of that terrorist party (including the blocked assets of any agency or instrumentality of that terrorist party) shall be subject to execution or attachment in aid of execution in order to satisfy such judgment to the extent of any compensatory damages for which such terrorist party has been adjudged liable. Subsection (b) of Section 201 provided waiver authority "in the national security interest," but only with respect to frozen foreign government "property subject to the Vienna Convention on Diplomatic Relations or the Vienna Convention on Consular Relations." When Congress amended the FSIA in 2008 to revamp the terrorism exception, it provided that judgments entered under the new exception could be satisfied out of the property of a foreign state notwithstanding the fact that the property in question is regulated by the United States government pursuant to TWEA or IEEPA. Congress has also directed that the proceeds from certain sanctions violations be paid into a fund for providing compensation to the former hostages of Iran and terrorist state judgment creditors. To fund the program, Congress designated that certain real property and bank accounts owned by Iran and forfeited to the United States could go into the United States Victims of State Sponsored Terrorism Fund, along with the sum of $1,025,000,000, representing the amount paid to the United States pursuant to the June 27, 2014, plea agreement and settlement between the United States and BNP Paribas for sanctions violations. The fund is replenished through criminal penalties and forfeitures for violations of IEEPA or TWEA-based regulations, or any related civil or criminal conspiracy, scheme, or other federal offense related to doing business or acting on behalf of a state sponsor of terrorism. Half of all civil penalties and forfeitures relating to the same offenses are also deposited into the fund. A number of lawsuits seeking to overturn actions taken pursuant to IEEPA have made their way through the judicial system, including challenges to the breadth of congressionally delegated authority and assertions of violations of constitutional rights. As demonstrated below, most of these challenges have failed. The few challenges that succeeded did not seriously undermine the overarching statutory scheme for sanctions. The breadth of presidential power under IEEPA is illustrated by the Supreme Court's 1981 opinion in Dames & Moore v. Regan . In Dames & Moore , petitioners had challenged President Carter's executive order establishing regulations to further compliance with the terms of the Algiers Accords, which the President had entered into to end the hostage crisis with Iran. Under these agreements, the United States was obligated (1) to terminate all legal proceedings in U.S. courts involving claims of U.S. nationals against Iran, (2) to nullify all attachments and judgments, and (3) to resolve outstanding claims exclusively through binding arbitration in the Iran-U.S. Claims Tribunal (IUSCT). The President, through executive orders, revoked all licenses that permitted the exercise of "any right, power, or privilege" with regard to Iranian funds, nullified all non-Iranian interests in assets acquired after a previous blocking order, and required banks holding Iranian assets to transfer them to the Federal Reserve Bank of New York to be held or transferred as directed by the Secretary of the Treasury. Dames and Moore had sued Iran for breach of contract to recover compensation for work performed. The district court had entered summary judgment in favor of Dames and Moore and issued an order attaching certain Iranian assets for satisfaction of any judgment that might result, but stayed the case pending appeal. The executive orders and regulations implementing the Algiers Accords resulted in the nullification of this prejudgment attachment and the dismissal of the case against Iran, directing that it be filed at the IUSCT. In response, Dames and Moore sued the government. The plaintiffs claimed that the President and the Secretary of the Treasury exceeded their statutory and constitutional powers to the extent they adversely affected Dames and Moore's judgment against Iran, the execution of that judgment, the prejudgment attachments, and the plaintiff's ability to continue to litigate against the Iranian banks. The government defended its actions, relying largely on IEEPA, which provided explicit support for most of the measures taken—nullification of the prejudgment attachment and transfer of the property to Iran—but could not be read to authorize actions affecting the suspension of claims in U.S. courts. Justice Rehnquist wrote for the majority: Although we have declined to conclude that the IEEPA…directly authorizes the President's suspension of claims for the reasons noted, we cannot ignore the general tenor of Congress' legislation in this area in trying to determine whether the President is acting alone or at least with the acceptance of Congress. As we have noted, Congress cannot anticipate and legislate with regard to every possible action the President may find it necessary to take or every possible situation in which he might act. Such failure of Congress specifically to delegate authority does not, "especially . . . in the areas of foreign policy and national security," imply "congressional disapproval" of action taken by the Executive. On the contrary, the enactment of legislation closely related to the question of the President's authority in a particular case which evinces legislative intent to accord the President broad discretion may be considered to "invite" "measures on independent presidential responsibility." At least this is so where there is no contrary indication of legislative intent and when, as here, there is a history of congressional acquiescence in conduct of the sort engaged in by the President. The Court remarked that Congress's implicit approval of the long-standing presidential practice of settling international claims by executive agreement was critical to its holding that the challenged actions were not in conflict with acts of Congress. For support, the Court cited to Justice Frankfurter's concurrence in Youngstown Sheet and Tube Co. v. Sawyer stating that "a systematic, unbroken, executive practice, long pursued to the knowledge of the Congress and never before questioned … may be treated as a gloss on 'Executive Power' vested in the President by § 1 of Art. II." Consequently, it may be argued that Congress's exclusion of certain express powers in IEEPA do not necessarily preclude the President from exercising them, at least where a court finds sufficient precedent exists. Lower courts have examined IEEPA under a number of other constitutional doctrines. Courts have reviewed whether Congress violated the non-delegation principle of separation of powers by delegating too much power to the President to legislate, in particular by creating new crimes. These challenges have generally failed. As the U.S. Court of Appeals for the Second Circuit explained while evaluating IEEPA, delegations of congressional authority are constitutional so long as Congress provides through a legislative act an "intelligible principle" governing the exercise of the delegated authority. Even if the standards are higher for delegations of authority to define criminal offenses, the court held, IEEPA provides sufficient guidance. The court stated: The IEEPA "meaningfully constrains the [President's] discretion," by requiring that "[t]he authorities granted to the President ... may only be exercised to deal with an unusual and extraordinary threat with respect to which a national emergency has been declared." And the authorities delegated are defined and limited. The Second Circuit found it significant that "IEEPA relates to foreign affairs—an area in which the President has greater discretion," bolstering its view that IEEPA does not violate the non-delegation doctrine. The U.S. Court of Appeals for the Eleventh Circuit considered whether Section 207(b) of IEEPA is an unconstitutional legislative veto. That provision states: The authorities described in subsection (a)(1) may not continue to be exercised under this section if the national emergency is terminated by the Congress by concurrent resolution pursuant to section 202 of the National Emergencies Act [50 U.S.C. § 1622] and if the Congress specifies in such concurrent resolution that such authorities may not continue to be exercised under this section. In U.S. v. Romero-Fernandez , two defendants convicted of violating the terms of an executive order issued under IEEPA argued on appeal that IEEPA was unconstitutional, in part, because of the above provision. The Eleventh Circuit accepted that the provision was an unconstitutional legislative veto (as conceded by the government) based on INS v. Chadha , in which the Supreme Court held that Congress cannot void the exercise of power by the executive branch through concurrent resolution, but can act only through bicameral passage followed by presentment of the law to the President. The Eleventh Circuit nevertheless upheld the defendants' convictions for violations of IEEPA regulations, holding that the legislative veto provision was severable from the rest of the statute. Courts have also addressed whether certain actions taken pursuant to IEEPA have effected an uncompensated taking of property rights in violation of the Fifth Amendment. The Fifth Amendment's Takings Clause prohibits "private property [from being] taken for public use, without just compensation." The Fifth Amendment's prohibitions apply as well to regulatory takings, in which the government does not physically take property but instead imposes restrictions on the right of enjoyment that decreases the value of the property or right therein. The Supreme Court has held that the nullification of prejudgment attachments pursuant to regulations issued under IEEPA was not an uncompensated taking, suggesting that the reason for this position was the contingent nature of the licenses that had authorized the attachments. The Court also suggested that the broader purpose of the statute supported the view that there was no uncompensated taking: This Court has previously recognized that the congressional purpose in authorizing blocking orders is "to put control of foreign assets in the hands of the President...." Such orders permit the President to maintain the foreign assets at his disposal for use in negotiating the resolution of a declared national emergency. The frozen assets serve as a "bargaining chip" to be used by the President when dealing with a hostile country. Accordingly, it is difficult to accept petitioner's argument because the practical effect of it is to allow individual claimants throughout the country to minimize or wholly eliminate this "bargaining chip" through attachments, garnishments, or similar encumbrances on property. Neither the purpose the statute was enacted to serve nor its plain language supports such a result. Similarly, a lower court held that the extinguishment of contractual rights due to sanctions enacted pursuant to IEEPA does not amount to a regulatory taking requiring compensation under the Fifth Amendment. Even though the plaintiff suffered "obvious economic loss" due to the sanctions regulations, that factor alone was not enough to sustain plaintiff's claim of a compensable taking. The court quoted long-standing Supreme Court precedent to support its finding: A new tariff, an embargo, a draft, or a war may inevitably bring upon individuals great losses; may, indeed, render valuable property almost valueless. They may destroy the worth of contracts. But whoever supposed that, because of this, a tariff could not be changed, or a non-intercourse act, or an embargo be enacted, or a war be declared? .... [W]as it ever imagined this was taking private property without compensation or without due process of law? Accordingly, it seems unlikely that entities whose business interests are harmed by the imposition of sanctions pursuant to IEEPA will be entitled to compensation from the government for their losses. Persons whose assets have been directly blocked by the U.S. Department of the Treasury Office of Foreign Assets Control (OFAC) pursuant to IEEPA have likewise found little success challenging the loss of the use of their assets as uncompensated takings. Many courts have recognized that a temporary blocking of assets does not constitute a taking because it is a temporary action that does not vest title in the United States. This conclusion is apparently so even if the blocking of assets necessitates the closing altogether of a business enterprise. In some circumstances, however, a court may analyze at least the initial blocking of assets under a Fourth Amendment standard for seizure. One court found a blocking to be unreasonable under a Fourth Amendment standard where there was no reason that OFAC could not have first obtained a judicial warrant. Some persons whose assets have been blocked have asserted that their right to due process has been violated. The Due Process Clause of the Fifth Amendment provides that no person shall be deprived of life, liberty, or property, without due process of law. Where one company protested that the blocking of its assets without a pre-deprivation hearing violated its right to due process, a district court found that a temporary deprivation of property does not necessarily give rise to a right to notice and an opportunity to be heard. A second district court stated that the exigencies of national security and foreign policy considerations that are implicated in IEEPA cases have meant that OFAC historically has not provided pre-deprivation notice in sanctions programs. A third district court stated that OFAC's failure to provide a charitable foundation with notice or a hearing prior to its designation as a terrorist organization and blocking of its assets did not violate its right to procedural due process, because the OFAC designation and blocking order serve the important governmental interest of combating terrorism by curtailing the flow of terrorist financing. That same court also held that prompt action by the government was necessary to protect against the transfer of assets subject to the blocking order. In Al Haramain Islamic Foundation v. U.S. Department of Treasury , the U.S. Court of Appeals for the Ninth Circuit considered whether OFAC's use of classified information without any disclosure of its content in its decision to freeze the assets of a charitable organization, and its failure to provide adequate notice and a meaningful opportunity to respond, violated the organization's right to procedural due process. The court applied the balancing test set forth by the Supreme Court in its landmark administrative law case Mathews v. Eldridge to resolve these questions. Under the Eldridge test, to determine if an individual has received constitutional due process, courts must weigh: (1) [the person's or entity's] private property interest, (2) the risk of an erroneous deprivation of such interest through the procedures used, as well as the value of additional safeguards, and (3) the Government's interest in maintaining its procedures, including the burdens of additional procedural requirements." While weighing the interests and risks at issue in Al Haramain , the Ninth Circuit found the organization's property interest to be significant: By design, a designation by OFAC completely shutters all domestic operations of an entity. All assets are frozen. No person or organization may conduct any business whatsoever with the entity, other than a very narrow category of actions such as legal defense. Civil penalties attach even for unwitting violations. Criminal penalties, including up to 20 years' imprisonment, attach for willful violations. For domestic organizations such as AHIF–Oregon, a designation means that it conducts no business at all. The designation is indefinite. Although an entity can seek administrative reconsideration and limited judicial relief, those remedies take considerable time, as evidenced by OFAC's long administrative delay in this case and the ordinary delays inherent in our judicial system. In sum, designation is not a mere inconvenience or burden on certain property interests; designation indefinitely renders a domestic organization financially defunct. Nevertheless, the court found "the government's interest in national security [could not] be understated." In evaluating the government's interest in maintaining its procedures, the Ninth Circuit explained that the Constitution requires that the government "take reasonable measures to ensure basic fairness to the private party and that the government follow procedures reasonably designed to protect against erroneous deprivation of the private party's interests." While the Ninth Circuit had previously held that the use of undisclosed information in a case involving the exclusion of certain longtime resident aliens should be considered presumptively unconstitutional, the court found that the presumption had been overcome in this case. The Ninth Circuit noted that all federal courts that have considered the argument that OFAC may not use undisclosed classified information in making its determinations have rejected it. Although the court found that OFAC's failure to provide even an unclassified summary of the information at issue was a violation of the organization's due process rights, the court deemed the error harmless because it would not likely have affected the outcome of the case. In the same case, the Ninth Circuit also considered the organization's argument that it had been denied adequate notice and an opportunity to be heard. Specifically, the organization asserted that OFAC had refused to disclose its reasons for investigating and designating the organization, leaving it unable to respond adequately to OFAC's unknown suspicions. Because OFAC had provided the organization with only one document to support its designation over the four-year period between the freezing of its assets and the redesignation of the organization as a specially designated global terrorist (SDGT), the court agreed that the organization had been deprived of due process rights. However, the court found that this error too was harmless. Some courts have considered whether asset blocking or penalties imposed pursuant to regulations promulgated under IEEPA have violated the subjects' First Amendment rights to free association, free speech, or religion. Challenges on these grounds have typically failed. Courts have held that there is no First Amendment right to support terrorists. The U.S. Court of Appeals for the District of Columbia Circuit distinguished advocacy from financial support and held that the blocking of assets affected only the ability to provide financial support, but did not implicate the organization's freedom of association. Similarly, a district court interpreted relevant case law to hold that government actions prohibiting charitable contributions are subject to intermediate scrutiny rather than strict scrutiny, a higher standard that applies to political contributions. With respect to a free speech challenge brought by a charitable organization whose assets were temporarily blocked during the pendency of an investigation, a district court explained that "when 'speech' and 'nonspeech' elements are combined in the same course of conduct, a sufficiently important government interest in regulating the nonspeech element can justify incidental limitations on First Amendment freedoms." Accordingly, the district court applied the following test to determine whether the designations and blocking actions were lawful. Citing the Supreme Court's opinion in United States v. O'Brien , the court stated that a government regulation is sufficiently justified if: it is within the constitutional power of the government; it furthers an important or substantial governmental interest; the governmental interest is unrelated to the suppression of free expression; and the incidental restriction on alleged First Amendment freedoms is no greater than is essential to the furtherance of that interest. The court found the government's actions to fall within the bounds of this test: First, the President clearly had the power to issue the Executive Order. Second, the Executive Order promotes an important and substantial government interest—that of preventing terrorist attacks. Third, the government's action is unrelated to the suppression of free expression; it prohibits the provision of financial and other support to terrorists. Fourth, the incidental restrictions on First Amendment freedoms are no greater than necessary. However, with respect to an organization that was not itself designated as an SDGT but wished to conduct coordinated advocacy with another organization that was so designated, one appellate court found that an OFAC regulation barring such coordinated advocacy based on its content was subject to strict scrutiny. Accordingly, the court rejected the government's reliance on the Supreme Court's decision in Holder v. Humanitarian Law Project to find that the regulation impermissibly implicated the organization's right to free speech. Accordingly, there may be some circumstances where the First Amendment protects speech coordinated with (but not on behalf of) an organization designated as an SDGT. Until the recent enactment of the Export Control Reform Act of 2018, export of dual use goods and services was regulated pursuant to the authority of the Export Administration Act (EAA), which was subject to periodic expiry and reauthorization. President Reagan was the first President to use IEEPA as a vehicle for continuing the enforcement of the EAA's export controls. After Congress did not extend the expired EAA, President Reagan issued Executive Order 12444 in 1983, finding that "unrestricted access of foreign parties to United States commercial goods, technology, and technical data and the existence of certain boycott practices of foreign nations constitute, in light of the expiration of the Export Administration Act of 1979, an unusual and extraordinary threat to the national security." Although the EAA had been reauthorized for short periods since its initial expiration in 1983, every subsequent President utilized the authorities granted under IEEPA to maintain the existing system of export controls during periods of lapse. Figure 1 . In the latest iteration, President George W. Bush issued Executive Order 13222 in 2001, finding the existence of a national emergency with respect to the expiration of the EAA and directing—pursuant to the authorities allocated under IEEPA—that "the provisions for administration of the [EAA] shall be carried out under this order so as to continue in full force and effect…the export control system heretofore maintained." Presidents Obama and Trump annually extended the 2001 executive order. Courts have generally treated this arrangement as authorized by Congress, although certain provisions of the EAA in effect under IEEPA have led to challenges. The determining factor appears to be whether IEEPA itself provides the President the authority to carry out the challenged action. In one case, the U.S. Court of Appeals for the Fifth Circuit upheld a conviction for an attempt to violate the regulations even though the EAA had expired and did not expressly criminalize such attempts. The circuit court rejected the defendants' argument that the President had exceeded his delegated authority under the EEA by "enlarging" the crimes punishable under the regulations. Nevertheless, a district court held that the conspiracy provisions of the EAA regulations were rendered inoperative by the lapse of the EAA and "could not be repromulgated by executive order under the general powers that IEEPA vests in the President." The district court found that, even if Congress intended to preserve the operation of the EAA through IEEPA, that intent was limited by the scope of the statutes' substantive coverage at the time of IEEPA's enactment, when no conspiracy provision existed in either statute. The U.S. Court of Appeals for the D.C. Circuit upheld the application of the EAA as a statute permitting the government to withhold information under exemption 3 of the Freedom of Information Act (FOIA), which exempts from disclosure information exempted from disclosure by statute, even though the EAA had expired. Referring to legislative history it interpreted as congressional approval of the use of IEEPA to continue the EAA provisions during periods of lapse, the court stated: Although the legislative history does not refer to the EAA's confidentiality provision, it does evince Congress's intent to authorize the President to preserve the operation of the export regulations promulgated under the EAA. Moreover, it is significant for purposes of determining legislative intent that Congress acted with the knowledge that the EAA's export regulations had long provided for confidentiality and that the President's ongoing practice of extending the EAA by executive order had always included these confidentiality protections. The D.C. Circuit distinguished this holding in a later case involving appellate jurisdiction over a decision by the Department of Commerce to apply sanctions for a company's violation of the EAA regulations. Pursuant to the regulations and under the direction of the Commerce Department, the company sought judicial review directly in the D.C. Circuit. The D.C. Circuit, however, concluded that it lacked jurisdiction: This court would have jurisdiction pursuant to the President's order only if the President has the authority to confer jurisdiction—an authority that, if it exists, must derive from either the Executive's inherent power under the Constitution or a permissible delegation of power from Congress. The former is unavailing, as the Constitution vests the power to confer jurisdiction in Congress alone. Whether the executive order can provide the basis of our jurisdiction, then, turns on whether the President can confer jurisdiction on this court under the auspices of IEEPA…..We conclude that the President lacks that power. Nothing in the text of IEEPA delegates to the President the authority to grant jurisdiction to any federal court. Consequently, the appeal of the agency decision was determined to belong in the district court according to the default rule under the Administrative Procedure Act (APA). Congress may wish to address a number of issues with respect to IEEPA; two are addressed here. The first pertains to how Congress has delegated its authority under IEEPA and its umbrella statute, the NEA. The second pertains to choices made in the Export Control Reform Act of 2018. Although the stated aim of the drafters of the NEA and IEEPA was to restrain the use of emergency powers, the use of such powers has expanded by several measures. Presidents declare national emergencies and renew them for years or even decades. The limitation of IEEPA to transactions involving some foreign interest was intended to limit IEEPA's domestic application. However, globalization has eroded that limit, as few transactions today do not involve some foreign interest. Many of the other criticisms of TWEA that IEEPA was supposed to address—consultation, time limits, congressional review, scope of power, and logical relationship to the emergency declared—are criticisms that scholars levy against IEEPA today. In general, three common criticisms are levied by scholars with respect to the structure of the NEA and IEEPA that may be of interest to Congress. First, the NEA and IEEPA do not define the phrases "national emergency" and "unusual and extraordinary threat" and Presidents have interpreted these terms broadly. Second, the scope of presidential authority under IEEPA has become less constrained in a highly globalized era. Third, owing to rulings by the Supreme Court and amendments to the NEA, Congress would likely have to have a two-thirds majority rather than a simple majority to terminate a national emergency. Despite these criticisms, Congress has not acted to terminate or otherwise express displeasure with an emergency declaration invoking IEEPA. This absence of any explicit statement of disapproval, coupled with explicit statements of approval in some instances, may indicate congressional approval of presidential use of IEEPA thus far. Arguably, then, IEEPA could be seen as an effective tool for carrying out the will of Congress. Neither the NEA nor IEEPA define what constitutes a "national emergency." IEEPA conditions its invocation in a declaration on its necessity for dealing with an "unusual and extraordinary threat … to the national security, foreign policy, or economy of the United States." In the markup of IEEPA in the House, Fred Bergsten, then-Assistant Secretary for International Affairs in the Department of the Treasury, praised the requirement that a national emergency for the purposes of IEEPA be "based on an unusual and extraordinary threat" because such language "emphasizes that such powers should be available only in true emergencies." Because "unusual" and "extraordinary" are also undefined, the usual and ordinary invocation of the statute seems to conflict with those statutory conditions. If Congress wanted to refine the meaning of "national emergency" or "unusual and extraordinary threat," it could do so through statute. Additionally, Congress could consider requiring some sort of factual finding by a court prior to, or shortly after, the exercise of any authority, such as under the First Militia Act of 1792 or the Foreign Intelligence Surveillance Act. However, Congress may consider that the ambiguity in the existing statute provides the executive with the flexibility necessary to address national emergencies with the requisite dispatch. While IEEPA nominally applies only to foreign transactions, the breadth of the phrase, "any interest of any foreign country or a national thereof" has left a great deal of room for executive discretion. The interconnectedness of the modern global economy has left few major transactions in which a foreign interest is not involved. As a result, at least one scholar has concluded, "the exemption of purely domestic transactions from the President's transaction controls seems to be a limitation without substance." Presidents have used IEEPA since the 1980s to control exports by maintaining the dual-use export control system, enshrined in the Export Administration Regulations (EAR) in times when its underlying authorization, the Export Administration Act (EAA), periodically expired. During those times when Congress did not reauthorize the EAA, Presidents have declared emergencies to maintain the dual-use export control system. The current emergency has been ongoing since 2001. While Presidents have used IEEPA to implement trade restrictions against adversaries, it has not been used as a general way to impose tariffs. However, as noted above, President Nixon used TWEA to impose a 10% ad valorem tariff on goods entering the United States to avoid a balance of payments crisis after he ended the convertibility of the U.S. dollar to gold. Although the use of TWEA in this instance was criticized at the time, it does not appear that the subsequent reforms resulting in the enactment of IEEPA would prevent the President from imposing tariffs or other restrictions on trade. However, the availability of diverse other authorities for addressing trade, including for national security purposes, makes the use of IEEPA for this purpose unlikely. The scope of powers over individual targets is also extensive. Under IEEPA, the President has the power to prohibit all financial transactions with individuals designated by Executive Order. Such power allows the President to block all the assets of a U.S. citizen or permanent resident. Such uses of IEEPA may reflect the will of Congress or they may represent a grant of authority that may have gone beyond what Congress originally intended. The heart of the curtailment of presidential power by the NEA and IEEPA was the provision that Congress could terminate a state of emergency declared pursuant to the NEA with a concurrent resolution. When the "legislative veto" was struck down by the Supreme Court (see above), it left Congress with a steeper climb—presumably requiring passage of a veto-proof joint resolution—to terminate a national emergency declared under the NEA. Two such resolutions have ever been introduced and neither declarations of emergency involved IEEPA. The lack of congressional action here could be the result of the necessity of obtaining a veto-proof majority or it could be that the use of IEEPA has so far reflected the will of Congress. If Congress wanted to assert more authority over the use of IEEPA, it could amend the NEA or IEEPA to include a "sunset provision," terminating any national emergency after a certain number of days. At least one scholar has recommended such an amendment. Alternatively, Congress could amend IEEPA to provide for a review mechanism that would give Congress an active role. In the Senate during the 115 th Congress, for example, Senator Mike Lee introduced the Global Trade Accountability Act of 2017 required the President to report to Congress on any proposed trade action (including the use of IEEPA), including a description of the proposal together with a list of items to be affected, an economic impact study of the proposal including potential retaliation. Congress, using expedited procedures, would need to approve the President's action through a joint resolution within a 60-day period. The legislation would have provided for a temporary one-time unilateral trade action for a 90-day period. Similarly, in the 116 th Congress, Senator Lee introduced S. 764 , a bill to provide for congressional approval of national emergency declarations, and for other purposes, which would amend the NEA to require an act of Congress within 30 days to allow a national emergency to continue. Another approach would establish a means for Congress to pass a resolution of disapproval if IEEPA authorities are invoked. An example of this approach is the Trade Authority Protection Act (H.R. 5760). After the submission of similar reporting requirement to S. 177 (above), Congress could, under Congressional Review Act (CRA)-style procedures, pass a joint resolution of disapproval. Congress does have the authority to pass a joint resolution under IEEPA, as noted above, but the use of CRA procedures would allow for certain expedited consideration. Alternatively, Congress could use any of these mechanisms to amend the current disapproval resolution process in IEEPA or the NEA itself. In testimony before the House Committee on International Relations in 1977, Professor Harold G. Maier summed up the main criticisms of TWEA: Section 5(b)'s effect is no longer confined to "emergency situations" in the sense of existing imminent danger. The continuing retroactive approval, either explicit or implicit, by Congress of broad executive interpretations of the scope of powers which it confers has converted the section into a general grant of legislative authority to the President…" Like TWEA before it, IEEPA sits at the center of the modern U.S. sanction regime. Like TWEA before it, Congress has often approved explicitly of the President's use of IEEPA. In several circumstances, Congress has directed the President to impose a variety of sanctions under IEEPA and waived the requirement of an emergency declaration. Even when Congress has not given explicit approval, no Member of Congress has ever introduced a resolution to terminate a national emergency citing IEEPA. The NEA requires that both houses of Congress meet every six months to consider a vote on a joint resolution on terminating an emergency. Neither house has ever met to do so. In response to concerns over the scale and scope of the emergency economic powers granted by IEEPA, supporters of the status quo would argue that Congress has implicitly and explicitly expressed approval of the statute and its use. In 2018, Congress passed the Export Control Reform Act (ECRA). The legislation repealed the expired Export Administration Act of 1979, the regulations of which had been continued by reference to IEEPA since 2001. The ECRA became the new statutory authority for Export Administration Regulations. Nevertheless, several export controls addressed in the Export Administration Act of 1979 were not updated in the Export Control Reform Act of 2018; instead, Congress chose to require the President to continue to use IEEPA to continue to implement the three sections of the Export Administration Act of 1979 that were not repealed. Going forward, Congress may wish to revisit these provisions, which all relate to deterring the proliferation of weapons of mass destruction. Appendix A. NEA and IEEPA Use